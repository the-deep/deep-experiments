{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n\\n!pip install s3fs\\n!pip install smdebug'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from typing import Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = True \n",
    "\n",
    "if sample:\n",
    "    data_file = 'data/sample_data.json'# sample data\n",
    "else:\n",
    "    data_file = ... #full data\n",
    "\n",
    "with open(data_file, 'r') as openfile:\n",
    "    data = json.load(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_dict(data: Dict):\n",
    "\n",
    "    str_data = {k: str(v) for k, v in data.items()}\n",
    "\n",
    "    keys = list(str_data.keys())\n",
    "    vals = list(str_data.values()) \n",
    "\n",
    "    df_data = pd.DataFrame(\n",
    "        list(zip(keys, vals)),\n",
    "        columns =['col_name', 'vals']\n",
    "    )\n",
    "\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'val', 'test', 'tagname_to_id'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### send data to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = f\"pytorch-{formatted_time()}-entry-extraction\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "data_path = str(input_path / 'data.pickle') # keep it as it is\n",
    "\n",
    "# send data to s3 bucket\n",
    "# need too check protocol, depending on data type (protocol 4 was made for pandas data inputs)\n",
    "\n",
    "data_df = get_df_from_dict(data)\n",
    "data_df.to_pickle(data_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]\n",
    "\n",
    "# CPU instances\n",
    "instances = [\n",
    "    'ml.c4.2xlarge',\n",
    "    'ml.c4.4xlarge',\n",
    "    'ml.c5n.2xlarge'\n",
    "]\n",
    "\n",
    "# https://aws.amazon.com/sagemaker/pricing/instance-types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "experiment_name = \"entry_extraction\"\n",
    "run_name = experiment_name  \n",
    "\n",
    "hyperparameters = {\n",
    "    \"instance_type\": instance_type,\n",
    "    \"tracking_uri\": MLFLOW_SERVER,\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"run_name\": run_name,\n",
    "    \"model_name_or_path\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
    "    \"tokenizer_name_or_path\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"n_epochs\": 1 if sample else 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"dataloader_num_workers\": 6,\n",
    "    \"val_batch_size\": 32,\n",
    "    \"train_batch_size\": 16,\n",
    "    \"max_len\": 512,\n",
    "    \"extra_context_length\": 64,\n",
    "    \"dropout\": 0.2\n",
    "    #\"n_separate_layers\": 1,\n",
    "    #\"per_device_train_batch_size\": 1,\n",
    "    #\"per_device_eval_batch_size\": 1,\n",
    "    #\"gradient_accumulation_steps\": 8,\n",
    "    #\"save_strategy\": \"epoch\",\n",
    "    #\"adam_beta1\": 0.9,\n",
    "    #\"adam_beta2\": 0.98,\n",
    "    #\"adam_epsilon\": 1e-6,\n",
    "    #\"warmup_ratio\": 0.3,\n",
    "    #\"fp16\": true,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=str(\n",
    "        \"scripts\"\n",
    "    ),\n",
    "    output_path=str(DEV_BUCKET / \"models/\"),\n",
    "    code_location=str(input_path),\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    job_name=job_name,\n",
    "    debugger_hook_config=False\n",
    "    #     train_instance_count=2,\n",
    "    #     train_instance_type=\"ml.c4.xlarge\",\n",
    ")\n",
    "\n",
    "fit_arguments = {\"train\": str(input_path)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-04 10:29:19 Starting - Starting the training job...\n",
      "2022-10-04 10:29:46 Starting - Preparing the instances for trainingProfilerReport-1664879356: InProgress\n",
      ".........\n",
      "2022-10-04 10:31:24 Downloading - Downloading input data...\n",
      "2022-10-04 10:32:04 Training - Downloading the training image..............................\n",
      "2022-10-04 10:37:25 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-04 10:37:30,089 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-04 10:37:30,125 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-04 10:37:30,135 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-04 10:37:30,879 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.8.2\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.4.1\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.8\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm==4.41.1\n",
      "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.19.0\n",
      "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.49.1\n",
      "  Downloading sagemaker-2.49.1.tar.gz (421 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3fs==2021.07.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mCollecting smdebug==1.0.11\n",
      "  Downloading smdebug-1.0.11-py2.py3-none-any.whl (269 kB)\u001b[0m\n",
      "\u001b[34mCollecting pytest==7.0\n",
      "  Downloading pytest-7.0.0-py3-none-any.whl (296 kB)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (4.8.3)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.9.13-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (756 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (2.26.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3.1 in /opt/conda/lib/python3.6/site-packages (from torchmetrics==0.4.1->-r requirements.txt (line 2)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (8.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.20.3-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.41-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (8.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (3.19.1)\u001b[0m\n",
      "\u001b[34mCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (0.3)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from mlflow==1.19.0->-r requirements.txt (line 5)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 6)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 6)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.16.32 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (1.20.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 7)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiobotocore>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from s3fs==2021.07.0->-r requirements.txt (line 8)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug==1.0.11->-r requirements.txt (line 9)) (3.4.2)\u001b[0m\n",
      "\u001b[34mCollecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting tomli>=1.0.0\n",
      "  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from huggingface-hub==0.0.12->transformers==4.8.2->-r requirements.txt (line 1)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp>=3.3.1 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.23.25,>=1.23.24 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.23.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wrapt>=1.10.10 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.13.3)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow==1.19.0->-r requirements.txt (line 5)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 7)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 7)) (0.5.0)\u001b[0m\n",
      "\u001b[34mCollecting pyjwt>=1.7.0\n",
      "  Downloading PyJWT-2.4.0-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.1.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.19.0->-r requirements.txt (line 5)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.19.0->-r requirements.txt (line 5)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=4.0.0->mlflow==1.19.0->-r requirements.txt (line 5)) (1.2.3)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.8.2->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 1)) (3.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug==1.0.11->-r requirements.txt (line 9)) (0.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy->mlflow==1.19.0->-r requirements.txt (line 5)) (1.1.2)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (58.0.4)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.19.0->-r requirements.txt (line 5)) (3.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.19.0->-r requirements.txt (line 5)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 7)) (1.6.6.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 7)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 7)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 7)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from prometheus-flask-exporter->mlflow==1.19.0->-r requirements.txt (line 5)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (0.13.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna-ssl>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 8)) (1.2.0)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=3.0->Flask->mlflow==1.19.0->-r requirements.txt (line 5)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.4.8)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, alembic, databricks-cli, sacremoses\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.49.1-py2.py3-none-any.whl size=591938 sha256=36646330666babab21bdff5c463fb92dd3c1ed4c437f4b598555f784c77093a4\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/af/ea/8ff5943a87155df5b184e54474fbf2b59b75e5c172854643c6\n",
      "  Building wheel for alembic (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=0a132cbcc52b3f323af7516a39b63a88574f1a0f692a15732ed0c4aa9a02d661\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
      "  Building wheel for databricks-cli (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=614493a2d4e5a9bace5c8c41ffb032d32974161d39ae74f27fdc5e3f2b135249\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/04/45/0f84000ef6c124a8abcdf9924a4aeb30939680b09dcb4c56d3\n",
      "  Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=9add32d879c718f3c355746f60a9566922b278b436b1ecfb46a5b2431088fae7\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker alembic databricks-cli sacremoses\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, smmap, requests-oauthlib, google-auth, tqdm, tensorboard-plugin-wit, tensorboard-data-server, sqlalchemy, regex, python-editor, pyjwt, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, absl-py, torchmetrics, tomli, tokenizers, tensorboard, sqlparse, sacremoses, querystring-parser, pyDeprecate, py, prometheus-flask-exporter, pluggy, iniconfig, huggingface-hub, gunicorn, gitpython, docker, databricks-cli, alembic, transformers, smdebug, scikit-learn, sagemaker, pytorch-lightning, pytest, mlflow\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.9\n",
      "    Uninstalling smdebug-1.0.9:\n",
      "      Successfully uninstalled smdebug-1.0.9\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\u001b[0m\n",
      "\u001b[34m    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.72.0\n",
      "    Uninstalling sagemaker-2.72.0:\n",
      "      Successfully uninstalled sagemaker-2.72.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.1.6 absl-py-1.2.0 alembic-1.4.1 cachetools-4.2.4 databricks-cli-0.17.3 docker-5.0.3 gitdb-4.0.9 gitpython-3.1.18 google-auth-2.12.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 gunicorn-20.1.0 huggingface-hub-0.0.12 iniconfig-1.1.1 markdown-3.3.7 mlflow-1.19.0 oauthlib-3.2.1 pluggy-1.0.0 prometheus-flask-exporter-0.20.3 py-1.11.0 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 pyjwt-2.4.0 pytest-7.0.0 python-editor-1.0.4 pytorch-lightning-1.3.8 querystring-parser-1.2.4 regex-2022.9.13 requests-oauthlib-1.3.1 sacremoses-0.0.53 sagemaker-2.49.1 scikit-learn-0.22.2.post1 smdebug-1.0.11 smmap-5.0.0 sqlalchemy-1.4.41 sqlparse-0.4.3 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 tomli-1.2.3 torchmetrics-0.4.1 tqdm-4.41.1 transformers-4.8.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-10-04 10:38:06,060 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataloader_num_workers\": 6,\n",
      "        \"dropout\": 0.2,\n",
      "        \"experiment_name\": \"entry_extraction\",\n",
      "        \"extra_context_length\": 64,\n",
      "        \"instance_type\": \"ml.p2.xlarge\",\n",
      "        \"learning_rate\": 0.0001,\n",
      "        \"max_len\": 512,\n",
      "        \"model_name_or_path\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"n_epochs\": 1,\n",
      "        \"run_name\": \"entry_extraction\",\n",
      "        \"tokenizer_name_or_path\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\n",
      "        \"train_batch_size\": 16,\n",
      "        \"val_batch_size\": 32,\n",
      "        \"weight_decay\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2022-10-04-13-29-10-040-entry-extraction\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-10-04-13-29-10-040-entry-extraction/pytorch-2022-10-04-13-29-10-040-entry-extraction/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p2.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p2.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dataloader_num_workers\":6,\"dropout\":0.2,\"experiment_name\":\"entry_extraction\",\"extra_context_length\":64,\"instance_type\":\"ml.p2.xlarge\",\"learning_rate\":0.0001,\"max_len\":512,\"model_name_or_path\":\"microsoft/xtremedistil-l6-h384-uncased\",\"n_epochs\":1,\"run_name\":\"entry_extraction\",\"tokenizer_name_or_path\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_batch_size\":16,\"val_batch_size\":32,\"weight_decay\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-10-04-13-29-10-040-entry-extraction/pytorch-2022-10-04-13-29-10-040-entry-extraction/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataloader_num_workers\":6,\"dropout\":0.2,\"experiment_name\":\"entry_extraction\",\"extra_context_length\":64,\"instance_type\":\"ml.p2.xlarge\",\"learning_rate\":0.0001,\"max_len\":512,\"model_name_or_path\":\"microsoft/xtremedistil-l6-h384-uncased\",\"n_epochs\":1,\"run_name\":\"entry_extraction\",\"tokenizer_name_or_path\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_batch_size\":16,\"val_batch_size\":32,\"weight_decay\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2022-10-04-13-29-10-040-entry-extraction\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-10-04-13-29-10-040-entry-extraction/pytorch-2022-10-04-13-29-10-040-entry-extraction/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p2.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p2.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dataloader_num_workers\",\"6\",\"--dropout\",\"0.2\",\"--experiment_name\",\"entry_extraction\",\"--extra_context_length\",\"64\",\"--instance_type\",\"ml.p2.xlarge\",\"--learning_rate\",\"0.0001\",\"--max_len\",\"512\",\"--model_name_or_path\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--n_epochs\",\"1\",\"--run_name\",\"entry_extraction\",\"--tokenizer_name_or_path\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"--train_batch_size\",\"16\",\"--val_batch_size\",\"32\",\"--weight_decay\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DATALOADER_NUM_WORKERS=6\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=entry_extraction\u001b[0m\n",
      "\u001b[34mSM_HP_EXTRA_CONTEXT_LENGTH=64\u001b[0m\n",
      "\u001b[34mSM_HP_INSTANCE_TYPE=ml.p2.xlarge\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0001\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME_OR_PATH=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_RUN_NAME=entry_extraction\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER_NAME_OR_PATH=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_BATCH_SIZE=32\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --dataloader_num_workers 6 --dropout 0.2 --experiment_name entry_extraction --extra_context_length 64 --instance_type ml.p2.xlarge --learning_rate 0.0001 --max_len 512 --model_name_or_path microsoft/xtremedistil-l6-h384-uncased --n_epochs 1 --run_name entry_extraction --tokenizer_name_or_path microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_batch_size 16 --val_batch_size 32 --weight_decay 0.01\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/1 [00:00<?, ?it/s][2022-10-04 10:38:45.843 algo-1:56 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-10-04 10:38:45.914 algo-1:56 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34mINFO:root:building training and testing datasets\u001b[0m\n",
      "\u001b[34mINFO:root:training model\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/526 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 526/526 [00:00<00:00, 448kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]#015Downloading:   5%|▍         | 4.28M/90.9M [00:00<00:02, 42.8MB/s]#015Downloading:   9%|▉         | 8.32M/90.9M [00:00<00:01, 42.0MB/s]#015Downloading:  14%|█▍        | 12.6M/90.9M [00:00<00:01, 42.3MB/s]#015Downloading:  17%|█▋        | 15.8M/90.9M [00:00<00:01, 38.6MB/s]#015Downloading:  22%|██▏       | 20.1M/90.9M [00:00<00:01, 39.7MB/s]#015Downloading:  27%|██▋       | 24.4M/90.9M [00:00<00:01, 40.7MB/s]#015Downloading:  31%|███       | 28.0M/90.9M [00:00<00:01, 38.9MB/s]#015Downloading:  35%|███▍      | 31.6M/90.9M [00:00<00:01, 35.9MB/s]#015Downloading:  39%|███▉      | 35.6M/90.9M [00:00<00:01, 37.1MB/s]#015Downloading:  44%|████▍     | 39.9M/90.9M [00:01<00:01, 38.7MB/s]#015Downloading:  48%|████▊     | 44.0M/90.9M [00:01<00:01, 39.3MB/s]#015Downloading:  53%|█████▎    | 48.3M/90.9M [00:01<00:01, 40.6MB/s]#015Downloading:  58%|█████▊    | 52.7M/90.9M [00:01<00:00, 41.5MB/s]#015Downloading:  63%|██████▎   | 57.2M/90.9M [00:01<00:00, 42.3MB/s]#015Downloading:  68%|██████▊   | 61.5M/90.9M [00:01<00:00, 42.7MB/s]#015Downloading:  72%|███████▏  | 65.8M/90.9M [00:01<00:00, 41.1MB/s]#015Downloading:  77%|███████▋  | 69.9M/90.9M [00:01<00:00, 39.4MB/s]#015Downloading:  82%|████████▏ | 74.4M/90.9M [00:01<00:00, 40.8MB/s]#015Downloading:  86%|████████▋ | 78.5M/90.9M [00:01<00:00, 40.2MB/s]#015Downloading:  91%|█████████ | 82.9M/90.9M [00:02<00:00, 41.3MB/s]#015Downloading:  96%|█████████▌| 87.0M/90.9M [00:02<00:00, 41.1MB/s]#015Downloading: 100%|██████████| 90.9M/90.9M [00:02<00:00, 40.4MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 37.9MB/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py:479: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "  | Name                   | Type           | Params\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------\u001b[0m\n",
      "\u001b[34m0 | entry_extraction_model | EntryExtractor | 65.3 M\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------\u001b[0m\n",
      "\u001b[34m51.6 M    Trainable params\u001b[0m\n",
      "\u001b[34m13.7 M    Non-trainable params\u001b[0m\n",
      "\u001b[34m65.3 M    Total params\u001b[0m\n",
      "\u001b[34m261.201   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 192, in <module>\n",
      "    trainer.fit(training_model, training_loader, val_loader)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 492, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 242, in patch_with_managed_run\n",
      "    result = patch_function(original, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/pytorch/_pytorch_autolog.py\", line 316, in fit\n",
      "    return _run_and_log_function(self, original, args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/pytorch/_pytorch_autolog.py\", line 308, in _run_and_log_function\n",
      "    result = original(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 448, in call_original\n",
      "    original_result = original(*og_args, **og_kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 758, in _run\n",
      "    self.dispatch()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 799, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 809, in run_stage\n",
      "    return self.run_train()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 844, in run_train\n",
      "    self.run_sanity_check(self.lightning_module)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in run_sanity_check\n",
      "    self.run_evaluation()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 954, in run_evaluation\n",
      "    for batch_idx, batch in enumerate(dataloader):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 525, in __next__\n",
      "    (data, worker_id) = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1273, in _next_data\n",
      "    return (self._process_data(data), w_id)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1299, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/_utils.py\", line 429, in reraise\n",
      "    raise self.exc_type(msg)\u001b[0m\n",
      "\u001b[34mRuntimeError: Caught RuntimeError in DataLoader worker process 0.\u001b[0m\n",
      "\u001b[34mOriginal Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 210, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\u001b[0m\n",
      "\u001b[34mRuntimeError: result type Float can't be cast to the desired output type Long\u001b[0m\n",
      "\u001b[34m2022-10-04 10:38:48,014 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.6 train.py --dataloader_num_workers 6 --dropout 0.2 --experiment_name entry_extraction --extra_context_length 64 --instance_type ml.p2.xlarge --learning_rate 0.0001 --max_len 512 --model_name_or_path microsoft/xtremedistil-l6-h384-uncased --n_epochs 1 --run_name entry_extraction --tokenizer_name_or_path microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_batch_size 16 --val_batch_size 32 --weight_decay 0.01\"\u001b[0m\n",
      "\u001b[34mINFO:root:building training and testing datasets\u001b[0m\n",
      "\u001b[34mINFO:root:training model\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/526 [00:00<?, ?B/s]#015Downloading: 100%|ââââââââââ| 526/526 [00:00<00:00, 448kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]#015Downloading:   5%|â         | 4.28M/90.9M [00:00<00:02, 42.8MB/s]#015Downloading:   9%|â         | 8.32M/90.9M [00:00<00:01, 42.0MB/s]#015Downloading:  14%|ââ        | 12.6M/90.9M [00:00<00:01, 42.3MB/s]#015Downloading:  17%|ââ        | 15.8M/90.9M [00:00<00:01, 38.6MB/s]#015Downloading:  22%|âââ       | 20.1M/90.9M [00:00<00:01, 39.7MB/s]#015Downloading:  27%|âââ       | 24.4M/90.9M [00:00<00:01, 40.7MB/s]#015Downloading:  31%|âââ       | 28.0M/90.9M [00:00<00:01, 38.9MB/s]#015Downloading:  35%|ââââ      | 31.6M/90.9M [00:00<00:01, 35.9MB/s]#015Downloading:  39%|ââââ      | 35.6M/90.9M [00:00<00:01, 37.1MB/s]#015Downloading:  44%|âââââ     | 39.9M/90.9M [00:01<00:01, 38.7MB/s]#015Downloading:  48%|âââââ     | 44.0M/90.9M [00:01<00:01, 39.3MB/s]#015Downloading:  53%|ââââââ    | 48.3M/90.9M [00:01<00:01, 40.6MB/s]#015Downloading:  58%|ââââââ    | 52.7M/90.9M [00:01<00:00, 41.5MB/s]#015Downloading:  63%|âââââââ   | 57.2M/90.9M [00:01<00:00, 42.3MB/s]#015Downloading:  68%|âââââââ   | 61.5M/90.9M [00:01<00:00, 42.7MB/s]#015Downloading:  72%|ââââââââ  | 65.8M/90.9M [00:01<00:00, 41.1MB/s]#015Downloading:  77%|ââââââââ  | 69.9M/90.9M [00:01<00:00, 39.4MB/s]#015Downloading:  82%|âââââââââ | 74.4M/90.9M [00:01<00:00, 40.8MB/s]#015Downloading:  86%|âââââââââ | 78.5M/90.9M [00:01<00:00, 40.2MB/s]#015Downloading:  91%|âââââââââ | 82.9M/90.9M [00:02<00:00, 41.3MB/s]#015Downloading:  96%|ââââââââââ| 87.0M/90.9M [00:02<00:00, 41.1MB/s]#015Downloading: 100%|ââââââââââ| 90.9M/90.9M [00:02<00:00, 40.4MB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|ââââââââââ| 232k/232k [00:00<00:00, 37.9MB/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py:479: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "  | Name                   | Type           | Params\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------\u001b[0m\n",
      "\u001b[34m0 | entry_extraction_model | EntryExtractor | 65.3 M\u001b[0m\n",
      "\u001b[34m----------------------------------------------------------\u001b[0m\n",
      "\u001b[34m51.6 M    Trainable params\u001b[0m\n",
      "\u001b[34m13.7 M    Non-trainable params\u001b[0m\n",
      "\u001b[34m65.3 M    Total params\u001b[0m\n",
      "\u001b[34m261.201   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"train.py\", line 192, in <module>\n",
      "    trainer.fit(training_model, training_loader, val_loader)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 492, in safe_patch_function\n",
      "    patch_function(call_original, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 242, in patch_with_managed_run\n",
      "    result = patch_function(original, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/pytorch/_pytorch_autolog.py\", line 316, in fit\n",
      "    return _run_and_log_function(self, original, args, kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/pytorch/_pytorch_autolog.py\", line 308, in _run_and_log_function\n",
      "    result = original(self, *args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/mlflow/utils/autologging_utils/safety.py\", line 448, in call_original\n",
      "    original_result = original(*og_args, **og_kwargs)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 460, in fit\n",
      "    self._run(model)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 758, in _run\n",
      "    self.dispatch()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 799, in dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 96, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 144, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 809, in run_stage\n",
      "    return self.run_train()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 844, in run_train\n",
      "    self.run_sanity_check(self.lightning_module)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in run_sanity_check\n",
      "    self.run_evaluation()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 954, in run_evaluation\n",
      "    for batch_idx, batch in enumerate(dataloader):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 525, in __next__\n",
      "    (data, worker_id) = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1273, in _next_data\n",
      "    return (self._process_data(data), w_id)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1299, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/_utils.py\", line 429, in reraise\n",
      "    raise self.exc_type(msg)\u001b[0m\n",
      "\u001b[34mRuntimeError: Caught RuntimeError in DataLoader worker process 0.\u001b[0m\n",
      "\u001b[34mOriginal Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 210, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in default_collate\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 73, in <dictcomp>\n",
      "    return {key: default_collate([d[key] for d in batch]) for key in elem}\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 55, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\u001b[0m\n",
      "\u001b[34mRuntimeError: result type Float can't be cast to the desired output type Long\u001b[0m\n",
      "\n",
      "2022-10-04 10:39:26 Uploading - Uploading generated training model\n",
      "2022-10-04 10:39:26 Failed - Training job failed\n",
      "ProfilerReport-1664879356: NoIssuesFound\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job pytorch-2022-10-04-13-29-10-040-entry-extraction: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 train.py --dataloader_num_workers 6 --dropout 0.2 --experiment_name entry_extraction --extra_context_length 64 --instance_type ml.p2.xlarge --learning_rate 0.0001 --max_len 512 --model_name_or_path microsoft/xtremedistil-l6-h384-uncased --n_epochs 1 --run_name entry_extraction --tokenizer_name_or_path microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_batch_size 16 --val_batch_size 32 --weight_decay 0.01\"\nINFO:root:building training and testing datasets\nINFO:root:training model\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\n\rDownloading:   0%|          | 0.00/526 [00:00<?, ?B/s]\rDownloading: 100%|ââââââââââ| 526/526 [00:00<00:00, 448kB/s]\n\rDownloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]\rDownloading:   5%|â         | 4.28M/90.9M [00:00<00:02, 42.8MB/s]\rDownloading:   9%|â         | , exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-004139172237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_arguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3681\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3683\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3238\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FailureReason\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(No reason provided)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3239\u001b[0m             \u001b[0mjob_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus_key_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"JobStatus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3240\u001b[0;31m             raise exceptions.UnexpectedStatusException(\n\u001b[0m\u001b[1;32m   3241\u001b[0m                 message=\"Error for {job_type} {job_name}: {status}. Reason: {reason}\".format(\n\u001b[1;32m   3242\u001b[0m                     \u001b[0mjob_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job pytorch-2022-10-04-13-29-10-040-entry-extraction: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/opt/conda/bin/python3.6 train.py --dataloader_num_workers 6 --dropout 0.2 --experiment_name entry_extraction --extra_context_length 64 --instance_type ml.p2.xlarge --learning_rate 0.0001 --max_len 512 --model_name_or_path microsoft/xtremedistil-l6-h384-uncased --n_epochs 1 --run_name entry_extraction --tokenizer_name_or_path microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_batch_size 16 --val_batch_size 32 --weight_decay 0.01\"\nINFO:root:building training and testing datasets\nINFO:root:training model\nGPU available: True, used: True\nTPU available: False, using: 0 TPU cores\n\rDownloading:   0%|          | 0.00/526 [00:00<?, ?B/s]\rDownloading: 100%|ââââââââââ| 526/526 [00:00<00:00, 448kB/s]\n\rDownloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]\rDownloading:   5%|â         | 4.28M/90.9M [00:00<00:02, 42.8MB/s]\rDownloading:   9%|â         | , exit code: 1"
     ]
    }
   ],
   "source": [
    "# Fit the estimator\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
