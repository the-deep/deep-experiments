{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6b06090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:51.778527Z",
     "start_time": "2021-12-09T11:45:51.024103Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import functools\n",
    "from ast import literal_eval\n",
    "from operator import itemgetter\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from collections.abc import Sequence\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from num2words import num2words\n",
    "                                                                \n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2452aca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:51.781862Z",
     "start_time": "2021-12-09T11:45:51.779570Z"
    }
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4d7f07f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:51.787885Z",
     "start_time": "2021-12-09T11:45:51.783199Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    if doc != doc:\n",
    "        return \"\"\n",
    "    doc = doc.lower()\n",
    "    # remove preceeding dates\n",
    "    #doc = re.sub(\"^\\[.+\\]\", \" \", doc).strip()\n",
    "    #doc = re.sub(\"^\\(.+\\)\", \" \", doc).strip()\n",
    "    # spaces btw numbers and words\n",
    "    doc = re.sub('(\\d+(\\W\\d+)?)', r' \\1 ', doc).strip()\n",
    "    doc = re.sub(\"[‐‑–—―─_]\", \"-\", doc)\n",
    "    doc = re.sub(\"(\\w)\\- (\\w)\", r\"\\1\\2\", doc)\n",
    "    doc = re.sub(\n",
    "        \"[\" + re.escape(\n",
    "            '_@^~.()[],\"“’…<❖‐»—─|•&{≥➢\\ue0e4\\uf0d8\\uf0fc●°#\\u200b>`?�€■!‘%;̧\\'›«”:≤―\\uf0b7$}*´=‑▪\\xad❑·–'\n",
    "        ) + \"]\", \" \", doc)\n",
    "    #remove some puncs\n",
    "    doc = re.sub('\\s+', \" \", doc).strip()\n",
    "    return doc\n",
    "##\n",
    "def preprocess_and_tokenize(doc, n=1):\n",
    "    doc = preprocess(doc)\n",
    "    # tokenize\n",
    "    words = word_tokenize(doc)\n",
    "    if n == 1:\n",
    "        return set(words)\n",
    "    return set(ngrams(words, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d4f0c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:53.943779Z",
     "start_time": "2021-12-09T11:45:51.789379Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/train_v0.7.1.csv\",\n",
    "                       usecols=[\n",
    "                           'entry_id', 'excerpt', 'age', 'lang',\n",
    "                           \"translation_en\", \"translation_fr\", \"translation_es\"\n",
    "                       ])\n",
    "df_val = pd.read_csv(\"../data/val_v0.7.1.csv\",\n",
    "                     usecols=[\n",
    "                         'entry_id', 'excerpt', 'age', 'lang',\n",
    "                         \"translation_en\", \"translation_fr\", \"translation_es\"\n",
    "                     ])\n",
    "df_test = pd.read_csv(\"../data/test_v0.7.1.csv\",\n",
    "                      usecols=[\n",
    "                          'entry_id', 'excerpt', 'age', 'lang',\n",
    "                          \"translation_en\", \"translation_fr\", \"translation_es\"\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d999dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:54.923891Z",
     "start_time": "2021-12-09T11:45:53.944910Z"
    }
   },
   "outputs": [],
   "source": [
    "col = \"age\"\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df[col] = df[col].apply(lambda x: list(sorted(list(set(literal_eval(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e727b1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.073976Z",
     "start_time": "2021-12-09T11:45:54.926633Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_en = df_train.copy()\n",
    "df_train_en.loc[df_train_en[\"lang\"].ne(\"en\"),\n",
    "                \"excerpt\"] = df_train_en.loc[df_train_en[\"lang\"].ne(\"en\"),\n",
    "                                             \"translation_en\"]\n",
    "##\n",
    "df_train_fr = df_train.copy()\n",
    "df_train_fr.loc[df_train_fr[\"lang\"].ne(\"fr\"),\n",
    "                \"excerpt\"] = df_train_fr.loc[df_train_fr[\"lang\"].ne(\"fr\"),\n",
    "                                             \"translation_fr\"]\n",
    "##\n",
    "df_train_es = df_train.copy()\n",
    "df_train_es.loc[df_train_es[\"lang\"].ne(\"es\"),\n",
    "                \"excerpt\"] = df_train_es.loc[df_train_es[\"lang\"].ne(\"es\"),\n",
    "                                             \"translation_es\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76a7b2a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.184942Z",
     "start_time": "2021-12-09T11:45:55.075318Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_en = df_train.copy()\n",
    "df_train_en = df_train_en[df_train_en[\"lang\"].eq(\"en\")]\n",
    "##\n",
    "df_train_fr = df_train.copy()\n",
    "df_train_fr = df_train_fr[df_train_fr[\"lang\"].eq(\"fr\")]\n",
    "##\n",
    "df_train_es = df_train.copy()\n",
    "df_train_es = df_train_es[df_train_es[\"lang\"].eq(\"es\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808b77dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.189295Z",
     "start_time": "2021-12-09T11:45:55.186373Z"
    }
   },
   "outputs": [],
   "source": [
    "def unique_values(df, col):\n",
    "    vals = Counter()\n",
    "    for val in df[col]:\n",
    "        vals.update(val)\n",
    "    return vals.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0f412e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.246279Z",
     "start_time": "2021-12-09T11:45:55.192010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children/Youth (5 to 17 years old)', 7629),\n",
       " ('Adult (18 to 59 years old)', 3505),\n",
       " ('Older Persons (60+ years old)', 2708),\n",
       " ('Infants/Toddlers (<5 years old)', 1497)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values(df_train_en, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7ff39e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.264109Z",
     "start_time": "2021-12-09T11:45:55.247102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children/Youth (5 to 17 years old)', 3286),\n",
       " ('Adult (18 to 59 years old)', 1798),\n",
       " ('Older Persons (60+ years old)', 864),\n",
       " ('Infants/Toddlers (<5 years old)', 750)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values(df_train_fr, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0373df6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.281643Z",
     "start_time": "2021-12-09T11:45:55.265177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children/Youth (5 to 17 years old)', 2390),\n",
       " ('Adult (18 to 59 years old)', 1710),\n",
       " ('Older Persons (60+ years old)', 614),\n",
       " ('Infants/Toddlers (<5 years old)', 544)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values(df_train_es, \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "787dd7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.284919Z",
     "start_time": "2021-12-09T11:45:55.282797Z"
    }
   },
   "outputs": [],
   "source": [
    "child = 'Children/Youth (5 to 17 years old)'\n",
    "adult = 'Adult (18 to 59 years old)'\n",
    "old = 'Older Persons (60+ years old)'\n",
    "infant = 'Infants/Toddlers (<5 years old)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588e82fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.323932Z",
     "start_time": "2021-12-09T11:45:55.286021Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_en_age = df_train_en[df_train_en['age'].apply(\n",
    "    lambda x: x != [])].copy()\n",
    "##\n",
    "df_train_en_age_infant = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: infant in x)]\n",
    "df_train_en_age_child = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: child in x)]\n",
    "df_train_en_age_adult = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: adult in x)]\n",
    "df_train_en_age_old = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: old in x)]\n",
    "##\n",
    "df_train_en_age_infant_only = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: [infant] == x)]\n",
    "df_train_en_age_child_only = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: [child] == x)]\n",
    "df_train_en_age_adult_only = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: [adult] == x)]\n",
    "df_train_en_age_old_only = df_train_en_age[df_train_en_age['age'].apply(\n",
    "    lambda x: [old] == x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef360081",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.346699Z",
     "start_time": "2021-12-09T11:45:55.325013Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_fr_age = df_train_fr[df_train_fr['age'].apply(\n",
    "    lambda x: x != [])].copy()\n",
    "##\n",
    "df_train_fr_age_infant = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: infant in x)]\n",
    "df_train_fr_age_child = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: child in x)]\n",
    "df_train_fr_age_adult = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: adult in x)]\n",
    "df_train_fr_age_old = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: old in x)]\n",
    "##\n",
    "df_train_fr_age_infant_only = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: [infant] == x)]\n",
    "df_train_fr_age_child_only = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: [child] == x)]\n",
    "df_train_fr_age_adult_only = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: [adult] == x)]\n",
    "df_train_fr_age_old_only = df_train_fr_age[df_train_fr_age['age'].apply(\n",
    "    lambda x: [old] == x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab734dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.372524Z",
     "start_time": "2021-12-09T11:45:55.347925Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_es_age = df_train_es[df_train_es['age'].apply(\n",
    "    lambda x: x != [])].copy()\n",
    "##\n",
    "df_train_es_age_infant = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: infant in x)]\n",
    "df_train_es_age_child = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: child in x)]\n",
    "df_train_es_age_adult = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: adult in x)]\n",
    "df_train_es_age_old = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: old in x)]\n",
    "##\n",
    "df_train_es_age_infant_only = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: [infant] == x)]\n",
    "df_train_es_age_child_only = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: [child] == x)]\n",
    "df_train_es_age_adult_only = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: [adult] == x)]\n",
    "df_train_es_age_old_only = df_train_es_age[df_train_es_age['age'].apply(\n",
    "    lambda x: [old] == x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef459b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.398673Z",
     "start_time": "2021-12-09T11:45:55.373723Z"
    }
   },
   "outputs": [],
   "source": [
    "class KeywordExtractor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        docs_bg_corpus,\n",
    "        docs_classes,\n",
    "        lang=\"en\",\n",
    "        n_grams=2,\n",
    "        num_to_words=False,\n",
    "        stop_words=None,\n",
    "    ):\n",
    "        if isinstance(stop_words, Sequence) and not isinstance(stop_words, set):\n",
    "            self.stop_words = set(stop_words)\n",
    "        elif stop_words is None:\n",
    "            self.stop_words = set()\n",
    "        self.n_grams = n_grams\n",
    "        self.num_to_words = num_to_words\n",
    "        self.docs_bg_corpus = docs_bg_corpus\n",
    "        self.class_name_to_idx = dict(\n",
    "            zip(list(docs_classes.keys()), range(len(docs_classes))))\n",
    "        self.docs_classes = list(docs_classes.values())\n",
    "        self.lang = lang\n",
    "        ## for preprocessing - should be moved to a util class/func\n",
    "        self.num_normalizer = dict(\n",
    "            zip(\"⁰¹²³⁴⁵⁶⁷⁸⁹\", [str(i) for i in range(10)]))\n",
    "        self.num_normalizer.update(\n",
    "            dict(zip(\"₀₁₂₃₄₅₆₇₈₉\", [str(i) for i in range(10)])))\n",
    "        if lang == \"en\":\n",
    "            self.num_normalizer.update({\"⅓\": \"one-third\", \"¼\": \"one-fourth\"})\n",
    "        elif lang == \"fr\":\n",
    "            self.num_normalizer.update({\"⅓\": \"un-tiers\", \"¼\": \"un-quart\"})\n",
    "        elif lang == \"es\":\n",
    "            self.num_normalizer.update({\"⅓\": \"un-tercio\", \"¼\": \"un-tercio\"})\n",
    "        ##\n",
    "        self.word_to_freq_bg_corpus = self.extract_word_counts(docs_bg_corpus)\n",
    "        # split word to freq dict into multiple dicts according to ngram len\n",
    "        self.ngram_to_freq_bg_corpus = [dict() for _ in range(n_grams)]\n",
    "        for kw, count in self.word_to_freq_bg_corpus.items():\n",
    "            if isinstance(kw, str):\n",
    "                self.ngram_to_freq_bg_corpus[0][kw] = count\n",
    "            else:\n",
    "                self.ngram_to_freq_bg_corpus[len(kw) - 1][kw] = count\n",
    "        self.bg_corpus_sizes = [\n",
    "            sum(self.ngram_to_freq_bg_corpus[i].values())\n",
    "            for i in range(n_grams)\n",
    "        ]\n",
    "        ##\n",
    "        self.word_to_freq_classes = [\n",
    "            self.extract_word_counts(corpus) for corpus in self.docs_classes\n",
    "        ]\n",
    "        # split word to freq dict of each class into multiple dicts\n",
    "        # len(ngram_word_to_freq_classes) = c\n",
    "        # len(ngram_word_to_freq_classes[x]) = n\n",
    "        self.ngram_word_to_freq_classes = [[dict() for _ in range(n_grams)]\n",
    "                                           for _ in self.class_name_to_idx]\n",
    "        for c, word_to_freq_cls in enumerate(self.word_to_freq_classes):\n",
    "            for kw, count in word_to_freq_cls.items():\n",
    "                n = 0 if isinstance(kw, str) else len(kw) - 1\n",
    "                self.ngram_word_to_freq_classes[c][n][kw] = count\n",
    "        self.ngram_corpora_sizes = [[\n",
    "            sum(word_to_freq[i].values()) for i in range(n_grams)\n",
    "        ] for word_to_freq in self.ngram_word_to_freq_classes]\n",
    "\n",
    "        self.ngram_corpora_sizes = [[\n",
    "            sum(word_to_freq[i].values()) for i in range(n_grams)\n",
    "        ] for word_to_freq in self.ngram_word_to_freq_classes]\n",
    "        ##\n",
    "        # calc likelihoods for each ngram length in each class separately\n",
    "        # a list of lists of dicts\n",
    "        # each represents a class\n",
    "        # each class is represented by n dicts\n",
    "        # each dict is {\"ngram in class\": likelihood}\n",
    "        self.ngram_likelihoods = [[] for _ in self.class_name_to_idx]\n",
    "        for c, cls_name in enumerate(self.class_name_to_idx):\n",
    "            for n in range(self.n_grams):\n",
    "                w_to_f = self.ngram_word_to_freq_classes[c][n]\n",
    "                corpus_size = self.ngram_corpora_sizes[c][n]\n",
    "                self.ngram_likelihoods[c].append(\n",
    "                    self.calc_likelihoods(w_to_f, corpus_size))\n",
    "        ##\n",
    "        # calc potts scores for each ngram in each class\n",
    "        add_two_dict = lambda a, b: {\n",
    "            **a,\n",
    "            **b,\n",
    "            **{k: a[k] + b[k]\n",
    "               for k in a.keys() & b}\n",
    "        }\n",
    "        self.ngram_potts_scores = [[] for _ in self.class_name_to_idx]\n",
    "        self.ngram_z_score_of_the_log_odds_ratios = [\n",
    "            [] for _ in self.class_name_to_idx\n",
    "        ]\n",
    "        for c, cls_name in enumerate(self.class_name_to_idx):\n",
    "            for n in range(self.n_grams):\n",
    "                lh = self.ngram_likelihoods[c][n]\n",
    "                other_lhs = [\n",
    "                    self.ngram_likelihoods[c_other][n]\n",
    "                    for c_other, _ in enumerate(self.class_name_to_idx)\n",
    "                    if c != c_other\n",
    "                ]\n",
    "                other_lhs = functools.reduce(add_two_dict, other_lhs)\n",
    "                self.ngram_potts_scores[c].append(\n",
    "                    self.calc_potts_scores(lh, other_lhs))\n",
    "\n",
    "                word_to_freq = self.ngram_word_to_freq_classes[c][n]\n",
    "                corpus_size = self.ngram_corpora_sizes[c][n]\n",
    "                word_to_freq_others = [\n",
    "                    self.ngram_word_to_freq_classes[c_other][n]\n",
    "                    for c_other, _ in enumerate(self.class_name_to_idx)\n",
    "                    if c != c_other\n",
    "                ]\n",
    "                word_to_freq_others = functools.reduce(add_two_dict,\n",
    "                                                       word_to_freq_others)\n",
    "                corpus_size_others = sum([\n",
    "                    self.ngram_corpora_sizes[c_other][n]\n",
    "                    for c_other, _ in enumerate(self.class_name_to_idx)\n",
    "                    if c != c_other\n",
    "                ])\n",
    "\n",
    "                self.ngram_z_score_of_the_log_odds_ratios[c].append(\n",
    "                    self.calc_prior_modified_log_odds_ratio(\n",
    "                        word_to_freq, corpus_size, word_to_freq_others,\n",
    "                        corpus_size_others, self.ngram_to_freq_bg_corpus[n],\n",
    "                        self.bg_corpus_sizes[n]))\n",
    "\n",
    "    def preprocess_and_tokenize(self, doc):\n",
    "        if doc != doc:\n",
    "            return \"\"\n",
    "        # remove preceeding dates\n",
    "        doc = re.sub(\"^\\[.+\\]\", \" \", doc).strip()\n",
    "        doc = re.sub(\"^\\(.+\\)\", \" \", doc).strip()\n",
    "        # spaces btw numbers and words\n",
    "        doc = re.sub('(\\d+(\\W\\d+)?)', r' \\1 ', doc).strip()\n",
    "        doc = re.sub(\"[‐‑–—―─_]\", \"-\", doc)\n",
    "        doc = re.sub(\n",
    "            \"[\" + re.escape(\n",
    "                '_@^~.()[],\"“’…<❖‐»—─|•&{≥➢\\ue0e4\\uf0d8\\uf0fc●°#\\u200b>`?�€■!‘%;̧\\'›«”:≤―\\uf0b7$}*+´=‑▪\\xad❑·–'\n",
    "            ) + \"]\", \" \", doc)\n",
    "        #remove some puncs\n",
    "        doc = re.sub('\\s+', \" \", doc)\n",
    "\n",
    "        # tokenize\n",
    "        words = word_tokenize(doc)\n",
    "        # lower and remove non-words\n",
    "        words = [word.lower() for word in words if word not in self.stop_words]\n",
    "        words = [self.num_normalizer.get(token, token) for token in words]\n",
    "        if self.num_to_words:\n",
    "            words = [\n",
    "                num2words(token, lang=self.lang)\n",
    "                if token.isnumeric() else token for token in words\n",
    "            ]\n",
    "        kw_kp = words.copy()\n",
    "        for n in range(2, self.n_grams + 1):\n",
    "            kw_kp.extend(list(ngrams(words, n)))\n",
    "        return kw_kp\n",
    "\n",
    "    def calc_potts_scores(self, word_to_likelihood_main,\n",
    "                          word_to_likelihood_other):\n",
    "        potts_scores = dict()\n",
    "        for word in word_to_likelihood_main.keys():\n",
    "            potts_scores[word] = word_to_likelihood_main[word] / (\n",
    "                word_to_likelihood_main[word] +\n",
    "                word_to_likelihood_other.get(word, 0))\n",
    "        return potts_scores\n",
    "\n",
    "    def calc_likelihoods(self, word_to_freq, corpus_size):\n",
    "        likelihoods = dict()\n",
    "        for word, count in word_to_freq.items():\n",
    "            likelihoods[word] = count / corpus_size\n",
    "        return likelihoods\n",
    "\n",
    "    def extract_word_counts(self, docs):\n",
    "        word_to_freq = defaultdict(int)\n",
    "        for doc in docs:\n",
    "            words = self.preprocess_and_tokenize(doc)\n",
    "            for word in words:\n",
    "                #if word in stopwords, then do not add it\n",
    "                word_to_freq[word] += 1\n",
    "\n",
    "        return word_to_freq\n",
    "\n",
    "    def calc_prior_modified_log_odds_ratio(self, word_to_freq_c1,\n",
    "                                           corpus_size_c1, word_to_freq_c2,\n",
    "                                           corpus_size_c2, word_to_freq_all,\n",
    "                                           corpus_size_all):\n",
    "\n",
    "        prior_modified_log_odds_ratio_c1 = dict()\n",
    "        variance_of_the_log_odds_ratio = dict()\n",
    "        z_score_of_the_log_odds_ratio_c1 = dict()\n",
    "        ##\n",
    "        for word in word_to_freq_c1.keys():\n",
    "            numerator_1 = word_to_freq_c1[word] + word_to_freq_all[word]\n",
    "            denomerator_1 = corpus_size_c1 + corpus_size_all - (numerator_1)\n",
    "            ratio_1 = np.log(numerator_1 / denomerator_1)\n",
    "            ##\n",
    "            numerator_2 = word_to_freq_c2.get(word, 0) + word_to_freq_all[word]\n",
    "            denomerator_2 = corpus_size_c2 + corpus_size_all - (numerator_2)\n",
    "            ratio_2 = np.log(numerator_2 / denomerator_2)\n",
    "            ##\n",
    "            prior_modified_log_odds_ratio_c1[word] = ratio_1 - ratio_2\n",
    "            ##\n",
    "            variance_of_the_log_odds_ratio[word] = (1 / numerator_1) + (\n",
    "                1 / numerator_2)\n",
    "            ##\n",
    "            z_score_of_the_log_odds_ratio_c1[\n",
    "                word] = prior_modified_log_odds_ratio_c1[word] / np.sqrt(\n",
    "                    variance_of_the_log_odds_ratio[word])\n",
    "        return z_score_of_the_log_odds_ratio_c1\n",
    "\n",
    "    def get_kws(self, cls_name, n):\n",
    "        cls_idx = self.class_name_to_idx[cls_name]\n",
    "        kw_dict = self.ngram_z_score_of_the_log_odds_ratios[cls_idx][n - 1]\n",
    "        return list(\n",
    "            sorted([(word, score) for word, score in kw_dict.items()],\n",
    "                   key=itemgetter(1),\n",
    "                   reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5784fec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.415782Z",
     "start_time": "2021-12-09T11:45:55.399758Z"
    }
   },
   "outputs": [],
   "source": [
    "kw_en_infant = [\n",
    "    '(24-59m)',\n",
    "    ('0', '-', '59', 'months'),\n",
    "    ('0-59', 'months'),\n",
    "    ('1', '-year-old'),\n",
    "    '1-year-old',\n",
    "    ('12-15', 'month'),\n",
    "    ('2', '-year-old'),\n",
    "    '2-year-old',\n",
    "    ('24-59', 'm'),\n",
    "    ('3', '-year-old'),\n",
    "    '3-year-old',\n",
    "    ('4', '-year-old'),\n",
    "    '4-year-old',\n",
    "    ('5', '-year-old'),\n",
    "    '5-year-old',\n",
    "    ('6', '-', '23', 'months', 'old'),\n",
    "    ('6-', '23', 'months', 'old'),\n",
    "    ('6-23', 'months', 'old'),\n",
    "    ('age', 'of', '5'),\n",
    "    ('age', 'of', 'five'),\n",
    "    ('aged', '0', '-', '23', 'months'),\n",
    "    ('aged', '0-23', 'months'),\n",
    "    ('aged', '0-', '23', 'months'),\n",
    "    ('aged', 'zero', '-', 'twenty-three', 'months'),\n",
    "    'babies',\n",
    "    'baby',\n",
    "    'born',\n",
    "    'breastfed',\n",
    "    ('children', '6-', '59', 'months', 'of', 'age'),\n",
    "    ('children', '6-59', 'months'),\n",
    "    ('children', 'under', 'the', 'age', 'of', 'five', 'years'),\n",
    "    ('children', 'below', 'five', 'years', 'of', 'age'),\n",
    "    ('children', '6-', '59', 'months'),\n",
    "    ('children', '0-23', 'months'),\n",
    "    ('children', 'aged', '0-', '23', 'months'),\n",
    "    ('children', 'under', '5', 'years', 'of', 'age'),\n",
    "    ('children', 'of', '6-', '59', 'months'),\n",
    "    ('children', 'six', '-', 'fifty-nine', 'months'),\n",
    "    ('children', 'aged', '0-23', 'months'),\n",
    "    ('children', 'aged', '0', '-', '23', 'months'),\n",
    "    ('children', 'under', 'five', 'years', 'of', 'age'),\n",
    "    ('children', 'aged', 'six', 'to', 'fifty-nine', 'months'),\n",
    "    ('children', 'between', 'the', 'ages', 'of', 'twenty-four', 'and',\n",
    "     'fifty-nine', 'months'),\n",
    "    ('children', 'aged', '6-59', 'months'),\n",
    "    ('children', '6-59', 'months', 'of', 'age'),\n",
    "    ('children', 'of', '6-59', 'months'),\n",
    "    ('children', 'under', 'the', 'age', 'of', '5'),\n",
    "    ('children', 'below', '5', 'years', 'of', 'age'),\n",
    "    ('children', 'between', 'six', 'to', 'twenty-three', 'months'),\n",
    "    ('children', 'from', '6', 'to', '59', 'months'),\n",
    "    ('children', '6', '-', '59', 'months'),\n",
    "    ('children', 'under', '5', 'years', 'old'),\n",
    "    ('children', 'under', 'the', 'age', 'of', '5', 'years'),\n",
    "    ('children', 'aged', 'six', '-', 'fifty-nine', 'months'),\n",
    "    ('children', 'aged', '6-', '59', 'months'),\n",
    "    ('children', 'six', '-', 'fifty-nine', 'months', 'of', 'age'),\n",
    "    ('children', 'aged', '6', '-', '59', 'months'),\n",
    "    ('children', '0', '-', '23', 'months'),\n",
    "    ('children', 'from', 'six', 'to', 'fifty-nine', 'months'),\n",
    "    ('children', 'zero', '-', 'twenty-three', 'months'),\n",
    "    ('children', 'of', '6', '-', '59', 'months'),\n",
    "    ('children', 'under', 'five', 'years'),\n",
    "    ('children', 'of', 'six', '-', 'fifty-nine', 'months'),\n",
    "    ('children', 'aged', 'zero', '-', 'twenty-three', 'months'),\n",
    "    ('children', '0-', '23', 'months'),\n",
    "    ('children', 'between', 'the', 'ages', 'of', '24', 'and', '59', 'months'),\n",
    "    ('children', 'under', 'the', 'age', 'of', 'five'),\n",
    "    ('children', '6', '-', '59', 'months', 'of', 'age'),\n",
    "    ('children', 'under', 'five', 'years', 'old'),\n",
    "    ('children', 'aged', '6', 'to', '59', 'months'),\n",
    "    ('children', 'between', '6', 'to', '23', 'months'),\n",
    "    'cmam',\n",
    "    'congenital',\n",
    "    ('infant', 'and', 'young', 'child'),\n",
    "    'infant',\n",
    "    ('infant', 'and', 'young', 'child', 'feeding'),\n",
    "    'infantile',\n",
    "    'infants',\n",
    "    'iycf',\n",
    "    ('less', 'than', 'five', 'years'),\n",
    "    ('less', 'than', '5', 'years'),\n",
    "    ('live', 'births'),\n",
    "    ('live', 'birth'),\n",
    "    'measles',\n",
    "    'neonatal',\n",
    "    'newborn',\n",
    "    'newborns',\n",
    "    'perinatal',\n",
    "    'post-natal',\n",
    "    ('six', '-', 'twenty-three', 'months', 'old'),\n",
    "    'stunted',\n",
    "    'stunting',\n",
    "    ('under', 'the', 'age', 'of', 'five', 'years'),\n",
    "    ('under', 'the', 'age', 'of', '5'),\n",
    "    ('under', 'the', 'age', 'of', 'five'),\n",
    "    ('under', 'the', 'age', 'of', '5', 'years'),\n",
    "    (\"aged\", \"0-9\", \"years\"),\n",
    "]\n",
    "# list(\n",
    "#     sorted(list(set(kw_en_infant)),\n",
    "#            key=lambda x: x if isinstance(x, str) else x[0]))\n",
    "negative_kw_infant = [(\"women\",\"with\",\"babies\"),]\n",
    "##\n",
    "r_0_59 = r\"\\b(5[0-9]|[0-9])\\b\"  # 0->59\n",
    "r_0_5 = r\"\\b([0-5])\\b\"  # 0->5\n",
    "##\n",
    "infant_patterns = [\n",
    "    f\"less than {r_0_5} years\",\n",
    "    f\"younger than {r_0_5} years\",\n",
    "    f\"under the age of {r_0_5}\",\n",
    "    f\"below the age of {r_0_5}\",\n",
    "    f\"{r_0_59} ?- ?{r_0_59} months old\",\n",
    "    f\"aged {r_0_5} ?- ?[0-9] years\",\n",
    "    f\"aged {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"{r_0_59} ?- ?{r_0_59} ?m\",\n",
    "    f\"{r_0_59} ?- ?{r_0_59} ?months?\",\n",
    "    f\"{r_0_5}-year-old\",\n",
    "    f\"children {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"children of {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"children under {r_0_5}\",\n",
    "    f\"children under the age of {r_0_5}\",\n",
    "    f\"children under {r_0_5} years\",\n",
    "    f\"children below {r_0_5} years\",\n",
    "    f\"children below the age of {r_0_5}\",\n",
    "    f\"children below {r_0_5}\",\n",
    "    f\"children aged {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"children aged {r_0_59} to {r_0_59} months?\",\n",
    "    f\"children between {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"children between {r_0_59} to {r_0_59} months?\",\n",
    "    f\"children between the ages of {r_0_59} and {r_0_59} months?\",\n",
    "    f\"children from {r_0_59} ?- ?{r_0_59} months?\",\n",
    "    f\"children from {r_0_59} to {r_0_59} months?\",\n",
    "    f\"children of {r_0_59} ?- ?{r_0_59} months?\",\n",
    "]\n",
    "##\n",
    "def is_infant(row):\n",
    "    for kw in negative_kw_infant:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return False\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return False\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return False\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return False\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return False\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return False\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return False\n",
    "    for p in infant_patterns:\n",
    "        if re.search(p, row[\"excerpt_pp\"]): return True\n",
    "    for kw in kw_en_infant:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return True\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return True\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return True\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return True\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return True\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return True\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d5ce89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.431569Z",
     "start_time": "2021-12-09T11:45:55.416950Z"
    }
   },
   "outputs": [],
   "source": [
    "kw_en_child = [\n",
    "    ('14', 'years'), ('17', 'years'), 'adolescent', 'adolescents',\n",
    "    ('age', 'group', '5', '-', '14', 'years'),\n",
    "    ('age', 'group', '5-14', 'years'), ('aged', 'ten'), ('aged', '10'),\n",
    "    ('attending', 'school'), ('below', '18', 'years'), ('below', '18'),\n",
    "    ('below', 'the', 'age', 'of', '14'), ('below', '14'),\n",
    "    ('below', '18', 'years', 'of', 'age'), ('below', 'the', 'age', 'of', '17'),\n",
    "    ('below', 'the', 'age', 'of','18'), ('below', '17'),\n",
    "    ('below', 'eighteen', 'years'), ('below', 'eighteen'),\n",
    "    ('below', 'the', 'age', 'of','19'), 'boy', 'boys', 'child',\n",
    "    ('child', 'marriages'), ('child', 'labor'), ('child', 'abuse'),\n",
    "    ('child', 'marriage'), ('child', 'labour'), ('child', 'friendly'),\n",
    "    'child-friendly', ('child-friendly', 'spaces'), 'child-headed',\n",
    "    ('children', 'with', 'disabilities'), 'children',\n",
    "    ('children', 'under', 'eighteen'),\n",
    "    ('children', 'below', 'the', 'age', 'of', 'twelve'),\n",
    "    ('children', 'dropping', 'out', 'of', 'school'),\n",
    "    ('children', 'separated', 'from', 'their', 'parents'),\n",
    "    ('children', 'below', 'the', 'age', 'of', '12'),\n",
    "    ('children', 'not', 'attending', 'school'), ('children', 'school'),\n",
    "    ('children', 'under', '18'), ('children', 'caregivers'),\n",
    "    ('early', 'marriage'),\n",
    "    ('eighteen', 'years'), ('for', 'refugee', 'children'),\n",
    "    ('for', 'displaced', 'children'), ('fourteen', 'years'), 'girl', 'girls',\n",
    "    ('girls', 'children'), 'grades', 'in-school', ('labor', 'child'),\n",
    "    ('minor', 'child'), ('minor', 'children'), 'minors', ('mixed', 'school'),\n",
    "    ('out', 'of', 'education'), ('out', 'of', 'school'),\n",
    "    ('out-of-school', 'children'), 'out-of-school', 'pediatric',\n",
    "    ('primary', 'students'), ('primary', 'student'), ('refugee', 'children'),\n",
    "    ('rohingya', 'children'), ('school', 'students'),\n",
    "    ('school', 'aged', 'children'), ('school', 'children'),\n",
    "    ('school', 'aged'), 'school-age', ('school-age', 'children'),\n",
    "    ('school-aged', 'children'), 'school-aged', 'school-going', 'schoolboys',\n",
    "    'schoolchildren', 'schoolgirls', ('separated', 'children'),\n",
    "    ('seventeen', 'years'), 'students', 'teenagers', 'uasc', ('under', '18'),\n",
    "    ('under', 'the', 'age', 'of','14'), ('under', '18', 'years'), ('under', '14'),\n",
    "    ('under', 'the', 'age', 'of', 'eighteen'), ('under', 'the', 'age', 'of', '17'),\n",
    "    ('under', '17'), ('under', 'the', 'age', 'of', '18'),\n",
    "    ('under', 'the', 'age', 'of', '19'), ('under', 'eighteen'),\n",
    "    ('under', 'eighteen', 'years'), ('under', '18', 'years', 'of', 'age'),\n",
    "    ('under', 'the', 'age', 'of', '18'), ('venezuelan', 'minors'),\n",
    "    ('violence', 'against', 'children'), ('vulnerable', 'children'),\n",
    "    ('young', 'girls'), (\"teenage\",\"girl\"), (\"teenage\",\"girls\"),\n",
    "    (\"teenage\",\"boy\"), (\"teenage\",\"boys\"), (\"older\", \"than\", \"5\", \"years\")\n",
    "]\n",
    "# list(\n",
    "#     sorted(list(set(kw_en_child)),\n",
    "#            key=lambda x: x if isinstance(x, str) else x[0]))\n",
    "negative_kw_child = [\n",
    "    \"gam\",\n",
    "    \"sam\",\n",
    "    \"muac\",\n",
    "    \"24-59m\",\n",
    "    ('above', 'the', 'age', '18', 'years'),\n",
    "    ('above', '18', 'years', 'of', 'age'),\n",
    "    ('moderate', 'acute', 'malnutrition', 'mam'),\n",
    "    ('moderate', 'acute', 'malnutrition'),\n",
    "    'mam',\n",
    "    ('aged', '6-59', 'months'),\n",
    "    ('aged', '6-59'),\n",
    "]\n",
    "##\n",
    "##\n",
    "r_6_18 = r\"\\b(1[0-8]|[6-9])\\b\"  # 6->18\n",
    "r_5_15 = r\"\\b(1[0-5]|[5-9])\\b\"  # 5->15\n",
    "r_5_18 = r\"\\b(1[0-8]|[5-9])\\b\"  # 5->18\n",
    "r_14_18 = r\"\\b(1[4-8])\\b\"  # 4->18\n",
    "##\n",
    "child_patterns = [\n",
    "    f\"between {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"between {r_6_18} to {r_6_18}\",\n",
    "    f\"between the age of {r_6_18} and {r_6_18}\",\n",
    "    f\"the {r_6_18} ?- ?{r_6_18} age\",\n",
    "    f\"{r_6_18} ?- ?{r_6_18} years\",\n",
    "    f\"{r_6_18} to {r_6_18} years\",\n",
    "    f\"{r_6_18} ?-year-old\",\n",
    "    f\"{r_6_18} ?-year-olds\",\n",
    "    f\"{r_6_18} ?- ?{r_6_18} years old\",\n",
    "    f\"{r_6_18} ?- ?{r_6_18} age\",\n",
    "    f\"ages of {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"ages of {r_6_18} and {r_6_18}\",\n",
    "    f\"age of {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"age of {r_6_18} years\",\n",
    "    f\"age {r_6_18}\",\n",
    "    f\"aged {r_6_18}\",\n",
    "    f\"age {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"ages {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"aged {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"age {r_6_18} ?- ?{r_6_18}\",\n",
    "    f\"{r_6_18} years\",\n",
    "    f\"age group {r_5_18} ?- ?{r_6_18} years\",\n",
    "    f\"below {r_14_18} years\",\n",
    "    f\"below the age of {r_14_18}\",\n",
    "    f\"children under {r_14_18}\",\n",
    "    f\"under the age of {r_14_18}\",\n",
    "    f\"under {r_14_18} years\",\n",
    "    f\"below {r_14_18} years\",\n",
    "    f\"below the age of {r_14_18}\",\n",
    "    f\"younger than {r_14_18}\",\n",
    "    f\"less than {r_14_18}\",\n",
    "    f\"older than {r_5_15} years\",\n",
    "]\n",
    "##\n",
    "def is_child(row):\n",
    "    for kw in negative_kw_child:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return False\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return False\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return False\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return False\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return False\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return False\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return False\n",
    "    for p in child_patterns:\n",
    "        if re.search(p, row[\"excerpt_pp\"]): return True\n",
    "    for kw in kw_en_child:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return True\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return True\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return True\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return True\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return True\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return True\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28aa3ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.442046Z",
     "start_time": "2021-12-09T11:45:55.432893Z"
    }
   },
   "outputs": [],
   "source": [
    "kw_en_adult = [\n",
    "    'adult', 'adults', ('asylum', 'seekers'), 'breadwinner',\n",
    "    ('care', 'givers'), 'care-giving', 'caregivers', 'child-bearing',\n",
    "    'childbearing', 'employability', 'employed', 'employees', 'employers',\n",
    "    'employment', 'entrepreneurs', ('female', 'detainees'), 'female-headed',\n",
    "    ('foreign', 'health', 'professionals'), 'gbv', 'graduates',\n",
    "    ('had', 'given', 'a', 'life', 'birth'), 'husbands', 'jobs',\n",
    "    ('killing', 'of', 'teachers'), ('labor', 'market'), ('life', 'birth'),\n",
    "    ('male', 'headed'), 'male-headed', 'maternal', 'men', 'mothers', 'parents',\n",
    "    ('reproductive', 'age'), 'scholarships', ('stateless', 'persons'),\n",
    "    ('to',\n",
    "     'work'), 'underemployed', 'underemployment', 'unemployed', 'unemployment',\n",
    "    ('unintended', 'pregnancies'), 'university', 'widow',\n",
    "    'widows', 'wives', 'woman', 'women', 'women-headed', 'workers',\n",
    "    ('working', 'in'), 'working-age', 'youth', 'youths'\n",
    "]\n",
    "# list(\n",
    "#     sorted(list(set(kw_en_adult)),\n",
    "#            key=lambda x: x if isinstance(x, str) else x[0]))\n",
    "negative_kw_adult = []\n",
    "##\n",
    "r_18_59 = r\"\\b([2-5][0-9]|1[8-9])\\b\"  # 18->59\n",
    "r_20_59 = r\"\\b([2-5][0-9])\\b\"  # 20->59\n",
    "r_15_19 = r\"\\b(1[5-9])\\b\"  # 15->19\n",
    "r_11_19 = r\"\\b(1[1-9])\\b\"  # 11->19\n",
    "r_18_49 = r\"\\b([2-4][0-9]|1[8-9])\\b\"  # 18->49\n",
    "##\n",
    "adult_patterns = [\n",
    "    f\"between {r_11_19} ?- ?{r_20_59}\",\n",
    "    f\"between {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"between {r_18_59} to {r_18_59}\",\n",
    "    f\"between {r_11_19} to {r_20_59}\",\n",
    "    f\"between the age of {r_18_59} and {r_18_59}\",\n",
    "    f\"between the age of {r_11_19} and {r_20_59}\",\n",
    "    f\"the {r_18_59} ?- ?{r_18_59} age\",\n",
    "    f\"{r_18_59} ?- ?{r_18_59} years\",\n",
    "    f\"{r_18_59} to {r_18_59} years\",\n",
    "    f\"{r_18_59}\\+ years\",\n",
    "    f\"{r_18_59} ?-year-old\",\n",
    "    f\"{r_18_59} ?-year-olds\",\n",
    "    f\"{r_18_59} ?- ?{r_18_59} years old\",\n",
    "    f\"{r_18_59} ?- ?{r_18_59} age\",\n",
    "    f\"ages of {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"ages of {r_11_19} ?- ?{r_20_59}\",\n",
    "    f\"ages of {r_11_19} and {r_20_59}\",\n",
    "    f\"age of {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"age of {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"age of {r_18_59} years\",\n",
    "    f\"age {r_18_59}\",\n",
    "    f\"age {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"ages {r_11_19} ?- ?{r_20_59}\",\n",
    "    f\"aged {r_18_59} ?- ?{r_18_59}\",\n",
    "    f\"age {r_11_19} ?- ?{r_20_59}\",\n",
    "    f\"\\d\\d+,?\\d* female\",\n",
    "    f\"\\d\\d+,?\\d* females\",\n",
    "    f\"\\d\\d+,?\\d* male\",\n",
    "    f\"\\d\\d+,?\\d* males\",\n",
    "    #f\"\\d\\d+,?\\d* people\",\n",
    "    #f\"\\d\\d+,?\\d* persons\",\n",
    "    f\"older than {r_18_49} years\",\n",
    "    f\"{r_18_49} years and above\",\n",
    "    f\"{r_18_49} years old and above\",\n",
    "    f\"above the age of {r_18_49}\",\n",
    "    f\"over the age of {r_18_49}\",\n",
    "    f\"over >{r_18_59} ?years\",\n",
    "    f\"above >{r_18_59} ?years\",\n",
    "]\n",
    "##\n",
    "def is_adult(row):\n",
    "    for kw in negative_kw_adult:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return False\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return False\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return False\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return False\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return False\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return False\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return False\n",
    "    for p in adult_patterns:\n",
    "        if re.search(p, row[\"excerpt_pp\"]): return True\n",
    "    for kw in kw_en_adult:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return True\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return True\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return True\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return True\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return True\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return True\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81eec97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-09T11:45:55.459417Z",
     "start_time": "2021-12-09T11:45:55.443180Z"
    }
   },
   "outputs": [],
   "source": [
    "kw_en_old = [\n",
    "    ('55', 'years', 'and', 'above'),\n",
    "    ('59', 'years', 'and', 'above'),\n",
    "    ('60', 's'),\n",
    "    ('60', 'years'),\n",
    "    ('60', 'years', 'and', 'above'),\n",
    "    '60-year-old',\n",
    "    ('62', 'older'),\n",
    "    ('65', 'years'),\n",
    "    ('65', 'years', 'and', 'above'),\n",
    "    ('70', 'years'),\n",
    "    ('70', 'years', 'and', 'above'),\n",
    "    ('70', '-year-old'),\n",
    "    '70-year-old',\n",
    "    ('75', 'years', 'and', 'above'),\n",
    "    ('80', 'years'),\n",
    "    '80-year-old',\n",
    "    ('above', '65', 'years'),\n",
    "    ('above', '65', 'years', 'of', 'age'),\n",
    "    ('above', '60', 'years'),\n",
    "    ('above', '55', 'years'),\n",
    "    ('above', '70'),\n",
    "    ('above', '80'),\n",
    "    ('above', '59'),\n",
    "    ('above', '70', 'years'),\n",
    "    ('above', '59', 'years'),\n",
    "    ('above', '75', 'years'),\n",
    "    ('above', '60'),\n",
    "    ('above', '65'),\n",
    "    ('adults', 'aged', '65'),\n",
    "    ('adults', 'aged', '70'),\n",
    "    ('aged', 'above', '59'),\n",
    "    ('aged', '80', 'and', 'above'),\n",
    "    ('aged', 'above', '60'),\n",
    "    ('aged', '65'),\n",
    "    ('aged', 'above', '85'),\n",
    "    ('aged', 'above', '55'),\n",
    "    ('aged', '70', 'and', 'above'),\n",
    "    ('aged', '75', 'and', 'above'),\n",
    "    ('aged', 'above', '65'),\n",
    "    ('aged', '80'),\n",
    "    ('aged', 'above', '75'),\n",
    "    ('aged', '70'),\n",
    "    ('aged', 'above', '50'),\n",
    "    ('aged', 'above', '70'),\n",
    "    ('aged', '60', 'and', 'above'),\n",
    "    ('aged', '65', 'and', 'above'),\n",
    "    ('aged', '60'),\n",
    "    ('aged', 'above', '80'),\n",
    "    'ageing',\n",
    "    ('elderly', 'community'),\n",
    "    ('elderly', 'population'),\n",
    "    ('elderly', 'men'),\n",
    "    ('elderly', 'women'),\n",
    "    ('elderly', 'persons'),\n",
    "    'elderly',\n",
    "    ('elderly', 'people'),\n",
    "    ('elders', 'people'),\n",
    "    ('older', 'persons'),\n",
    "    ('older', 'people'),\n",
    "    ('older', 'population'),\n",
    "    ('older', 'person'),\n",
    "    ('older', 'men'),\n",
    "    ('older', 'women'),\n",
    "    ('over', '59'),\n",
    "    ('over', '70', 'years'),\n",
    "    ('over', '59', 'years'),\n",
    "    ('over', '55'),\n",
    "    ('over', '60', 'years', 'old'),\n",
    "    ('over', '80', 'years', 'old'),\n",
    "    ('over', '60'),\n",
    "    ('over', '65', 'years'),\n",
    "    ('over', '60', 'years'),\n",
    "    ('over', '55', 'years'),\n",
    "    ('over', '80', 'years'),\n",
    "    ('people', 'aged', '59'),\n",
    "    ('people', 'over', '65'),\n",
    "    ('people', 'aged', '55'),\n",
    "    ('people', 'aged', '60'),\n",
    "    ('people', 'over', '80'),\n",
    "    ('people', 'over', '70'),\n",
    "    ('the', '59', '+', 'population'),\n",
    "    \"elders\",\n",
    "    ('50', '+', 'years'),\n",
    "    (\"geriatric\", \"population\"),\n",
    "]\n",
    "# list(\n",
    "#     sorted(list(set(kw_en_old)),\n",
    "#            key=lambda x: x if isinstance(x, str) else x[0]))\n",
    "negative_kw_old = []\n",
    "r_59_100 = r\"\\b(100|[6-9][0-9]|59)\\b\"  # 59-100\n",
    "r_50_100 = r\"\\b(100|[6-9][0-9]|5[0-9])\\b\"  # 50-100\n",
    "r_61_100 = r\"\\b(100|[6-9][1-9])\\b\"  # 61-100\n",
    "r_60_100 = r\"\\b(100|[6-9][0-9])\\b\"  # 60-100\n",
    "r_0_59 = r\"\\b(5[0-9]|[0-9][0-9])\\b\"  # 0-59\n",
    "patterns_old = [\n",
    "    f\"between {r_59_100} ?- ?{r_59_100}\",\n",
    "    f\"between {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"{r_59_100} years and older\",\n",
    "    f\"{r_59_100} years and above\",\n",
    "    f\"{r_59_100} years old and above\",\n",
    "    f\"above {r_59_100} years\",\n",
    "    f\"over {r_59_100} years\",\n",
    "    f\"above the age of {r_50_100}\",\n",
    "    f\"over the age of {r_50_100}\",\n",
    "    f\"between {r_50_100} ?- ?{r_59_100}\",\n",
    "    f\"between {r_50_100} to {r_59_100}\",\n",
    "    f\"between the age of {r_50_100} and {r_59_100}\",\n",
    "    f\"between the ages of {r_50_100} and {r_59_100}\",\n",
    "    f\"the {r_59_100} ?- ?{r_59_100} age\",\n",
    "    f\"{r_50_100} ?- ?{r_61_100} years\",\n",
    "    f\"{r_50_100} to {r_61_100} years\",\n",
    "    f\"{r_50_100}\\+ years\",\n",
    "    f\"{r_60_100} ?-year-old\",\n",
    "    f\"{r_60_100} ?-year-olds\",\n",
    "    f\"{r_50_100} ?- ?{r_61_100} years old\",\n",
    "    f\"{r_50_100} ?- ?{r_61_100} age\",\n",
    "    f\"ages of {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"ages of {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"ages of {r_50_100} and {r_61_100}\",\n",
    "    f\"age of {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"age of {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"age of {r_60_100} years\",\n",
    "    f\"age {r_60_100}\",\n",
    "    f\"age {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"ages {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"aged {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"age {r_50_100} ?- ?{r_61_100}\",\n",
    "    f\"aged {r_50_100} years and older\",\n",
    "    f\"older than {r_50_100}\",\n",
    "]\n",
    "\n",
    "\n",
    "##\n",
    "def is_old(row):\n",
    "    for kw in negative_kw_old:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return False\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return False\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return False\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return False\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return False\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return False\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return False\n",
    "    for p in patterns_old:\n",
    "        if re.search(p, row[\"excerpt_pp\"]): return True\n",
    "    for kw in kw_en_old:\n",
    "        if isinstance(kw, str) and kw in row['tokenized_excerpt']: return True\n",
    "        elif len(kw) == 2 and kw in row['bigram_excerpt']: return True\n",
    "        elif len(kw) == 3 and kw in row['trigram_excerpt']: return True\n",
    "        elif len(kw) == 4 and kw in row['fourgram_excerpt']: return True\n",
    "        elif len(kw) == 5 and kw in row['fivegram_excerpt']: return True\n",
    "        elif len(kw) == 6 and kw in row['sixgram_excerpt']: return True\n",
    "        elif len(kw) == 7 and kw in row['sevengram_excerpt']: return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba62a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "df_train_en[\"excerpt_pp\"] = df_train_en[\"excerpt\"].progress_apply(preprocess)\n",
    "# tokenize and cacl ngrams\n",
    "df_train_en[\"tokenized_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(preprocess_and_tokenize)\n",
    "df_train_en[\"bigram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 2))\n",
    "df_train_en[\"trigram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 3))\n",
    "df_train_en[\"fourgram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 4))\n",
    "df_train_en[\"fivegram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 5))\n",
    "df_train_en[\"sixgram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 6))\n",
    "df_train_en[\"sevengram_excerpt\"] = df_train_en[\"excerpt\"].progress_apply(lambda x: preprocess_and_tokenize(x, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be90b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143947d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python385jvsc74a57bd0f487e277ea6a75fd1c7c341a1deb40c7861148cbc006695943c5304af00fedbe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
