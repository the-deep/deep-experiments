{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from difflib import SequenceMatcher\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv(\"data_pp/sentences.csv\")\n",
    "sentences_annotated = pd.read_csv(\"data_pp/sentences_annotated.csv\")\n",
    "collections = pd.read_csv(\"data_pp/collections.csv\")\n",
    "entries_raw = pd.read_csv(\"data/entries_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. entries_raw: remove \"$/[.+/] \" from the begining of entries\n",
    "def entry_pp(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s = re.sub(r\"^\\[.+\\] \", \"\", s).strip()\n",
    "    s = re.sub(r\"^\\(.+\\) \", \"\", s).strip()\n",
    "    return s\n",
    "entries_raw[\"modified_excerpt_text_clean\"] = entries_raw[\"modified_excerpt_text\"].apply(entry_pp)\n",
    "entries_raw = entries_raw[~entries_raw[\"modified_excerpt_text_clean\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. sentences: remove sentences with tagged=True\n",
    "# deactivated\n",
    "unannotated_sentences = sentences_annotated[~sentences_annotated[\"is_selected\"]][[\"lead_id\", \"excerpt_id\"]]\n",
    "unannotated_sentences[\"unique_id\"] = unannotated_sentences['lead_id'].astype(str) + \"_\" + unannotated_sentences['excerpt_id'].astype(str)\n",
    "sentences[\"unique_id\"] = sentences['lead_id'].astype(str) + \"_\" + sentences['excerpt_id'].astype(str)\n",
    "#sentences_to_be_matched = sentences[sentences[\"unique_id\"].isin(unannotated_sentences[\"unique_id\"])]\n",
    "sentences_to_be_matched = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(354334, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. unannotated_sentences: remove sentences with\n",
    "#    word count < 4\n",
    "#    meaningless content, e.g. Low Int, random strings, etc.\n",
    "\n",
    "def pp(s):\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return False\n",
    "    split = s.split()\n",
    "    if len(split) < 3:\n",
    "        return False\n",
    "    if re.match(r\"((Low )|(High )|(Low High )|(High Low ))+Int\\.\", s):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "sentences_to_be_matched[\"keep\"] = sentences_to_be_matched[\"excerpt_text\"].map(pp)\n",
    "sentences_to_be_matched = sentences_to_be_matched[sentences_to_be_matched[\"keep\"]]\n",
    "sentences_to_be_matched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339549, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. sentences: remove sentences with doc_ids that do not exist in entries_raw[\"lead_id\"]\n",
    "sentences_to_be_matched = sentences_to_be_matched[sentences_to_be_matched[\"lead_id\"].isin(entries_raw[\"lead_id\"])]\n",
    "sentences_to_be_matched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59feecb4d3324b578147e16721b48c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=339549.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. sentences: for each sentence: fuzzymatch it entries that have the same doc_id\n",
    "# take a sentence\n",
    "threshold = 70\n",
    "matches = []\n",
    "for i, sentence_row in tqdm(enumerate(sentences_to_be_matched.itertuples()), total=len(sentences_to_be_matched)):\n",
    "    sentence = sentence_row.excerpt_text # sentence_row[1][\"excerpt_text\"]\n",
    "    doc_id = sentence_row.lead_id # sentence_row[1][\"lead_id\"]\n",
    "    # extract entries with same doc_id\n",
    "    candidates = entries_raw[entries_raw[\"lead_id\"]==doc_id]\n",
    "    candidates = candidates[\"modified_excerpt_text_clean\"].to_dict()\n",
    "    matching_entry_text, ratio, matching_entry_id = process.extractOne(sentence, candidates, scorer=fuzz.token_set_ratio)\n",
    "    # matching_entry_text, ratio, matching_entry_id = process.extractOne(sentence, candidates, scorer=fuzz.partial_ratio)\n",
    "    # matching_entry_text, ratio, matching_entry_id = process.extractOne(sentence, candidates, scorer=fuzz.)\n",
    "    if ratio >= threshold:\n",
    "        matches.append((sentence_row[0], matching_entry_id, ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b0c69b621f4d9fb57863c7ff20dcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=75792.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "long = 0\n",
    "short = 0\n",
    "long_matches = []\n",
    "short_matches = []\n",
    "shortest_contiguous_sequence_length = 4\n",
    "for orig_i, mod_i, _ in tqdm(matches):\n",
    "    s1 = sentences_to_be_matched.loc[orig_i, \"excerpt_text\"]\n",
    "    s2 = entries_raw.loc[mod_i, \"modified_excerpt_text_clean\"]\n",
    "    if len(s2) > len(s1):\n",
    "        s1, s2 = s2, s1\n",
    "    match = SequenceMatcher(None, s1, s2, False).find_longest_match(0, len(s1), 0, len(s2))\n",
    "    match_ratio = match.size/len(s2)\n",
    "    match_len = len(s1[match.a: match.a + match.size].split())\n",
    "    if match_len > shortest_contiguous_sequence_length:\n",
    "        long += 1\n",
    "        long_matches.append((orig_i, mod_i, match.size, match_ratio))\n",
    "    else:\n",
    "        short += 1\n",
    "        short_matches.append((orig_i, mod_i, match.size, match_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66919, 8873)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long, short #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_dict = dict() # orig_sen --> mod_sen\n",
    "for orig_sen_i, mod_sen_i, _, _ in long_matches:\n",
    "    matches_dict[sentences.loc[orig_sen_i, \"unique_id\"]] = (orig_sen_i, mod_sen_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique id for sentences\n",
    "sentences[\"unique_id\"] = sentences['lead_id'].astype(str) + \"_\" + sentences['excerpt_id'].astype(str)\n",
    "# unique id for sentences_annotated\n",
    "sentences_annotated[\"unique_id\"] = sentences_annotated['lead_id'].astype(str) + \"_\" + sentences_annotated['excerpt_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8849e7f6a7e43768cf7c8c4fc061cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=355715.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "already_labeled = 0\n",
    "sentences_annotated_new = sentences_annotated.copy()\n",
    "for i, sentence_row in tqdm(enumerate(sentences_annotated.itertuples()), total=len(sentences_annotated)):\n",
    "    unique_id = sentence_row.unique_id # sentence_row[1][\"unique_id\"]\n",
    "    if unique_id in matches_dict:\n",
    "        # fetch the annotation from entries_raw\n",
    "        orig_sen_i, mod_sen_i = matches_dict[unique_id]\n",
    "        assert sentences_annotated_new.loc[orig_sen_i, \"unique_id\"] == unique_id\n",
    "        assert entries_raw.loc[mod_sen_i, \"lead_id\"] == sentences_annotated_new.loc[orig_sen_i, \"lead_id\"]\n",
    "        if (entries_raw.loc[mod_sen_i, \"label_sectors\"] is not None) or (entries_raw.loc[mod_sen_i, \"label_dimensions\"] is not None):\n",
    "            if sentences_annotated.loc[orig_sen_i, \"is_selected\"]:\n",
    "                already_labeled += 1\n",
    "            sentences_annotated_new.loc[orig_sen_i, \"is_selected\"] = True\n",
    "            sentences_annotated_new.loc[orig_sen_i, \"label_sectors\"] = entries_raw.loc[mod_sen_i, \"label_sectors\"]\n",
    "            sentences_annotated_new.loc[orig_sen_i, \"label_dimensions\"] = entries_raw.loc[mod_sen_i, \"label_dimensions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_annotated_new.to_csv(\"data_pp/sentences_annotated_new.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41620"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66919"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25299"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(long_matches) - already_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26830"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels_count = (~entries_raw[\"label_sectors\"].isna() | ~entries_raw[\"label_dimensions\"].isna()).sum()\n",
    "new_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69476"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_annotated[\"is_selected\"].sum() + new_labels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25299"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_annotated_new[\"is_selected\"].sum() - sentences_annotated[\"is_selected\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67945, 42646)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_annotated_new[\"is_selected\"].sum(), sentences_annotated[\"is_selected\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
