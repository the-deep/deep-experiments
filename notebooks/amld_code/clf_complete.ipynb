{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d43b39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install all depedencies\n",
    "# a GPU is needed, so run this notebook in a cuda working environment\n",
    "\n",
    "!pip install -r ./src/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2e27b6",
   "metadata": {},
   "source": [
    "### DEEP Assisted Tagging Tool\n",
    "\n",
    "\n",
    "In this notebook we propose an example of the main model architecture for the assisted tagging tool that will soon be implemented in [**The DEEP**](https://thedeep.io/) platform.\n",
    "\n",
    "Let's recap for completeness what The DEEP is, and how Machine Learning models improve its use. \n",
    "\n",
    "The DEEP is a collaborative platform for qualitative data analysis supporting humanitarian analytical teams to produce actionable insights. Since its inception in the aftermath of the 2015 Nepal Earthquake, DEEP has significantly contributed to improving the humanitarian data ecosystem, and today, without a doubt, is the largest repository of annotated humanitarian response documents: 50k+ sources/leads and 400k+ entries, used for 300+ projects by 3.5k+ registered users in 60+ countries.\n",
    "\n",
    "During crises, rapidly identifying important information from available data (news, reports, research, etc.) is crucial to understanding the needs of affected populations and to improving evidence-based decision-making. To make the information classification process even faster, DEEP is largely benefitting from  Natural Language Processing (NLP) and Deep Learning (DL) to aid and support the manual tagging process and give the humanitarian community more time to produce analyses and take rapid action to save more lives.\n",
    "\n",
    "Up to now, all the information (of any kind: reports, news, articles, maps, infographics, etc.) uploaded to the platform has been annotated by hand by experts in the humanitarian sector. The tagging was done under several projects according to different predefined multi-label categories (analytical frameworks). Since the data is mostly textual, we internally developed NLP models that could improve and speed up the analysis of the texts. \n",
    "\n",
    "We must also consider that informations are often contained within document reports (PDF, docx etc.) of numerous pages, making the tagging effort very difficult and time-consuming, therefore we understand how important it can be to optimize the humanitarian response during, for example, an ongoing natural disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533325ec",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Let's go into the details of the model now, starting from the data.\n",
    "\n",
    "In The DEEP platform each user or group has the possibility to create a project, which is usually link to a certain humanitarian crisis, such as a natural disaster, or to a certain geographic region or state where a rapid response is needed. Users can create custom labels and use them to annotate the information that will be uploaded within each project. Therefore each user will have the possibility to upload, for example, a document (of any format), select an exerpt of text (which perhaps contains important details for the purpose of the analysis) and annotate it using its own project labels. \n",
    "\n",
    "To combine entries from those projects and various analytical frameworks (set of labels), we defined a generic analytical framework and we transformed our labels accordingly. Our generic analytical framework has 10 different multi-label categories, totalling 86 different labels, covering all areas of a detailed humanitarian analysis.\n",
    "\n",
    "Our proposed dataset contains 8 categories overall:\n",
    "- 3 **primary tags**: sectors, pillars/subpillars_2d, pillars/subpillars_1d\n",
    "- 5 **secondary tags**: affected_groups, demographic_groups, specific_needs_groups, severity, geolocation\n",
    "\n",
    "Different tags are treated independently one from another. One model is trained alone for each different tag.\n",
    "\n",
    "In this notebook we focus only on a subset of above categories, **primary tags**.\n",
    "Primary tags contain 75 labels under different subcategories named as follows: \n",
    "- **Sectors** with 11 labels,\n",
    "- **2D Pillars** with  6 labels,\n",
    "- **2D Sub-pillars** with  18 labels,\n",
    "- **1D Pillars** with  7 labels,\n",
    "- **1D Sub-pillars** with  33 labels\n",
    "\n",
    "Let's see how they are divided:\n",
    "\n",
    "<div> <center><img src=\"./img/plot1.png\" alt=\"Drawing\" style=\"width: 1500px;\"/></center></div> \n",
    "\n",
    "We can see that, apart from Sectors, each subcategory has an annotation hierarchy, from Pillar to Sub-pillar (1D and 2D) . Furthermore, each text excerpt can be annotated with multiple labels, thus making the problem a multi-label text classification.\n",
    "\n",
    "The difference between 1D and 2D Pillars (and respective Sub-pillars), as we can see in the previous image, lies in the fact that the 2D subcategory presents an additional level of hierarchy, given by the Sectors. Example:\n",
    "\n",
    "<div> <center><img src=\"./img/ex.png\" alt=\"Drawing\" style=\"width: 1400px;\"/></center></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d712e645",
   "metadata": {},
   "source": [
    "#### Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09b8e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dowload_dataset import download_file_from_google_drive\n",
    "\n",
    "# download public data from google drive\n",
    "\n",
    "TRAIN_VAL_ID = \"1W9-IN0DgYYsiwrWi9Aefyc1V87_q_LWd\"\n",
    "TEST_ID = \"11NQCwixCW2ZiFlSp1QNen2uiS2gThu2B\"\n",
    "\n",
    "# set files path for training and testing set\n",
    "TRAIN_VAL_NAME = \"train_val_dataset.csv\"\n",
    "TEST_NAME = \"test_dataset.csv\"\n",
    "\n",
    "# downloading\n",
    "download_file_from_google_drive(id=TRAIN_VAL_ID, destination=TRAIN_VAL_NAME)\n",
    "download_file_from_google_drive(id=TEST_ID, destination=TEST_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d549acb",
   "metadata": {},
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c056a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 10420 samples\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "important_columns = ['entry_id', 'project_id', 'lead_id', 'analysis_framework_id', 'excerpt', 'sectors', 'subpillars_1d', 'subpillars_2d', 'lang']\n",
    "\n",
    "dataset = pd.read_csv(TEST_NAME)[important_columns]\n",
    "nb_samples = dataset.shape[0]\n",
    "print(f'We have {nb_samples} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8ad0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "classification_columns = ['sectors', 'subpillars_1d', 'subpillars_2d']\n",
    "for col in classification_columns:\n",
    "    dataset[col] = dataset[col].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b75f0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>lead_id</th>\n",
       "      <th>analysis_framework_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>sectors</th>\n",
       "      <th>subpillars_1d</th>\n",
       "      <th>subpillars_2d</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>489433</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>67488.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>Primary and secondary net enrollment rates are...</td>\n",
       "      <td>[Education]</td>\n",
       "      <td>[Context-&gt;Socio Cultural]</td>\n",
       "      <td>[Humanitarian Conditions-&gt;Living Standards]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>489430</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>67488.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>Like few other countries globally, the majorit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Context-&gt;Socio Cultural]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489438</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>67488.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>And the policy is already having significant i...</td>\n",
       "      <td>[Education]</td>\n",
       "      <td>[Context-&gt;Socio Cultural]</td>\n",
       "      <td>[Impact-&gt;Impact On Systems, Services And Netwo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187423</td>\n",
       "      <td>2170.0</td>\n",
       "      <td>43202.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>[9thNov 2020,Nigeria]With the latest update, N...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Covid-19-&gt;Cases]</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>489437</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>67488.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>But almost 2 years on, it is safe to say that ...</td>\n",
       "      <td>[Education]</td>\n",
       "      <td>[Context-&gt;Socio Cultural]</td>\n",
       "      <td>[Capacities &amp; Response-&gt;National Response, Imp...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  project_id  lead_id  analysis_framework_id  \\\n",
       "0    489433      2225.0  67488.0                 1306.0   \n",
       "1    489430      2225.0  67488.0                 1306.0   \n",
       "2    489438      2225.0  67488.0                 1306.0   \n",
       "3    187423      2170.0  43202.0                 1306.0   \n",
       "4    489437      2225.0  67488.0                 1306.0   \n",
       "\n",
       "                                             excerpt      sectors  \\\n",
       "0  Primary and secondary net enrollment rates are...  [Education]   \n",
       "1  Like few other countries globally, the majorit...           []   \n",
       "2  And the policy is already having significant i...  [Education]   \n",
       "3  [9thNov 2020,Nigeria]With the latest update, N...           []   \n",
       "4  But almost 2 years on, it is safe to say that ...  [Education]   \n",
       "\n",
       "               subpillars_1d  \\\n",
       "0  [Context->Socio Cultural]   \n",
       "1  [Context->Socio Cultural]   \n",
       "2  [Context->Socio Cultural]   \n",
       "3          [Covid-19->Cases]   \n",
       "4  [Context->Socio Cultural]   \n",
       "\n",
       "                                       subpillars_2d lang  \n",
       "0        [Humanitarian Conditions->Living Standards]   en  \n",
       "1                                                 []   en  \n",
       "2  [Impact->Impact On Systems, Services And Netwo...   en  \n",
       "3                                                 []   en  \n",
       "4  [Capacities & Response->National Response, Imp...   en  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# explore the data\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d83322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'piechart of languages present in dataset')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "language_counts = dict(Counter(dataset.lang))\n",
    "plt.pie(list(language_counts.values()), labels=list(language_counts.keys()))\n",
    "plt.title('piechart of languages present in dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783509b6",
   "metadata": {},
   "source": [
    "Textual entries are in 3 different languages: **English (mainly)**, **Spanish** and **French**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0aa0a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 57 tags\n"
     ]
    }
   ],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "merged_tags = flatten(\n",
    "    dataset.apply(lambda x: x.sectors + x.subpillars_1d + x.subpillars_2d, axis=1)\n",
    ")\n",
    "total_nb_tags = len(set(merged_tags))\n",
    "\n",
    "print(f'We have a total of {total_nb_tags} tags')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1bae709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shannon Entropy of the tags is: 3.48\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "nb_occurences_each_tag = dict(Counter(merged_tags))\n",
    "probability_occurence_each_tag = {tag_name: 100 * number_of_occurences/nb_samples for tag_name, number_of_occurences in nb_occurences_each_tag.items()}\n",
    "print(f'The Shannon Entropy of the tags is: {np.round(entropy(list(probability_occurence_each_tag.values())), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cbea671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'boxplot of probability of occurences for each tag')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=list(probability_occurence_each_tag.values()))\n",
    "plt.xlabel('probability of occurences of tags (%)')\n",
    "plt.title('boxplot of probability of occurences for each tag')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38815158",
   "metadata": {},
   "source": [
    "**Conclusions about Data**: \n",
    "* Multilingual Data\n",
    "* many tags to be handled\n",
    "* Imbalanced repartition of tags with some tags nearly absent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5504f1d",
   "metadata": {},
   "source": [
    "**Implemented Ways to augment data**:\n",
    "1) Basic Data augmentation techniques (random swapping, random deletion etc.)  \n",
    "2) Data augmentation with translation  \n",
    "3) Targetted Data Augmentation (augment text containing number-related tags by changing numbers)  \n",
    "\n",
    "$\\rightarrow$ Option 2 improved results, while options 1 and 3 did not show any improvement in results\n",
    "\n",
    "**Data Splitting**:\n",
    "- We create a unified training and testing data to be able to have a clear understanding of models performance.\n",
    "- We use stratified splitting, which keeps the same labels proportions in both the train and the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71469685",
   "metadata": {},
   "source": [
    "### **Model**\n",
    "\n",
    "#### *I. Model specifications*:\n",
    "The model developed is based on pre-trained transformer architecture. The transformer had to fulfill some criteria:\n",
    "- **multilingual** : it needs to work for different languages\n",
    "- **good performance** : in order for it to be useful, the model needs to be performant\n",
    "- **fast predictions** : the main goal of the modelling is to give live predictions to taggers while they are working on tagging. Speed is critical in this case and the faster the model the better.\n",
    "- **ability to handle important number of imbalanced tags** : The model needs to be able to adapt to data specificities: many tags which are not represented the same way.\n",
    "- **one endpoint only for deployment**: in order to optimize costs, we want to have one endpoint only for all models and predictions. To do this, we create one custom class containing models and deploy it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf8808",
   "metadata": {},
   "source": [
    "#### *II. model training*\n",
    "\n",
    "- **backbone**: We use the transformer [**microsoft/xtremedistil-l6-h256-uncased**](https://huggingface.co/microsoft/xtremedistil-l6-h256-uncased) as a backbone.\n",
    "  \n",
    "- **trained models**: In this notebook we overall train three independent models: `sectors`, one for `subpillars (1D and 2D)` and one for `secondary tags`. \n",
    "    - *`sectors` model training*: `sectors` is trained with a MLP-like standard architecture.\n",
    "    - *other models training: `subpillars` and one for `secondary tags`*: we use tree-like multi-task learning models, fine-tuning the last hidden state of the transformer differently for each subtask. The 5 first hidden layers from the backbone are common to all the tasks and the last hidden layer is specific to each task.  \n",
    "    <br>\n",
    "\n",
    "\n",
    "- **multi-task learning models**: \n",
    "    - `subpillars`: Each subtask corresponds to one different pillar $\\rightarrow$ We have 13 different sub-tasks for a total of 51 different tags.\n",
    "    - `secondary tags` we don't have a hierarchy, so the submodel is only a multi-task architecture $\\rightarrow$ We have 5 different tasks\n",
    "    - *benefits*:\n",
    "        - Share the encoding information, obtained from our transformer backbone, and then train different heads separately for different tasks\n",
    "        - Further anneal the problems due to data imbalance\n",
    "        - Deal with a big number of different tags in single models\n",
    "    \n",
    "<!-- We have 13 different subtasks for the subpillars model (Humanitarian Conditions, At Risk, Displacement, Covid-19, Humanitarian Access, Impact, Information And Communication, Shock/Event, Capacities & Response, Context, Casualties, Priority Interventions, Priority Needs) each of which then has its own final labels, which we want to predict. -->\n",
    "\n",
    "- **threshold tuning**: \n",
    "    - *objective: \n",
    "    1) After training the models on the training set we generate logit predictions on the vlidation set.  \n",
    "    2) and to optimize our results, we hypertune the threshold for each label to optimize the f1 score on the validation set. Therefore, each different label has a different threshold. This keeps the models from overtagging and helps adapt to the data imbalanceness problem.\n",
    "\n",
    "<div> <center><img src=\"./img/model.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center></div> \n",
    "<!-- ![image info](./img/model.png) -->\n",
    "\n",
    "\n",
    "Now let's get started with the serious stuff ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d78166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use pytorch and pytorch-lightning as main frameworks\n",
    "\n",
    "import torch\n",
    "import copy, os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "from typing import Optional, List\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import metrics\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from transformers import AdamW\n",
    "\n",
    "# importing some utilities methods\n",
    "from src.utils import *\n",
    "# loss\n",
    "from src.loss import FocalLoss\n",
    "# encoder embeddings pooling module\n",
    "from src.pooling import Pooling\n",
    "# pytorch Dataset custom dataset builder\n",
    "from src.data import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5be607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the classifier architecture\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        ids_each_level,\n",
    "        dropout_rate=0.3,\n",
    "        output_length=384,\n",
    "        dim_hidden_layer: int = 256,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ids_each_level = ids_each_level\n",
    "        self.l0 = AutoModel.from_pretrained(model_name_or_path)\n",
    "        self.pool = Pooling(word_embedding_dimension=output_length, pooling_mode=\"cls\")\n",
    "\n",
    "        self.LayerNorm_backbone = torch.nn.LayerNorm(output_length)\n",
    "        self.LayerNorm_specific_hidden = torch.nn.LayerNorm(dim_hidden_layer)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.specific_hidden_layer = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(output_length, dim_hidden_layer) for _ in ids_each_level\n",
    "        ])\n",
    "\n",
    "        self.output_layer = torch.nn.ModuleList([\n",
    "            torch.nn.Linear(dim_hidden_layer, len(id_one_level))\n",
    "            for id_one_level in ids_each_level\n",
    "        ])\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        \"\"\"\n",
    "        Multi-task forward.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        output = self.l0(\n",
    "            inputs[\"ids\"],\n",
    "            attention_mask=inputs[\"mask\"],\n",
    "        )\n",
    "        output = self.pool(\n",
    "            {\n",
    "                \"token_embeddings\": output.last_hidden_state,\n",
    "                \"attention_mask\": inputs[\"mask\"],\n",
    "            }\n",
    "        )[\"sentence_embedding\"]\n",
    "\n",
    "        last_hidden_states = [output.clone() for _ in self.ids_each_level]\n",
    "\n",
    "        heads = []\n",
    "        for i in range(len(self.ids_each_level)):\n",
    "            # specific hidden layer\n",
    "            output_tmp = F.selu(last_hidden_states[i])\n",
    "            output_tmp = self.dropout(output_tmp)\n",
    "            output_tmp = self.LayerNorm_specific_hidden(output_tmp)\n",
    "\n",
    "            # output layer\n",
    "            output_tmp = self.output_layer[i](output_tmp)\n",
    "            heads.append(output_tmp)\n",
    "\n",
    "        return heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f482890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch-lightining model class\n",
    "# as loss we use a BCE focal loss (details in ./src/loss.py)\n",
    "\n",
    "class Transformer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        train_params,\n",
    "        val_params,\n",
    "        tokenizer,\n",
    "        column_name,\n",
    "        multiclass,\n",
    "        learning_rate: float = 1e-5,\n",
    "        adam_epsilon: float = 1e-7,\n",
    "        warmup_steps: int = 500,\n",
    "        weight_decay: float = 0.1,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        dropout_rate: float = 0.3,\n",
    "        max_len: int = 512,\n",
    "        output_length: int = 384,\n",
    "        training_device: str = \"cuda\",\n",
    "        keep_neg_examples: bool = False,\n",
    "        dim_hidden_layer: int = 256,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.output_length = output_length\n",
    "        self.column_name = column_name\n",
    "        self.save_hyperparameters()\n",
    "        self.targets = train_dataset[\"target\"]\n",
    "        self.tagname_to_tagid = tagname_to_id(train_dataset[\"target\"])\n",
    "        self.num_labels = len(self.tagname_to_tagid)\n",
    "        self.get_first_level_ids()\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.model = Model(\n",
    "            model_name_or_path,\n",
    "            self.ids_each_level,\n",
    "            dropout_rate,\n",
    "            self.output_length,\n",
    "            dim_hidden_layer,\n",
    "        )\n",
    "        self.tokenizer = tokenizer\n",
    "        self.val_params = val_params\n",
    "\n",
    "        self.training_device = training_device\n",
    "\n",
    "        self.multiclass = multiclass\n",
    "        self.keep_neg_examples = keep_neg_examples\n",
    "\n",
    "        self.training_loader = self.get_loaders(\n",
    "            train_dataset, train_params, self.tagname_to_tagid, self.tokenizer, max_len\n",
    "        )\n",
    "        self.val_loader = self.get_loaders(\n",
    "            val_dataset, val_params, self.tagname_to_tagid, self.tokenizer, max_len\n",
    "        )\n",
    "        self.Focal_loss = FocalLoss()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        train_loss = self.get_loss(outputs, batch[\"targets\"])\n",
    "\n",
    "        self.log(\n",
    "            \"train_loss\", train_loss.item(), prog_bar=True, on_step=False, on_epoch=True\n",
    "        )\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        val_loss = self.get_loss(outputs, batch[\"targets\"])\n",
    "        self.log(\n",
    "            \"val_loss\",\n",
    "            val_loss,\n",
    "            on_step=False,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=False,\n",
    "        )\n",
    "\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        optimizer = AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.learning_rate,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "            eps=self.hparams.adam_epsilon,\n",
    "        )\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(\n",
    "            optimizer, \"min\", 0.5, patience=self.hparams.max_epochs // 6\n",
    "        )\n",
    "        scheduler = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",\n",
    "            \"frequency\": 1,\n",
    "            \"monitor\": \"val_loss\",\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.training_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_loader\n",
    "\n",
    "    def get_loaders(\n",
    "        self, dataset, params, tagname_to_tagid, tokenizer, max_len: int = 128\n",
    "    ):\n",
    "\n",
    "        set = CustomDataset(dataset, tagname_to_tagid, tokenizer, max_len)\n",
    "        loader = DataLoader(set, **params, pin_memory=True)\n",
    "        return loader\n",
    "\n",
    "    def get_loss(self, outputs, targets, only_pos: bool = False):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "            - outputs: raw outputs of model: List[List[float]]\n",
    "            - targets: groundtruth: List[int]\n",
    "            - only_pos: if True: do not do backpropagation for negative samples \n",
    "            (Negative samples are rows which do not contain any subatg)\n",
    "        OUTPUTS:\n",
    "            loss\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(self.ids_each_level) == 1:\n",
    "            return self.Focal_loss(outputs[0], targets)\n",
    "        else:\n",
    "            tot_loss = 0\n",
    "            for i_th_level in range(len(self.ids_each_level)):\n",
    "                ids_one_level = self.ids_each_level[i_th_level]\n",
    "                outputs_i_th_level = outputs[i_th_level]\n",
    "                targets_one_level = targets[:, ids_one_level]\n",
    "                \n",
    "                # main objective: for each level, if row contains only zeros, not to do backpropagation\n",
    "\n",
    "                if only_pos:\n",
    "                    mask_ids_neg_example = [\n",
    "                        not bool(int(torch.sum(one_row)))\n",
    "                        for one_row in targets_one_level\n",
    "                    ]\n",
    "                    outputs_i_th_level[mask_ids_neg_example, :] = 1e-8\n",
    "\n",
    "                tot_loss += self.Focal_loss(outputs_i_th_level, targets_one_level)\n",
    "\n",
    "            return tot_loss\n",
    "\n",
    "    def get_first_level_ids(self):\n",
    "        \"\"\"\n",
    "        function used to get different tasks and levels of classification\n",
    "            - What characterizes multitask data from non multitask data is the presence of the arrow '->'\n",
    "            Therefore, use it as characterization for multitask or not.\n",
    "            - When having a multitask scenario, we return a list of lists for ids\n",
    "            Example: We have 3 different tasks, each containing 2 subtasks\n",
    "            The output would be [[0, 1], [2, 3], [4, 5]]\n",
    "            This will be used later in models to get ids of each specific task.\n",
    "        \"\"\"\n",
    "        all_names = list(self.tagname_to_tagid.keys())\n",
    "        if np.all([\"->\" in name for name in all_names]):\n",
    "            first_level_names = list(\n",
    "                np.unique([name.split(\"->\")[0] for name in all_names])\n",
    "            )\n",
    "            self.ids_each_level = [\n",
    "                [i for i in range(len(all_names)) if name in all_names[i]]\n",
    "                for name in first_level_names\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            self.ids_each_level = [[i for i in range(len(all_names))]]\n",
    "\n",
    "    def custom_predict(\n",
    "        self, validation_dataset, testing=False, hypertuning_threshold: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        1) get raw predictions\n",
    "        2) postprocess them to output an output compatible with what we want in the inference\n",
    "        \"\"\"\n",
    "\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        if testing:\n",
    "            self.val_params[\"num_workers\"] = 0\n",
    "\n",
    "        validation_loader = self.get_loaders(\n",
    "            validation_dataset,\n",
    "            self.val_params,\n",
    "            self.tagname_to_tagid,\n",
    "            self.tokenizer,\n",
    "            self.max_len,\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            testing_device = \"cuda\"\n",
    "        else:\n",
    "            testing_device = \"cpu\"\n",
    "\n",
    "        self.to(testing_device)\n",
    "        self.eval()\n",
    "        self.freeze()\n",
    "        y_true = []\n",
    "        logit_predictions = []\n",
    "        indexes = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(\n",
    "                validation_loader,\n",
    "                total=len(validation_loader.dataset) // validation_loader.batch_size,\n",
    "            ):\n",
    "\n",
    "                if not testing:\n",
    "                    y_true.append(batch[\"targets\"].detach())\n",
    "                    indexes.append(batch[\"entry_id\"].detach())\n",
    "\n",
    "                logits = self(\n",
    "                    {\n",
    "                        \"ids\": batch[\"ids\"].to(testing_device),\n",
    "                        \"mask\": batch[\"mask\"].to(testing_device),\n",
    "                        \"token_type_ids\": batch[\"token_type_ids\"].to(testing_device),\n",
    "                    }\n",
    "                )\n",
    "                logits = torch.cat(logits, dim=1)  # have a matrix like in the beginning\n",
    "                logits_to_array = np.array([np.array(t) for t in logits.cpu()])\n",
    "                logit_predictions.append(logits_to_array)\n",
    "\n",
    "        logit_predictions = np.concatenate(logit_predictions)\n",
    "        logit_predictions = sigmoid(logit_predictions)\n",
    "\n",
    "        target_list = list(self.tagname_to_tagid.keys())\n",
    "        probabilities_dict = []\n",
    "        # postprocess predictions\n",
    "        for i in range(logit_predictions.shape[0]):\n",
    "\n",
    "            # Return predictions\n",
    "            row_logits = logit_predictions[i, :]\n",
    "\n",
    "            # Return probabilities\n",
    "            probabilities_item_dict = {}\n",
    "            for j in range(logit_predictions.shape[1]):\n",
    "                if hypertuning_threshold:\n",
    "                    probabilities_item_dict[target_list[j]] = row_logits[j]\n",
    "                else:\n",
    "                    probabilities_item_dict[target_list[j]] = (\n",
    "                        row_logits[j] / self.optimal_thresholds[target_list[j]]\n",
    "                    )\n",
    "\n",
    "            probabilities_dict.append(probabilities_item_dict)\n",
    "\n",
    "        if not testing:\n",
    "            y_true = np.concatenate(y_true)\n",
    "            indexes = np.concatenate(indexes)\n",
    "            return indexes, logit_predictions, y_true, probabilities_dict\n",
    "\n",
    "        else:\n",
    "            return probabilities_dict\n",
    "\n",
    "    def hypertune_threshold(self, beta_f1: float = 0.8):\n",
    "        \"\"\"\n",
    "        having the probabilities, loop over a list of thresholds to see which one:\n",
    "        1) yields the best results\n",
    "        2) without being an aberrant value (we use a runinng ean)\n",
    "        \"\"\"\n",
    "\n",
    "        data_for_threshold_tuning = self.val_loader.dataset.data\n",
    "        indexes, logit_predictions, y_true, _ = self.custom_predict(\n",
    "            data_for_threshold_tuning, hypertuning_threshold=True\n",
    "        )\n",
    "\n",
    "        thresholds_list = np.linspace(0.0, 1.0, 101)[::-1]\n",
    "        optimal_thresholds_dict = {}\n",
    "        optimal_scores = []\n",
    "        for ids_one_level in self.ids_each_level:\n",
    "            y_true_one_level = y_true[:, ids_one_level]\n",
    "            logit_preds_one_level = logit_predictions[:, ids_one_level]\n",
    "\n",
    "            for j in range(len(ids_one_level)):\n",
    "                scores = []\n",
    "                for thresh_tmp in thresholds_list:\n",
    "                    metric = self.get_metric(\n",
    "                        logit_preds_one_level[:, j],\n",
    "                        y_true_one_level[:, j],\n",
    "                        beta_f1,\n",
    "                        thresh_tmp,\n",
    "                    )\n",
    "                    scores.append(metric)\n",
    "\n",
    "                max_threshold = 0\n",
    "                max_score = 0\n",
    "                for i in range(1, len(scores) - 1):\n",
    "                    # take running mean to have smoother results\n",
    "                    score = np.mean(scores[i - 1 : i + 2])\n",
    "                    if score >= max_score:\n",
    "                        max_score = score\n",
    "                        max_threshold = thresholds_list[i]\n",
    "\n",
    "                optimal_scores.append(max_score)\n",
    "\n",
    "                optimal_thresholds_dict[\n",
    "                    list(self.tagname_to_tagid.keys())[ids_one_level[j]]\n",
    "                ] = max_threshold\n",
    "\n",
    "        self.optimal_thresholds = optimal_thresholds_dict\n",
    "\n",
    "        return np.mean(optimal_scores)\n",
    "\n",
    "    def get_metric(self, preds: List[float], groundtruth: List[int], beta_f1: float, threshold_tmp: float):\n",
    "        \"\"\"\n",
    "        INPUTS:\n",
    "            - preds: list of all probabilities for one specific subtag\n",
    "            - groundtruth: list of all predictions for one specific subtag\n",
    "            - beta_f1: beta value used for computing the beta f1 score\n",
    "            - threshold_tmp: threshold tested\n",
    "        \n",
    "        OUTPUTS:\n",
    "            - f1 / beta_f1 score for specific subtag for specific threshold\n",
    "        \"\"\"\n",
    "\n",
    "        column_pred = [\n",
    "            1 if one_logit > threshold_tmp else 0 for one_logit in preds\n",
    "        ]\n",
    "\n",
    "        if self.multiclass:\n",
    "            metric = metrics.fbeta_score(\n",
    "                groundtruth,\n",
    "                column_pred,\n",
    "                beta_f1,\n",
    "                average='binary', \n",
    "                pos_label=1\n",
    "            )\n",
    "        else:\n",
    "            metric = metrics.f1_score(\n",
    "                groundtruth,\n",
    "                column_pred,\n",
    "                average='binary', \n",
    "                pos_label=1\n",
    "            )\n",
    "        return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main class used to train model\n",
    "    \n",
    "class CustomTrainer:\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_dataset,\n",
    "        val_dataset,\n",
    "        training_column,\n",
    "        MODEL_DIR: str,\n",
    "        MODEL_NAME: str,\n",
    "        TOKENIZER_NAME: str,\n",
    "        dropout_rate: float,\n",
    "        train_params,\n",
    "        val_params,\n",
    "        gpu_nb: int,\n",
    "        MAX_EPOCHS: int,\n",
    "        weight_decay=0.02,\n",
    "        warmup_steps=500,\n",
    "        output_length=384,\n",
    "        max_len=150,\n",
    "        multiclass_bool=True,\n",
    "        keep_neg_examples_bool=False,\n",
    "        learning_rate=3e-5,\n",
    "        weighted_loss: str = \"sqrt\",\n",
    "        training_device: str = \"cuda\",\n",
    "        beta_f1: float = 0.8,\n",
    "        dim_hidden_layer: int = 256\n",
    "    ) -> None:\n",
    "        \n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.training_column = training_column\n",
    "        self.MODEL_DIR = MODEL_DIR\n",
    "        self.MODEL_NAME = MODEL_NAME\n",
    "        self.TOKENIZER_NAME = TOKENIZER_NAME\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.train_params = train_params\n",
    "        self.val_params = val_params\n",
    "        self.gpu_nb = gpu_nb\n",
    "        self.MAX_EPOCHS = MAX_EPOCHS\n",
    "        self.weight_decay = weight_decay\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.output_length = output_length\n",
    "        self.max_len = max_len\n",
    "        self.multiclass_bool = multiclass_bool\n",
    "        self.keep_neg_examples_bool = keep_neg_examples_bool\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weighted_loss = weighted_loss\n",
    "        self.training_device = training_device\n",
    "        self.beta_f1 = beta_f1\n",
    "        self.dim_hidden_layer = dim_hidden_layer\n",
    "\n",
    "    def train_model(self):\n",
    "        PATH_NAME = self.MODEL_DIR\n",
    "        if not os.path.exists(PATH_NAME):\n",
    "            os.makedirs(PATH_NAME)\n",
    "\n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=2, mode=\"min\"\n",
    "        )\n",
    "\n",
    "        checkpoint_callback_params = {\n",
    "            \"save_top_k\": 1,\n",
    "            \"verbose\": True,\n",
    "            \"monitor\": \"val_loss\",\n",
    "            \"mode\": \"min\",\n",
    "        }\n",
    "\n",
    "        FILENAME = \"model_\" + self.training_column\n",
    "        dirpath_pillars = str(PATH_NAME)\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=dirpath_pillars, filename=FILENAME, **checkpoint_callback_params\n",
    "        )\n",
    "\n",
    "        logger = TensorBoardLogger(\"lightning_logs\", name=FILENAME)\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            logger=logger,\n",
    "            callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "            progress_bar_refresh_rate=40,\n",
    "            profiler=\"simple\",\n",
    "            log_gpu_memory=True,\n",
    "            weights_summary=None,\n",
    "            gpus=self.gpu_nb,\n",
    "            precision=16,\n",
    "            accumulate_grad_batches=1,\n",
    "            max_epochs=self.MAX_EPOCHS,\n",
    "            gradient_clip_val=1,\n",
    "            gradient_clip_algorithm=\"norm\"\n",
    "        )\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.TOKENIZER_NAME)\n",
    "        \n",
    "        model = Transformer(\n",
    "            model_name_or_path=self.MODEL_NAME,\n",
    "            train_dataset=self.train_dataset,\n",
    "            val_dataset=self.val_dataset,\n",
    "            train_params=self.train_params,\n",
    "            val_params=self.val_params,\n",
    "            tokenizer=tokenizer,\n",
    "            column_name=self.training_column,\n",
    "            gpus=self.gpu_nb,\n",
    "            plugin=\"deepspeed_stage_3_offload\",\n",
    "            accumulate_grad_batches=1,\n",
    "            max_epochs=self.MAX_EPOCHS,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            weight_decay=self.weight_decay,\n",
    "            warmup_steps=self.warmup_steps,\n",
    "            output_length=self.output_length,\n",
    "            learning_rate=self.learning_rate,\n",
    "            multiclass=self.multiclass_bool,\n",
    "            weighted_loss=self.weighted_loss,\n",
    "            training_device=self.training_device,\n",
    "            keep_neg_examples=self.keep_neg_examples_bool,\n",
    "            dim_hidden_layer=self.dim_hidden_layer\n",
    "        )\n",
    "\n",
    "        trainer.fit(model)\n",
    "        model.train_f1_score = model.hypertune_threshold(self.beta_f1)\n",
    "\n",
    "        #delete data from models\n",
    "        del model.training_loader\n",
    "        del model.val_loader\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1823358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns selection to train\n",
    "# here we train only primary tags: sectors and pillars/sub-pillars (1D & 2D)\n",
    "\n",
    "columns = [\n",
    "    'excerpt', \n",
    "    'entry_id', \n",
    "    'subpillars', \n",
    "    'sectors' \n",
    "    #'secondary_tags' we don't train secondary tags here \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf697fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = {  \n",
    "    \"epochs\": 2,\n",
    "    \"train_batch_size\": 32,\n",
    "    \"val_batch_size\": 32,\n",
    "    \"max_len\": 512,\n",
    "    \"warmup_steps\": 10,\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"output_length\": 256,\n",
    "    \"nb_repetitions\": 1,\n",
    "    \"model_name\":  \"microsoft/xtremedistil-l6-h256-uncased\",\n",
    "    \"tokenizer_name\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
    "    \"beta_f1\": 0.7,   \n",
    "    \"n_gpu\": 1,\n",
    "    # set a directory name for trianed-models checkpoints\n",
    "    \"model_dir\": \"./models\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cc49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(dataset, training_columns, hyperparaments):\n",
    "        \n",
    "    models = {}\n",
    "    \n",
    "    train_params = {\n",
    "        \"batch_size\": hyperparaments[\"train_batch_size\"],\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4\n",
    "    }\n",
    "    \n",
    "    val_params = {\n",
    "        \"batch_size\": hyperparaments[\"val_batch_size\"],\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 4\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_nb = 1\n",
    "        training_device = \"cuda\"\n",
    "    else:\n",
    "        gpu_nb = 0\n",
    "        training_device = \"cpu\"\n",
    "        \n",
    "    print(f\"Training device: {training_device}\")\n",
    "        \n",
    "    for column in training_columns[2:]:\n",
    "        \n",
    "        #only for the severity tag, we have single label classification\n",
    "        multiclass_bool = column != \"severity\"\n",
    "        keep_neg_examples = True\n",
    "        \n",
    "        best_score = 0\n",
    "        iter_nb = 0\n",
    "\n",
    "        while best_score < 0.3 and iter_nb < hyperparaments[\"nb_repetitions\"]:\n",
    "\n",
    "            train_df, val_df = preprocess_df(\n",
    "                dataset, column, multiclass_bool, keep_neg_examples\n",
    "            )\n",
    "            print(f\"Data pre-processing. Train: {len(train_df)}, Validation: {len(val_df)}\")\n",
    "            \n",
    "            # for the purpose of our sample notebook we select a minimal number of epochs\n",
    "            max_epochs = 1\n",
    "\n",
    "            #depending on the training data size, we have different optimal training parameters\n",
    "            if len(train_df) > 120_000:\n",
    "                dropout_column = 0.2\n",
    "                weight_decay_col = 1e-3\n",
    "                dim_hidden_layer = 256\n",
    "                # max_epochs = 5\n",
    "                learning_rate = 8e-5\n",
    "\n",
    "            elif len(train_df) > 50_000:\n",
    "                dropout_column = 0.3\n",
    "                weight_decay_col = 3e-3\n",
    "                dim_hidden_layer = 256\n",
    "                # max_epochs = 8\n",
    "                learning_rate = 5e-5\n",
    "            else:\n",
    "                dropout_column = 0.3\n",
    "                weight_decay_col = 0.01\n",
    "                dim_hidden_layer = 256\n",
    "                # max_epochs = 12\n",
    "                learning_rate = 3e-5\n",
    "\n",
    "            #when the results are bad, lower learning rate and augment the weight decay\n",
    "            if iter_nb != 0:\n",
    "                learning_rate = learning_rate * 0.7\n",
    "                weight_decay_col = weight_decay_col * 2\n",
    "                \n",
    "            \n",
    "            model_trainer = CustomTrainer(\n",
    "                    train_dataset=train_df,\n",
    "                    val_dataset=val_df,\n",
    "                    MODEL_DIR=hyperparaments[\"model_dir\"],\n",
    "                    MODEL_NAME=hyperparaments[\"model_name\"],\n",
    "                    TOKENIZER_NAME=hyperparaments[\"tokenizer_name\"],\n",
    "                    training_column=column,\n",
    "                    gpu_nb=gpu_nb,\n",
    "                    train_params=train_params,\n",
    "                    val_params=val_params,\n",
    "                    MAX_EPOCHS=max_epochs,\n",
    "                    dropout_rate=dropout_column,\n",
    "                    weight_decay=weight_decay_col,\n",
    "                    learning_rate=learning_rate,\n",
    "                    max_len=hyperparaments[\"max_len\"],\n",
    "                    warmup_steps=hyperparaments[\"warmup_steps\"],\n",
    "                    output_length=hyperparaments[\"output_length\"],\n",
    "                    multiclass_bool=multiclass_bool,\n",
    "                    training_device=training_device,\n",
    "                    beta_f1=hyperparaments[\"beta_f1\"],\n",
    "                    dim_hidden_layer=dim_hidden_layer\n",
    "                )\n",
    "        \n",
    "            model = model_trainer.train_model()\n",
    "            model_score = model.train_f1_score\n",
    "            \n",
    "            if model_score > best_score:\n",
    "                best_score = model_score\n",
    "                models.update({column: model})\n",
    "\n",
    "            iter_nb += 1\n",
    "    \n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74121925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "\n",
    "models = run_training(dataset, training_columns=columns, hyperparaments=hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3aa228",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use resulting models in a second time loading from models checkpoints. Example:\n",
    "\n",
    "# cm_subpillars = Transformer.load_from_checkpoint(\"./models/model_subpillars.ckpt\")\n",
    "# cm_sectors = Transformer.load_from_checkpoint(\"./models/model_sectors.ckpt\")\n",
    "# cm_subpilllars.hypertune_threshold(beta_f1=hyp[\"beta_f1\"])\n",
    "# cm_sectors.hyptertune_threshold(beta_f1=hyp[\"beta_f1\"])\n",
    "\n",
    "# models = {\"subpillars\": cm_subpillars, \"sectors\": cm_sectors}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251a0f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(TEST_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54beedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = {}\n",
    "\n",
    "for tag_name, trained_model in models.items():\n",
    "\n",
    "    predictions_one_model = trained_model.custom_predict(\n",
    "        test_dataset[\"excerpt\"], testing=True\n",
    "    )\n",
    "    raw_predictions[tag_name] = predictions_one_model\n",
    "\n",
    "outputs = {\n",
    "    \"preds\": raw_predictions,\n",
    "    \"thresholds\": trained_model.optimal_thresholds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd48bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pillars_1d_tags = ['Covid-19',\n",
    " 'Casualties',\n",
    " 'Context',\n",
    " 'Displacement',\n",
    " 'Humanitarian Access',\n",
    " 'Shock/Event',\n",
    " 'Information And Communication']\n",
    "\n",
    "pillars_2d_tags = ['At Risk',\n",
    " 'Priority Interventions',\n",
    " 'Capacities & Response',\n",
    " 'Humanitarian Conditions',\n",
    " 'Impact',\n",
    " 'Priority Needs']\n",
    " \n",
    "def get_predictions_all(ratio_proba_threshold, \n",
    "    output_columns,\n",
    "    pillars_2d,\n",
    "    pillars_1d,\n",
    "    nb_entries: int, \n",
    "    ratio_nb: int):\n",
    "    \n",
    "    predictions = {column:[] for column in output_columns }\n",
    "    for entry_nb in range (nb_entries):\n",
    "        returns_sectors = ratio_proba_threshold['sectors'][entry_nb] \n",
    "        preds_sectors = get_preds_entry (returns_sectors, False, ratio_nb)  \n",
    "        predictions['sectors'].append(preds_sectors)\n",
    "        \n",
    "        returns_subpillars = ratio_proba_threshold['subpillars'][entry_nb] \n",
    "        \n",
    "        subpillars_2d_tags = {\n",
    "           key: value for key, value in returns_subpillars.items() if\\\n",
    "                key.split('->')[0] in pillars_2d\n",
    "        }\n",
    "        subpillars_1d_tags = {\n",
    "           key: value for key, value in returns_subpillars.items() if\\\n",
    "                key.split('->')[0] in pillars_1d\n",
    "        }\n",
    "        if len(preds_sectors)==0:\n",
    "            preds_2d = []\n",
    "        else:\n",
    "            preds_2d = get_preds_entry (subpillars_2d_tags, True, ratio_nb)\n",
    "        \n",
    "        predictions['subpillars_2d'].append(preds_2d)\n",
    "        \n",
    "        preds_1d = get_preds_entry (subpillars_1d_tags, False, ratio_nb)\n",
    "        predictions['subpillars_1d'].append(preds_1d)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def get_preds_entry (preds_column, return_at_least_one=True, ratio_nb=1, return_only_one=False):\n",
    "    preds_entry = [\n",
    "        sub_tag for sub_tag in list(preds_column.keys()) if preds_column[sub_tag]>ratio_nb\n",
    "    ]\n",
    "    if return_only_one:\n",
    "        preds_entry = [\n",
    "            sub_tag for sub_tag in list(preds_column.keys())\\\n",
    "                if preds_column[sub_tag]==max(list(preds_column.values()))\n",
    "        ]\n",
    "    if return_at_least_one:\n",
    "        if len(preds_entry)==0:\n",
    "            preds_entry = [\n",
    "                sub_tag for sub_tag in list(preds_column.keys())\\\n",
    "                    if preds_column[sub_tag]==max(list(preds_column.values()))\n",
    "            ]\n",
    "    return preds_entry\n",
    "\n",
    "final_preds = get_predictions_all(\n",
    "    outputs['preds'], #raw predictions returned\n",
    "    [ 'sectors', 'subpillars_2d', 'subpillars_1d'],\n",
    "    pillars_2d=pillars_2d_tags,\n",
    "    pillars_1d=pillars_1d_tags,\n",
    "    nb_entries=len(test_set), #total number of predictions to be postprocessed\n",
    "    ratio_nb=1)\n",
    "\n",
    "\n",
    "predictions_df = test_dataset[[\n",
    "    'excerpt', 'entry_id'\n",
    "]]\n",
    "\n",
    "predictions_df['sectors'] = final_preds['sectors']\n",
    "predictions_df['subpillars_2d'] = final_preds['subpillars_2d']\n",
    "predictions_df['subpillars_1d'] = final_preds['subpillars_1d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d793194f",
   "metadata": {},
   "source": [
    "Once you have the predictions it is easy to get the metrics you want against the targets in the test dataset.\n",
    "\n",
    "### Results\n",
    "For completeness we report here our results, obtained with a larger number of epochs and data.\n",
    "\n",
    "#### General results\n",
    "<div> <center><img src=\"./img/image.png\" alt=\"Drawing\" style=\"width: 600px;\"/></center></div> \n",
    "\n",
    "#### Specific Results\n",
    "**sectors**\n",
    "<div> <center><img src=\"./img/sectors_with_scores.png\" alt=\"Drawing\" style=\"width: 800px;\"/></center></div> \n",
    "\n",
    "**subpillars_2d**\n",
    "<div> <center><img src=\"./img/subpillars2d_with_scores.png\" alt=\"Drawing\" style=\"width: 900px;\"/></center></div> \n",
    "\n",
    "**subpillars_1d**\n",
    "<div> <center><img src=\"./img/subpillars1d_with_scores.png\" alt=\"Drawing\" style=\"width: 900px;\"/></center></div> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e667e8a",
   "metadata": {},
   "source": [
    "### Next steps in NLP:\n",
    "- `Humanitarian Backbone`: Create a humanitarian backbone using humanitarian data scraped from the web\n",
    "- `Automatic text extraction`: Having a raw document, being able to extract automatically relevant entries\n",
    "- `Natural Language Generation`: Write humanitarian Analysis articles using NLP using the tagged data\n",
    "- `Question Answering using tagged data`: Example: return number of people at risk for a specific project and a specific country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42842ed1",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- interactive slides? talk more about others? keep jupyter notebook if presentation? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1d6f5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
  },
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
