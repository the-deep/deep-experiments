{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd7d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random, string, os\n",
    "\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfaf29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "\n",
    "def custom_stratified_train_test_split(df: pd.DataFrame, ratios: dict[str, float]):\n",
    "    \"\"\"\n",
    "    custom function for stratified train test splitting\n",
    "    1) take unique sub-tags (example: ['Health'])\n",
    "    2) For each unique subtag:\n",
    "        i) take all indexes that have that specific subtag\n",
    "        ii) split them randomly to train, val and test sets\n",
    "    \"\"\"\n",
    "\n",
    "    train_ids = []\n",
    "    val_ids = []\n",
    "    test_ids = []\n",
    "\n",
    "    ratio_val_to_test = ratios['val'] / (1 - ratios['train'])\n",
    "    positive_df = df.copy()\n",
    "    positive_df[\"target\"] = positive_df.target.apply(str)\n",
    "    ids = positive_df.groupby(\"target\")[\"entry_id\"].agg(list).values\n",
    "    unique_ids = [list(np.unique(list_tmp)) for list_tmp in ids]\n",
    "\n",
    "    for ids_entry in unique_ids:\n",
    "\n",
    "        train_ids_entry = random.sample(\n",
    "            ids_entry, int(len(ids_entry) * ratios[\"train\"]) + 1\n",
    "        )\n",
    "\n",
    "        val_test_ids_entry = list(set(ids_entry) - set(train_ids_entry))\n",
    "\n",
    "        val_ids_entry = random.sample(\n",
    "            val_test_ids_entry, int(len(val_test_ids_entry) * ratio_val_to_test) \n",
    "        )\n",
    "        test_ids_entry = list(set(val_test_ids_entry) - set(val_ids_entry))\n",
    "\n",
    "        train_ids.append(train_ids_entry)\n",
    "        val_ids.append(val_ids_entry)\n",
    "        test_ids.append(test_ids_entry)\n",
    "\n",
    "    train_df = df[df.entry_id.isin(flatten(train_ids))]\n",
    "    val_df = df[df.entry_id.isin(flatten(val_ids))]\n",
    "    test_df = df[df.entry_id.isin(flatten(test_ids))]\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987f9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns = ['entry_id', 'project_id', 'lead_id', 'analysis_framework_id', 'excerpt', 'sectors', 'subpillars_1d', 'subpillars_2d', 'lang']\n",
    "dataset = pd.read_csv(\"./test_dataset.csv\")[important_columns]\n",
    "nb_samples = dataset.shape[0]\n",
    "\n",
    "\n",
    "classification_columns = ['sectors', 'subpillars_1d', 'subpillars_2d']\n",
    "for col in classification_columns:\n",
    "    dataset[col] = dataset[col].apply(literal_eval)\n",
    "    \n",
    "\n",
    "\n",
    "dataset[\"target\"] = dataset.apply(\n",
    "        lambda x: x.sectors + x.subpillars_1d + x.subpillars_2d, axis=1\n",
    "    )\n",
    "\n",
    "most_frequent_tags = list(dict(Counter(flatten(dataset['target'])).most_common(50)).keys())\n",
    "\n",
    "dataset[\"target\"] = dataset[\"target\"].apply(\n",
    "    lambda x: [tag for tag in x if tag in most_frequent_tags]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SELECT LANGUAGE\n",
    "\n",
    "d = dataset[dataset[\"lang\"]==\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e4ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = {'train': 0.7, 'val': 0.2, 'test': 0.1}\n",
    "train_df, val_df, test_df = custom_stratified_train_test_split(d, ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"subpillars\"] = dataset.apply(\n",
    "        lambda x: x.subpillars_1d + x.subpillars_2d, axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(x):\n",
    "    x = x.replace(\"\\n\", \" \")\n",
    "    x = x.translate(str.maketrans(' ', ' ', string.punctuation))\n",
    "    return x\n",
    "\n",
    "def prepare_fasttext_data(df, column, filename=None):\n",
    "    if not os.path.exists(\"./fast_data\"):\n",
    "        os.makedir(\"./fast_data\")\n",
    "    total = []\n",
    "    text = [c.strip().lower() for c in df.excerpt]\n",
    "    target = [[a.strip().lower().replace(\" \", \"*\") for a in c] if c else [\"NEGATIVE\"] for c in df[column].tolist()]\n",
    "    for x, y in zip(text, target):\n",
    "        x = clean_sentence(x)\n",
    "        labels = \" \".join([f\"__label__{c}\" for c in y])\n",
    "        total.append(\" \".join([labels, x]))\n",
    "        \n",
    "    a =  \"\\n\".join(total)\n",
    "    with open(f\"./fast_data/{filename}\", \"w+\") as f:\n",
    "        f.write(a)\n",
    "        \n",
    "def prepare_total_data(columns=[\"sectors\"]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386684e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_fasttext_data(train_df, \"sectors\", \"sectors.train\")\n",
    "prepare_fasttext_data(val_df, \"sectors\", \"sectors.val\")\n",
    "prepare_fasttext_data(test_df, \"sectors\", \"sectors.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3106f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"./fast_data/sectors.train\",\n",
    "                                  autotuneValidationFile=\"./fast_data/sectors.val\",\n",
    "                                  thread=1,\n",
    "                                  loss=\"ova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7075004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(filename, model, thres = 0.5):\n",
    "    tot = []\n",
    "    test = open(filename, \"r\").read().split(\"\\n\")\n",
    "    for s in test:\n",
    "        labels = [c for c in s.split() if \"__label__\" in c]\n",
    "        ss = \" \".join([c for c in s.split() if \"__label__\" not in c]).strip()\n",
    "        pred = model.predict(ss, k=-1, threshold=thres)\n",
    "        lab = [c.replace(\"__label__\",\"\").replace(\"*\", \" \") for c in pred[0] if not \"NEGATIVE\" in c]\n",
    "        tot.append(lab)\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3fcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = get_pred(\"./fast_data/sectors.val\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e438f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = [[c.lower() for c in a] for a in val_df.subpillars_1d]\n",
    "multi = MultiLabelBinarizer()\n",
    "multi.fit(target)\n",
    "target = multi.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(target, multi.transform(pred), target_names=multi.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "deepl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
