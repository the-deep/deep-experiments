{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb8eb979",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73551f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow\n",
    "!pip install torch==1.8.1\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install cloudpathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8386f54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:36.273295Z",
     "iopub.status.busy": "2021-07-12T10:07:36.271713Z",
     "iopub.status.idle": "2021-07-12T10:07:36.286959Z",
     "shell.execute_reply": "2021-07-12T10:07:36.285548Z",
     "shell.execute_reply.started": "2021-07-12T10:07:36.272960Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3bb4b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:36.600048Z",
     "iopub.status.busy": "2021-07-12T10:07:36.599397Z",
     "iopub.status.idle": "2021-07-12T10:07:39.383778Z",
     "shell.execute_reply": "2021-07-12T10:07:39.383424Z",
     "shell.execute_reply.started": "2021-07-12T10:07:36.599996Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22e37b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:39.384806Z",
     "iopub.status.busy": "2021-07-12T10:07:39.384691Z",
     "iopub.status.idle": "2021-07-12T10:07:39.500501Z",
     "shell.execute_reply": "2021-07-12T10:07:39.500106Z",
     "shell.execute_reply.started": "2021-07-12T10:07:39.384793Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0007d936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:39.501748Z",
     "iopub.status.busy": "2021-07-12T10:07:39.501630Z",
     "iopub.status.idle": "2021-07-12T10:07:39.533324Z",
     "shell.execute_reply": "2021-07-12T10:07:39.532994Z",
     "shell.execute_reply.started": "2021-07-12T10:07:39.501735Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe29333",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c73356b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:39.534136Z",
     "iopub.status.busy": "2021-07-12T10:07:39.534034Z",
     "iopub.status.idle": "2021-07-12T10:07:39.563216Z",
     "shell.execute_reply": "2021-07-12T10:07:39.562500Z",
     "shell.execute_reply.started": "2021-07-12T10:07:39.534124Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logged_model = 's3://deep-mlflow-artifact/2/011aa4a20c5d4783bf6ed2fc100813ff/artifacts/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48362853-8236-4825-8a0e-4fa118a144f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:39.564153Z",
     "iopub.status.busy": "2021-07-12T10:07:39.564043Z",
     "iopub.status.idle": "2021-07-12T10:07:39.591474Z",
     "shell.execute_reply": "2021-07-12T10:07:39.591034Z",
     "shell.execute_reply.started": "2021-07-12T10:07:39.564140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_model = 's3://deep-mlflow-artifact/2/4a9f23dfab7f4d9cbda9803a1754fe19/artifacts/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08448413",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba32e3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:39.733409Z",
     "iopub.status.busy": "2021-07-12T10:07:39.733257Z",
     "iopub.status.idle": "2021-07-12T10:07:39.934326Z",
     "shell.execute_reply": "2021-07-12T10:07:39.933916Z",
     "shell.execute_reply.started": "2021-07-12T10:07:39.733396Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "prefix = \"pl/example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3099f28f-a4e3-4e7e-b9af-2d3ec2c6aedb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-12T10:07:55.958928Z",
     "iopub.status.busy": "2021-07-12T10:07:55.957767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlflow.sagemaker.deploy(\n",
    "    'pl-example',\n",
    "    temp_model,\n",
    "    execution_role_arn=SAGEMAKER_ROLE_ARN,\n",
    "    image_url='961104659532.dkr.ecr.us-east-1.amazonaws.com/mlflow-pyfunc:latest',\n",
    "    region_name='us-east-1',\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    mode='replace'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbea3ce6-2636-4a1d-91c5-ec687debe21a",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfd9d2-b28f-4a14-a1d3-dcdf22a64a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be7123b-4ad0-4d11-beab-cc18b061a746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T12:46:37.218843Z",
     "iopub.status.busy": "2021-07-07T12:46:37.217857Z",
     "iopub.status.idle": "2021-07-07T12:46:37.441277Z",
     "shell.execute_reply": "2021-07-07T12:46:37.440859Z",
     "shell.execute_reply.started": "2021-07-07T12:46:37.218801Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "def query_endpoint(app_name, input_json):\n",
    "    client = boto3.session.Session().client(\"sagemaker-runtime\", 'us-east-1')\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "      EndpointName=app_name,\n",
    "      Body=input_json,\n",
    "      ContentType='application/json; format=pandas-split',\n",
    "    )\n",
    "    preds = response['Body'].read().decode(\"ascii\")\n",
    "    preds = json.loads(preds)\n",
    "    print(\"Received response: {}\".format(preds))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27bf123e-7eaf-4507-a100-6d625093cc89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T12:47:41.432179Z",
     "iopub.status.busy": "2021-07-07T12:47:41.430759Z",
     "iopub.status.idle": "2021-07-07T12:47:41.539583Z",
     "shell.execute_reply": "2021-07-07T12:47:41.539019Z",
     "shell.execute_reply.started": "2021-07-07T12:47:41.432073Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.DataFrame(\n",
    "    {\n",
    "        \"excerpt\": ['Agriculture is an important element of life','Young people in school are poor'],\n",
    "    }\n",
    ")\n",
    "input_json = test_data.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "df2f1f1e-f975-419f-b31b-b686f345e7a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T12:47:54.803755Z",
     "iopub.status.busy": "2021-07-07T12:47:54.803298Z",
     "iopub.status.idle": "2021-07-07T12:47:56.279740Z",
     "shell.execute_reply": "2021-07-07T12:47:56.278568Z",
     "shell.execute_reply.started": "2021-07-07T12:47:54.803706Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response: [{'0': 1}, {'0': 2}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'0': 1}, {'0': 2}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction1 = query_endpoint(app_name='prova7', input_json=input_json)\n",
    "prediction1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe70161-af21-458e-97cc-4e4709609609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55ea11-295f-4f1c-9727-8dc0f001839a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efe3cee0-993d-468e-8a0e-587a2755ba88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T08:18:31.507908Z",
     "iopub.status.busy": "2021-07-07T08:18:31.507370Z",
     "iopub.status.idle": "2021-07-07T08:20:56.204748Z",
     "shell.execute_reply": "2021-07-07T08:20:56.204090Z",
     "shell.execute_reply.started": "2021-07-07T08:18:31.507861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/07/07 10:20:55 INFO mlflow.sagemaker: launching docker image with path /var/folders/yk/w85rmwmj3bl1l522v_bw9xh80000gn/T/tmpwgtrgc44/model\n",
      "2021/07/07 10:20:55 INFO mlflow.sagemaker: executing: docker run -v /var/folders/yk/w85rmwmj3bl1l522v_bw9xh80000gn/T/tmpwgtrgc44/model:/opt/ml/model/ -p 5000:8080 -e MLFLOW_DEPLOYMENT_FLAVOR_NAME=python_function --rm mlflow-pyfunc serve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the python_function flavor for local serving!\n"
     ]
    },
    {
     "ename": "UnsupportedOperation",
     "evalue": "fileno",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperation\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bbede4e374e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogged_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.9/site-packages/mlflow/sagemaker/__init__.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(model_uri, port, image, flavor)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"--rm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"serve\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executing: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniversal_newlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sigterm_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    823\u001b[0m         (p2cread, p2cwrite,\n\u001b[1;32m    824\u001b[0m          \u001b[0mc2pread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m          errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;31m# We wrap OS handles *before* launching the child, otherwise a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_get_handles\u001b[0;34m(self, stdin, stdout, stderr)\u001b[0m\n\u001b[1;32m   1594\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m                 \u001b[0;31m# Assuming file-like object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1596\u001b[0;31m                 \u001b[0mc2pwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnsupportedOperation\u001b[0m: fileno"
     ]
    }
   ],
   "source": [
    "mlflow.sagemaker.run_local(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c891b4e-1c5f-4d60-9906-b36373c342b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a71488-1b45-4909-b6f5-952b2ac7a9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e81349-a784-40c1-9ad3-9f2cde697b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05b04b-7951-4675-9f4c-90cc77c92806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d71b6-0d9a-40fc-9b9f-da7c984aec82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707dc81-816a-4f81-8bdc-a5f34e250aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "516f111e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232127ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:41:05.647355Z",
     "start_time": "2021-06-02T09:41:05.627326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=str(SCRIPTS_PATH / 'examples/inference-sector-pl'),\n",
    "    role=role,\n",
    "    model_data=logged_model,\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5db4ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:41:05.666384Z",
     "start_time": "2021-06-02T09:41:05.648215Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge',\n",
    "    'ml.c4.xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a588c66-a847-403f-a56c-710ae58012d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = pd.read_pickle('/Users/stefano/Downloads/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79a9e8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-02T09:53:27.899912Z",
     "start_time": "2021-06-02T09:41:05.667240Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# set local_mode to False if you want to deploy on a remote\n",
    "# SageMaker instance\n",
    "\n",
    "local_mode = True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.p2.xlarge\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b5b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f4bbca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69627e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9255a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.pytorch import pickle_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923ea2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7210f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976cb27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../scripts/examples/sector-pl/')\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cdf435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.load('/Users/stefano/Downloads/model.pth', pickle_module=pickle_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f53717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "logged_model = 's3://deep-mlflow-artifact/2/9f216acf38d54ff6b185441a0f80e8b7/artifacts/model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pytorch.load_model(logged_model, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9c6431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset \n",
    "import pandas as pd\n",
    "\n",
    "class SectorsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.excerpt_text = dataframe[\"excerpt\"].tolist() if dataframe is not None else None\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode_example(self, excerpt_text: str, index=None, as_batch: bool = False):\n",
    "        inputs = self.tokenizer(\n",
    "            excerpt_text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        encoded = {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "        if as_batch:\n",
    "            return {\n",
    "                \"ids\": encoded[\"ids\"].unsqueeze(0),\n",
    "                \"mask\": encoded[\"mask\"].unsqueeze(0),\n",
    "                \"token_type_ids\": encoded[\"ids\"].unsqueeze(0),\n",
    "            }\n",
    "        return encoded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.excerpt_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        excerpt_text = str(self.excerpt_text[index])\n",
    "        return self.encode_example(excerpt_text, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59f6f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/paraphrase-mpnet-base-v2'\n",
    "data = pd.DataFrame({\n",
    "    'excerpt': ['hello, how', 'how, hello']\n",
    "})\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "dataset = SectorsDataset(data, tokenizer, 200)\n",
    "loaded_model.cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d24fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    preds = loaded_model.forward(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c602bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [preds, preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(torch.cat(a).argmax(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ef3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b21ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac7b653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loaded_model.predict(pd.DataFrame({'data': []}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c55435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b07f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
