{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbc383e-4d43-4c54-9397-708a64266073",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8642a2-16f7-4ca0-9179-3f1fe6cc3cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:20:12.842894Z",
     "iopub.status.busy": "2021-07-07T15:20:12.842476Z",
     "iopub.status.idle": "2021-07-07T15:20:12.848930Z",
     "shell.execute_reply": "2021-07-07T15:20:12.848218Z",
     "shell.execute_reply.started": "2021-07-07T15:20:12.842796Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c6d755-d815-485c-ad01-8ec2c9706239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T15:20:12.850937Z",
     "iopub.status.busy": "2021-07-07T15:20:12.850745Z",
     "iopub.status.idle": "2021-07-07T15:20:15.647341Z",
     "shell.execute_reply": "2021-07-07T15:20:15.646404Z",
     "shell.execute_reply.started": "2021-07-07T15:20:12.850917Z"
    }
   },
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6fc93-72b6-43e6-a572-a2cf2070fbe8",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f87238-4742-437c-a64d-aba4bd76b4b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:20:15.649032Z",
     "iopub.status.busy": "2021-07-07T15:20:15.648846Z",
     "iopub.status.idle": "2021-07-07T15:20:15.658081Z",
     "shell.execute_reply": "2021-07-07T15:20:15.657763Z",
     "shell.execute_reply.started": "2021-07-07T15:20:15.649016Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../../scripts/examples/sector-pl/')\n",
    "from data import SectorsDataset\n",
    "from model import SectorsTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b1c22ff-0103-4a09-85c7-829fa9bfb804",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:20:15.658781Z",
     "iopub.status.busy": "2021-07-07T15:20:15.658690Z",
     "iopub.status.idle": "2021-07-07T15:20:15.753196Z",
     "shell.execute_reply": "2021-07-07T15:20:15.752843Z",
     "shell.execute_reply.started": "2021-07-07T15:20:15.658768Z"
    }
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18d0f4-e057-4f9d-a32d-e6378f1499e0",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40d889f-ccfa-43e5-9fe6-156103fbac30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:20:15.753974Z",
     "iopub.status.busy": "2021-07-07T15:20:15.753878Z",
     "iopub.status.idle": "2021-07-07T15:20:15.764958Z",
     "shell.execute_reply": "2021-07-07T15:20:15.764522Z",
     "shell.execute_reply.started": "2021-07-07T15:20:15.753961Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name_or_path: str, num_labels: int):\n",
    "        super().__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(model_name_or_path)\n",
    "        self.l2 = torch.nn.Dropout(0.3)\n",
    "        self.l3 = torch.nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output = self.l1(\n",
    "            inputs[\"ids\"],\n",
    "            attention_mask=inputs[\"mask\"],\n",
    "        )\n",
    "        output = output.last_hidden_state\n",
    "        output = self.l2(output)\n",
    "        output = self.l3(output)\n",
    "        return output[:, 0, :]\n",
    "\n",
    "\n",
    "class SectorsTransformer(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name_or_path: str,\n",
    "        num_labels: int,\n",
    "        pred_threshold: float = 0.5,\n",
    "        learning_rate: float = 2e-5,\n",
    "        adam_epsilon: float = 1e-8,\n",
    "        warmup_steps: int = 0,\n",
    "        weight_decay: float = 0.0,\n",
    "        train_batch_size: int = 32,\n",
    "        eval_batch_size: int = 32,\n",
    "        eval_splits: Optional[list] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = Model(model_name_or_path, num_labels)\n",
    "        self.pred_threshold = pred_threshold\n",
    "\n",
    "        self.f1_score_train = torchmetrics.F1(\n",
    "            num_classes=2,\n",
    "            threshold=0.5,\n",
    "            average=\"macro\",\n",
    "            mdmc_average=\"samplewise\",\n",
    "            ignore_index=None,\n",
    "            top_k=None,\n",
    "            multiclass=True,\n",
    "            compute_on_step=True,\n",
    "            dist_sync_on_step=False,\n",
    "            process_group=None,\n",
    "            dist_sync_fn=None,\n",
    "        )\n",
    "\n",
    "        self.f1_score_val = torchmetrics.F1(\n",
    "            num_classes=2,\n",
    "            threshold=0.5,\n",
    "            average=\"macro\",\n",
    "            mdmc_average=\"samplewise\",\n",
    "            ignore_index=None,\n",
    "            top_k=None,\n",
    "            multiclass=True,\n",
    "            compute_on_step=True,\n",
    "            dist_sync_on_step=False,\n",
    "            process_group=None,\n",
    "            dist_sync_fn=None,\n",
    "        )\n",
    "\n",
    "    @auto_move_data\n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, batch[\"targets\"])\n",
    "\n",
    "        self.f1_score_train(torch.sigmoid(outputs), batch[\"targets\"].to(dtype=torch.long))\n",
    "        self.log(\"train_f1\", self.f1_score_train, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        outputs = self(batch)\n",
    "        val_loss = F.binary_cross_entropy_with_logits(outputs, batch[\"targets\"])\n",
    "\n",
    "        self.f1_score_val(torch.sigmoid(outputs), batch[\"targets\"].to(dtype=torch.long))\n",
    "        self.log(\n",
    "            \"val_f1\",\n",
    "            self.f1_score_val,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=False,\n",
    "        )\n",
    "\n",
    "        self.log(\"val_loss\", val_loss, on_step=True, on_epoch=True, prog_bar=True, logger=False)\n",
    "        return {\"val_loss\": val_loss}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        logits = self(batch)\n",
    "        preds = torch.sigmoid(logits) > 0.5\n",
    "        return {\"preds\": preds, \"targets_i\": batch[\"targets\"]}\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        output = self(batch)\n",
    "        return {\"logits\": output}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=self.hparams.learning_rate,\n",
    "            eps=self.hparams.adam_epsilon,\n",
    "        )\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=1000,  # CHANGE ME\n",
    "        )\n",
    "        scheduler = {\"scheduler\": scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [optimizer], [scheduler]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae2fbcb-0e9b-49f7-a4a8-30727be83303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:46.249651Z",
     "iopub.status.busy": "2021-07-07T15:24:46.247351Z",
     "iopub.status.idle": "2021-07-07T15:24:46.308501Z",
     "shell.execute_reply": "2021-07-07T15:24:46.307955Z",
     "shell.execute_reply.started": "2021-07-07T15:24:46.249477Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SectorsDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, class_to_id=None, max_len=200):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.excerpt_text = list(dataframe[\"excerpt\"])\n",
    "        self.targets = list(dataframe[\"sectors\"]) if \"sectors\" in dataframe.columns else None\n",
    "        self.class_to_id = class_to_id\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode_example(self, excerpt_text: str, index=None):\n",
    "        # excerpt_text = \" \".join(excerpt_text.split())\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            excerpt_text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        encoded = {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "        if self.targets:\n",
    "            target_indices = [\n",
    "                self.class_to_id[target]\n",
    "                for target in self.targets[index]\n",
    "                if target in self.class_to_id\n",
    "            ]\n",
    "            targets = np.zeros(len(self.class_to_id), dtype=np.int)\n",
    "            targets[target_indices] = 1\n",
    "\n",
    "            encoded[\"targets\"] = torch.tensor(targets, dtype=torch.float32) if targets is not None else None\n",
    "\n",
    "        return encoded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.excerpt_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        excerpt_text = str(self.excerpt_text[index])\n",
    "        return self.encode_example(excerpt_text, index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ddc4935-5672-4099-bf12-ae1f0adba6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:48.331578Z",
     "iopub.status.busy": "2021-07-07T15:24:48.331236Z",
     "iopub.status.idle": "2021-07-07T15:24:48.337244Z",
     "shell.execute_reply": "2021-07-07T15:24:48.335292Z",
     "shell.execute_reply.started": "2021-07-07T15:24:48.331544Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'sentence-transformers/paraphrase-mpnet-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04053433-db6a-4dc7-ba7c-29513709d604",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:48.464018Z",
     "iopub.status.busy": "2021-07-07T15:24:48.463582Z",
     "iopub.status.idle": "2021-07-07T15:24:49.360728Z",
     "shell.execute_reply": "2021-07-07T15:24:49.359942Z",
     "shell.execute_reply.started": "2021-07-07T15:24:48.463977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(LATEST_DATA_PATH / \"data_v0.5_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13e247ea-5fb4-4c39-b9c1-d86bd16d65a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:49.361840Z",
     "iopub.status.busy": "2021-07-07T15:24:49.361723Z",
     "iopub.status.idle": "2021-07-07T15:24:49.364075Z",
     "shell.execute_reply": "2021-07-07T15:24:49.363750Z",
     "shell.execute_reply.started": "2021-07-07T15:24:49.361828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_to_id = {class_: i for i, class_ in enumerate(SECTORS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff239f2-664a-4587-9240-059dc50878e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:49.365141Z",
     "iopub.status.busy": "2021-07-07T15:24:49.365036Z",
     "iopub.status.idle": "2021-07-07T15:24:51.992071Z",
     "shell.execute_reply": "2021-07-07T15:24:51.991643Z",
     "shell.execute_reply.started": "2021-07-07T15:24:49.365129Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "training_set = SectorsDataset(\n",
    "    dataframe=train_df, tokenizer=tokenizer, class_to_id=class_to_id, max_len=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7aa1744-7c01-4114-89cc-1d1a6a5318e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:51.993088Z",
     "iopub.status.busy": "2021-07-07T15:24:51.992981Z",
     "iopub.status.idle": "2021-07-07T15:24:51.996993Z",
     "shell.execute_reply": "2021-07-07T15:24:51.996640Z",
     "shell.execute_reply.started": "2021-07-07T15:24:51.993075Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {\"batch_size\": 4, \"shuffle\": True, \"num_workers\": 0}\n",
    "training_loader = DataLoader(training_set, **train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17bb755d-9462-4b8e-be66-3201e42ce7b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:51.997753Z",
     "iopub.status.busy": "2021-07-07T15:24:51.997656Z",
     "iopub.status.idle": "2021-07-07T15:24:52.019009Z",
     "shell.execute_reply": "2021-07-07T15:24:52.018583Z",
     "shell.execute_reply.started": "2021-07-07T15:24:51.997740Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-2974c503aa57>:36: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets = np.zeros(len(self.class_to_id), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_set[0]['targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df701a43-2b9d-47f6-9e53-59d416ebf712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-07T15:24:52.020854Z",
     "iopub.status.busy": "2021-07-07T15:24:52.020720Z",
     "iopub.status.idle": "2021-07-07T15:25:25.819115Z",
     "shell.execute_reply": "2021-07-07T15:25:25.816336Z",
     "shell.execute_reply.started": "2021-07-07T15:24:52.020841Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name           | Type  | Params\n",
      "-----------------------------------------\n",
      "0 | model          | Model | 109 M \n",
      "1 | f1_score_train | F1    | 0     \n",
      "-----------------------------------------\n",
      "109 M     Trainable params\n",
      "0         Non-trainable params\n",
      "109 M     Total params\n",
      "437.980   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c188c5f409d4d9b8e15c1a1d4ee67d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-2974c503aa57>:36: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  targets = np.zeros(len(self.class_to_id), dtype=np.int)\n",
      "/Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=0,\n",
    "    max_epochs=1,\n",
    ")\n",
    "model = SectorsTransformer(\n",
    "    model_name,\n",
    "    len(class_to_id),\n",
    ")\n",
    "trainer.fit(model, training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3ca92-521b-4fa3-bd28-c46ca9c32767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
