{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:03.040075Z",
     "iopub.status.busy": "2021-07-06T19:39:03.039917Z",
     "iopub.status.idle": "2021-07-06T19:39:08.628685Z",
     "shell.execute_reply": "2021-07-06T19:39:08.627820Z",
     "shell.execute_reply.started": "2021-07-06T19:39:03.040031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (1.18.0)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (3.17.3)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (0.18.2)\n",
      "Requirement already satisfied: docker>=4.0.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (5.0.0)\n",
      "Requirement already satisfied: numpy in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.20.3)\n",
      "Requirement already satisfied: pytz in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (2021.1)\n",
      "Requirement already satisfied: entrypoints in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (0.4.1)\n",
      "Requirement already satisfied: querystring-parser in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: pandas in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: alembic<=1.4.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.4.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (2.25.1)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (3.1.17)\n",
      "Requirement already satisfied: packaging in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (20.9)\n",
      "Requirement already satisfied: gunicorn in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: click>=7.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (0.14.3)\n",
      "Requirement already satisfied: Flask in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (2.0.1)\n",
      "Requirement already satisfied: cloudpickle in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.6.0)\n",
      "Requirement already satisfied: sqlalchemy in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (1.4.18)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from mlflow) (5.4.1)\n",
      "Requirement already satisfied: python-editor>=0.3 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from alembic<=1.4.1->mlflow) (1.0.4)\n",
      "Requirement already satisfied: Mako in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from alembic<=1.4.1->mlflow) (1.1.4)\n",
      "Requirement already satisfied: python-dateutil in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from docker>=4.0.0->mlflow) (1.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests>=2.17.3->mlflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests>=2.17.3->mlflow) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests>=2.17.3->mlflow) (4.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from sqlalchemy->mlflow) (1.1.0)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from Flask->mlflow) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from Jinja2>=3.0->Flask->mlflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from gunicorn->mlflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: prometheus-client in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from prometheus-flask-exporter->mlflow) (0.11.0)\n",
      "Requirement already satisfied: torch==1.8.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from torch==1.8.1) (3.10.0.0)\n",
      "Requirement already satisfied: numpy in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from torch==1.8.1) (1.20.3)\n",
      "Requirement already satisfied: pytorch-lightning in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (4.61.0)\n",
      "Requirement already satisfied: pyDeprecate==0.3.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (0.3.0)\n",
      "Requirement already satisfied: torch>=1.4 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (1.8.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: torchmetrics>=0.2.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (0.3.2)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (2.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.4.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (2021.6.0)\n",
      "Requirement already satisfied: packaging in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pytorch-lightning) (20.9)\n",
      "Requirement already satisfied: requests in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (2.25.1)\n",
      "Requirement already satisfied: aiohttp in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (3.7.4.post0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.12.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.30.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.4)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.38.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from torch>=1.4->pytorch-lightning) (3.10.0.0)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (1.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from packaging->pytorch-lightning) (2.4.7)\n",
      "Requirement already satisfied: transformers in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (4.6.1)\n",
      "Requirement already satisfied: sacremoses in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (4.61.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/stefano/miniconda3/envs/deep/lib/python3.9/site-packages (from sacremoses->transformers) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow\n",
    "!pip install torch==1.8.1\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:08.630948Z",
     "iopub.status.busy": "2021-07-06T19:39:08.630715Z",
     "iopub.status.idle": "2021-07-06T19:39:08.634881Z",
     "shell.execute_reply": "2021-07-06T19:39:08.634378Z",
     "shell.execute_reply.started": "2021-07-06T19:39:08.630920Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:08.636088Z",
     "iopub.status.busy": "2021-07-06T19:39:08.635937Z",
     "iopub.status.idle": "2021-07-06T19:39:10.978158Z",
     "shell.execute_reply": "2021-07-06T19:39:10.977813Z",
     "shell.execute_reply.started": "2021-07-06T19:39:08.636068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:10.978876Z",
     "iopub.status.busy": "2021-07-06T19:39:10.978783Z",
     "iopub.status.idle": "2021-07-06T19:39:11.074679Z",
     "shell.execute_reply": "2021-07-06T19:39:11.074317Z",
     "shell.execute_reply.started": "2021-07-06T19:39:10.978863Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:11.075440Z",
     "iopub.status.busy": "2021-07-06T19:39:11.075344Z",
     "iopub.status.idle": "2021-07-06T19:39:11.104456Z",
     "shell.execute_reply": "2021-07-06T19:39:11.104127Z",
     "shell.execute_reply.started": "2021-07-06T19:39:11.075427Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:11.105163Z",
     "iopub.status.busy": "2021-07-06T19:39:11.105062Z",
     "iopub.status.idle": "2021-07-06T19:39:12.746570Z",
     "shell.execute_reply": "2021-07-06T19:39:12.746218Z",
     "shell.execute_reply.started": "2021-07-06T19:39:11.105151Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(LATEST_DATA_PATH / \"data_v0.5_train.csv\")\n",
    "val_dataset = pd.read_csv(LATEST_DATA_PATH / \"data_v0.5_val.csv\")\n",
    "##\n",
    "train_dataset[\"sectors\"] = train_dataset[\"sectors\"].apply(literal_eval)\n",
    "val_dataset[\"sectors\"] = val_dataset[\"sectors\"].apply(literal_eval)\n",
    "##\n",
    "sector_set = set()\n",
    "for sectors_i in train_dataset[\"sectors\"]:\n",
    "    sector_set.update(sectors_i)\n",
    "sectorname_to_sectorid = {sector:i for i, sector in enumerate(list(sorted(sector_set)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:12.749894Z",
     "iopub.status.busy": "2021-07-06T19:39:12.749809Z",
     "iopub.status.idle": "2021-07-06T19:39:12.864045Z",
     "shell.execute_reply": "2021-07-06T19:39:12.863661Z",
     "shell.execute_reply.started": "2021-07-06T19:39:12.749882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = 'arn:aws:iam::961104659532:role/service-role/AmazonSageMaker-ExecutionRole-20210519T102514'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:12.864880Z",
     "iopub.status.busy": "2021-07-06T19:39:12.864785Z",
     "iopub.status.idle": "2021-07-06T19:39:18.408534Z",
     "shell.execute_reply": "2021-07-06T19:39:18.407150Z",
     "shell.execute_reply.started": "2021-07-06T19:39:12.864867Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = True\n",
    "\n",
    "if sample:\n",
    "    train_dataset = train_dataset.sample(100)\n",
    "    val_dataset = val_dataset.sample(100)\n",
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-test\"\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "\n",
    "train_dataset.to_pickle(train_path, protocol=4)\n",
    "val_dataset.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:18.411350Z",
     "iopub.status.busy": "2021-07-06T19:39:18.410870Z",
     "iopub.status.idle": "2021-07-06T19:39:18.474153Z",
     "shell.execute_reply": "2021-07-06T19:39:18.473556Z",
     "shell.execute_reply.started": "2021-07-06T19:39:18.411291Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.303558Z",
     "start_time": "2021-06-09T08:31:43.285723Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:18.475179Z",
     "iopub.status.busy": "2021-07-06T19:39:18.475048Z",
     "iopub.status.idle": "2021-07-06T19:39:18.507472Z",
     "shell.execute_reply": "2021-07-06T19:39:18.507104Z",
     "shell.execute_reply.started": "2021-07-06T19:39:18.475162Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S3Path('s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-06-21-39-12-922-test')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:18.508211Z",
     "iopub.status.busy": "2021-07-06T19:39:18.508112Z",
     "iopub.status.idle": "2021-07-06T19:39:18.664444Z",
     "shell.execute_reply": "2021-07-06T19:39:18.664058Z",
     "shell.execute_reply.started": "2021-07-06T19:39:18.508199Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters={\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
    "    'experiment_name': 'pl_test',\n",
    "    'max_len': 200,\n",
    "    'epochs': 1,\n",
    "    'train_batch_size': 16,\n",
    "    'eval_batch_size': 16,\n",
    "    'model_name': 'sentence-transformers/paraphrase-mpnet-base-v2',\n",
    "    'classes': str(SECTORS)\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir=str(SCRIPTS_EXAMPLES_PATH / 'sector-pl'),\n",
    "    output_path=str(DEV_BUCKET / 'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:18.665074Z",
     "iopub.status.busy": "2021-07-06T19:39:18.664982Z",
     "iopub.status.idle": "2021-07-06T19:39:18.691014Z",
     "shell.execute_reply": "2021-07-06T19:39:18.690692Z",
     "shell.execute_reply.started": "2021-07-06T19:39:18.665062Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-06T19:39:18.691712Z",
     "iopub.status.busy": "2021-07-06T19:39:18.691608Z",
     "iopub.status.idle": "2021-07-06T19:48:58.470334Z",
     "shell.execute_reply": "2021-07-06T19:48:58.468856Z",
     "shell.execute_reply.started": "2021-07-06T19:39:18.691699Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-06 19:39:21 Starting - Starting the training job...\n",
      "2021-07-06 19:39:44 Starting - Launching requested ML instancesProfilerReport-1625600358: InProgress\n",
      "......\n",
      "2021-07-06 19:40:45 Starting - Preparing the instances for training......\n",
      "2021-07-06 19:42:05 Downloading - Downloading input data...\n",
      "2021-07-06 19:42:31 Training - Downloading the training image.....................\n",
      "2021-07-06 19:46:26 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-06 19:46:21,704 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-06 19:46:21,733 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-06 19:46:27,969 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-06 19:46:28,411 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.18.0\n",
      "  Downloading mlflow-1.18.0-py3-none-any.whl (14.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.6.1\n",
      "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.3\n",
      "  Downloading pytorch_lightning-1.3.3-py3-none-any.whl (806 kB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.3.2\n",
      "  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\u001b[0m\n",
      "\u001b[34mCollecting smdebug==1.0.10\n",
      "  Downloading smdebug-1.0.10-py2.py3-none-any.whl (269 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (3.17.1)\u001b[0m\n",
      "\u001b[34mCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.17.3 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting Flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (20.9)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.20-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 1)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (4.51.0)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.7.6-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.1->-r requirements.txt (line 2)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.4.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (2021.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug==1.0.10->-r requirements.txt (line 5)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.6/site-packages (from smdebug==1.0.10->-r requirements.txt (line 5)) (1.17.85)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow==1.18.0->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.85 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug==1.0.10->-r requirements.txt (line 5)) (1.20.85)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug==1.0.10->-r requirements.txt (line 5)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.10.32->smdebug==1.0.10->-r requirements.txt (line 5)) (0.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.21.0,>=1.20.85->boto3>=1.10.32->smdebug==1.0.10->-r requirements.txt (line 5)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.18.0->-r requirements.txt (line 1)) (0.8.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.18.0->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=4.0.0->mlflow==1.18.0->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.0 in /opt/conda/lib/python3.6/site-packages (from gitpython>=2.1.0->mlflow==1.18.0->-r requirements.txt (line 1)) (3.10.0.0)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug==1.0.10->-r requirements.txt (line 5)) (0.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.17.3->mlflow==1.18.0->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.17.3->mlflow==1.18.0->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.17.3->mlflow==1.18.0->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy->mlflow==1.18.0->-r requirements.txt (line 1)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.38.1-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.1-py2.py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\u001b[0m\n",
      "\u001b[34m  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning==1.3.3->-r requirements.txt (line 3)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.18.0->-r requirements.txt (line 1)) (3.0.1)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=3.0->Flask->mlflow==1.18.0->-r requirements.txt (line 1)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.1->-r requirements.txt (line 2)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->mlflow==1.18.0->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting prometheus_client\n",
      "  Downloading prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.1->-r requirements.txt (line 2)) (1.0.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: alembic, databricks-cli, idna-ssl, prometheus-flask-exporter\n",
      "  Building wheel for alembic (setup.py): started\n",
      "  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=4f8ce6322e723f7201a390147c945dbfb9ac02a9a677f095af62e02347322567\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
      "  Building wheel for databricks-cli (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100556 sha256=0a824113bac9f62f9e12434ed50b8c683e1aeb56978da7d921c584c033a89bd1\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/88/95/bd32d0e2dc0cf30e55574faab3118df2bb9ebebc60978c147b\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=ca53e25c94c5847bbfa420868643619bd3c278bb6cebead8f6aabcf7567ea4d2\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17398 sha256=afa291ca609b0f8b7a67ae4867ca8d2509f5cc1944ca1c770e03ec3b21ce776f\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/77/e8/3ca90b66243b0b58d5a5323a3da02cc8c5daf1de7a65141701\u001b[0m\n",
      "\u001b[34mSuccessfully built alembic databricks-cli idna-ssl prometheus-flask-exporter\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pyasn1-modules, oauthlib, multidict, cachetools, yarl, smmap, requests-oauthlib, itsdangerous, idna-ssl, google-auth, async-timeout, tensorboard-plugin-wit, sqlalchemy, regex, python-editor, prometheus-client, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, Flask, filelock, aiohttp, absl-py, torchmetrics, tokenizers, tensorboard, sqlparse, sacremoses, querystring-parser, pyDeprecate, prometheus-flask-exporter, huggingface-hub, gunicorn, gitpython, entrypoints, docker, databricks-cli, alembic, transformers, smdebug, pytorch-lightning, mlflow\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.9\u001b[0m\n",
      "\u001b[34m    Uninstalling smdebug-1.0.9:\n",
      "      Successfully uninstalled smdebug-1.0.9\u001b[0m\n",
      "\u001b[34mSuccessfully installed Flask-2.0.1 Mako-1.1.4 absl-py-0.13.0 aiohttp-3.7.4.post0 alembic-1.4.1 async-timeout-3.0.1 cachetools-4.2.2 databricks-cli-0.14.3 docker-5.0.0 entrypoints-0.3 filelock-3.0.12 gitdb-4.0.7 gitpython-3.1.18 google-auth-1.32.1 google-auth-oauthlib-0.4.4 grpcio-1.38.1 gunicorn-20.1.0 huggingface-hub-0.0.8 idna-ssl-1.1.0 itsdangerous-2.0.1 markdown-3.3.4 mlflow-1.18.0 multidict-5.1.0 oauthlib-3.1.1 prometheus-client-0.11.0 prometheus-flask-exporter-0.18.2 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 python-editor-1.0.4 pytorch-lightning-1.3.3 querystring-parser-1.2.4 regex-2021.7.6 requests-oauthlib-1.3.0 sacremoses-0.0.45 smdebug-1.0.10 smmap-4.0.0 sqlalchemy-1.4.20 sqlparse-0.4.1 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tokenizers-0.10.3 torchmetrics-0.3.2 transformers-4.6.1 yarl-1.6.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-06 19:46:52,394 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"experiment_name\": \"pl_test\",\n",
      "        \"classes\": \"['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH']\",\n",
      "        \"eval_batch_size\": 16,\n",
      "        \"max_len\": 200,\n",
      "        \"train_batch_size\": 16,\n",
      "        \"model_name\": \"sentence-transformers/paraphrase-mpnet-base-v2\",\n",
      "        \"epochs\": 1,\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2021-07-06-21-39-12-922-test\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-06-21-39-12-922-test/pytorch-2021-07-06-21-39-12-922-test/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"classes\":\"['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH']\",\"epochs\":1,\"eval_batch_size\":16,\"experiment_name\":\"pl_test\",\"max_len\":200,\"model_name\":\"sentence-transformers/paraphrase-mpnet-base-v2\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_batch_size\":16}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-06-21-39-12-922-test/pytorch-2021-07-06-21-39-12-922-test/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"classes\":\"['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH']\",\"epochs\":1,\"eval_batch_size\":16,\"experiment_name\":\"pl_test\",\"max_len\":200,\"model_name\":\"sentence-transformers/paraphrase-mpnet-base-v2\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_batch_size\":16},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2021-07-06-21-39-12-922-test\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-06-21-39-12-922-test/pytorch-2021-07-06-21-39-12-922-test/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--classes\",\"['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH']\",\"--epochs\",\"1\",\"--eval_batch_size\",\"16\",\"--experiment_name\",\"pl_test\",\"--max_len\",\"200\",\"--model_name\",\"sentence-transformers/paraphrase-mpnet-base-v2\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"--train_batch_size\",\"16\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=pl_test\u001b[0m\n",
      "\u001b[34mSM_HP_CLASSES=['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH']\u001b[0m\n",
      "\u001b[34mSM_HP_EVAL_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=200\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=sentence-transformers/paraphrase-mpnet-base-v2\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --classes ['Agriculture', 'Cross', 'Education', 'Food Security', 'Health', 'Livelihoods', 'Logistics', 'Nutrition', 'Protection', 'Shelter', 'WASH'] --epochs 1 --eval_batch_size 16 --experiment_name pl_test --max_len 200 --model_name sentence-transformers/paraphrase-mpnet-base-v2 --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_batch_size 16\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s][2021-07-06 19:47:15.240 algo-1:55 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.286 algo-1:55 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.287 algo-1:55 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.288 algo-1:55 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.289 algo-1:55 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.289 algo-1:55 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.313 algo-1:55 INFO hook.py:594] name:model.l1.embeddings.word_embeddings.weight count_params:23444736\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.313 algo-1:55 INFO hook.py:594] name:model.l1.embeddings.position_embeddings.weight count_params:394752\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.313 algo-1:55 INFO hook.py:594] name:model.l1.embeddings.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.embeddings.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.314 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.0.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.315 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.316 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.1.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.317 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.2.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.318 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.319 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.3.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.320 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.321 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.4.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.322 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.323 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.5.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.324 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.6.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.325 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.326 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.7.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.327 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.328 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.8.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.329 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.9.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.330 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.331 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.10.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.q.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.q.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.k.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.k.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.v.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.332 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.v.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.o.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.attn.o.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.attention.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.intermediate.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.intermediate.dense.bias count_params:3072\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.output.dense.weight count_params:2359296\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.output.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.333 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.output.LayerNorm.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l1.encoder.layer.11.output.LayerNorm.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l1.encoder.relative_attention_bias.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l1.pooler.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l1.pooler.dense.bias count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l3.weight count_params:8448\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:594] name:model.l3.bias count_params:11\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.334 algo-1:55 INFO hook.py:596] Total Trainable Params: 109494923\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.335 algo-1:55 INFO hook.py:423] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-07-06 19:47:15.337 algo-1:55 INFO hook.py:486] Hook is writing from the hook with pid: 55\n",
      "\u001b[0m\n",
      "\u001b[34m#015Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]#015                                                                      #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/14 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/14 [00:00<?, ?it/s] #015Epoch 0:   7%|▋         | 1/14 [00:00<00:03,  3.86it/s]#015Epoch 0:   7%|▋         | 1/14 [00:00<00:03,  3.86it/s, loss=0.702, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702]#015Epoch 0:  14%|█▍        | 2/14 [00:00<00:02,  4.31it/s, loss=0.702, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702]#015Epoch 0:  14%|█▍        | 2/14 [00:00<00:02,  4.30it/s, loss=0.692, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.373]#015Epoch 0:  21%|██▏       | 3/14 [00:00<00:02,  4.48it/s, loss=0.692, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.373]#015Epoch 0:  21%|██▏       | 3/14 [00:00<00:02,  4.48it/s, loss=0.683, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.416]#015Epoch 0:  29%|██▊       | 4/14 [00:00<00:02,  4.55it/s, loss=0.683, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.416]#015Epoch 0:  29%|██▊       | 4/14 [00:00<00:02,  4.55it/s, loss=0.674, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.466]#015Epoch 0:  36%|███▌      | 5/14 [00:01<00:01,  4.61it/s, loss=0.674, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.466]#015Epoch 0:  36%|███▌      | 5/14 [00:01<00:01,  4.61it/s, loss=0.666, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.519]#015Epoch 0:  43%|████▎     | 6/14 [00:01<00:01,  4.69it/s, loss=0.666, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.519]#015Epoch 0:  43%|████▎     | 6/14 [00:01<00:01,  4.68it/s, loss=0.657, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.478]#015Epoch 0:  50%|█████     | 7/14 [00:01<00:01,  5.01it/s, loss=0.657, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.478]#015Epoch 0:  50%|█████     | 7/14 [00:01<00:01,  5.01it/s, loss=0.653, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.476]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/7 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  29%|██▊       | 2/7 [00:00<00:00, 13.80it/s]#033[A#015Epoch 0:  71%|███████▏  | 10/14 [00:01<00:00,  6.44it/s, loss=0.653, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.476]\u001b[0m\n",
      "\u001b[34m#015Validating:  57%|█████▋    | 4/7 [00:00<00:00, 13.80it/s]#033[A#015Epoch 0:  93%|█████████▎| 13/14 [00:01<00:00,  7.34it/s, loss=0.653, v_num=0, val_f1_epoch=0.348, val_loss_epoch=0.702, train_f1=0.476]\u001b[0m\n",
      "\u001b[34m#015Validating:  86%|████████▌ | 6/7 [00:00<00:00, 13.79it/s]#033[A#015Epoch 0: 100%|██████████| 14/14 [00:02<00:00,  6.72it/s, loss=0.653, v_num=0, val_f1_epoch=0.472, val_loss_epoch=0.591, train_f1=0.460, val_f1_step=0.463, val_loss_step=0.598]\u001b[0m\n",
      "\u001b[34m#015                                                         #033[A#015Epoch 0: 100%|██████████| 14/14 [00:05<00:00,  2.53it/s, loss=0.653, v_num=0, val_f1_epoch=0.472, val_loss_epoch=0.591, train_f1=0.460, val_f1_step=0.463, val_loss_step=0.598]\u001b[0m\n",
      "\u001b[34mINFO:root:reading data\u001b[0m\n",
      "\u001b[34mINFO:root:building training and testing datasets\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430922016 acquired on /root/.cache/huggingface/transformers/96eb1c084a276166de559d1ad85205eb6ba5dd929bb90f41af67e0d9d7a0c6fd.bbbef2c70c87c42bb5499099ec8bd707180a1fa6a72cbd40f6f23649d8bd6d8c.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/594 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 594/594 [00:00<00:00, 464kB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430922016 released on /root/.cache/huggingface/transformers/96eb1c084a276166de559d1ad85205eb6ba5dd929bb90f41af67e0d9d7a0c6fd.bbbef2c70c87c42bb5499099ec8bd707180a1fa6a72cbd40f6f23649d8bd6d8c.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430964824 acquired on /root/.cache/huggingface/transformers/d48c7a894f2f0438eb62fcb8884f11ff35ea7e1e44ca0274b6ae0a288fca285b.98b26f9c960899aa0e99c10a12750104e467743b3b460b79fa7d76907549319b.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 40.9MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430964824 released on /root/.cache/huggingface/transformers/d48c7a894f2f0438eb62fcb8884f11ff35ea7e1e44ca0274b6ae0a288fca285b.98b26f9c960899aa0e99c10a12750104e467743b3b460b79fa7d76907549319b.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963032 acquired on /root/.cache/huggingface/transformers/ae71b00a0e284b08264509b65ada716ffa2872f3063c4c939b59959e62d4ab75.4e84197f9f04666b541217ec3e1bd301b154ec9bfa8b968b3f9185b34bd73da6.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 466k/466k [00:00<00:00, 42.8MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963032 released on /root/.cache/huggingface/transformers/ae71b00a0e284b08264509b65ada716ffa2872f3063c4c939b59959e62d4ab75.4e84197f9f04666b541217ec3e1bd301b154ec9bfa8b968b3f9185b34bd73da6.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963032 acquired on /root/.cache/huggingface/transformers/e341629aba7afac8fd72ecdea6343b69a33eb5bb76ced6b288dbe1e666c35c47.18ebceb237d999d8f1cb15935e35b314f3e73dd6c4f65e119f4790fa226c9236.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 239/239 [00:00<00:00, 196kB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963032 released on /root/.cache/huggingface/transformers/e341629aba7afac8fd72ecdea6343b69a33eb5bb76ced6b288dbe1e666c35c47.18ebceb237d999d8f1cb15935e35b314f3e73dd6c4f65e119f4790fa226c9236.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963256 acquired on /root/.cache/huggingface/transformers/8ceef1c800b05474d2b470c6dac1644ac368e78b997569934c1d9e48989fa09c.9777c1408575043925e0a5a63c1144e4c19e67cc033b9c85069a11e52ea4bc2d.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/1.19k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 1.19k/1.19k [00:00<00:00, 1.43MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273430963256 released on /root/.cache/huggingface/transformers/8ceef1c800b05474d2b470c6dac1644ac368e78b997569934c1d9e48989fa09c.9777c1408575043925e0a5a63c1144e4c19e67cc033b9c85069a11e52ea4bc2d.lock\u001b[0m\n",
      "\u001b[34m2021-07-06 19:47:48,050 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mINFO:root:training model\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273420233192 acquired on /root/.cache/huggingface/transformers/992e9e88844a23031919226d183d2dec1973bb93482dd767713146d989b9972e.aabd9267f2a2af6ec34667d063ffbcacdfd7da949d6c2f6e145f113dacce0263.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]#015Downloading:   1%|          | 4.16M/438M [00:00<00:10, 41.6MB/s]#015Downloading:   2%|▏         | 8.86M/438M [00:00<00:09, 43.1MB/s]#015Downloading:   3%|▎         | 13.6M/438M [00:00<00:09, 44.4MB/s]#015Downloading:   4%|▍         | 18.5M/438M [00:00<00:09, 45.6MB/s]#015Downloading:   5%|▌         | 23.3M/438M [00:00<00:08, 46.3MB/s]#015Downloading:   6%|▋         | 28.3M/438M [00:00<00:08, 47.3MB/s]#015Downloading:   8%|▊         | 33.3M/438M [00:00<00:08, 48.1MB/s]#015Downloading:   9%|▉         | 38.4M/438M [00:00<00:08, 48.8MB/s]#015Downloading:  10%|▉         | 43.0M/438M [00:00<00:08, 47.6MB/s]#015Downloading:  11%|█         | 47.7M/438M [00:01<00:08, 47.4MB/s]#015Downloading:  12%|█▏        | 52.7M/438M [00:01<00:08, 48.0MB/s]#015Downloading:  13%|█▎        | 57.6M/438M [00:01<00:07, 48.3MB/s]#015Downloading:  14%|█▍        | 62.5M/438M [00:01<00:07, 48.6MB/s]#015Downloading:  15%|█▌        | 67.5M/438M [00:01<00:07, 49.0MB/s]#015Downloading:  17%|█▋        | 72.4M/438M [00:01<00:07, 48.0MB/s]#015Downloading:  18%|█▊        | 77.4M/438M [00:01<00:07, 48.5MB/s]#015Downloading:  19%|█▉        | 82.3M/438M [00:01<00:07, 48.9MB/s]#015Downloading:  20%|█▉        | 87.4M/438M [00:01<00:07, 49.3MB/s]#015Downloading:  21%|██        | 92.4M/438M [00:01<00:06, 49.5MB/s]#015Downloading:  22%|██▏       | 97.4M/438M [00:02<00:06, 49.8MB/s]#015Downloading:  23%|██▎       | 102M/438M [00:02<00:06, 49.2MB/s] #015Downloading:  24%|██▍       | 107M/438M [00:02<00:06, 48.2MB/s]#015Downloading:  26%|██▌       | 112M/438M [00:02<00:06, 48.5MB/s]#015Downloading:  27%|██▋       | 117M/438M [00:02<00:06, 48.7MB/s]#015Downloading:  28%|██▊       | 122M/438M [00:02<00:06, 48.3MB/s]#015Downloading:  29%|██▉       | 127M/438M [00:02<00:06, 48.5MB/s]#015Downloading:  30%|███       | 132M/438M [00:02<00:06, 48.7MB/s]#015Downloading:  31%|███       | 137M/438M [00:02<00:06, 48.8MB/s]#015Downloading:  32%|███▏      | 142M/438M [00:02<00:06, 49.0MB/s]#015Downloading:  33%|███▎      | 147M/438M [00:03<00:05, 49.1MB/s]#015Downloading:  35%|███▍      | 152M/438M [00:03<00:05, 49.5MB/s]#015Downloading:  36%|███▌      | 157M/438M [00:03<00:05, 49.6MB/s]#015Downloading:  37%|███▋      | 162M/438M [00:03<00:05, 49.6MB/s]#015Downloading:  38%|███▊      | 167M/438M [00:03<00:05, 49.6MB/s]#015Downloading:  39%|███▉      | 172M/438M [00:03<00:05, 48.7MB/s]#015Downloading:  40%|████      | 176M/438M [00:03<00:05, 46.8MB/s]#015Downloading:  41%|████▏     | 181M/438M [00:03<00:05, 47.7MB/s]#015Downloading:  43%|████▎     | 186M/438M [00:03<00:05, 47.7MB/s]#015Downloading:  44%|████▎     | 191M/438M [00:03<00:05, 45.7MB/s]#015Downloading:  45%|████▍     | 196M/438M [00:04<00:05, 46.9MB/s]#015Downloading:  46%|████▌     | 201M/438M [00:04<00:04, 47.7MB/s]#015Downloading:  47%|████▋     | 206M/438M [00:04<00:04, 47.7MB/s]#015Downloading:  48%|████▊     | 211M/438M [00:04<00:04, 48.4MB/s]#015Downloading:  49%|████▉     | 216M/438M [00:04<00:04, 49.2MB/s]#015Downloading:  50%|█████     | 221M/438M [00:04<00:04, 49.2MB/s]#015Downloading:  52%|█████▏    | 226M/438M [00:04<00:04, 49.6MB/s]#015Downloading:  53%|█████▎    | 231M/438M [00:04<00:04, 50.2MB/s]#015Downloading:  54%|█████▍    | 236M/438M [00:04<00:04, 50.0MB/s]#015Downloading:  55%|█████▌    | 241M/438M [00:04<00:03, 49.9MB/s]#015Downloading:  56%|█████▌    | 246M/438M [00:05<00:03, 49.3MB/s]#015Downloading:  57%|█████▋    | 251M/438M [00:05<00:03, 50.5MB/s]#015Downloading:  59%|█████▊    | 257M/438M [00:05<00:03, 51.6MB/s]#015Downloading:  60%|█████▉    | 262M/438M [00:05<00:03, 51.9MB/s]#015Downloading:  61%|██████    | 268M/438M [00:05<00:03, 53.4MB/s]#015Downloading:  62%|██████▏   | 273M/438M [00:05<00:03, 53.1MB/s]#015Downloading:  64%|██████▎   | 278M/438M [00:05<00:03, 51.2MB/s]#015Downloading:  65%|██████▍   | 284M/438M [00:05<00:03, 50.8MB/s]#015Downloading:  66%|██████▌   | 289M/438M [00:05<00:02, 50.5MB/s]#015Downloading:  67%|██████▋   | 294M/438M [00:05<00:02, 51.1MB/s]#015Downloading:  68%|██████▊   | 299M/438M [00:06<00:02, 51.4MB/s]#015Downloading:  69%|██████▉   | 304M/438M [00:06<00:02, 51.4MB/s]#015Downloading:  71%|███████   | 310M/438M [00:06<00:02, 51.3MB/s]#015Downloading:  72%|███████▏  | 315M/438M [00:06<00:02, 51.5MB/s]#015Downloading:  73%|███████▎  | 320M/438M [00:06<00:02, 51.2MB/s]#015Downloading:  74%|███████▍  | 325M/438M [00:06<00:02, 50.6MB/s]#015Downloading:  75%|███████▌  | 330M/438M [00:06<00:02, 51.1MB/s]#015Downloading:  77%|███████▋  | 335M/438M [00:06<00:01, 51.5MB/s]#015Downloading:  78%|███████▊  | 341M/438M [00:06<00:01, 51.9MB/s]#015Downloading:  79%|███████▉  | 346M/438M [00:06<00:01, 52.0MB/s]#015Downloading:  80%|████████  | 351M/438M [00:07<00:01, 52.1MB/s]#015Downloading:  81%|████████▏ | 356M/438M [00:07<00:01, 52.0MB/s]#015Downloading:  83%|████████▎ | 362M/438M [00:07<00:01, 50.8MB/s]#015Downloading:  84%|████████▎ | 367M/438M [00:07<00:01, 50.8MB/s]#015Downloading:  85%|████████▍ | 372M/438M [00:07<00:01, 51.2MB/s]#015Downloading:  86%|████████▌ | 377M/438M [00:07<00:01, 50.5MB/s]#015Downloading:  87%|████████▋ | 382M/438M [00:07<00:01, 50.9MB/s]#015Downloading:  88%|████████▊ | 387M/438M [00:07<00:00, 51.3MB/s]#015Downloading:  90%|████████▉ | 393M/438M [00:07<00:00, 50.7MB/s]#015Downloading:  91%|█████████ | 398M/438M [00:08<00:00, 51.0MB/s]#015Downloading:  92%|█████████▏| 403M/438M [00:08<00:00, 51.3MB/s]#015Downloading:  93%|█████████▎| 408M/438M [00:08<00:00, 51.5MB/s]#015Downloading:  94%|█████████▍| 413M/438M [00:08<00:00, 51.4MB/s]#015Downloading:  96%|█████████▌| 418M/438M [00:08<00:00, 51.5MB/s]#015Downloading:  97%|█████████▋| 424M/438M [00:08<00:00, 51.8MB/s]#015Downloading:  98%|█████████▊| 429M/438M [00:08<00:00, 51.0MB/s]#015Downloading:  99%|█████████▉| 434M/438M [00:08<00:00, 51.3MB/s]#015Downloading: 100%|██████████| 438M/438M [00:08<00:00, 49.8MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 140273420233192 released on /root/.cache/huggingface/transformers/992e9e88844a23031919226d183d2dec1973bb93482dd767713146d989b9972e.aabd9267f2a2af6ec34667d063ffbcacdfd7da949d6c2f6e145f113dacce0263.lock\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type  | Params\u001b[0m\n",
      "\u001b[34m-----------------------------------------\u001b[0m\n",
      "\u001b[34m0 | model          | Model | 109 M \u001b[0m\n",
      "\u001b[34m1 | f1_score_train | F1    | 0     \u001b[0m\n",
      "\u001b[34m-----------------------------------------\u001b[0m\n",
      "\u001b[34m109 M     Trainable params\u001b[0m\n",
      "\u001b[34m0         Non-trainable params\u001b[0m\n",
      "\u001b[34m109 M     Total params\u001b[0m\n",
      "\u001b[34m437.980   Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.6/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\u001b[0m\n",
      "\n",
      "2021-07-06 19:48:07 Uploading - Uploading generated training modelProfilerReport-1625600358: NoIssuesFound\n",
      "\n",
      "2021-07-06 19:48:23 Completed - Training job completed\n",
      "Training seconds: 379\n",
      "Billable seconds: 379\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
