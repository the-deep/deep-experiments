{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1D sub-pillar modeling: Transformers\n",
    "\n",
    "Runs `huggingface-multihead` on SageMaker to train transformer-based classifiers.\n",
    "\n",
    "* 1D pillars and subpillars preprocessing\n",
    "* Multihead (per pillar) transformer sequence classification\n",
    "* SageMaker training jobs\n",
    "* Macro precision, recall, fscore evaluation\n",
    "* MLFlow tracking\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.getcwd() + \"../../../../\"))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import sagemaker\n",
    "from deep.constants import DEV_BUCKET\n",
    "from deep.utils import formatted_time\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "job_name = f\"1D-test-{formatted_time()}\" "
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../../../data/frameworks_data/data_v0.5/data_v0.5_train.csv\")\n",
    "val_df = pd.read_csv(\"../../../data/frameworks_data/data_v0.5/data_v0.5_val.csv\")\n",
    "\n",
    "sample = False  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
    "    train_df = train_df.sample(n=1000)\n",
    "    val_df = val_df.sample(n=1000)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train_df.pickle')\n",
    "val_path = str(input_path / 'test_df.pickle')\n",
    "\n",
    "train_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "val_df.to_pickle(val_path, protocol=4)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sagemaker"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "from deep.constants import MLFLOW_SERVER, SAGEMAKER_ROLE\n",
    "\n",
    "hyperparameters={\n",
    "    'epochs': 5,\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
    "    'experiment_name': '1D-multihead-transformers',\n",
    "    'iterative': False,\n",
    "    'loss': 'focal'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir=str('../../../scripts/training/oguz/huggingface-multihead'),\n",
    "    output_path=str(DEV_BUCKET / 'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=SAGEMAKER_ROLE,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Fit the estimator\n",
    "\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": true,
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Debugging (SageMaker JupyterLab)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!pip install cloudpathlib\n",
    "#!pip install mlflow\n",
    "#!pip install transformers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from deep.constants import MLFLOW_SERVER, SAGEMAKER_ROLE\n",
    "\n",
    "PATH = os.path.abspath('../../../../deep-experiments/scripts/training/oguz/huggingface-multihead/train.py')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%env SM_OUTPUT_DATA_DIR=''\n",
    "%env SM_MODEL_DIR=''\n",
    "%env SM_NUM_GPUS=1\n",
    "%env SM_CHANNEL_TRAIN={input_path}\n",
    "%env SM_CHANNEL_TEST={input_path}\n",
    "\n",
    "!python {PATH} --epochs 3 --tracking_uri {MLFLOW_SERVER} --experiment_name {'1D-multihead-transformers'} --model_name {'distilbert-base-uncased'}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "\n",
    "from deep.constants import MLFLOW_SERVER\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER)\n",
    "\n",
    "experiment_name = \"1D-multihead-transformers\"\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "experiment_id = dict(experiment)['experiment_id']\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "runs = runs.reindex(index=runs.index[::-1])\n",
    "runs.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "\n",
    "def get_cols(reg):\n",
    "    cols = []\n",
    "    matches = []\n",
    "    for col in runs.columns:\n",
    "        match = re.match(reg, col)\n",
    "        if match:\n",
    "            cols.append(col)\n",
    "            matches.append('->'.join(match.groups()))\n",
    "    return cols, matches\n",
    "\n",
    "reg = 'metrics\\.eval_(.+)-(.+)_binary_f1'\n",
    "cols, matches = get_cols(reg)\n",
    "print(cols)\n",
    "print(matches)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Subpillar Recall-Precision"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "runs.sort_values('metrics.eval_subpillar_micro_f1', ascending=False).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# get data\n",
    "run_id = 9\n",
    "data = runs.loc[run_id]\n",
    "\n",
    "# get precision\n",
    "reg = 'metrics\\.eval_(.+)-(.+)_binary_precision'\n",
    "cols, subpillars = get_cols(reg)\n",
    "precision = data[cols]\n",
    "precision = { k: v for k, v in zip(subpillars, precision.values ) }\n",
    "\n",
    "# get recall\n",
    "reg = 'metrics\\.eval_(.+)-(.+)_binary_recall'\n",
    "cols, subpillars = get_cols(reg)\n",
    "recall = data[cols]\n",
    "recall = { k: v for k, v in zip(subpillars, recall.values ) }\n",
    "\n",
    "# get f1\n",
    "reg = 'metrics\\.eval_(.+)-(.+)_binary_f1'\n",
    "cols, subpillars = get_cols(reg)\n",
    "f1 = data[cols]\n",
    "f1 = { k: v for k, v in zip(subpillars, f1.values ) }\n",
    "\n",
    "# reorder\n",
    "keys = list(f1.keys())\n",
    "precision = [ precision[k] for k in keys ]\n",
    "recall = [ recall[k] for k in keys ]\n",
    "f1 = [ f1[k] for k in keys ]\n",
    "\n",
    "# form a pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    'subpillar': keys,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1\n",
    "})\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plot\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='precision',\n",
    "    y='recall'\n",
    ")\n",
    "for i in range(df.shape[0]):\n",
    "    plt.text(\n",
    "        x=df.precision[i],\n",
    "        y=df.recall[i]+0.01,\n",
    "        s=df.subpillar[i],\n",
    "        fontdict=dict(color='red', size=8, ha='center'),\n",
    "        bbox=dict(facecolor='yellow', alpha=0.1))\n",
    "plt.xlim(df.precision.min()-0.2, df.precision.max()+0.2)                \n",
    "plt.ylim(df.recall.min()-0.2, df.recall.max()+0.2)              \n",
    "plt.title('Subpillar precision-recall scatter')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.hist('f1', bins=25)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bad precision\n",
    "df[df.precision < 0.5].head(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# bad recall\n",
    "df[df.recall < 0.5].head(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference Preprocessing (Offline Testing Environment)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'leads.csv'\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "lengths = {}\n",
    "\n",
    "for field in ['extracted_text_as_paragraphs', 'extracted_text_as_sentences']:\n",
    "    arr = data[field].apply(literal_eval).tolist()\n",
    "    lengths[field] = [len(ds) for ds in arr]\n",
    "    \n",
    "    infer_df = pd.DataFrame.from_dict({\n",
    "        'excerpt': [d for ds in arr for d in ds]\n",
    "    })\n",
    "    infer_df = infer_df[~(infer_df['excerpt'].str.len() == 0)]\n",
    "    infer_df.to_csv(f'infer_{field}.csv', header=True, index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit ('deepl': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "interpreter": {
   "hash": "edf37a5c134433dc7c91edbc64d783a1f377a9eacd02d109a75d6112334aa942"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}