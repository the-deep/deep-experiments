{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33cca39",
   "metadata": {},
   "source": [
    "Using kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1dd508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df34043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef5237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ebb10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('data_prep/final_data/en/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1954e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('data_prep/data/entries_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a152eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data / 'sentences_en_train.csv')\n",
    "test = pd.read_csv(data / 'sentences_en_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc67980",
   "metadata": {},
   "source": [
    "# Get balanced data for sector 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7694ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = 4\n",
    "train_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de06211a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevant_train = train[train.is_relevant == 1]\n",
    "relevant_train.sector_ids = relevant_train.sector_ids.apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ad55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_train = list(relevant_train[relevant_train.sector_ids.apply(lambda x: sector in x)].sentence_text)\n",
    "negative_train = list(relevant_train[relevant_train.sector_ids.apply(lambda x: sector not in x)].sentence_text)\n",
    "random.shuffle(positive_train)\n",
    "random.shuffle(negative_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f70fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sentences = positive_train[:train_size]\n",
    "negative_sentences = negative_train[:train_size]\n",
    "\n",
    "sentences = positive_sentences + negative_sentences\n",
    "labels = [1] * train_size + [0] * train_size\n",
    "\n",
    "all_ = [(x, y) for x, y in zip(sentences, labels)]\n",
    "random.shuffle(all_)\n",
    "\n",
    "sentences = [x[0] for x in all_]\n",
    "labels = [x[1] for x in all_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f7e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = positive_train[train_size:2*train_size] + negative_train[train_size:2*train_size]\n",
    "test_labels = [1] * train_size + [0] * train_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9656fb",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"bert-large-uncased\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631bb909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(sentences, truncation=True, padding=True)\n",
    "train_labels = labels\n",
    "test_encodings = tokenizer(test, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b667700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, train_labels)\n",
    "test_dataset = Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32ce523",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=6,              # total # of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=300,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=train_dataset            # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6a1b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dbc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fbe444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2e2a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "outputs = trainer.predict(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d21aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = outputs.predictions\n",
    "labels = outputs.label_ids\n",
    "preds_max = np.argmax(preds, axis=1)\n",
    "np.mean(preds_max == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f905f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e111b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = outputs.predictions\n",
    "labels = outputs.label_ids\n",
    "preds_max = np.argmax(preds, axis=1)\n",
    "np.mean(preds_max == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5fc514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fea071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
