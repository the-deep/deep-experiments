{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e23c9bd",
   "metadata": {},
   "source": [
    "Using kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe37a35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25f5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b14efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28fcde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acf99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c74d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce730f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = IMMAP_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f979d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data / 'final_data/en' / 'sentences_en_train.csv')\n",
    "test = pd.read_csv(data / 'final_data/en' / 'sentences_en_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4fb6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_sector(df, sector, train):\n",
    "    relevant_train = df[df.is_relevant == 1]\n",
    "    relevant_train.sector_ids = relevant_train.sector_ids.apply(eval)\n",
    "    relevant_train = relevant_train[relevant_train.sector_ids.apply(len) > 0]\n",
    "    \n",
    "    positive_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector in x)]\n",
    "    negative_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector not in x)]\n",
    "\n",
    "    positive_train.sector_ids = 1\n",
    "    negative_train.sector_ids = 0\n",
    "    train_df = pd.concat([positive_train, negative_train])\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_df['is_valid'] = False if train else True\n",
    "        \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f232d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/core/generic.py:5494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "train_df = process_for_sector(train, 4, True)\n",
    "test_df = process_for_sector(test, 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98af596",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60dc23e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>sentence_text</th>\n",
       "      <th>is_relevant</th>\n",
       "      <th>sector_ids</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44635</td>\n",
       "      <td>16</td>\n",
       "      <td>Khaled karzeh, an SCD volunteer at the center ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45354</td>\n",
       "      <td>5</td>\n",
       "      <td>As displaced continues to grow in the country,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37691</td>\n",
       "      <td>0</td>\n",
       "      <td>Ar-Raqqa - Wednesday, August 19th 2020* *- Tod...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40332</td>\n",
       "      <td>4</td>\n",
       "      <td>Some of the worst floods in decades followed a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34594</td>\n",
       "      <td>227</td>\n",
       "      <td>Moreover, 38 collective shelters have latrines...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22967</th>\n",
       "      <td>40930</td>\n",
       "      <td>20</td>\n",
       "      <td>The ward has opened initially for moderate COV...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22968</th>\n",
       "      <td>50728</td>\n",
       "      <td>3</td>\n",
       "      <td>There has been a drop in the number of cases r...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22969</th>\n",
       "      <td>49804</td>\n",
       "      <td>126</td>\n",
       "      <td>The national average price also in- creased by...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22970</th>\n",
       "      <td>50966</td>\n",
       "      <td>4</td>\n",
       "      <td>A risk of Famine (IPC Phase 5) persists, and F...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22971</th>\n",
       "      <td>44543</td>\n",
       "      <td>75</td>\n",
       "      <td>Also, households limited purchasing power play...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22972 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id  sentence_id                                      sentence_text  \\\n",
       "0       44635           16  Khaled karzeh, an SCD volunteer at the center ...   \n",
       "1       45354            5  As displaced continues to grow in the country,...   \n",
       "2       37691            0  Ar-Raqqa - Wednesday, August 19th 2020* *- Tod...   \n",
       "3       40332            4  Some of the worst floods in decades followed a...   \n",
       "4       34594          227  Moreover, 38 collective shelters have latrines...   \n",
       "...       ...          ...                                                ...   \n",
       "22967   40930           20  The ward has opened initially for moderate COV...   \n",
       "22968   50728            3  There has been a drop in the number of cases r...   \n",
       "22969   49804          126  The national average price also in- creased by...   \n",
       "22970   50966            4  A risk of Famine (IPC Phase 5) persists, and F...   \n",
       "22971   44543           75  Also, households limited purchasing power play...   \n",
       "\n",
       "       is_relevant  sector_ids  is_valid  \n",
       "0                1           1     False  \n",
       "1                1           0     False  \n",
       "2                1           1     False  \n",
       "3                1           0     False  \n",
       "4                1           0     False  \n",
       "...            ...         ...       ...  \n",
       "22967            1           1     False  \n",
       "22968            1           1     False  \n",
       "22969            1           0     False  \n",
       "22970            1           0     False  \n",
       "22971            1           0     False  \n",
       "\n",
       "[22972 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4af19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(train_df.sentence_text), truncation=True, padding=True)\n",
    "train_labels = list(train_df.sector_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd80cca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = tokenizer(list(test_df.sentence_text), truncation=True, padding=True)\n",
    "test_labels = list(test_df.sector_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b1867a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = Dataset(train_encodings, train_labels)\n",
    "test_dataset = Dataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc11d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics function for binary classification\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c4e6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=1,              # total # of training epochs\n",
    "    per_device_train_batch_size=1,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "#     logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=train_dataset            # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e389dbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f184ba71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a9b9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22972' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   22/22972 03:17 < 62:53:10, 0.10 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.806200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.735300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.667200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.643600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.748200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.726100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.677000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.674300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.724200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.673300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.686700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.706500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.677200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-20-3435b262f1ae>\", line 1, in <module>\n",
      "    trainer.train()\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/transformers/trainer.py\", line 1272, in train\n",
      "    tr_loss += self.training_step(model, inputs)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/transformers/trainer.py\", line 1752, in training_step\n",
      "    loss.backward()\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/torch/tensor.py\", line 245, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 145, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  File \"/Users/stefano/miniconda3/envs/deep-exp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b1a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6128ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(outputs.predictions, axis=1)\n",
    "labels = outputs.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258db08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep = classification_report(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814afb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9942c4cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
