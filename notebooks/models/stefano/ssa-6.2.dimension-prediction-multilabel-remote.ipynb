{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24591703",
   "metadata": {},
   "source": [
    "Using kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20eedaba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:15.832149Z",
     "start_time": "2021-06-03T08:53:15.830488Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install cloudpathlib\n",
    "# !pip install s3fs\n",
    "# !pip install transformers\\\n",
    "# !pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa23b6fa",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "999f3add",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:15.845787Z",
     "start_time": "2021-06-03T08:53:15.843408Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3c9d77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:15.852350Z",
     "start_time": "2021-06-03T08:53:15.849807Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7ee89c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.440564Z",
     "start_time": "2021-06-03T08:53:15.854287Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c036b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.548860Z",
     "start_time": "2021-06-03T08:53:19.441964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86b862e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.576813Z",
     "start_time": "2021-06-03T08:53:19.550047Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe489b21",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d147ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.781776Z",
     "start_time": "2021-06-03T08:53:19.577723Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/stefano/Dropbox/Work/DFS/Code/deep-experiments/notebooks/models/stefano/../../../data/frameworks_data/data_v0.4.3/data_v0.4.2_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1a1b984f13f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATEST_DATA_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'data_v0.4.2_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATEST_DATA_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'data_v0.4.2_val.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLATEST_DATA_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'data_v0.4.2_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deep-exp/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/stefano/Dropbox/Work/DFS/Code/deep-experiments/notebooks/models/stefano/../../../data/frameworks_data/data_v0.4.3/data_v0.4.2_train.csv'"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(LATEST_DATA_PATH / 'data_v0.4.2_train.csv')\n",
    "val = pd.read_csv(LATEST_DATA_PATH / 'data_v0.4.2_val.csv')\n",
    "test = pd.read_csv(LATEST_DATA_PATH / 'data_v0.4.2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12eb48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.783404Z",
     "start_time": "2021-06-03T08:53:15.870Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(df, column='subpillars'):\n",
    "    df = df.copy()\n",
    "    df[column] = df[column].apply(eval)\n",
    "#     df['dimension_ids'] = df['dimension_ids'].apply(lambda x: torch.tensor(x, dtype=torch.float))\n",
    "    \n",
    "    mlb = MultiLabelBinarizer()\n",
    "    labels = mlb.fit_transform(list(df[column]))\n",
    "    df['labels'] = list(labels)\n",
    "    \n",
    "    df = df[['excerpt', 'labels']]\n",
    "    df = df.rename(columns={'excerpt': 'texts'})\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2710bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.783995Z",
     "start_time": "2021-06-03T08:53:15.891Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = process(train, column='sectors')\n",
    "val_df = process(val, column='sectors')\n",
    "test_df = process(test, column='sectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c92db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.784464Z",
     "start_time": "2021-06-03T08:53:15.895Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e805e622",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4baaca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2753a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.785051Z",
     "start_time": "2021-06-03T08:53:15.898Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = 'AmazonSageMaker-ExecutionRole-20210519T102514'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e4b932",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09a9c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.785570Z",
     "start_time": "2021-06-03T08:53:15.900Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = False\n",
    "\n",
    "if sample:\n",
    "    train_df = train_df.sample(100)\n",
    "    val_df = val_df.sample(100)\n",
    "    test_df = test_df.sample(100)\n",
    "\n",
    "    \n",
    "job_name = f\"pytorch-training-{formatted_time()}-sectors-test\"\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name\n",
    "\n",
    "s3_train_data = str(input_path / 'train_df.pickle')\n",
    "s3_validation_data = str(input_path / 'val_df.pickle')\n",
    "s3_test_data = str(input_path / 'test_df.pickle')\n",
    "\n",
    "\n",
    "train_df.to_pickle(s3_train_data, protocol=4)\n",
    "test_df.to_pickle(s3_validation_data, protocol=4)\n",
    "test_df.to_pickle(s3_test_data, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83f4dc3",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5152e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.786132Z",
     "start_time": "2021-06-03T08:53:15.907Z"
    }
   },
   "outputs": [],
   "source": [
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94388e0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.786777Z",
     "start_time": "2021-06-03T08:53:15.911Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_definitions=[\n",
    "    {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_loss', 'Regex': \"'eval_loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_accuracy', 'Regex': \"'eval_accuracy': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'f1', 'Regex': \"'f1': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_precision', 'Regex': \"'eval_precision': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_recall', 'Regex': \"'eval_recall': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'stupid_metric', 'Regex': \"'stupid_metric': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_runtime', 'Regex': \"'eval_runtime': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'eval_samples_per_second', 'Regex': \"'eval_samples_per_second': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "    {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b5cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.787466Z",
     "start_time": "2021-06-03T08:53:15.917Z"
    }
   },
   "outputs": [],
   "source": [
    "# # set True if you need spot instance\n",
    "# use_spot = True\n",
    "# train_max_run_secs =   2*24 * 60 * 60\n",
    "# spot_wait_sec =  5 * 60\n",
    "# max_wait_time_secs = train_max_run_secs +  spot_wait_sec\n",
    "\n",
    "# if not use_spot:\n",
    "#     max_wait_time_secs = None\n",
    "    \n",
    "# # During local mode, no spot.., use smaller dataset\n",
    "# if instance_type == 'local':\n",
    "#     use_spot = False\n",
    "#     max_wait_time_secs = 0\n",
    "#     wait = True\n",
    "#     # Use smaller dataset to run locally\n",
    "#     inputs = inputs_sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8458da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.788037Z",
     "start_time": "2021-06-03T08:53:15.920Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'train_batch_size': 32,\n",
    "                 'model_name': 'distilbert-base-uncased',\n",
    "                 'n_classes': 11,\n",
    "                 }\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir=str(SCRIPTS_TRAINING_PATH / 'stefano/multiclass-lightning'),\n",
    "    output_path=str(DEV_BUCKET / 'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d57e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.788646Z",
     "start_time": "2021-06-03T08:53:15.927Z"
    }
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e230e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.789174Z",
     "start_time": "2021-06-03T08:53:15.929Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit(fit_arguments, job_name=job_name, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6267d0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.789913Z",
     "start_time": "2021-06-03T08:53:15.932Z"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "# Captured metrics can be accessed as a Pandas dataframe\n",
    "df = TrainingJobAnalytics(training_job_name=estimator.latest_training_job.name).dataframe()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12a7e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-03T08:53:19.790440Z",
     "start_time": "2021-06-03T08:53:15.934Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27ac85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb5587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
