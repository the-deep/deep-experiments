{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cd52ea6",
   "metadata": {},
   "source": [
    "Using kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8677220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcf67b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea047d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31752dfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (constants.py, line 13)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-95d2dfc9ac9f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from deep.constants import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"../../../deep/constants.py\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    <<<<<<< HEAD\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from deep.constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd171b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd8d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FRAMEWORKS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95825ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "afexportable = pd.read_csv(data /'afexportable_of_af_of_projects_of_interest.csv')\n",
    "all_afs = pd.read_csv(data /'all_afs.csv')\n",
    "\n",
    "proj_interest = pd.read_csv(data / 'projects_of_interest.csv')\n",
    "entr_proj_interest = pd.read_csv(data / 'entries_of_projects_of_interest.csv')\n",
    "exp_proj_interest = pd.read_csv(data / 'exportdata_of_entries_of_projects_of_interest.csv')\n",
    "wid_proj_interest = pd.read_csv(data / 'widgets_of_afs_of_interest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f54738b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(FRAMEWORKS_PATH / 'data_v0.3_train.csv')\n",
    "val = pd.read_csv(FRAMEWORKS_PATH / 'data_v0.3_val.csv')\n",
    "test = pd.read_csv(FRAMEWORKS_PATH / 'data_v0.3_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3026ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85922, 46)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "744ebc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'excerpt', 'analysis_framework_id', 'created_by_id',\n",
       "       'lead_id', 'modified_by_id', 'information_date', 'order', 'client_id',\n",
       "       'project_id', 'tabular_field_id', 'dropped_excerpt', 'verified',\n",
       "       'verification_last_changed_by_id', 'exportdata_id', 'exportable_id',\n",
       "       'dimensions', 'subdimensions', 'sectors', 'subsectors', 'Shelter',\n",
       "       'Livelihoods', 'Protection', 'Shelter and NFIs', 'NFI', 'Food Security',\n",
       "       'Logistics', 'Cross', 'CCCM', 'Agriculture', 'Health', 'Nutrition',\n",
       "       'Education', 'WASH', 'sector_ids', 'Shock Informaton',\n",
       "       'Effects Systems And Networks', 'Effects On Population',\n",
       "       'Capacities & Response', 'At Risk', 'Scope & Scale', 'Impact',\n",
       "       'Humanitarian Conditions', 'Priorities', 'Context', 'dimension_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b468a545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4eece7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7edb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3d469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_sector(df, sector, train):\n",
    "    relevant_train = df[df.is_relevant == 1]\n",
    "    relevant_train.sector_ids = relevant_train.sector_ids.apply(eval)\n",
    "    relevant_train = relevant_train[relevant_train.sector_ids.apply(len) > 0]\n",
    "    \n",
    "    positive_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector in x)]\n",
    "    negative_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector not in x)]\n",
    "\n",
    "    positive_train.sector_ids = 1\n",
    "    negative_train.sector_ids = 0\n",
    "    train_df = pd.concat([positive_train, negative_train])\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_df['is_valid'] = False if train else True\n",
    "        \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ffc85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = process_for_sector(train, 4, True)\n",
    "test_df = process_for_sector(test, 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75609e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b7468",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df.pickle')\n",
    "test_df.to_pickle('test_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100acda",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68be7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\n",
    "    role\n",
    ")  # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = SAGEMAKER_BUCKET\n",
    "prefix = \"huggingface/first\"  # Replace with the prefix under which you want to store the data if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e8af4",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077cfab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucket_path = 'test1/data'\n",
    "train_channel = bucket_path + \"/train_df.pickle\"\n",
    "validation_channel = bucket_path + \"/test_df.pickle\"\n",
    "\n",
    "sess.upload_data(path=\"train_df.pickle\", bucket=SAGEMAKER_BUCKET, key_prefix=bucket_path)\n",
    "sess.upload_data(path=\"test_df.pickle\", bucket=SAGEMAKER_BUCKET, key_prefix=bucket_path)\n",
    "\n",
    "s3_train_data = f\"s3://{SAGEMAKER_BUCKET}/{train_channel}\"\n",
    "s3_validation_data = f\"s3://{SAGEMAKER_BUCKET}/{validation_channel}\"\n",
    "\n",
    "s3_output_location = f\"s3://{SAGEMAKER_BUCKET}/{bucket_path}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'per_device_train_batch_size': 32,\n",
    "                 'model_name': 'distilbert-base-uncased'\n",
    "                 }\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='train.py',\n",
    "        source_dir=str(SCRIPTS_MODELS_PATH / 'stefano'),\n",
    "        instance_type='ml.p3.2xlarge',\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        transformers_version='4.4',\n",
    "        pytorch_version='1.6',\n",
    "        py_version='py36',\n",
    "        hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4dfbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': f's3://{SAGEMAKER_BUCKET}/{bucket_path}',\n",
    "    'test': f's3://{SAGEMAKER_BUCKET}/{bucket_path}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd810b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(fit_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b46a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b4c07",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print(\"Using SageMaker BlazingText container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.4xlarge\",\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        \"mode\": \"supervised\",\n",
    "        \"epochs\": 4,\n",
    "        \"min_count\": 2,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"vector_dim\": 10,\n",
    "#         \"early_stopping\": False,\n",
    "        \"patience\": 4,\n",
    "#         \"min_epochs\": 5,\n",
    "#         \"word_ngrams\": 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52012c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train data channel with S3_data_type as 'AugmentedManifestFile' and attribute names.\n",
    "# train_data = sagemaker.session.s3_input(\n",
    "#     your_augmented_manifest_file,\n",
    "#     distribution='FullyReplicated',\n",
    "#     content_type='application/x-recordio',\n",
    "#     s3_data_type='AugmentedManifestFile',\n",
    "#     attribute_names=['source-ref', 'annotations'],\n",
    "#     input_mode='Pipe',\n",
    "#     record_wrapping='RecordIO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437c4d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    input_mode='Pipe',\n",
    "    attribute_names=['source', 'label'],\n",
    "    record_wrapping='RecordIO',\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    input_mode='Pipe',\n",
    "    attribute_names=['source', 'label'],\n",
    "    record_wrapping='RecordIO',\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108539b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73112d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier = bt_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=JSONSerializer()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c081650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(test_df.sentence_text)\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\": tokenized_sentences, \"configuration\": {\"k\": 5}}\n",
    "\n",
    "response = text_classifier.predict(payload)\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1477d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "thresh = 0.05\n",
    "for pred in predictions:\n",
    "    labels = [int(x.replace('__label__', '')) for x, y in zip(pred['label'], pred['prob']) if y > thresh]\n",
    "    a.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t['preds'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "\n",
    "for i, class_ in enumerate(classes):\n",
    "    class_preds = [1 if i in x else 0 for x in t.preds]\n",
    "    class_targets = [1 if i in x else 0 for x in t.sector_ids]\n",
    "\n",
    "    indexes.append(class_)\n",
    "    precisions.append(precision_score(class_targets, class_preds))\n",
    "    recalls.append(recall_score(class_targets, class_preds))    \n",
    "    f1_scores.append(f1_score(class_targets, class_preds))        \n",
    "\n",
    "\n",
    "all_metrics = pd.DataFrame(\n",
    "    {\n",
    "        'class': indexes,\n",
    "        'recall': recalls,\n",
    "        'precision': precisions,\n",
    "        'f1_score': f1_scores\n",
    "    }\n",
    ").set_index('class', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.plot(\n",
    "    figsize=(20, 10), xticks=range(12), yticks=[x/10 for x in range(11)], ylim=(0, 1), grid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac79068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af957f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae1ff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
