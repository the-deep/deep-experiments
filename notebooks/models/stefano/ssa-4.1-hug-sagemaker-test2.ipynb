{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af940ea4",
   "metadata": {},
   "source": [
    "Using kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b68965bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eef203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc1c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6776847",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep.constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a382609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'Agricolture',\n",
    "    'Cross',\n",
    "    'Education',\n",
    "    'Food Security',\n",
    "    'Health',\n",
    "    'Livelihoods',\n",
    "    'Logistics',\n",
    "    'Nutrition',\n",
    "    'Protection',\n",
    "    'Shelter',\n",
    "    'Wash'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a43dcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b104cb95",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d3a4a",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c95284fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FRAMEWORKS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fdecff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(FRAMEWORKS_PATH / 'data_v0.3_train.csv')\n",
    "test = pd.read_csv(FRAMEWORKS_PATH / 'data_v0.3_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf3cc27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85922, 46)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffcbe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'excerpt', 'analysis_framework_id', 'created_by_id',\n",
       "       'lead_id', 'modified_by_id', 'information_date', 'order', 'client_id',\n",
       "       'project_id', 'tabular_field_id', 'dropped_excerpt', 'verified',\n",
       "       'verification_last_changed_by_id', 'exportdata_id', 'exportable_id',\n",
       "       'dimensions', 'subdimensions', 'sectors', 'subsectors', 'Shelter',\n",
       "       'Livelihoods', 'Protection', 'Shelter and NFIs', 'NFI', 'Food Security',\n",
       "       'Logistics', 'Cross', 'CCCM', 'Agriculture', 'Health', 'Nutrition',\n",
       "       'Education', 'WASH', 'sector_ids', 'Shock Informaton',\n",
       "       'Effects Systems And Networks', 'Effects On Population',\n",
       "       'Capacities & Response', 'At Risk', 'Scope & Scale', 'Impact',\n",
       "       'Humanitarian Conditions', 'Priorities', 'Context', 'dimension_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f9cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fda2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_for_sector(df, sector, train):\n",
    "    relevant_train = df[df.is_relevant == 1]\n",
    "    relevant_train.sector_ids = relevant_train.sector_ids.apply(eval)\n",
    "    relevant_train = relevant_train[relevant_train.sector_ids.apply(len) > 0]\n",
    "    \n",
    "    positive_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector in x)]\n",
    "    negative_train = relevant_train[relevant_train.sector_ids.apply(lambda x: sector not in x)]\n",
    "\n",
    "    positive_train.sector_ids = 1\n",
    "    negative_train.sector_ids = 0\n",
    "    train_df = pd.concat([positive_train, negative_train])\n",
    "    train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    train_df['is_valid'] = False if train else True\n",
    "        \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3971eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = process_for_sector(train, 4, True)\n",
    "test_df = process_for_sector(test, 4, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a377f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b66c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df.pickle')\n",
    "test_df.to_pickle('test_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add4fd63",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\n",
    "    role\n",
    ")  # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = SAGEMAKER_BUCKET\n",
    "prefix = \"huggingface/first\"  # Replace with the prefix under which you want to store the data if needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b520f5",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58286d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucket_path = 'test1/data'\n",
    "train_channel = bucket_path + \"/train_df.pickle\"\n",
    "validation_channel = bucket_path + \"/test_df.pickle\"\n",
    "\n",
    "sess.upload_data(path=\"train_df.pickle\", bucket=SAGEMAKER_BUCKET, key_prefix=bucket_path)\n",
    "sess.upload_data(path=\"test_df.pickle\", bucket=SAGEMAKER_BUCKET, key_prefix=bucket_path)\n",
    "\n",
    "s3_train_data = f\"s3://{SAGEMAKER_BUCKET}/{train_channel}\"\n",
    "s3_validation_data = f\"s3://{SAGEMAKER_BUCKET}/{validation_channel}\"\n",
    "\n",
    "s3_output_location = f\"s3://{SAGEMAKER_BUCKET}/{bucket_path}/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd4b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 1,\n",
    "                 'per_device_train_batch_size': 32,\n",
    "                 'model_name': 'distilbert-base-uncased'\n",
    "                 }\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='train.py',\n",
    "        source_dir=str(SCRIPTS_MODELS_PATH / 'stefano'),\n",
    "        instance_type='ml.p3.2xlarge',\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        transformers_version='4.4',\n",
    "        pytorch_version='1.6',\n",
    "        py_version='py36',\n",
    "        hyperparameters = hyperparameters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25421ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': f's3://{SAGEMAKER_BUCKET}/{bucket_path}',\n",
    "    'test': f's3://{SAGEMAKER_BUCKET}/{bucket_path}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823bac42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit(fit_arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f92f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea77b46",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7d23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print(\"Using SageMaker BlazingText container: {} ({})\".format(container, region_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdad9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.4xlarge\",\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=s3_output_location,\n",
    "    hyperparameters={\n",
    "        \"mode\": \"supervised\",\n",
    "        \"epochs\": 4,\n",
    "        \"min_count\": 2,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"vector_dim\": 10,\n",
    "#         \"early_stopping\": False,\n",
    "        \"patience\": 4,\n",
    "#         \"min_epochs\": 5,\n",
    "#         \"word_ngrams\": 2,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519af33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train data channel with S3_data_type as 'AugmentedManifestFile' and attribute names.\n",
    "# train_data = sagemaker.session.s3_input(\n",
    "#     your_augmented_manifest_file,\n",
    "#     distribution='FullyReplicated',\n",
    "#     content_type='application/x-recordio',\n",
    "#     s3_data_type='AugmentedManifestFile',\n",
    "#     attribute_names=['source-ref', 'annotations'],\n",
    "#     input_mode='Pipe',\n",
    "#     record_wrapping='RecordIO'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e95009",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    input_mode='Pipe',\n",
    "    attribute_names=['source', 'label'],\n",
    "    record_wrapping='RecordIO',\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/plain\",\n",
    "    s3_data_type=\"AugmentedManifestFile\",\n",
    "    input_mode='Pipe',\n",
    "    attribute_names=['source', 'label'],\n",
    "    record_wrapping='RecordIO',\n",
    ")\n",
    "data_channels = {\"train\": train_data, \"validation\": validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776f3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f58a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "text_classifier = bt_model.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m4.xlarge\", serializer=JSONSerializer()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac67b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(test_df.sentence_text)\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [\" \".join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\": tokenized_sentences, \"configuration\": {\"k\": 5}}\n",
    "\n",
    "response = text_classifier.predict(payload)\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7365ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "thresh = 0.05\n",
    "for pred in predictions:\n",
    "    labels = [int(x.replace('__label__', '')) for x, y in zip(pred['label'], pred['prob']) if y > thresh]\n",
    "    a.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c77cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t['preds'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9322c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1_scores = []\n",
    "\n",
    "for i, class_ in enumerate(classes):\n",
    "    class_preds = [1 if i in x else 0 for x in t.preds]\n",
    "    class_targets = [1 if i in x else 0 for x in t.sector_ids]\n",
    "\n",
    "    indexes.append(class_)\n",
    "    precisions.append(precision_score(class_targets, class_preds))\n",
    "    recalls.append(recall_score(class_targets, class_preds))    \n",
    "    f1_scores.append(f1_score(class_targets, class_preds))        \n",
    "\n",
    "\n",
    "all_metrics = pd.DataFrame(\n",
    "    {\n",
    "        'class': indexes,\n",
    "        'recall': recalls,\n",
    "        'precision': precisions,\n",
    "        'f1_score': f1_scores\n",
    "    }\n",
    ").set_index('class', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.plot(\n",
    "    figsize=(20, 10), xticks=range(12), yticks=[x/10 for x in range(11)], ylim=(0, 1), grid=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef8b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9297116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
