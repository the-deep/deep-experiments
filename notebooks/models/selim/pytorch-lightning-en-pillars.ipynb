{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n!pip install s3fs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "!pip install s3fs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('..', '..', '..', \"data\", \"frameworks_data\", \"data_v0.4.4\", \"data_v0.4.4_train.csv\")\n",
    "VAL_PATH = os.path.join('..', '..', '..', \"data\", \"frameworks_data\", \"data_v0.4.4\", \"data_v0.4.4_val.csv\")\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 8,
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = False  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
<<<<<<< HEAD
    "    train_df = train_df.sample(n=10000)\n",
    "    val_df = val_df.sample(n=10000)\n",
=======
    "    train_df = train_df.sample(n=1000)\n",
    "    val_df = val_df.sample(n=1000)\n",
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-subpillars-model\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "\n",
    "train_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "val_df.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S3Path('s3://sagemaker-deep-experiments-dev')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEV_BUCKET"
   ]
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "\n",
    "hyperparameters={\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
<<<<<<< HEAD
    "    'experiment_name': 'en_language_subpillars',\n",
    "    'max_len': 128,\n",
    "    'epochs': 3,\n",
    "    'model_name': 'distilbert-base-uncased',\n",
    "    'tokenizer_name': 'distilbert-base-uncased',\n",
    "    'dropout_rate': 0.4\n",
    "    'language_method': 'keep',\n",
    "    'pred_threshold':0.4,\n",
    "    'output_length': 768\n",
=======
    "    'experiment_name': 'all_languages_subpillars',\n",
    "    'max_len': 128,\n",
    "    'epochs': 3,\n",
    "    'model_name': 'microsoft/xtremedistil-l12-h384-uncased',\n",
    "    'tokenizer_name': 'microsoft/xtremedistil-l12-h384-uncased',\n",
    "    'dropout_rate': 0.2,\n",
    "    'pred_threshold':0.4,\n",
    "    'output_length': 384\n",
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir=str('../../../scripts/training/selim/multiclass-lightning'),\n",
<<<<<<< HEAD
    "    output_path=str(DEV_BUCKET / 'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p2.xlarge',\n",
=======
    "    output_path=str(DEV_BUCKET/'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 12,
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 13,
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": true,
    "tags": []
   },
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-26 14:11:35 Starting - Starting the training job...\n",
      "2021-07-26 14:11:59 Starting - Launching requested ML instancesProfilerReport-1627308692: InProgress\n",
      "......\n",
      "2021-07-26 14:12:59 Starting - Preparing the instances for training.........\n",
      "2021-07-26 14:14:47 Downloading - Downloading input data...\n",
      "2021-07-26 14:15:20 Training - Downloading the training image.....................\n",
      "2021-07-26 14:19:05 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-07-26 14:19:05,209 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-07-26 14:19:05,234 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-07-26 14:19:05,242 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-07-26 14:19:05,726 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.8.2\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4.0\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.8\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.4.1\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm==4.41.1\n",
      "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting nlpaug==1.1.6\n",
      "  Downloading nlpaug-1.1.6-py3-none-any.whl (405 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk==3.2.5\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.7.6-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (4.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting h5py~=2.10.0\u001b[0m\n",
      "\u001b[34m  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (3.17.3)\u001b[0m\n",
      "\u001b[34mCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\u001b[0m\n",
      "\u001b[34m  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.17\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (8.3.1)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.33.1-py2.py3-none-any.whl (152 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.8.2->-r requirements.txt (line 1)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.8.2->-r requirements.txt (line 1)) (7.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.8.2->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, termcolor, wrapt, idna-ssl\n",
      "  Building wheel for nltk (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.2.5-py3-none-any.whl size=1392140 sha256=010fc1573231e2d9395e8ce6661068443fb44241286e7eec1b92b2d82c2ec7cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/7f/71/cb36468789a03b5e2908281c8e1ce093e6860258b6b61677d8\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=911d04fda020fa05ed6760a5bae9c51d07567996b3bbfc1b9bfde129b24b65c2\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69749 sha256=0aa089b7557e0adcc5b2645ecab84894422f123b773d9e05639e4a15a89bd6e4\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for idna-ssl (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=cd08bc4d682a3a5bb427f49e442bbbfbf10da35965aad0dd134118962bbfc0e3\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk termcolor wrapt idna-ssl\u001b[0m\n",
      "\u001b[34mInstalling collected packages: typing-extensions, six, pyasn1-modules, oauthlib, multidict, cachetools, yarl, requests-oauthlib, numpy, idna-ssl, google-auth, async-timeout, tqdm, tensorboard-plugin-wit, regex, markdown, grpcio, google-auth-oauthlib, filelock, aiohttp, absl-py, wrapt, torchmetrics, tokenizers, termcolor, tensorflow-estimator, tensorboard, sacremoses, pyDeprecate, opt-einsum, keras-preprocessing, huggingface-hub, h5py, gast, flatbuffers, astunparse, transformers, tensorflow, pytorch-lightning, nltk, nlpaug\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.51.0\n",
      "    Uninstalling tqdm-4.51.0:\n",
      "      Successfully uninstalled tqdm-4.51.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed absl-py-0.13.0 aiohttp-3.7.4.post0 astunparse-1.6.3 async-timeout-3.0.1 cachetools-4.2.2 filelock-3.0.12 flatbuffers-1.12 gast-0.3.3 google-auth-1.33.1 google-auth-oauthlib-0.4.4 grpcio-1.32.0 h5py-2.10.0 huggingface-hub-0.0.12 idna-ssl-1.1.0 keras-preprocessing-1.1.2 markdown-3.3.4 multidict-5.1.0 nlpaug-1.1.6 nltk-3.2.5 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 pytorch-lightning-1.3.8 regex-2021.7.6 requests-oauthlib-1.3.0 sacremoses-0.0.45 six-1.15.0 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 tokenizers-0.10.3 torchmetrics-0.4.1 tqdm-4.41.1 transformers-4.8.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-07-26 14:19:56,186 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout_rate\": 0.2,\n",
      "        \"experiment_name\": \"all_languages_subpillars\",\n",
      "        \"max_len\": 128,\n",
      "        \"model_name\": \"microsoft/xtremedistil-l12-h384-uncased\",\n",
      "        \"output_length\": 384,\n",
      "        \"tokenizer_name\": \"microsoft/xtremedistil-l12-h384-uncased\",\n",
      "        \"epochs\": 3,\n",
      "        \"pred_threshold\": 0.4,\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2021-07-26-16-06-51-578-subpillars-model\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-26-16-06-51-578-subpillars-model/pytorch-2021-07-26-16-06-51-578-subpillars-model/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout_rate\":0.2,\"epochs\":3,\"experiment_name\":\"all_languages_subpillars\",\"max_len\":128,\"model_name\":\"microsoft/xtremedistil-l12-h384-uncased\",\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l12-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-26-16-06-51-578-subpillars-model/pytorch-2021-07-26-16-06-51-578-subpillars-model/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout_rate\":0.2,\"epochs\":3,\"experiment_name\":\"all_languages_subpillars\",\"max_len\":128,\"model_name\":\"microsoft/xtremedistil-l12-h384-uncased\",\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l12-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2021-07-26-16-06-51-578-subpillars-model\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-07-26-16-06-51-578-subpillars-model/pytorch-2021-07-26-16-06-51-578-subpillars-model/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout_rate\",\"0.2\",\"--epochs\",\"3\",\"--experiment_name\",\"all_languages_subpillars\",\"--max_len\",\"128\",\"--model_name\",\"microsoft/xtremedistil-l12-h384-uncased\",\"--output_length\",\"384\",\"--pred_threshold\",\"0.4\",\"--tokenizer_name\",\"microsoft/xtremedistil-l12-h384-uncased\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=all_languages_subpillars\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=128\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=microsoft/xtremedistil-l12-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_LENGTH=384\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER_NAME=microsoft/xtremedistil-l12-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=3\u001b[0m\n",
      "\u001b[34mSM_HP_PRED_THRESHOLD=0.4\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train.py --dropout_rate 0.2 --epochs 3 --experiment_name all_languages_subpillars --max_len 128 --model_name microsoft/xtremedistil-l12-h384-uncased --output_length 384 --pred_threshold 0.4 --tokenizer_name microsoft/xtremedistil-l12-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[nltk_data] Downloading package averaged_perceptron_tagger to\u001b[0m\n",
      "\u001b[34m[nltk_data]     /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package wordnet to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/wordnet.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package omw to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/omw.zip.\u001b[0m\n",
      "\u001b[34mimporting data ............\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:12,840 - filelock - INFO - Lock 139949817653792 acquired on /root/.cache/huggingface/transformers/21cea44dcf4371d5b1e3a1918136af8e26ed277e0bf64d59432061fb1c2106c4.137610c2d8cb598fe78b4c0dd3132bb67cd019fdd6ddd61a9290ac3b9df3bd94.lock\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:12,868 - filelock - INFO - Lock 139949817653792 released on /root/.cache/huggingface/transformers/21cea44dcf4371d5b1e3a1918136af8e26ed277e0bf64d59432061fb1c2106c4.137610c2d8cb598fe78b4c0dd3132bb67cd019fdd6ddd61a9290ac3b9df3bd94.lock\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:12,895 - filelock - INFO - Lock 139948864515544 acquired on /root/.cache/huggingface/transformers/549fddb29131352e707b89821b10203de40df038297108564f1ea4f97a3ca1fe.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:12,933 - filelock - INFO - Lock 139948864515544 released on /root/.cache/huggingface/transformers/549fddb29131352e707b89821b10203de40df038297108564f1ea4f97a3ca1fe.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:13,305 - filelock - INFO - Lock 139948846373296 acquired on /root/.cache/huggingface/transformers/3f51a219edcb6936c3aa85610b95f148df2d362b72136a4a2d297304ccf3750e.278515964ff18908761ab05adff4e2a21aab39c23274d79125a985cc04c110c6.lock\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:16,122 - filelock - INFO - Lock 139948846373296 released on /root/.cache/huggingface/transformers/3f51a219edcb6936c3aa85610b95f148df2d362b72136a4a2d297304ccf3750e.278515964ff18908761ab05adff4e2a21aab39c23274d79125a985cc04c110c6.lock\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s][2021-07-26 14:21:46.430 algo-1:61 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.496 algo-1:61 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.497 algo-1:61 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.497 algo-1:61 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.498 algo-1:61 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.498 algo-1:61 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.679 algo-1:61 INFO hook.py:591] name:model.l1.embeddings.word_embeddings.weight count_params:11720448\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.embeddings.position_embeddings.weight count_params:196608\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.embeddings.token_type_embeddings.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.embeddings.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.embeddings.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.680 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.681 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.0.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.682 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.683 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.1.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.684 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.2.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.685 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.686 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.3.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.687 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.688 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.4.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.689 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.5.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.690 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.691 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.6.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.692 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.693 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.7.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.694 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.695 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.8.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.696 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.9.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.697 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.698 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.10.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.699 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.700 algo-1:61 INFO hook.py:591] name:model.l1.encoder.layer.11.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.701 algo-1:61 INFO hook.py:591] name:model.l1.pooler.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.701 algo-1:61 INFO hook.py:591] name:model.l1.pooler.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.701 algo-1:61 INFO hook.py:591] name:model.l3.weight count_params:7680\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.701 algo-1:61 INFO hook.py:591] name:model.l3.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.701 algo-1:61 INFO hook.py:593] Total Trainable Params: 33367700\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.702 algo-1:61 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-07-26 14:21:46.707 algo-1:61 INFO hook.py:488] Hook is writing from the hook with pid: 61\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1547 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1547 [00:00<?, ?it/s] #015Epoch 0:   2%|▏         | 30/1547 [00:03<03:13,  7.82it/s]#015Epoch 0:   2%|▏         | 30/1547 [00:03<03:14,  7.82it/s, loss=2, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.184]#015Epoch 0:   4%|▍         | 60/1547 [00:07<03:03,  8.10it/s, loss=2, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.184]#015Epoch 0:   4%|▍         | 60/1547 [00:07<03:03,  8.10it/s, loss=0.79, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.464]#015Epoch 0:   6%|▌         | 90/1547 [00:10<02:56,  8.26it/s, loss=0.79, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.464]#015Epoch 0:   6%|▌         | 90/1547 [00:10<02:56,  8.26it/s, loss=0.653, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.532]#015Epoch 0:   8%|▊         | 120/1547 [00:14<02:53,  8.22it/s, loss=0.653, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.532]#015Epoch 0:   8%|▊         | 120/1547 [00:14<02:53,  8.22it/s, loss=0.595, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.548]#015Epoch 0:  10%|▉         | 150/1547 [00:18<02:50,  8.20it/s, loss=0.595, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.548]#015Epoch 0:  10%|▉         | 150/1547 [00:18<02:50,  8.20it/s, loss=0.535, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.531]#015Epoch 0:  12%|█▏        | 180/1547 [00:21<02:46,  8.20it/s, loss=0.535, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.531]#015Epoch 0:  12%|█▏        | 180/1547 [00:21<02:46,  8.20it/s, loss=0.488, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.518]#015Epoch 0:  14%|█▎        | 210/1547 [00:25<02:42,  8.21it/s, loss=0.488, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.518]#015Epoch 0:  14%|█▎        | 210/1547 [00:25<02:42,  8.21it/s, loss=0.452, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.476]#015Epoch 0:  16%|█▌        | 240/1547 [00:29<02:38,  8.24it/s, loss=0.452, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.476]#015Epoch 0:  16%|█▌        | 240/1547 [00:29<02:38,  8.24it/s, loss=0.424, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  17%|█▋        | 270/1547 [00:32<02:34,  8.24it/s, loss=0.424, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  17%|█▋        | 270/1547 [00:32<02:34,  8.24it/s, loss=0.403, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  19%|█▉        | 300/1547 [00:36<02:31,  8.25it/s, loss=0.403, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  19%|█▉        | 300/1547 [00:36<02:31,  8.25it/s, loss=0.423, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.519]#015Epoch 0:  21%|██▏       | 330/1547 [00:39<02:27,  8.26it/s, loss=0.423, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.519]#015Epoch 0:  21%|██▏       | 330/1547 [00:39<02:27,  8.26it/s, loss=0.361, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.493]#015Epoch 0:  23%|██▎       | 360/1547 [00:43<02:23,  8.24it/s, loss=0.361, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.493]#015Epoch 0:  23%|██▎       | 360/1547 [00:43<02:24,  8.24it/s, loss=0.359, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.480]#015Epoch 0:  25%|██▌       | 390/1547 [00:47<02:20,  8.25it/s, loss=0.359, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.480]#015Epoch 0:  25%|██▌       | 390/1547 [00:47<02:20,  8.25it/s, loss=0.329, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  27%|██▋       | 420/1547 [00:50<02:16,  8.26it/s, loss=0.329, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  27%|██▋       | 420/1547 [00:50<02:16,  8.26it/s, loss=0.313, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  29%|██▉       | 450/1547 [00:54<02:12,  8.27it/s, loss=0.313, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  29%|██▉       | 450/1547 [00:54<02:12,  8.27it/s, loss=0.338, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.490]#015Epoch 0:  31%|███       | 480/1547 [00:58<02:09,  8.26it/s, loss=0.338, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.490]#015Epoch 0:  31%|███       | 480/1547 [00:58<02:09,  8.26it/s, loss=0.293, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.483]#015Epoch 0:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.293, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.483]#015Epoch 0:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.284, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  35%|███▍      | 540/1547 [01:05<02:01,  8.28it/s, loss=0.284, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  35%|███▍      | 540/1547 [01:05<02:01,  8.28it/s, loss=0.273, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.484]#015Epoch 0:  37%|███▋      | 570/1547 [01:08<01:58,  8.27it/s, loss=0.273, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.484]#015Epoch 0:  37%|███▋      | 570/1547 [01:08<01:58,  8.27it/s, loss=0.264, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  39%|███▉      | 600/1547 [01:12<01:54,  8.28it/s, loss=0.264, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  39%|███▉      | 600/1547 [01:12<01:54,  8.28it/s, loss=0.278, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.479]#015Epoch 0:  41%|████      | 630/1547 [01:16<01:51,  8.25it/s, loss=0.278, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.479]#015Epoch 0:  41%|████      | 630/1547 [01:16<01:51,  8.25it/s, loss=0.268, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  43%|████▎     | 660/1547 [01:20<01:47,  8.24it/s, loss=0.268, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  43%|████▎     | 660/1547 [01:20<01:47,  8.24it/s, loss=0.268, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.479]#015Epoch 0:  45%|████▍     | 690/1547 [01:23<01:43,  8.25it/s, loss=0.268, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.479]#015Epoch 0:  45%|████▍     | 690/1547 [01:23<01:43,  8.25it/s, loss=0.26, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481] #015Epoch 0:  45%|████▍     | 690/1547 [01:39<02:04,  6.90it/s, loss=0.26, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  47%|████▋     | 720/1547 [01:47<02:03,  6.69it/s, loss=0.26, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  47%|████▋     | 720/1547 [01:47<02:03,  6.69it/s, loss=0.241, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  48%|████▊     | 750/1547 [01:51<01:58,  6.75it/s, loss=0.241, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  48%|████▊     | 750/1547 [01:51<01:58,  6.75it/s, loss=0.234, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.483]#015Epoch 0:  50%|█████     | 780/1547 [01:54<01:52,  6.80it/s, loss=0.234, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.483]#015Epoch 0:  50%|█████     | 780/1547 [01:54<01:52,  6.80it/s, loss=0.257, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  52%|█████▏    | 810/1547 [01:58<01:47,  6.85it/s, loss=0.257, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  52%|█████▏    | 810/1547 [01:58<01:47,  6.85it/s, loss=0.228, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.498]#015Epoch 0:  54%|█████▍    | 840/1547 [02:01<01:42,  6.89it/s, loss=0.228, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.498]#015Epoch 0:  54%|█████▍    | 840/1547 [02:01<01:42,  6.89it/s, loss=0.224, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.497]#015Epoch 0:  56%|█████▌    | 870/1547 [02:05<01:37,  6.94it/s, loss=0.224, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.497]#015Epoch 0:  56%|█████▌    | 870/1547 [02:05<01:37,  6.94it/s, loss=0.244, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  58%|█████▊    | 900/1547 [02:09<01:32,  6.98it/s, loss=0.244, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  58%|█████▊    | 900/1547 [02:09<01:32,  6.98it/s, loss=0.238, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  60%|██████    | 930/1547 [02:12<01:27,  7.02it/s, loss=0.238, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.478]#015Epoch 0:  60%|██████    | 930/1547 [02:12<01:27,  7.02it/s, loss=0.239, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  62%|██████▏   | 960/1547 [02:16<01:23,  7.05it/s, loss=0.239, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  62%|██████▏   | 960/1547 [02:16<01:23,  7.05it/s, loss=0.236, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.508]#015Epoch 0:  64%|██████▍   | 990/1547 [02:19<01:18,  7.08it/s, loss=0.236, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.508]#015Epoch 0:  64%|██████▍   | 990/1547 [02:19<01:18,  7.08it/s, loss=0.21, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.496] #015Epoch 0:  66%|██████▌   | 1020/1547 [02:23<01:14,  7.10it/s, loss=0.21, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.496]#015Epoch 0:  66%|██████▌   | 1020/1547 [02:23<01:14,  7.10it/s, loss=0.231, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.495]#015Epoch 0:  68%|██████▊   | 1050/1547 [02:27<01:09,  7.13it/s, loss=0.231, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.495]#015Epoch 0:  68%|██████▊   | 1050/1547 [02:27<01:09,  7.13it/s, loss=0.21, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.497] #015Epoch 0:  70%|██████▉   | 1080/1547 [02:30<01:05,  7.16it/s, loss=0.21, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.497]#015Epoch 0:  70%|██████▉   | 1080/1547 [02:30<01:05,  7.16it/s, loss=0.2, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481] #015Epoch 0:  72%|███████▏  | 1110/1547 [02:34<01:00,  7.19it/s, loss=0.2, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  72%|███████▏  | 1110/1547 [02:34<01:00,  7.19it/s, loss=0.214, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  74%|███████▎  | 1140/1547 [02:37<00:56,  7.22it/s, loss=0.214, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  74%|███████▎  | 1140/1547 [02:37<00:56,  7.22it/s, loss=0.199, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  76%|███████▌  | 1170/1547 [02:41<00:52,  7.24it/s, loss=0.199, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  76%|███████▌  | 1170/1547 [02:41<00:52,  7.24it/s, loss=0.199, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.505]#015Epoch 0:  78%|███████▊  | 1200/1547 [02:45<00:47,  7.27it/s, loss=0.199, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.505]#015Epoch 0:  78%|███████▊  | 1200/1547 [02:45<00:47,  7.27it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.511]#015Epoch 0:  80%|███████▉  | 1230/1547 [02:48<00:43,  7.29it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.511]#015Epoch 0:  80%|███████▉  | 1230/1547 [02:48<00:43,  7.29it/s, loss=0.219, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  81%|████████▏ | 1260/1547 [02:52<00:39,  7.31it/s, loss=0.219, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  81%|████████▏ | 1260/1547 [02:52<00:39,  7.31it/s, loss=0.211, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  83%|████████▎ | 1290/1547 [02:55<00:35,  7.33it/s, loss=0.211, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.481]#015Epoch 0:  83%|████████▎ | 1290/1547 [02:55<00:35,  7.33it/s, loss=0.221, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.531]#015Epoch 0:  85%|████████▌ | 1320/1547 [02:59<00:30,  7.35it/s, loss=0.221, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.531]#015Epoch 0:  85%|████████▌ | 1320/1547 [02:59<00:30,  7.35it/s, loss=0.195, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  87%|████████▋ | 1350/1547 [03:03<00:26,  7.37it/s, loss=0.195, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.482]#015Epoch 0:  87%|████████▋ | 1350/1547 [03:03<00:26,  7.37it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]#015Epoch 0:  89%|████████▉ | 1380/1547 [03:06<00:22,  7.41it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/172 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  17%|█▋        | 30/172 [00:01<00:08, 16.90it/s]#033[A#015Epoch 0:  91%|█████████ | 1410/1547 [03:08<00:18,  7.50it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n",
      "\u001b[34m#015Validating:  35%|███▍      | 60/172 [00:03<00:06, 17.40it/s]#033[A#015Epoch 0:  93%|█████████▎| 1440/1547 [03:09<00:14,  7.59it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  52%|█████▏    | 90/172 [00:04<00:04, 17.78it/s]#033[A#015Epoch 0:  95%|█████████▌| 1470/1547 [03:11<00:10,  7.69it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n",
      "\u001b[34m#015Validating:  70%|██████▉   | 120/172 [00:06<00:02, 18.05it/s]#033[A#015Epoch 0:  97%|█████████▋| 1500/1547 [03:12<00:06,  7.78it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n",
      "\u001b[34m#015Validating:  87%|████████▋ | 150/172 [00:08<00:01, 18.16it/s]#033[A#015Epoch 0:  99%|█████████▉| 1530/1547 [03:14<00:02,  7.87it/s, loss=0.197, v_num=0, val_f1_epoch=0.0708, val_loss_epoch=0.668, train_f1=0.489]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 172/172 [00:09<00:00, 18.36it/s]#033[A#015Epoch 0: 100%|██████████| 1547/1547 [03:15<00:00,  7.91it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1547 [00:00<?, ?it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]           #015Epoch 1:   0%|          | 0/1547 [00:00<?, ?it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   2%|▏         | 30/1547 [00:03<03:16,  7.72it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   2%|▏         | 30/1547 [00:03<03:16,  7.71it/s, loss=0.196, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   4%|▍         | 60/1547 [00:07<03:05,  8.00it/s, loss=0.196, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.476, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   4%|▍         | 60/1547 [00:07<03:05,  8.00it/s, loss=0.284, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.536, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   6%|▌         | 90/1547 [00:11<02:59,  8.12it/s, loss=0.284, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.536, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   6%|▌         | 90/1547 [00:11<02:59,  8.12it/s, loss=0.197, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.479, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   8%|▊         | 120/1547 [00:14<02:54,  8.18it/s, loss=0.197, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.479, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:   8%|▊         | 120/1547 [00:14<02:54,  8.18it/s, loss=0.206, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.544, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  10%|▉         | 150/1547 [00:18<02:50,  8.18it/s, loss=0.206, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.544, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  10%|▉         | 150/1547 [00:18<02:50,  8.18it/s, loss=0.226, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.479, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  12%|█▏        | 180/1547 [00:21<02:46,  8.19it/s, loss=0.226, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.479, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  12%|█▏        | 180/1547 [00:21<02:46,  8.19it/s, loss=0.204, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.538, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  14%|█▎        | 210/1547 [00:25<02:42,  8.23it/s, loss=0.204, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.538, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  14%|█▎        | 210/1547 [00:25<02:42,  8.23it/s, loss=0.185, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.495, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  16%|█▌        | 240/1547 [00:29<02:38,  8.23it/s, loss=0.185, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.495, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  16%|█▌        | 240/1547 [00:29<02:38,  8.23it/s, loss=0.208, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.496, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  17%|█▋        | 270/1547 [00:32<02:34,  8.25it/s, loss=0.208, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.496, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  17%|█▋        | 270/1547 [00:32<02:34,  8.25it/s, loss=0.207, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.516, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  19%|█▉        | 300/1547 [00:36<02:31,  8.24it/s, loss=0.207, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.516, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  19%|█▉        | 300/1547 [00:36<02:31,  8.24it/s, loss=0.225, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.560, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  21%|██▏       | 330/1547 [00:40<02:27,  8.24it/s, loss=0.225, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.560, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  21%|██▏       | 330/1547 [00:40<02:27,  8.24it/s, loss=0.178, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.525, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  23%|██▎       | 360/1547 [00:43<02:23,  8.26it/s, loss=0.178, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.525, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  23%|██▎       | 360/1547 [00:43<02:23,  8.26it/s, loss=0.177, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.562, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  25%|██▌       | 390/1547 [00:47<02:19,  8.27it/s, loss=0.177, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.562, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  25%|██▌       | 390/1547 [00:47<02:19,  8.27it/s, loss=0.18, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.511, val_f1_step=0.479, val_loss_step=0.214] #015Epoch 1:  27%|██▋       | 420/1547 [00:50<02:16,  8.28it/s, loss=0.18, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.511, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  27%|██▋       | 420/1547 [00:50<02:16,  8.28it/s, loss=0.173, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.530, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  29%|██▉       | 450/1547 [00:54<02:12,  8.28it/s, loss=0.173, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.530, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  29%|██▉       | 450/1547 [00:54<02:12,  8.28it/s, loss=0.178, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.506, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  31%|███       | 480/1547 [00:57<02:08,  8.28it/s, loss=0.178, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.506, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  31%|███       | 480/1547 [00:57<02:08,  8.28it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.503, val_f1_step=0.479, val_loss_step=0.214] #015Epoch 1:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.503, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.508, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  35%|███▍      | 540/1547 [01:05<02:01,  8.25it/s, loss=0.203, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.508, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  35%|███▍      | 540/1547 [01:05<02:01,  8.25it/s, loss=0.224, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.558, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  37%|███▋      | 570/1547 [01:09<01:58,  8.26it/s, loss=0.224, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.558, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  37%|███▋      | 570/1547 [01:09<01:58,  8.26it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.655, val_f1_step=0.479, val_loss_step=0.214] #015Epoch 1:  39%|███▉      | 600/1547 [01:12<01:54,  8.25it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.655, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  39%|███▉      | 600/1547 [01:12<01:54,  8.25it/s, loss=0.194, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.517, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  41%|████      | 630/1547 [01:16<01:51,  8.25it/s, loss=0.194, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.517, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  41%|████      | 630/1547 [01:16<01:51,  8.25it/s, loss=0.184, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.520, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  43%|████▎     | 660/1547 [01:19<01:47,  8.26it/s, loss=0.184, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.520, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  43%|████▎     | 660/1547 [01:19<01:47,  8.26it/s, loss=0.174, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.570, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  45%|████▍     | 690/1547 [01:23<01:43,  8.26it/s, loss=0.174, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.570, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  45%|████▍     | 690/1547 [01:23<01:43,  8.26it/s, loss=0.173, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.528, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  47%|████▋     | 720/1547 [01:27<01:40,  8.26it/s, loss=0.173, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.528, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  47%|████▋     | 720/1547 [01:27<01:40,  8.26it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.576, val_f1_step=0.479, val_loss_step=0.214] #015Epoch 1:  48%|████▊     | 750/1547 [01:30<01:36,  8.26it/s, loss=0.17, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.576, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  48%|████▊     | 750/1547 [01:30<01:36,  8.26it/s, loss=0.19, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  50%|█████     | 780/1547 [01:34<01:32,  8.26it/s, loss=0.19, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  50%|█████     | 780/1547 [01:34<01:32,  8.26it/s, loss=0.169, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.515, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  52%|█████▏    | 810/1547 [01:37<01:29,  8.27it/s, loss=0.169, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.515, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  52%|█████▏    | 810/1547 [01:37<01:29,  8.27it/s, loss=0.167, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.588, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  54%|█████▍    | 840/1547 [01:41<01:25,  8.27it/s, loss=0.167, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.588, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  54%|█████▍    | 840/1547 [01:41<01:25,  8.27it/s, loss=0.164, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.565, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  56%|█████▌    | 870/1547 [01:45<01:21,  8.27it/s, loss=0.164, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.565, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  56%|█████▌    | 870/1547 [01:45<01:21,  8.27it/s, loss=0.165, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.571, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  58%|█████▊    | 900/1547 [01:48<01:18,  8.27it/s, loss=0.165, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.571, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  58%|█████▊    | 900/1547 [01:48<01:18,  8.27it/s, loss=0.192, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.608, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  60%|██████    | 930/1547 [01:52<01:14,  8.27it/s, loss=0.192, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.608, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  60%|██████    | 930/1547 [01:52<01:14,  8.27it/s, loss=0.199, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.659, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  62%|██████▏   | 960/1547 [01:56<01:10,  8.27it/s, loss=0.199, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.659, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  62%|██████▏   | 960/1547 [01:56<01:10,  8.27it/s, loss=0.191, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.592, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  64%|██████▍   | 990/1547 [01:59<01:07,  8.26it/s, loss=0.191, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.592, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  64%|██████▍   | 990/1547 [01:59<01:07,  8.26it/s, loss=0.194, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.527, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  66%|██████▌   | 1020/1547 [02:03<01:03,  8.26it/s, loss=0.194, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.527, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  66%|██████▌   | 1020/1547 [02:03<01:03,  8.26it/s, loss=0.166, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.563, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  68%|██████▊   | 1050/1547 [02:07<01:00,  8.26it/s, loss=0.166, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.563, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  68%|██████▊   | 1050/1547 [02:07<01:00,  8.26it/s, loss=0.165, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.663, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  70%|██████▉   | 1080/1547 [02:10<00:56,  8.25it/s, loss=0.165, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.663, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  70%|██████▉   | 1080/1547 [02:10<00:56,  8.25it/s, loss=0.195, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.617, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  72%|███████▏  | 1110/1547 [02:14<00:52,  8.26it/s, loss=0.195, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.617, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  72%|███████▏  | 1110/1547 [02:14<00:52,  8.26it/s, loss=0.208, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.582, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  74%|███████▎  | 1140/1547 [02:18<00:49,  8.26it/s, loss=0.208, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.582, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  74%|███████▎  | 1140/1547 [02:18<00:49,  8.26it/s, loss=0.183, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.552, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  76%|███████▌  | 1170/1547 [02:21<00:45,  8.27it/s, loss=0.183, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.552, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  76%|███████▌  | 1170/1547 [02:21<00:45,  8.27it/s, loss=0.174, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.549, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  78%|███████▊  | 1200/1547 [02:25<00:41,  8.27it/s, loss=0.174, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.549, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  78%|███████▊  | 1200/1547 [02:25<00:41,  8.27it/s, loss=0.205, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.606, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  80%|███████▉  | 1230/1547 [02:28<00:38,  8.27it/s, loss=0.205, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.606, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  80%|███████▉  | 1230/1547 [02:28<00:38,  8.27it/s, loss=0.186, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.547, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  81%|████████▏ | 1260/1547 [02:32<00:34,  8.27it/s, loss=0.186, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.547, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  81%|████████▏ | 1260/1547 [02:32<00:34,  8.27it/s, loss=0.161, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.626, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  83%|████████▎ | 1290/1547 [02:36<00:31,  8.27it/s, loss=0.161, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.626, v\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mal_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  83%|████████▎ | 1290/1547 [02:36<00:31,  8.27it/s, loss=0.152, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.629, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  85%|████████▌ | 1320/1547 [02:39<00:27,  8.27it/s, loss=0.152, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.629, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  85%|████████▌ | 1320/1547 [02:39<00:27,  8.27it/s, loss=0.211, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.594, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  87%|████████▋ | 1350/1547 [02:43<00:23,  8.27it/s, loss=0.211, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.594, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  87%|████████▋ | 1350/1547 [02:43<00:23,  8.27it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]#015Epoch 1:  89%|████████▉ | 1380/1547 [02:46<00:20,  8.29it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/172 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  17%|█▋        | 30/172 [00:01<00:08, 16.78it/s]#033[A#015Epoch 1:  91%|█████████ | 1410/1547 [02:48<00:16,  8.38it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating:  35%|███▍      | 60/172 [00:03<00:06, 17.31it/s]#033[A#015Epoch 1:  93%|█████████▎| 1440/1547 [02:49<00:12,  8.48it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating:  52%|█████▏    | 90/172 [00:04<00:04, 17.74it/s]#033[A#015Epoch 1:  95%|█████████▌| 1470/1547 [02:51<00:08,  8.58it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating:  70%|██████▉   | 120/172 [00:06<00:02, 18.02it/s]#033[A#015Epoch 1:  97%|█████████▋| 1500/1547 [02:53<00:05,  8.67it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating:  87%|████████▋ | 150/172 [00:08<00:01, 18.18it/s]#033[A#015Epoch 1:  99%|█████████▉| 1530/1547 [02:54<00:01,  8.76it/s, loss=0.168, v_num=0, val_f1_epoch=0.480, val_loss_epoch=0.214, train_f1=0.569, val_f1_step=0.479, val_loss_step=0.214]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 172/172 [00:09<00:00, 18.37it/s]#033[A#015Epoch 1: 100%|██████████| 1547/1547 [02:55<00:00,  8.80it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.517, val_f1_step=0.602, val_loss_step=0.190] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1547 [00:00<?, ?it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.517, val_f1_step=0.602, val_loss_step=0.190]           #015Epoch 2:   0%|          | 0/1547 [00:00<?, ?it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.517, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   2%|▏         | 30/1547 [00:03<03:14,  7.78it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.517, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   2%|▏         | 30/1547 [00:03<03:14,  7.78it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.569, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   4%|▍         | 60/1547 [00:07<03:05,  8.00it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.569, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   4%|▍         | 60/1547 [00:07<03:05,  8.00it/s, loss=0.205, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.669, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   6%|▌         | 90/1547 [00:11<02:59,  8.11it/s, loss=0.205, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.669, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   6%|▌         | 90/1547 [00:11<02:59,  8.11it/s, loss=0.159, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.573, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   8%|▊         | 120/1547 [00:14<02:55,  8.11it/s, loss=0.159, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.573, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:   8%|▊         | 120/1547 [00:14<02:55,  8.11it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.616, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  10%|▉         | 150/1547 [00:18<02:51,  8.16it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.616, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  10%|▉         | 150/1547 [00:18<02:51,  8.16it/s, loss=0.228, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.628, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  12%|█▏        | 180/1547 [00:22<02:47,  8.17it/s, loss=0.228, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.628, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  12%|█▏        | 180/1547 [00:22<02:47,  8.17it/s, loss=0.184, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.654, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  14%|█▎        | 210/1547 [00:25<02:43,  8.17it/s, loss=0.184, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.654, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  14%|█▎        | 210/1547 [00:25<02:43,  8.17it/s, loss=0.188, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.640, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  16%|█▌        | 240/1547 [00:29<02:39,  8.20it/s, loss=0.188, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.640, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  16%|█▌        | 240/1547 [00:29<02:39,  8.20it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.614, val_f1_step=0.602, val_loss_step=0.190] #015Epoch 2:  17%|█▋        | 270/1547 [00:32<02:35,  8.20it/s, loss=0.16, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.614, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  17%|█▋        | 270/1547 [00:32<02:35,  8.20it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.702, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  19%|█▉        | 300/1547 [00:36<02:31,  8.22it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.702, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  19%|█▉        | 300/1547 [00:36<02:31,  8.22it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.624, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  21%|██▏       | 330/1547 [00:40<02:28,  8.22it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.624, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  21%|██▏       | 330/1547 [00:40<02:28,  8.22it/s, loss=0.158, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.576, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  23%|██▎       | 360/1547 [00:43<02:24,  8.23it/s, loss=0.158, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.576, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  23%|██▎       | 360/1547 [00:43<02:24,  8.23it/s, loss=0.157, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  25%|██▌       | 390/1547 [00:47<02:20,  8.26it/s, loss=0.157, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  25%|██▌       | 390/1547 [00:47<02:20,  8.26it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.656, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  27%|██▋       | 420/1547 [00:50<02:16,  8.26it/s, loss=0.153, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.656, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  27%|██▋       | 420/1547 [00:50<02:16,  8.26it/s, loss=0.173, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.610, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  29%|██▉       | 450/1547 [00:54<02:12,  8.28it/s, loss=0.173, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.610, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  29%|██▉       | 450/1547 [00:54<02:12,  8.28it/s, loss=0.146, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.624, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  31%|███       | 480/1547 [00:57<02:08,  8.29it/s, loss=0.146, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.624, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  31%|███       | 480/1547 [00:57<02:08,  8.29it/s, loss=0.154, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.587, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.154, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.587, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  33%|███▎      | 510/1547 [01:01<02:05,  8.27it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.580, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  35%|███▍      | 540/1547 [01:05<02:01,  8.27it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.580, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  35%|███▍      | 540/1547 [01:05<02:01,  8.27it/s, loss=0.154, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.602, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  37%|███▋      | 570/1547 [01:08<01:58,  8.28it/s, loss=0.154, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.602, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  37%|███▋      | 570/1547 [01:08<01:58,  8.28it/s, loss=0.164, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.623, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  39%|███▉      | 600/1547 [01:12<01:54,  8.29it/s, loss=0.164, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.623, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  39%|███▉      | 600/1547 [01:12<01:54,  8.29it/s, loss=0.171, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.689, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  41%|████      | 630/1547 [01:15<01:50,  8.29it/s, loss=0.171, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.689, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  41%|████      | 630/1547 [01:15<01:50,  8.29it/s, loss=0.197, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  43%|████▎     | 660/1547 [01:19<01:47,  8.29it/s, loss=0.197, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  43%|████▎     | 660/1547 [01:19<01:47,  8.29it/s, loss=0.172, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.697, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  45%|████▍     | 690/1547 [01:23<01:43,  8.30it/s, loss=0.172, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.697, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  45%|████▍     | 690/1547 [01:23<01:43,  8.30it/s, loss=0.144, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.631, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  47%|████▋     | 720/1547 [01:26<01:39,  8.30it/s, loss=0.144, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.631, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  47%|████▋     | 720/1547 [01:26<01:39,  8.30it/s, loss=0.173, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.678, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  48%|████▊     | 750/1547 [01:30<01:35,  8.31it/s, loss=0.173, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.678, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  48%|████▊     | 750/1547 [01:30<01:35,  8.31it/s, loss=0.157, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.661, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  50%|█████     | 780/1547 [01:33<01:32,  8.31it/s, loss=0.157, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.661, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  50%|█████     | 780/1547 [01:33<01:32,  8.31it/s, loss=0.196, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.667, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  52%|█████▏    | 810/1547 [01:37<01:28,  8.31it/s, loss=0.196, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.667, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  52%|█████▏    | 810/1547 [01:37<01:28,  8.31it/s, loss=0.183, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  54%|█████▍    | 840/1547 [01:41<01:25,  8.32it/s, loss=0.183, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  54%|█████▍    | 840/1547 [01:41<01:25,  8.32it/s, loss=0.152, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.601, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  56%|█████▌    | 870/1547 [01:44<01:21,  8.32it/s, loss=0.152, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.601, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  56%|█████▌    | 870/1547 [01:44<01:21,  8.32it/s, loss=0.183, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  58%|█████▊    | 900/1547 [01:48<01:17,  8.32it/s, loss=0.183, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  58%|█████▊    | 900/1547 [01:48<01:17,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.632, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  60%|██████    | 930/1547 [01:51<01:14,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.632, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  60%|██████    | 930/1547 [01:51<01:14,  8.32it/s, loss=0.148, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.643, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  62%|██████▏   | 960/1547 [01:55<01:10,  8.32it/s, loss=0.148, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.643, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  62%|██████▏   | 960/1547 [01:55<01:10,  8.32it/s, loss=0.15, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.574, val_f1_step=0.602, val_loss_step=0.190] #015Epoch 2:  64%|██████▍   | 990/1547 [01:58<01:06,  8.33it/s, loss=0.15, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.574, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  64%|██████▍   | 990/1547 [01:58<01:06,  8.33it/s, loss=0.199, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.681, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  66%|██████▌   | 1020/1547 [02:02<01:03,  8.32it/s, loss=0.199, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.681, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  66%|██████▌   | 1020/1547 [02:02<01:03,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.665, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  68%|██████▊   | 1050/1547 [02:06<00:59,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.665, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  68%|██████▊   | 1050/1547 [02:06<00:59,  8.32it/s, loss=0.151, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  70%|██████▉   | 1080/1547 [02:09<00:56,  8.32it/s, loss=0.151, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  70%|██████▉   | 1080/1547 [02:09<00:56,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.708, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  72%|███████▏  | 1110/1547 [02:13<00:52,  8.32it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.708, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  72%|███████▏  | 1110/1547 [02:13<00:52,  8.32it/s, loss=0.147, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.727, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  74%|███████▎  | 1140/1547 [02:17<00:48,  8.32it/s, loss=0.147, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.727, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  74%|███████▎  | 1140/1547 [02:17<00:48,  8.32it/s, loss=0.143, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.640, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  76%|███████▌  | 1170/1547 [02:20<00:45,  8.31it/s, loss=0.143, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.640, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  76%|███████▌  | 1170/1547 [02:20<00:45,  8.31it/s, loss=0.181, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  78%|███████▊  | 1200/1547 [02:24<00:41,  8.31it/s, loss=0.181, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  78%|███████▊  | 1200/1547 [02:24<00:41,  8.31it/s, loss=0.177, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.638, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  80%|███████▉  | 1230/1547 [02:28<00:38,  8.31it/s, loss=0.177, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.638, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  80%|███████▉  | 1230/1547 [02:28<00:38,  8.31it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  81%|████████▏ | 1260/1547 [02:31<00:34,  8.31it/s, loss=0.149, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  81%|████████▏ | 1260/1547 [02:31<00:34,  8.31it/s, loss=0.161, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.588, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  83%|████████▎ | 1290/1547 [02:35<00:30,  8.31it/s, loss=0.161, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.588, \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mval_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  83%|████████▎ | 1290/1547 [02:35<00:30,  8.31it/s, loss=0.191, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.680, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  85%|████████▌ | 1320/1547 [02:38<00:27,  8.30it/s, loss=0.191, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.680, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  85%|████████▌ | 1320/1547 [02:38<00:27,  8.30it/s, loss=0.179, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.625, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  87%|████████▋ | 1350/1547 [02:42<00:23,  8.30it/s, loss=0.179, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.625, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  87%|████████▋ | 1350/1547 [02:42<00:23,  8.30it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]#015Epoch 2:  89%|████████▉ | 1380/1547 [02:45<00:20,  8.33it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/172 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  17%|█▋        | 30/172 [00:01<00:08, 16.73it/s]#033[A#015Epoch 2:  91%|█████████ | 1410/1547 [02:47<00:16,  8.42it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating:  35%|███▍      | 60/172 [00:03<00:06, 17.23it/s]#033[A#015Epoch 2:  93%|█████████▎| 1440/1547 [02:49<00:12,  8.51it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating:  52%|█████▏    | 90/172 [00:05<00:04, 17.59it/s]#033[A#015Epoch 2:  95%|█████████▌| 1470/1547 [02:50<00:08,  8.61it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating:  70%|██████▉   | 120/172 [00:06<00:02, 17.90it/s]#033[A#015Epoch 2:  97%|█████████▋| 1500/1547 [02:52<00:05,  8.70it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating:  87%|████████▋ | 150/172 [00:08<00:01, 18.11it/s]#033[A#015Epoch 2:  99%|█████████▉| 1530/1547 [02:53<00:01,  8.79it/s, loss=0.165, v_num=0, val_f1_epoch=0.617, val_loss_epoch=0.186, train_f1=0.739, val_f1_step=0.602, val_loss_step=0.190]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 172/172 [00:09<00:00, 18.29it/s]#033[A#015Epoch 2: 100%|██████████| 1547/1547 [02:55<00:00,  8.83it/s, loss=0.149, v_num=0, val_f1_epoch=0.674, val_loss_epoch=0.178, train_f1=0.681, val_f1_step=0.645, val_loss_step=0.186]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 2: 100%|██████████| 1547/1547 [02:56<00:00,  8.77it/s, loss=0.149, v_num=0, val_f1_epoch=0.674, val_loss_epoch=0.178, train_f1=0.681, val_f1_step=0.645, val_loss_step=0.186]\u001b[0m\n",
      "\u001b[34mratio of evaluated sentences (%): 66.28160814989995\u001b[0m\n",
      "\u001b[34m(7287, 20)\u001b[0m\n",
      "\u001b[34m(7287, 20)\u001b[0m\n",
      "\u001b[34mTime to predict 100 sentences:  0.0921400767691467\u001b[0m\n",
      "\u001b[34msubpillars:  Sector            NaN\u001b[0m\n",
      "\u001b[34mPrecision    0.687678\u001b[0m\n",
      "\u001b[34mRecall       0.636502\u001b[0m\n",
      "\u001b[34mF1 Score     0.643266\u001b[0m\n",
      "\u001b[34mAccuracy     0.942624\u001b[0m\n",
      "\u001b[34mName: mean, dtype: object\u001b[0m\n",
      "\u001b[34mpillars:  Sector            NaN\u001b[0m\n",
      "\u001b[34mPrecision    0.777916\u001b[0m\n",
      "\u001b[34mRecall        0.70758\u001b[0m\n",
      "\u001b[34mF1 Score     0.712133\u001b[0m\n",
      "\u001b[34mAccuracy     0.881158\u001b[0m\n",
      "\u001b[34mName: mean, dtype: object\u001b[0m\n",
      "\u001b[34m2021-07-26 14:20:08.492099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/527 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 527/527 [00:00<00:00, 548kB/s]\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 41.0MB/s]\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/134M [00:00<?, ?B/s]#015Downloading:   3%|▎         | 4.29M/134M [00:00<00:03, 42.9MB/s]#015Downloading:   7%|▋         | 9.12M/134M [00:00<00:02, 44.4MB/s]#015Downloading:  11%|█         | 14.1M/134M [00:00<00:02, 45.8MB/s]#015Downloading:  14%|█▍        | 19.1M/134M [00:00<00:02, 47.0MB/s]#015Downloading:  18%|█▊        | 24.1M/134M [00:00<00:02, 48.0MB/s]#015Downloading:  22%|██▏       | 29.2M/134M [00:00<00:02, 48.8MB/s]#015Downloading:  26%|██▌       | 34.1M/134M [00:00<00:02, 48.9MB/s]#015Downloading:  29%|██▉       | 39.2M/134M [00:00<00:01, 49.4MB/s]#015Downloading:  33%|███▎      | 44.3M/134M [00:00<00:01, 49.8MB/s]#015Downloading:  37%|███▋      | 49.4M/134M [00:01<00:01, 50.2MB/s]#015Downloading:  41%|████      | 54.5M/134M [00:01<00:01, 50.6MB/s]#015Downloading:  45%|████▍     | 59.7M/134M [00:01<00:01, 50.8MB/s]#015Downloading:  49%|████▊     | 64.8M/134M [00:01<00:01, 51.0MB/s]#015Downloading:  52%|█████▏    | 69.9M/134M [00:01<00:01, 51.1MB/s]#015Downloading:  56%|█████▌    | 75.1M/134M [00:01<00:01, 51.1MB/s]#015Downloading:  60%|██████    | 80.2M/134M [00:01<00:01, 51.1MB/s]#015Downloading:  64%|██████▍   | 85.3M/134M [00:01<00:00, 50.5MB/s]#015Downloading:  68%|██████▊   | 90.4M/134M [00:01<00:00, 50.7MB/s]#015Downloading:  72%|███████▏  | 95.5M/134M [00:01<00:00, 50.9MB/s]#015Downloading:  76%|███████▌  | 101M/134M [00:02<00:00, 52.3MB/s] #015Downloading:  80%|███████▉  | 107M/134M [00:02<00:00, 52.9MB/s]#015Downloading:  84%|████████▍ | 112M/134M [00:02<00:00, 52.8MB/s]#015Downloading:  88%|████████▊ | 117M/134M [00:02<00:00, 53.5MB/s]#015Downloading:  92%|█████████▏| 123M/134M [00:02<00:00, 54.2MB/s]#015Downloading:  96%|█████████▋| 129M/134M [00:02<00:00, 54.8MB/s]#015Downloading: 100%|██████████| 134M/134M [00:02<00:00, 51.5MB/s]\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[34mEpoch 0, global step 1374: val_f1 reached 0.48016 (best 0.48016), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l12-h384-uncased/epoch=0-step=1374.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 1, global step 2749: val_f1 reached 0.61659 (best 0.61659), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l12-h384-uncased/epoch=1-step=2749.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 2, global step 4124: val_f1 reached 0.67425 (best 0.67425), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l12-h384-uncased/epoch=2-step=4124.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mFIT Profiler Report\n",
      "\u001b[0m\n",
      "\u001b[34mAction                             #011|  Mean duration (s)#011|Num calls      #011|  Total time (s) #011|  Percentage %   #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mTotal                              #011|  -              #011|_              #011|  645.47         #011|  100 %          #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mrun_training_epoch                 #011|  183.53         #011|3              #011|  550.59         #011|  85.3           #011|\u001b[0m\n",
      "\u001b[34mrun_training_batch                 #011|  0.12005        #011|4125           #011|  495.21         #011|  76.721         #011|\u001b[0m\n",
      "\u001b[34moptimizer_step_and_closure_0       #011|  0.11962        #011|4125           #011|  493.45         #011|  76.448         #011|\u001b[0m\n",
      "\u001b[34mtraining_step_and_backward         #011|  0.10194        #011|4125           #011|  420.52         #011|  65.149         #011|\u001b[0m\n",
      "\u001b[34mbackward                           #011|  0.059326       #011|4125           #011|  244.72         #011|  37.914         #011|\u001b[0m\n",
      "\u001b[34mmodel_forward                      #011|  0.039533       #011|4125           #011|  163.07         #011|  25.264         #011|\u001b[0m\n",
      "\u001b[34mtraining_step                      #011|  0.039224       #011|4125           #011|  161.8          #011|  25.066         #011|\u001b[0m\n",
      "\u001b[34mevaluation_step_and_end            #011|  0.052979       #011|518            #011|  27.443         #011|  4.2517         #011|\u001b[0m\n",
      "\u001b[34mvalidation_step                    #011|  0.05275        #011|518            #011|  27.325         #011|  4.2333         #011|\u001b[0m\n",
      "\u001b[34mget_train_batch                    #011|  0.0031629      #011|4125           #011|  13.047         #011|  2.0213         #011|\u001b[0m\n",
      "\u001b[34mon_validation_end                  #011|  0.96737        #011|4              #011|  3.8695         #011|  0.59948        #011|\u001b[0m\n",
      "\u001b[34mcache_result                       #011|  2.3562e-05     #011|18099          #011|  0.42645        #011|  0.066067       #011|\u001b[0m\n",
      "\u001b[34mon_train_batch_end                 #011|  9.7329e-05     #011|4125           #011|  0.40148        #011|  0.062199       #011|\u001b[0m\n",
      "\u001b[34mon_after_backward                  #011|  2.7839e-05     #011|4125           #011|  0.11484        #011|  0.017791       #011|\u001b[0m\n",
      "\u001b[34mon_batch_start                     #011|  2.5048e-05     #011|4125           #011|  0.10332        #011|  0.016007       #011|\u001b[0m\n",
      "\u001b[34mon_before_zero_grad                #011|  2.2378e-05     #011|4125           #011|  0.092309       #011|  0.014301       #011|\u001b[0m\n",
      "\u001b[34mon_batch_end                       #011|  2.1402e-05     #011|4125           #011|  0.088285       #011|  0.013678       #011|\u001b[0m\n",
      "\u001b[34m2021-07-26 14:31:10,362 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mon_train_batch_start               #011|  1.6395e-05     #011|4125           #011|  0.06763        #011|  0.010478       #011|\u001b[0m\n",
      "\u001b[34mtraining_step_end                  #011|  1.333e-05      #011|4125           #011|  0.054987       #011|  0.008519       #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_end            #011|  5.3825e-05     #011|518            #011|  0.027882       #011|  0.0043196      #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_start          #011|  2.3629e-05     #011|518            #011|  0.01224        #011|  0.0018962      #011|\u001b[0m\n",
      "\u001b[34mvalidation_step_end                #011|  1.4622e-05     #011|518            #011|  0.0075744      #011|  0.0011735      #011|\u001b[0m\n",
      "\u001b[34mon_train_start                     #011|  0.0050269      #011|1              #011|  0.0050269      #011|  0.0007788      #011|\u001b[0m\n",
      "\u001b[34mon_validation_start                #011|  0.00059193     #011|4              #011|  0.0023677      #011|  0.00036682     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_start               #011|  0.00053008     #011|3              #011|  0.0015902      #011|  0.00024637     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_end                 #011|  0.00024044     #011|3              #011|  0.00072132     #011|  0.00011175     #011|\u001b[0m\n",
      "\u001b[34mon_train_end                       #011|  0.00063914     #011|1              #011|  0.00063914     #011|  9.9019e-05     #011|\u001b[0m\n",
      "\u001b[34mon_epoch_start                     #011|  2.1396e-05     #011|7              #011|  0.00014977     #011|  2.3204e-05     #011|\u001b[0m\n",
      "\u001b[34mon_epoch_end                       #011|  2.1227e-05     #011|7              #011|  0.00014859     #011|  2.302e-05      #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_end            #011|  2.9533e-05     #011|4              #011|  0.00011813     #011|  1.8302e-05     #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_start          #011|  1.6692e-05     #011|4              #011|  6.6769e-05     #011|  1.0344e-05     #011|\u001b[0m\n",
      "\u001b[34mon_fit_start                       #011|  2.9117e-05     #011|1              #011|  2.9117e-05     #011|  4.511e-06      #011|\u001b[0m\n",
      "\u001b[34mon_before_accelerator_backend_setup#011|  1.9067e-05     #011|1              #011|  1.9067e-05     #011|  2.954e-06      #011|\u001b[0m\n",
      "\u001b[34mon_val_dataloader                  #011|  1.6129e-05     #011|1              #011|  1.6129e-05     #011|  2.4988e-06     #011|\u001b[0m\n",
      "\u001b[34mon_train_dataloader                #011|  1.5473e-05     #011|1              #011|  1.5473e-05     #011|  2.3972e-06     #011|\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/171 [00:00<?, ?it/s]#015  1%|          | 1/171 [00:00<00:43,  3.92it/s]#015  2%|▏         | 4/171 [00:00<00:32,  5.18it/s]#015  4%|▎         | 6/171 [00:00<00:24,  6.64it/s]#015  5%|▌         | 9/171 [00:00<00:19,  8.30it/s]#015  6%|▋         | 11/171 [00:00<00:15, 10.02it/s]#015  8%|▊         | 13/171 [00:00<00:13, 11.78it/s]#015  9%|▉         | 15/171 [00:00<00:11, 13.41it/s]#015 10%|▉         | 17/171 [00:01<00:10, 14.86it/s]#015 11%|█         | 19/171 [00:01<00:09, 16.06it/s]#015 12%|█▏        | 21/171 [00:01<00:08, 17.03it/s]#015 13%|█▎        | 23/171 [00:01<00:08, 17.73it/s]#015 15%|█▍        | 25/171 [00:01<00:07, 18.33it/s]#015 16%|█▌        | 27/171 [00:01<00:07, 18.73it/s]#015 17%|█▋        | 29/171 [00:01<00:07, 19.07it/s]#015 18%|█▊        | 31/171 [00:01<00:07, 19.31it/s]#015 19%|█▉        | 33/171 [00:01<00:07, 19.47it/s]#015 20%|██        | 35/171 [00:01<00:06, 19.59it/s]#015 22%|██▏       | 37/171 [00:02<00:06, 19.63it/s]#015 23%|██▎       | 39/171 [00:02<00:06, 19.31it/s]#015 24%|██▍       | 41/171 [00:02<00:06, 19.16it/s]#015 25%|██▌       | 43/171 [00:02<00:06, 19.26it/s]#015 26%|██▋       | 45/171 [00:02<00:06, 19.30it/s]#015 27%|██▋       | 47/171 [00:02<00:06, 19.29it/s]#015 29%|██▊       | 49/171 [00:02<00:06, 19.42it/s]#015 30%|██▉       | 51/171 [00:02<00:06, 19.50it/s]#015 31%|███       | 53/171 [00:02<00:06, 19.53it/s]#015 32%|███▏      | 55/171 [00:02<00:05, 19.55it/s]#015 33%|███▎      | 57/171 [00:03<00:05, 19.62it/s]#015 35%|███▍      | 59/171 [00:03<00:05, 19.66it/s]#015 36%|███▌      | 61/171 [00:03<00:05, 19.71it/s]#015 37%|███▋      | 63/171 [00:03<00:05, 19.70it/s]#015 38%|███▊      | 65/171 [00:03<00:05, 19.74it/s]#015 39%|███▉      | 67/171 [00:03<00:05, 19.71it/s]#015 40%|████      | 69/171 [00:03<00:05, 19.75it/s]#015 42%|████▏     | 71/171 [00:03<00:05, 19.76it/s]#015 43%|████▎     | 73/171 [00:03<00:04, 19.82it/s]#015 44%|████▍     | 75/171 [00:04<00:04, 19.84it/s]#015 45%|████▌     | 77/171 [00:04<00:04, 19.87it/s]#015 46%|████▌     | 79/171 [00:04<00:04, 19.70it/s]#015 47%|████▋     | 81/171 [00:04<00:04, 19.73it/s]#015 49%|████▊     | 83/171 [00:04<00:04, 19.74it/s]#015 50%|████▉     | 85/171 [00:04<00:04, 19.75it/s]#015 51%|█████     | 87/171 [00:04<00:04, 19.62it/s]#015 52%|█████▏    | 89/171 [00:04<00:04, 19.68it/s]#015 53%|█████▎    | 91/171 [00:04<00:04, 19.69it/s]#015 54%|█████▍    | 93/171 [00:04<00:03, 19.71it/s]#015 56%|█████▌    | 95/171 [00:05<00:03, 19.72it/s]#015 57%|█████▋    | 97/171 [00:05<00:03, 19.53it/s]#015 58%|█████▊    | 99/171 [00:05<00:03, 19.56it/s]#015 59%|█████▉    | 101/171 [00:05<00:03, 19.55it/s]#015 60%|██████    | 103/171 [00:05<00:03, 19.62it/s]#015 61%|██████▏   | 105/171 [00:05<00:03, 19.69it/s]#015 63%|██████▎   | 107/171 [00:05<00:03, 19.72it/s]#015 64%|██████▎   | 109/171 [00:05<00:03, 19.65it/s]#015 65%|██████▍   | 111/171 [00:05<00:03, 19.56it/s]#015 66%|██████▌   | 113/171 [00:05<00:02, 19.34it/s]#015 67%|██████▋   | 115/171 [00:06<00:02, 19.32it/s]#015 68%|██████▊   | 117/171 [00:06<00:02, 19.31it/s]#015 70%|██████▉   | 119/171 [00:06<00:02, 19.34it/s]#015 71%|███████   | 121/171 [00:06<00:02, 19.21it/s]#015 72%|███████▏  | 123/171 [00:06<00:02, 19.16it/s]#015 73%|███████▎  | 125/171 [00:06<00:02, 19.01it/s]#015 74%|███████▍  | 127/171 [00:06<00:02, 19.20it/s]#015 75%|███████▌  | 129/171 [00:06<00:02, 19.35it/s]#015 77%|███████▋  | 131/171 [00:06<00:02, 19.46it/s]#015 78%|███████▊  | 133/171 [00:06<00:01, 19.56it/s]#015 79%|███████▉  | 135/171 [00:07<00:01, 19.57it/s]#015 80%|████████  | 137/171 [00:07<00:01, 19.49it/s]#015 81%|████████▏ | 139/171 [00:07<00:01, 19.57it/s]#015 82%|████████▏ | 141/171 [00:07<00:01, 19.52it/s]#015 84%|████████▎ | 143/171 [00:07<00:01, 19.54it/s]#015 85%|████████▍ | 145/171 [00:07<00:01, 19.48it/s]#015 86%|████████▌ | 147/171 [00:07<00:01, 19.50it/s]#015 87%|████████▋ | 149/171 [00:07<00:01, 19.60it/s]#015 88%|████████▊ | 151/171 [00:07<00:01, 19.69it/s]#015 89%|████████▉ | 153/171 [00:08<00:00, 19.74it/s]#015 91%|█████████ | 155/171 [00:08<00:00, 19.77it/s]#015 92%|█████████▏| 157/171 [00:08<00:00, 19.62it/s]#015 93%|█████████▎| 159/171 [00:08<00:00, 19.53it/s]#015 94%|█████████▍| 161/171 [00:08<00:00, 19.64it/s]#015 95%|█████████▌| 163/171 [00:08<00:00, 19.67it/s]#015 96%|█████████▋| 165/171 [00:08<00:00, 19.73it/s]#015 98%|█████████▊| 167/171 [00:08<00:00, 19.78it/s]#015 99%|█████████▉| 169/171 [00:08<00:00, 19.82it/s]#015100%|██████████| 171/171 [00:08<00:00, 19.83it/s]#015172it [00:09, 19.10it/s]                         \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-07-26 14:31:37 Uploading - Uploading generated training model\n",
      "2021-07-26 14:32:15 Completed - Training job completed\n",
      "Training seconds: 1048\n",
      "Billable seconds: 1048\n"
     ]
    }
   ],
>>>>>>> b272332754486d8c655cc7e65903baeb97a2a5f5
   "source": [
    "# Fit the estimator\n",
    "\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
