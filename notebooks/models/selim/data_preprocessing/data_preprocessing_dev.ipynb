{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "DATA_PATH = os.path.join(\n",
    "   '..', '..', '..', '..', \"data\", \"frameworks_data\", 'development_cca'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_data = (\n",
    "    pd.read_csv(\n",
    "        os.path.join(DATA_PATH, \"cca_deep_projects_with_translations_v0.2.csv\"),\n",
    "        usecols=[\n",
    "            \"id\",\n",
    "            \"lang\",\n",
    "            \"en\",\n",
    "            \"fr\",\n",
    "            \"es\",\n",
    "            \"pt\",\n",
    "            \"title\",\n",
    "            \"sectors\",\n",
    "            \"2dpillars\",\n",
    "            \"2dsubpillars\",\n",
    "            \"1dpillars\",\n",
    "            \"1dsubpillars\",\n",
    "        ],\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"1dpillars\": \"pillars_1d\",\n",
    "            \"2dpillars\": \"pillars_2d\",\n",
    "            \"1dsubpillars\": \"subpillars_1d\",\n",
    "            \"2dsubpillars\": \"subpillars_2d\",\n",
    "            \"id\": \"entry_id\",\n",
    "            \"created_at\": \"creation_year\",\n",
    "            \"lang\": \"original_language\",\n",
    "        }\n",
    "    )\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "classification_cols = [\n",
    "    \"sectors\",\n",
    "    \"pillars_2d\",\n",
    "    \"subpillars_2d\",\n",
    "    \"pillars_1d\",\n",
    "    \"subpillars_1d\",\n",
    "]\n",
    "\n",
    "for col in classification_cols:\n",
    "    if \"pillar\" not in col:\n",
    "        cca_data[col] = cca_data[col].apply(lambda x: list(set(literal_eval(x))))\n",
    "    else:\n",
    "        cca_data[col] = cca_data[col].apply(literal_eval)\n",
    "\n",
    "cca_data[\"subpillars_2d\"] = cca_data.apply(\n",
    "    lambda x: [\n",
    "        f\"{x['pillars_2d'][i]}->{x['subpillars_2d'][i]}\"\n",
    "        for i in range(len(x[\"subpillars_2d\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "cca_data[\"subpillars_1d\"] = cca_data.apply(\n",
    "    lambda x: [\n",
    "        f\"{x['pillars_1d'][i]}->{x['subpillars_1d'][i]}\"\n",
    "        for i in range(len(x[\"subpillars_1d\"]))\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "cca_data[\"pillars\"] = cca_data.apply(\n",
    "    lambda x: x[\"pillars_1d\"] + x[\"pillars_2d\"],\n",
    "    axis=1,\n",
    ")\n",
    "cca_data[\"subpillars\"] = cca_data.apply(\n",
    "    lambda x: x[\"subpillars_1d\"] + x[\"subpillars_2d\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "#cca_data = cca_data.drop(columns=[\"pillars_2d\", \"pillars_1d\"])\n",
    "cca_data[\"target\"] = cca_data.apply(\n",
    "    lambda x: str(\n",
    "        flatten(\n",
    "            [\n",
    "                x[col]\n",
    "                for col in [\n",
    "                    \"sectors\",\n",
    "                    \"subpillars_2d\",\n",
    "                    \"subpillars_1d\",\n",
    "                    #\"specific needs groups\",\n",
    "                    #\"demographic groups\",\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25442, 14)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCA/DEEP Central African Republic', 'CCA/DEEP Ghana',\n",
       "       'CCA/DEEP Somalia', 'CCA/DEEP Philippines', 'CCA/DEEP Ukraine',\n",
       "       'CCA/DEEP Namibia'], dtype=object)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_data.title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first_level_tags->pillars->COVID-19 Impact',\n",
       " 'first_level_tags->pillars->High Level tags',\n",
       " 'first_level_tags->pillars->Progress towards 2030 Agenda',\n",
       " 'first_level_tags->pillars->Risks',\n",
       " 'first_level_tags->pillars->Stakeholder/ Partnerships',\n",
       " 'first_level_tags->sectors->Partnership',\n",
       " 'first_level_tags->sectors->Peace',\n",
       " 'first_level_tags->sectors->People',\n",
       " 'first_level_tags->sectors->Planet',\n",
       " 'first_level_tags->sectors->Prosperity']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_data[\"sectors\"] = cca_data.sectors.apply(\n",
    "    lambda x: list(set([f\"first_level_tags->sectors->{item}\" for item in x]))\n",
    ")\n",
    "\n",
    "cca_data[\"pillars\"] = cca_data.pillars.apply(\n",
    "    lambda x: list(set([f\"first_level_tags->pillars->{item}\" for item in x]))\n",
    ")\n",
    "\n",
    "first_level_tags = [\n",
    "    \"sectors\",\n",
    "    \"pillars\"\n",
    "]\n",
    "\n",
    "cca_data[\"first_level_tags\"] = cca_data.apply(\n",
    "    lambda x: flatten([x[tag] for tag in first_level_tags]), axis=1\n",
    ")\n",
    "\n",
    "sorted(list(set(flatten(cca_data['first_level_tags']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subpillars->subpillars->COVID-19 Impact->Negative Coping Strategies',\n",
       " 'subpillars->subpillars->COVID-19 Impact->Socio-Economic Impact',\n",
       " 'subpillars->subpillars->COVID-19 Impact->Status of Recovery',\n",
       " 'subpillars->subpillars->High Level tags->Capacities',\n",
       " 'subpillars->subpillars->High Level tags->Challenges / Opportunities towards 2030 Agenda',\n",
       " 'subpillars->subpillars->High Level tags->Information Gaps',\n",
       " 'subpillars->subpillars->High Level tags->Progress towards 2030 Agenda',\n",
       " 'subpillars->subpillars->High Level tags->Recommendations from Stakeholders',\n",
       " 'subpillars->subpillars->Progress towards 2030 Agenda->Achievements / Situational Snapshot',\n",
       " 'subpillars->subpillars->Progress towards 2030 Agenda->Challenges & Barriers',\n",
       " 'subpillars->subpillars->Progress towards 2030 Agenda->Development Plans',\n",
       " 'subpillars->subpillars->Progress towards 2030 Agenda->Enabling Factors',\n",
       " 'subpillars->subpillars->Progress towards 2030 Agenda->National Capacities',\n",
       " 'subpillars->subpillars->Risks->Hazards and Threats',\n",
       " 'subpillars->subpillars->Risks->Vulnerable Groups / People at Risk (Leave No One Behind)',\n",
       " 'subpillars->subpillars->Stakeholder/ Partnerships->Contributions',\n",
       " 'subpillars->subpillars->Stakeholder/ Partnerships->Development solutions/ Recommendations',\n",
       " 'subpillars->subpillars->Stakeholder/ Partnerships->Stakeholder Capacities']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cca_data[\"subpillars\"] = cca_data.subpillars.apply(\n",
    "    lambda x: list(set([f\"subpillars->{item}\" for item in x]))\n",
    ")\n",
    "\n",
    "sorted(list(set(flatten(cca_data['subpillars']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca_data['target'] = cca_data.apply(\n",
    "    lambda x: x['first_level_tags'] + x['subpillars'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deleted_duplicates_ids(df):\n",
    "    # find if there are any duplicates\n",
    "    counts = cca_data['en'].value_counts().rename('en_counts')\n",
    "\n",
    "    treated_df_with_counts = cca_data.merge(counts.to_frame(),\n",
    "                                    left_on='en',\n",
    "                                    right_index=True)\n",
    "\n",
    "    duplicates_df = treated_df_with_counts[treated_df_with_counts.en_counts>1]\n",
    "    duplicates_df.drop(columns=['fr', 'es', 'pt'])\n",
    "\n",
    "    duplicates_tmp = duplicates_df.copy()\n",
    "    \n",
    "    duplicates_tmp = duplicates_tmp[[\"en\", \"target\"]].drop_duplicates()\n",
    "    counts_tmp = duplicates_tmp['en'].value_counts().rename('en_counts').to_frame()\n",
    "\n",
    "    kept_entries = list(counts_tmp[counts_tmp.en_counts==1].index)\n",
    "\n",
    "    same_duplicates_df = duplicates_df[duplicates_df.en.isin(kept_entries)]\n",
    "    kept_ids = same_duplicates_df.groupby('en').agg({'entry_id': lambda x: list(x)[0]}).entry_id.tolist()\n",
    "\n",
    "    deleted_ids = list(set(duplicates_df.entry_id.tolist()) - set(kept_ids))\n",
    "\n",
    "    return deleted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-8b4d6c568052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeleted_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_deleted_duplicates_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcca_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcca_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcca_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mcca_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeleted_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcca_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-133-db1a7c335540>\u001b[0m in \u001b[0;36mget_deleted_duplicates_ids\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mduplicates_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicates_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mduplicates_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicates_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"target\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcounts_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mduplicates_tmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en_counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[0;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   5269\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"inplace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5270\u001b[0m         \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore_index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5271\u001b[0;31m         \u001b[0mduplicated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[0;34m(self, subset, keep)\u001b[0m\n\u001b[1;32m   5406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5407\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5408\u001b[0;31m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5410\u001b[0m         \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(vals)\u001b[0m\n\u001b[1;32m   5380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5381\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5382\u001b[0;31m             labels, shape = algorithms.factorize(\n\u001b[0m\u001b[1;32m   5383\u001b[0m                 \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE_HINT_LIMIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5384\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[0;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m         codes, uniques = factorize_array(\n\u001b[0m\u001b[1;32m    723\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/deepl/lib/python3.9/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mfactorize_array\u001b[0;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     uniques, codes = table.factorize(\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     )\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "deleted_ids = get_deleted_duplicates_ids(cca_data)\n",
    "cca_data = cca_data[~cca_data.entry_id.isin(deleted_ids)]\n",
    "cca_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_stratified_train_test_split(df, ratios):\n",
    "    \"\"\"\n",
    "    custom function for stratified train test splitting\n",
    "    1) take unique sub-tags (example: ['Health'])\n",
    "    2) For each unique subtag:\n",
    "        i) take all indexes that have that specific subtag\n",
    "        ii) split them randomly to train and test sets\n",
    "    \"\"\"\n",
    "    train_ids = []\n",
    "    val_ids = []\n",
    "    positive_df = df.copy()\n",
    "    positive_df[\"target\"] = positive_df[\"target\"].apply(str)\n",
    "    ids = positive_df.groupby(\"target\")[\"entry_id\"].agg(list).values\n",
    "    unique_ids = [list(set(list_)) for list_ in ids]\n",
    "\n",
    "    for ids_entry in unique_ids:\n",
    "\n",
    "        train_ids_entry = random.sample(\n",
    "            ids_entry, int(len(ids_entry) * ratios[\"train\"])\n",
    "        )\n",
    "        val_ids_entry = list(set(ids_entry) - set(train_ids_entry))\n",
    "\n",
    "        train_ids.append(train_ids_entry)\n",
    "        val_ids.append(val_ids_entry)\n",
    "\n",
    "    return flatten(train_ids), flatten(val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_df = cca_data[['entry_id', 'fr']]\\\n",
    "        .rename(columns={'fr':'excerpt'}).dropna()\n",
    "\n",
    "en_df = cca_data[['entry_id', 'en']]\\\n",
    "        .rename(columns={'en':'excerpt'}).dropna()\n",
    "\n",
    "es_df = cca_data[['entry_id', 'es']]\\\n",
    "        .rename(columns={'es':'excerpt'}).dropna()\n",
    "\n",
    "pt_df = cca_data[['entry_id', 'pt']]\\\n",
    "        .rename(columns={'pt':'excerpt'}).dropna()\n",
    "\n",
    "augmented_data = pd.concat([en_df, fr_df, es_df, pt_df])\n",
    "\n",
    "augmented_data = pd.merge(\n",
    "    right=cca_data.drop(columns=[\n",
    "        'en', 'fr', 'es', 'pt']\n",
    "                           ),\n",
    "    left=augmented_data[['entry_id', 'excerpt']],\n",
    "    on='entry_id',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "ratios = {'train': 0.95, 'test': 0.05}\n",
    "train_val_ids, test_ids = custom_stratified_train_test_split(cca_data, ratios)\n",
    "\n",
    "train_val_data = augmented_data[augmented_data.entry_id.isin(train_val_ids)]\n",
    "ratios = {'train': 0.9, 'test': 0.1}\n",
    "train_ids, val_ids = custom_stratified_train_test_split(train_val_data, ratios)\n",
    "\n",
    "test_data = augmented_data[augmented_data.entry_id.isin(test_ids)]\n",
    "train_data = augmented_data[augmented_data.entry_id.isin(train_ids)]\n",
    "val_data = augmented_data[augmented_data.entry_id.isin(val_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74072, 12208, 15488)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0], val_data.shape[0], test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_data[['entry_id', 'excerpt', 'target']].to_csv(os.path.join(DATA_PATH, 'train_val_data.csv') , index=None)\n",
    "test_data[['entry_id', 'excerpt', 'target']].to_csv(os.path.join(DATA_PATH, 'test_data.csv') , index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
