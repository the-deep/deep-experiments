{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFoHamdsl8fa",
    "scrolled": true
   },
   "source": [
    "kernel `conda_pytorch_latest_p36`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "G-zRMx6ul8fo",
    "outputId": "ffcf5b4d-0cd3-49ea-beb7-b544aa169e44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"!pip install icecream\n",
    "!pip install tqdm\n",
    "!pip install torchmetrics\n",
    "!pip install pytorch_lightning\n",
    "!pip install transformers\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6j6KBiWl8f4",
    "outputId": "ab73160a-f2de-481f-cba5-ed6b9827f521"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "from icecream import ic\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:31.657777Z",
     "start_time": "2021-06-01T14:49:31.631040Z"
    },
    "id": "JpIr0FMtl8f9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:32.921745Z",
     "start_time": "2021-06-01T14:49:32.910873Z"
    },
    "id": "MLaS7_7Vl8gA"
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "rcParams['figure.figsize'] = 12, 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:35.745930Z",
     "start_time": "2021-06-01T14:49:35.741002Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLmILwiEl8gE",
    "outputId": "e0c9afca-b004-427b-fd76-a8262f2e0274"
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED=2021\n",
    "pl.seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:41.389959Z",
     "start_time": "2021-06-01T14:49:41.387543Z"
    },
    "id": "7430FF0Rl8gJ"
   },
   "outputs": [],
   "source": [
    "ic.configureOutput(outputFunction=sys.stdout.write, includeContext=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:02.359181Z",
     "start_time": "2021-06-01T14:57:02.353630Z"
    },
    "id": "w2xFSf4Sl8gN"
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:28.545897Z",
     "start_time": "2021-06-01T14:57:02.782629Z"
    },
    "id": "AZOykfjWl8gW"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 200\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 64\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05\n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "DATA_ROOT_DIR = os.path.join(\"..\", \"..\", \"..\", \"data\", \"frameworks_data\", \"data_v0.4.4\")\n",
    "TRAIN_PATH = os.path.join(\"data_v0.4.4_train.csv\")\n",
    "VAL_PATH = os.path.join(\"data_v0.4.4_val.csv\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBhJWZnSl8ga"
   },
   "outputs": [],
   "source": [
    "def clean_rows (row):\n",
    "    \"\"\"\n",
    "    1) Apply litteral evaluation\n",
    "    2) Drop values that are repeated multiple times in rows\n",
    "    \"\"\"\n",
    "    return list(set(literal_eval(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "id": "feaSkVCOl8ge"
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(TRAIN_PATH)\n",
    "val_dataset = pd.read_csv(VAL_PATH)\n",
    "\n",
    "all_dataset = pd.concat([train_dataset, val_dataset])\n",
    "\n",
    "# Keep only unique values in pillars\n",
    "all_dataset[\"subpillars\"] = all_dataset[\"subpillars\"].apply(lambda x: clean_rows (x))\n",
    "all_dataset[\"pillars\"] = all_dataset[\"pillars\"].apply(lambda x: clean_rows (x))\n",
    "\n",
    "# Keep only rows with a not empty pillar\n",
    "all_dataset = all_dataset[all_dataset.pillars.apply(lambda x: len(x)>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jp-5kCU2l8gi"
   },
   "outputs": [],
   "source": [
    "random_state=42\n",
    "val_size=0.2\n",
    "\n",
    "def get_subpillar_datasets (subpillar_name:str, dataset=all_dataset, seed=42):\n",
    "    \"\"\"\n",
    "    1) keep rows where the sub-pillar name is contained in the column 'subpillars'\n",
    "    2) keep only subpillar names in the column 'subpillar' (omit pillar name)\n",
    "    \"\"\"\n",
    "    df = dataset[['entry_id', 'excerpt', 'subpillars']].set_index('entry_id')\n",
    "    df['subpillars'] = df.subpillars\\\n",
    "                        .apply(lambda x: list(filter(lambda y: subpillar_name in y, x)))\\\n",
    "                        .apply(lambda x: [y.split('->')[1] for y in (x)])\n",
    "\n",
    "    df = df[df.subpillars.apply(lambda x: len(x)>0)].rename(columns={'pillars':'target'})\\\n",
    "            .rename(columns={'subpillars':'target'})\n",
    "    return train_test_split(df, test_size=val_size, random_state=random_state)\n",
    "    \n",
    "    \n",
    "    \n",
    "capacities_response_train_dataset, capacities_response_val_dataset =\\\n",
    "                get_subpillar_datasets ('Capacities & Response')\n",
    "\n",
    "hum_conditions_train_dataset, hum_conditions_val_dataset =\\\n",
    "                get_subpillar_datasets ('Humanitarian Conditions')\n",
    "\n",
    "\n",
    "impact_train_dataset, impact_val_dataset = get_subpillar_datasets ('Impact')\n",
    "\n",
    "people_at_risk_train_dataset, people_at_risk_val_dataset = get_subpillar_datasets ('People At Risk')\n",
    "\n",
    "priority_interventions_train_dataset, priority_interventions_val_dataset = \\\n",
    "                get_subpillar_datasets ('Priority Interventions')\n",
    "\n",
    "priority_needs_train_dataset, priority_needs_val_dataset = get_subpillar_datasets ('Priority Needs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oMa8Ci2wl8gl",
    "outputId": "b14c12d9-5a48-4528-82e8-1f659017fd8b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('number of rows for capacities & response :', capacities_response_train_dataset.shape[0])\n",
    "print('number of rows for Humanitarian Conditions:', hum_conditions_train_dataset.shape[0])\n",
    "print('number of rows for Impact :', impact_train_dataset.shape[0])\n",
    "print('number of rows for People At Risk :', people_at_risk_train_dataset.shape[0])\n",
    "print('number of rows for Priority Interventions :', priority_interventions_train_dataset.shape[0])\n",
    "print('number of rows for Priority Needs :', priority_needs_train_dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fsEmrR_l8gn"
   },
   "outputs": [],
   "source": [
    "all_dataset = all_dataset[['entry_id', 'excerpt', 'pillars']]\\\n",
    "                    .set_index('entry_id')\\\n",
    "                    .rename(columns={'pillars':'target'})\n",
    "\n",
    "pillars_train_dataset, pillars_val_dataset = train_test_split(all_dataset, \n",
    "                                                              random_state=random_state, \n",
    "                                                              test_size=val_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftjoGpuDl8gq",
    "outputId": "8ef823b3-7aff-43f5-a49d-31e4eae6ab61"
   },
   "outputs": [],
   "source": [
    "#check that entry_id is an id\n",
    "train_dataset.entry_id.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.890405Z",
     "start_time": "2021-06-01T14:57:29.883645Z"
    },
    "id": "Z1V-9qQRl8gr"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tagname_to_tagid, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.excerpt_text = dataframe[\"excerpt\"].tolist(\n",
    "        ) if dataframe is not None else None\n",
    "        self.targets = self.data['target'].tolist(\n",
    "        ) if dataframe is not None else None\n",
    "        self.tagname_to_tagid = tagname_to_tagid\n",
    "        self.tagid_to_tagname = list(tagname_to_tagid.keys())\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode_example(self,\n",
    "                       excerpt_text: str,\n",
    "                       index=None,\n",
    "                       as_batch: bool = False):\n",
    "        \n",
    "        inputs = self.tokenizer(excerpt_text,\n",
    "                                            None,\n",
    "                                            truncation=True,\n",
    "                                            add_special_tokens=True,\n",
    "                                            max_length=self.max_len,\n",
    "                                            padding=\"max_length\",\n",
    "                                            return_token_type_ids=True)\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        targets = None\n",
    "        if self.targets:\n",
    "            target_indices = [\n",
    "                self.tagname_to_tagid[target]\n",
    "                for target in self.targets[index]\n",
    "                if target in self.tagname_to_tagid\n",
    "            ]\n",
    "            targets = np.zeros(len(self.tagname_to_tagid), dtype=np.int)\n",
    "            targets[target_indices] = 1\n",
    "\n",
    "        encoded = {\n",
    "            'ids':\n",
    "            torch.tensor(ids, dtype=torch.long),\n",
    "            'mask':\n",
    "            torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids':\n",
    "            torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets':\n",
    "            torch.tensor(targets, dtype=torch.float32)\n",
    "            if targets is not None else None\n",
    "        }\n",
    "        if as_batch:\n",
    "            return {\n",
    "                \"ids\": encoded[\"ids\"].unsqueeze(0),\n",
    "                \"mask\": encoded[\"mask\"].unsqueeze(0),\n",
    "                \"token_type_ids\": encoded[\"ids\"].unsqueeze(0)\n",
    "            }\n",
    "        return encoded\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.excerpt_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        excerpt_text = str(self.excerpt_text[index])\n",
    "        return self.encode_example(excerpt_text, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.900276Z",
     "start_time": "2021-06-01T14:57:29.891880Z"
    },
    "id": "99IV090rl8gs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gsg6EnB4l8gt"
   },
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 4\n",
    "}\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.904210Z",
     "start_time": "2021-06-01T14:57:29.901478Z"
    },
    "id": "p67VeR1cl8gu"
   },
   "outputs": [],
   "source": [
    "def get_loaders (train_dataset, val_dataset):\n",
    "    training_set = CustomDataset(train_dataset, tagname_to_tagid, tokenizer, MAX_LEN)\n",
    "    val_set = CustomDataset(val_dataset, tagname_to_tagid, tokenizer, MAX_LEN)\n",
    "    val_set_frac = CustomDataset(val_dataset.sample(frac=.01),\n",
    "                                  tagname_to_tagid, tokenizer, MAX_LEN)\n",
    "    \n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "    val_loader_frac = DataLoader(val_set_frac, **val_params)\n",
    "    return training_loader, val_loader, val_loader_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iD0PN0rLl8gv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.909386Z",
     "start_time": "2021-06-01T14:57:29.905678Z"
    },
    "id": "WEZGpjaSl8gw"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_name_or_path: str, num_labels:int, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(model_name_or_path)\n",
    "        self.l2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l3 = torch.nn.Linear(384, num_labels)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        output = self.l1(inputs[\"ids\"],\n",
    "                            attention_mask=inputs[\"mask\"],)\n",
    "        output = output.last_hidden_state\n",
    "        output = self.l2(output)\n",
    "        output = self.l3(output)\n",
    "        return output[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T15:04:49.596074Z",
     "start_time": "2021-06-01T15:04:49.543948Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-bZqSQAl8gx",
    "outputId": "09fa9e13-fbc5-45c9-f057-bb91e8e11bfb"
   },
   "outputs": [],
   "source": [
    "class Transformer(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 model_name_or_path: str,\n",
    "                 num_labels: int,\n",
    "                 empty_dataset: CustomDataset,\n",
    "                 \n",
    "                 pred_threshold: float = .5,\n",
    "                 learning_rate: float = 2e-5,\n",
    "                 adam_epsilon: float = 1e-8,\n",
    "                 warmup_steps: int = 0,\n",
    "                 weight_decay: float = 0.0,\n",
    "                 train_batch_size: int = 32,\n",
    "                 eval_batch_size: int = 32,\n",
    "                 eval_splits: Optional[list] = None,\n",
    "                 dropout_rate: float = 0.3,\n",
    "\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = Model(model_name_or_path, num_labels, dropout_rate)\n",
    "        self.empty_dataset = empty_dataset\n",
    "        self.pred_threshold = pred_threshold\n",
    "\n",
    "        self.f1_score_train = torchmetrics.F1(\n",
    "            num_classes=2,\n",
    "            threshold=0.5,\n",
    "            average='macro',\n",
    "            mdmc_average=\"samplewise\",\n",
    "            ignore_index=None,\n",
    "            top_k=None,\n",
    "            multiclass=True,\n",
    "            compute_on_step=True,\n",
    "            dist_sync_on_step=False,\n",
    "            process_group=None,\n",
    "            dist_sync_fn=None,\n",
    "        )\n",
    "\n",
    "        self.f1_score_val = torchmetrics.F1(\n",
    "            num_classes=2,\n",
    "            threshold=0.5,\n",
    "            average='macro',\n",
    "            mdmc_average=\"samplewise\",\n",
    "            ignore_index=None,\n",
    "            top_k=None,\n",
    "            multiclass=True,\n",
    "            compute_on_step=True,\n",
    "            dist_sync_on_step=False,\n",
    "            process_group=None,\n",
    "            dist_sync_fn=None,\n",
    "        )\n",
    "    @auto_move_data\n",
    "    def forward(self, inputs):\n",
    "        output = self.model(inputs)\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self(batch)\n",
    "        loss = F.binary_cross_entropy_with_logits(outputs, batch[\"targets\"])\n",
    "\n",
    "        self.f1_score_train(torch.sigmoid(outputs),\n",
    "                            batch[\"targets\"].to(dtype=torch.long))\n",
    "        self.log(\"train_f1\", self.f1_score_train, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        outputs = self(batch)\n",
    "        val_loss = F.binary_cross_entropy_with_logits(outputs,\n",
    "                                                      batch[\"targets\"])\n",
    "\n",
    "        self.f1_score_val(torch.sigmoid(outputs),\n",
    "                          batch[\"targets\"].to(dtype=torch.long))\n",
    "        self.log(\"val_f1\",\n",
    "                 self.f1_score_val,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=False)\n",
    "        \n",
    "        self.log(\"val_loss\",\n",
    "                 val_loss,\n",
    "                 on_step=True,\n",
    "                 on_epoch=True,\n",
    "                 prog_bar=True,\n",
    "                 logger=False)\n",
    "        return {'val_loss': val_loss}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        logits = self(batch)\n",
    "        preds = (torch.sigmoid(logits) > .5)\n",
    "        return {\"preds\": preds, \"targets_i\": batch[\"targets\"]}\n",
    "\n",
    "    def on_test_epoch_end(self, outputs):\n",
    "        preds = torch.cat([output[\"preds\"] for output in outputs]).cpu()\n",
    "        targets = torch.cat([output[\"targets_i\"] for output in outputs]).cpu()\n",
    "        recalls = []\n",
    "        precisions = []\n",
    "        f1_scores = []\n",
    "        for i in range(targets.shape[1]):\n",
    "            class_roc_auc = auroc(preds[:, i], targets[:, i])\n",
    "            self.log(\n",
    "                f\"{self.empty_dataset.sectorid_to_sectorname[i]}_roc_auc/Train\",\n",
    "                class_roc_auc)\n",
    "            class_f1 = metrics.f1_score(targets[:, i], preds[:, i])\n",
    "            self.log(\n",
    "                f\"{self.empty_dataset.sectorid_to_sectorname[i]}_f1/Train\",\n",
    "                class_f1)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=None):\n",
    "        output = self(batch)\n",
    "        return {\"logits\": output}\n",
    "\n",
    "    def on_predict_epoch_end(self, outputs):\n",
    "        logits = torch.cat([output[\"logits\"] for output in outputs[0]])\n",
    "        preds = torch.sigmoid(logits) >= self.pred_threshold\n",
    "        pred_classes = []\n",
    "        for pred in preds:\n",
    "            pred_classes_i = [\n",
    "                self.empty_dataset.sectorid_to_sectorname[i]\n",
    "                for i, p in enumerate(pred) if p\n",
    "            ]\n",
    "            pred_classes.append(pred_classes_i)\n",
    "        self.log({\"pred_classes\": pred_classes})\n",
    "\n",
    "    def custom_predict(self, inputs):\n",
    "        self.eval()\n",
    "        self.freeze()\n",
    "        as_batch = False\n",
    "        if isinstance(inputs, str):\n",
    "            as_batch = True\n",
    "        inputs = self.empty_dataset.encode_example(inputs, as_batch)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self(inputs)\n",
    "        preds = (torch.sigmoid(logits) >= self.pred_threshold)\n",
    "        pred_classes = []\n",
    "        for pred in preds:\n",
    "            pred_classes_i = [\n",
    "                self.empty_dataset.tagid_to_tagname[i]\n",
    "                for i, p in enumerate(pred) if p\n",
    "            ]\n",
    "            pred_classes.append(pred_classes_i)\n",
    "        return pred_classes\n",
    "\n",
    "    def total_steps(self) -> int:\n",
    "        \"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"\n",
    "        self.dataset_size = len(self.train_dataloader().dataset)\n",
    "        num_devices = max(1, self.hparams.gpus)  # TODO: consider num_tpu_cores\n",
    "        effective_batch_size = self.hparams.train_batch_size * self.hparams.accumulate_grad_batches * num_devices\n",
    "        return (self.dataset_size /\n",
    "                effective_batch_size) * self.hparams.max_epochs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p for n, p in model.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\":\n",
    "                0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                          lr=self.hparams.learning_rate,\n",
    "                          eps=self.hparams.adam_epsilon)\n",
    "\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.hparams.warmup_steps,\n",
    "            num_training_steps=self.total_steps())\n",
    "        scheduler = {\n",
    "            'scheduler': scheduler,\n",
    "            'interval': 'step',\n",
    "            'frequency': 1\n",
    "        }\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return training_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return val_loader\n",
    "    \n",
    "    def custom_eval(self, eval_dataloader):\n",
    "        if self.device.type == \"cpu\":\n",
    "            self.to(\"cuda\")\n",
    "        self.eval()\n",
    "        self.freeze()\n",
    "        preds_val_all = []\n",
    "        y_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(eval_dataloader, total=len(eval_dataloader.dataset)//eval_dataloader.batch_size):\n",
    "                logits = self({\"ids\": batch[\"ids\"].to(\"cuda\"), \"mask\": batch[\"mask\"].to(\"cuda\"), \"token_type_ids\": batch[\"token_type_ids\"].to(\"cuda\")})\n",
    "                preds_batch = np.zeros(logits.shape, dtype=np.int)\n",
    "                preds_batch[(torch.sigmoid(logits) > self.pred_threshold).cpu().nonzero(as_tuple=True)] = 1\n",
    "                preds_val_all.append(preds_batch)\n",
    "                y_true.append(batch[\"targets\"].numpy().astype(np.int))\n",
    "\n",
    "        preds_val_all = np.concatenate(preds_val_all)\n",
    "        y_true = np.concatenate(y_true)\n",
    "\n",
    "        f1_scores = []\n",
    "        recalls = []\n",
    "        precisions = []\n",
    "        accuracies = []\n",
    "        supports = []\n",
    "        tagname_to_tagid = self.empty_dataset.tagname_to_tagid\n",
    "        for tag_name, tag_id in tagname_to_tagid.items():\n",
    "            cls_rprt = classification_report(y_true[:, tag_id], preds_val_all[:, tag_id], output_dict=True)\n",
    "            precisions.append(cls_rprt[\"macro avg\"][\"precision\"])\n",
    "            recalls.append(cls_rprt[\"macro avg\"][\"recall\"])\n",
    "            f1_scores.append(cls_rprt[\"macro avg\"][\"f1-score\"])\n",
    "            accuracies.append(cls_rprt[\"accuracy\"])\n",
    "\n",
    "        metrics_df = pd.DataFrame({\n",
    "            \"Sector\": list(tagname_to_tagid.keys()),\n",
    "            \"Precision\": precisions,\n",
    "            \"Recall\": recalls,\n",
    "            \"F1 Score\": f1_scores,\n",
    "            \"Accuracy\": accuracies,\n",
    "        })\n",
    "        return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOWN0w1fempJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_on_specific_targets (train_dataset, tagname_to_tagid, name_classifier:str, dropout_rate:float):\n",
    "\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=name_classifier)\n",
    "\n",
    "    empty_dataset = CustomDataset(None, tagname_to_tagid, tokenizer,\n",
    "                         MAX_LEN)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        logger=logger,\n",
    "        callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "        progress_bar_refresh_rate=30,\n",
    "        profiler=\"simple\",\n",
    "        log_gpu_memory=True,\n",
    "        weights_summary=None,\n",
    "        gpus=1,\n",
    "        accumulate_grad_batches=1,\n",
    "        max_epochs=EPOCHS,\n",
    "        gradient_clip_val=1,\n",
    "        gradient_clip_algorithm='norm'\n",
    "        #overfit_batches=1,\n",
    "        #limit_predict_batches=2,\n",
    "        #limit_test_batches=2,\n",
    "        #fast_dev_run=True,\n",
    "        #limit_train_batches=1,\n",
    "        #limit_val_batches=1,\n",
    "        #limit_test_batches: Union[int, float] = 1.0,\n",
    "    )\n",
    "\n",
    "\n",
    "    model = Transformer(MODEL_NAME,\n",
    "                            len(tagname_to_tagid),\n",
    "                            empty_dataset,\n",
    "                            gpus=1,\n",
    "                            precision=16,\n",
    "                            plugin='deepspeed_stage_3_offload',\n",
    "                            accumulate_grad_batches=1,\n",
    "                            max_epochs=EPOCHS,\n",
    "                            dropout_rate=dropout_rate)\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "    return model.custom_eval(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model to predict pillars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188,
     "referenced_widgets": [
      "73ba5d91e29644eab737ee941c7766ab",
      "70861782f6f84942908a33dc44cc6a35",
      "ff90695685354e509ef5861594a88fb3",
      "b0b66fe174474fba8a094561e56b5fdf",
      "d1d804e5ffd14d3e93308807091883a8",
      "75338528d7c7402697437b5fddede4cb",
      "33e819bd582a4838adde79ba0b567f05",
      "a33c4464f1214fdba886273ef94b47bf",
      "034bd079864046ceba94947a56dd7f35",
      "1ed346ab0dc749579f8c759afc52931b",
      "9d49c7dede2244ea86019c7c791fe4f8",
      "d031b8229e3340f7bfb61e94130ed95c",
      "4fefcbcc37f747f288c72d998d2a21b7",
      "ec79ee6d044e4aa78b11414f5a5fcd89",
      "3564f9a34d8e42768d71ab7194fa4727",
      "34e5d15380ae48b09a063dbc1e687200",
      "034c91422b074f41a20530bfa56e1b91",
      "93c483c66d654cb08d0ca1307f3e94c4",
      "f7dac1c42b294ad7b29c76eeb51906b9",
      "a6241d5cfe4f4940bf4639c71d68808d",
      "0ad5dc4a634344ba80c80be3f5887356",
      "66cd1d3c5bb646428869e3387b34a3af",
      "affe1134e95b49c992395b55b4d0d84e",
      "dd4d42dcce174346ba1aa29ec2146e1d"
     ]
    },
    "id": "8J1mMftfl8g3",
    "outputId": "4872824e-cbd0-4158-bd98-cad995f18d36"
   },
   "outputs": [],
   "source": [
    "log_dir_name = \"-\".join(MODEL_NAME.split(\"/\"))\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "\n",
    "dirpath = f\"./checkpoints-pillars-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in pillars_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (pillars_train_dataset,\n",
    "                                                 pillars_val_dataset)\n",
    "\n",
    "errors_pillars = train_on_specific_targets(pillars_train_dataset,\n",
    "                                                 tagname_to_tagid,\n",
    "                                                 f\"pillars-classifier-{log_dir_name}\",\n",
    "                                                 dropout_rate=0.5)\n",
    "errors_pillars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzPhU-gXl8g6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlCXu-8cl8hG"
   },
   "source": [
    "### Train models to predict sub-pillars\n",
    "- Dropout rate is 0.5 for length of training between 5.000 and 10.000\n",
    "- Dropout rate is 0.7 for length of training inferior to 5.000\n",
    "- Dropout rate is 0.3 for length of training superior to 10.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oxUu1WSHEo1w"
   },
   "outputs": [],
   "source": [
    "\n",
    "dirpath = f\"./checkpoints-subpillars-capacities-responses-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in capacities_response_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (capacities_response_train_dataset,\n",
    "                                                 capacities_response_val_dataset)\n",
    "\n",
    "errors_capacities_response = train_on_specific_targets(capacities_response_train_dataset,\n",
    "                                                 tagname_to_tagid,\n",
    "                                                 f\"capacities-and-response-classifier-{log_dir_name}\",\n",
    "                                                 dropout_rate=0.5)\n",
    "errors_capacities_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZa9FS8vE5Ty"
   },
   "outputs": [],
   "source": [
    "dirpath = f\"./checkpoints-subpillars-people-at-risk-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in people_at_risk_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (people_at_risk_train_dataset,\n",
    "                                                 people_at_risk_val_dataset)\n",
    "\n",
    "errors_people_at_risk = train_on_specific_targets(people_at_risk_train_dataset,\n",
    "                                            tagname_to_tagid,\n",
    "                                            f\"people-at-risk-classifier-{log_dir_name}\",\n",
    "                                            dropout_rate=0.5)\n",
    "errors_people_at_risk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27J-osEXE5Wj"
   },
   "outputs": [],
   "source": [
    "dirpath = f\"./checkpoints-subpillars-impact-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in impact_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (impact_train_dataset,\n",
    "                                                 impact_val_dataset)\n",
    "\n",
    "errors_impact = train_on_specific_targets(impact_train_dataset,\n",
    "                                    tagname_to_tagid,\n",
    "                                    f\"impact-classifier-{log_dir_name}\",\n",
    "                                    dropout_rate=0.3)\n",
    "errors_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzxHEuQbE5Z2"
   },
   "outputs": [],
   "source": [
    "dirpath = f\"./checkpoints-subpillars-humanitarian-conditions-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in hum_conditions_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (hum_conditions_train_dataset,\n",
    "                                                 hum_conditions_val_dataset)\n",
    "\n",
    "errors_hum_conditions = train_on_specific_targets(hum_conditions_train_dataset,\n",
    "                                                 tagname_to_tagid,\n",
    "                                                 f\"Humanitarian-Conditions-classifier-{log_dir_name}\",\n",
    "                                                 dropout_rate=0.3)\n",
    "errors_hum_conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WYEo4Uj0E5c3"
   },
   "outputs": [],
   "source": [
    "dirpath = f\"./checkpoints-subpillars-priority-interventions-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in priority_interventions_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (priority_interventions_train_dataset,\n",
    "                                                 priority_interventions_val_dataset)\n",
    "\n",
    "errors_priority_interventions = train_on_specific_targets(priority_interventions_train_dataset,\n",
    "                                                 tagname_to_tagid,\n",
    "                                                 f\"Priority-Interventions-classifier-{log_dir_name}\",\n",
    "                                                 dropout_rate=0.7)\n",
    "errors_priority_interventions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3JOjEO2E5f8"
   },
   "outputs": [],
   "source": [
    "dirpath = f\"./checkpoints-subpillars-priority-needs-{log_dir_name}\"\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=dirpath,\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "\n",
    "tag_set = set()\n",
    "for tags_i in priority_needs_train_dataset[\"target\"]:\n",
    "    tag_set.update(tags_i)\n",
    "tagname_to_tagid = {tag:i for i, tag in enumerate(list(sorted(tag_set)))}\n",
    "\n",
    "training_loader, val_loader, val_loader_frac = get_loaders (priority_needs_train_dataset,\n",
    "                                                 priority_needs_val_dataset)\n",
    "\n",
    "\n",
    "errors_priority_needs = train_on_specific_targets(priority_needs_train_dataset,\n",
    "                                                 tagname_to_tagid,\n",
    "                                                 f\"priority-needs-classifier-{log_dir_name}\",\n",
    "                                                 dropout_rate=0.6)\n",
    "errors_priority_needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfvuU2bkE5ij"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZVhl7Col8hH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "create_models_pillars_and_subpillars_paraphrase_multilingual_MiniLM_L12_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "034bd079864046ceba94947a56dd7f35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d49c7dede2244ea86019c7c791fe4f8",
       "IPY_MODEL_d031b8229e3340f7bfb61e94130ed95c"
      ],
      "layout": "IPY_MODEL_1ed346ab0dc749579f8c759afc52931b"
     }
    },
    "034c91422b074f41a20530bfa56e1b91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7dac1c42b294ad7b29c76eeb51906b9",
       "IPY_MODEL_a6241d5cfe4f4940bf4639c71d68808d"
      ],
      "layout": "IPY_MODEL_93c483c66d654cb08d0ca1307f3e94c4"
     }
    },
    "0ad5dc4a634344ba80c80be3f5887356": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1ed346ab0dc749579f8c759afc52931b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "33e819bd582a4838adde79ba0b567f05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34e5d15380ae48b09a063dbc1e687200": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3564f9a34d8e42768d71ab7194fa4727": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fefcbcc37f747f288c72d998d2a21b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "66cd1d3c5bb646428869e3387b34a3af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70861782f6f84942908a33dc44cc6a35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "73ba5d91e29644eab737ee941c7766ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff90695685354e509ef5861594a88fb3",
       "IPY_MODEL_b0b66fe174474fba8a094561e56b5fdf"
      ],
      "layout": "IPY_MODEL_70861782f6f84942908a33dc44cc6a35"
     }
    },
    "75338528d7c7402697437b5fddede4cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c483c66d654cb08d0ca1307f3e94c4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "9d49c7dede2244ea86019c7c791fe4f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Epoch 0: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec79ee6d044e4aa78b11414f5a5fcd89",
      "max": 16,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4fefcbcc37f747f288c72d998d2a21b7",
      "value": 16
     }
    },
    "a33c4464f1214fdba886273ef94b47bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6241d5cfe4f4940bf4639c71d68808d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd4d42dcce174346ba1aa29ec2146e1d",
      "placeholder": "",
      "style": "IPY_MODEL_affe1134e95b49c992395b55b4d0d84e",
      "value": " 0/2 [00:00&lt;?, ?it/s]"
     }
    },
    "affe1134e95b49c992395b55b4d0d84e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0b66fe174474fba8a094561e56b5fdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a33c4464f1214fdba886273ef94b47bf",
      "placeholder": "",
      "style": "IPY_MODEL_33e819bd582a4838adde79ba0b567f05",
      "value": " 2/2 [00:23&lt;00:00, 11.64s/it]"
     }
    },
    "d031b8229e3340f7bfb61e94130ed95c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34e5d15380ae48b09a063dbc1e687200",
      "placeholder": "",
      "style": "IPY_MODEL_3564f9a34d8e42768d71ab7194fa4727",
      "value": " 16/16 [05:23&lt;00:00, 20.19s/it]"
     }
    },
    "d1d804e5ffd14d3e93308807091883a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dd4d42dcce174346ba1aa29ec2146e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec79ee6d044e4aa78b11414f5a5fcd89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7dac1c42b294ad7b29c76eeb51906b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66cd1d3c5bb646428869e3387b34a3af",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0ad5dc4a634344ba80c80be3f5887356",
      "value": 0
     }
    },
    "ff90695685354e509ef5861594a88fb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validation sanity check: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75338528d7c7402697437b5fddede4cb",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1d804e5ffd14d3e93308807091883a8",
      "value": 2
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
