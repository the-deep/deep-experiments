{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import TranslationPipeline\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_train.csv')\n",
    "df_test = pd.read_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_test.csv')\n",
    "df_val = pd.read_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_val.csv')\n",
    "\n",
    "df_tot = pd.concat([df_train, df_test, df_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>lead_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>analysis_framework_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>created_by_id</th>\n",
       "      <th>modified_by_id</th>\n",
       "      <th>verified</th>\n",
       "      <th>sectors</th>\n",
       "      <th>pillars_2d</th>\n",
       "      <th>subpillars_2d</th>\n",
       "      <th>pillars_1d</th>\n",
       "      <th>subpillars_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165573</td>\n",
       "      <td>39661</td>\n",
       "      <td>2098</td>\n",
       "      <td>1306</td>\n",
       "      <td>260 frontline health staff including medical d...</td>\n",
       "      <td>1152</td>\n",
       "      <td>1152</td>\n",
       "      <td>False</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>161070</td>\n",
       "      <td>38796</td>\n",
       "      <td>2028</td>\n",
       "      <td>1306</td>\n",
       "      <td>The SNFI Cluster updated its recommendations o...</td>\n",
       "      <td>2444</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Priority Interventions']</td>\n",
       "      <td>['Priority Interventions-&gt;Expressed By Humanit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id  lead_id  project_id  analysis_framework_id  \\\n",
       "0    165573    39661        2098                   1306   \n",
       "1    161070    38796        2028                   1306   \n",
       "\n",
       "                                             excerpt  created_by_id  \\\n",
       "0  260 frontline health staff including medical d...           1152   \n",
       "1  The SNFI Cluster updated its recommendations o...           2444   \n",
       "\n",
       "   modified_by_id  verified     sectors                  pillars_2d  \\\n",
       "0            1152     False  ['Health']   ['Capacities & Response']   \n",
       "1              15     False    ['WASH']  ['Priority Interventions']   \n",
       "\n",
       "                                       subpillars_2d pillars_1d subpillars_1d  \n",
       "0  ['Capacities & Response->Number Of People Reac...         []            []  \n",
       "1  ['Priority Interventions->Expressed By Humanit...         []            []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot[['excerpt', 'entry_id', 'sectors', 'subpillars_2d', 'subpillars_1d']]\\\n",
    "            .to_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_language = pd.read_csv('../../../data/frameworks_data/data_v0.4.4/data_v0.4.4_full.csv', index_col=0)[\n",
    "    ['entry_id', 'language']\n",
    "]\n",
    "df_tot = pd.read_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_full.csv', index_col=0)\n",
    "#df_specific_needs = pd.read_csv('../../../data/secondary_tags/specific_needs_groups_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163664</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162812</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   entry_id language\n",
       "0    163664       en\n",
       "1    162812       en"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_language.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>sectors</th>\n",
       "      <th>subpillars_2d</th>\n",
       "      <th>subpillars_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260 frontline health staff including medical d...</td>\n",
       "      <td>165573</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The SNFI Cluster updated its recommendations o...</td>\n",
       "      <td>161070</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Priority Interventions-&gt;Expressed By Humanit...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             excerpt  entry_id     sectors  \\\n",
       "0  260 frontline health staff including medical d...    165573  ['Health']   \n",
       "1  The SNFI Cluster updated its recommendations o...    161070    ['WASH']   \n",
       "\n",
       "                                       subpillars_2d subpillars_1d  \n",
       "0  ['Capacities & Response->Number Of People Reac...            []  \n",
       "1  ['Priority Interventions->Expressed By Humanit...            []  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(\n",
    "    left=df_tot,\n",
    "    right=df_language,\n",
    "    on='entry_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>sectors</th>\n",
       "      <th>subpillars_2d</th>\n",
       "      <th>subpillars_1d</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260 frontline health staff including medical d...</td>\n",
       "      <td>165573</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The SNFI Cluster updated its recommendations o...</td>\n",
       "      <td>161070</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Priority Interventions-&gt;Expressed By Humanit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reported measures taken cope with problems usi...</td>\n",
       "      <td>165654</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Coping Mechanisms']</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To monitor Infection Control &amp; Prevention (IPC...</td>\n",
       "      <td>165576</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All the waste workers we interviewed had alrea...</td>\n",
       "      <td>165559</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             excerpt  entry_id     sectors  \\\n",
       "0  260 frontline health staff including medical d...    165573  ['Health']   \n",
       "1  The SNFI Cluster updated its recommendations o...    161070    ['WASH']   \n",
       "2  Reported measures taken cope with problems usi...    165654    ['WASH']   \n",
       "3  To monitor Infection Control & Prevention (IPC...    165576  ['Health']   \n",
       "4  All the waste workers we interviewed had alrea...    165559          []   \n",
       "\n",
       "                                       subpillars_2d subpillars_1d language  \n",
       "0  ['Capacities & Response->Number Of People Reac...            []       en  \n",
       "1  ['Priority Interventions->Expressed By Humanit...            []       en  \n",
       "2     ['Humanitarian Conditions->Coping Mechanisms']            []       en  \n",
       "3  ['Capacities & Response->Number Of People Reac...            []       en  \n",
       "4                                                 []            []      NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "# https://fasttext.cc/docs/en/language-identification.html\n",
    "# https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "fmodel = fasttext.load_model(path_to_pretrained_model)\n",
    "def lang_detect_ft(doc):\n",
    "    if isinstance(doc, str):\n",
    "        doc = re.sub(\"\\s+\", \" \", doc)\n",
    "        return fmodel.predict([doc])[0][0][0][len(\"__label__\"):]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_labeled = df_merged[df_merged.language.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137801/137801 [00:16<00:00, 8344.46it/s]\n"
     ]
    }
   ],
   "source": [
    "df_merged[\"language\"] = df_merged[\"excerpt\"].progress_apply(lang_detect_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='language', ylabel='Count'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(df_merged.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_present = df_merged[df_merged.apply(lambda x: len(x.sectors)>2 and len(x.subpillars_2d)>2, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>sectors</th>\n",
       "      <th>subpillars_2d</th>\n",
       "      <th>subpillars_1d</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260 frontline health staff including medical d...</td>\n",
       "      <td>165573</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The SNFI Cluster updated its recommendations o...</td>\n",
       "      <td>161070</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Priority Interventions-&gt;Expressed By Humanit...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reported measures taken cope with problems usi...</td>\n",
       "      <td>165654</td>\n",
       "      <td>['WASH']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Coping Mechanisms']</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To monitor Infection Control &amp; Prevention (IPC...</td>\n",
       "      <td>165576</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Although most workers we interviewed know abou...</td>\n",
       "      <td>165558</td>\n",
       "      <td>['Health']</td>\n",
       "      <td>['Capacities &amp; Response-&gt;Number Of People Reac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137605</th>\n",
       "      <td>Près de 1,6 millions de personnes déplacées ou...</td>\n",
       "      <td>246754</td>\n",
       "      <td>['Protection']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Number Of People In...</td>\n",
       "      <td>[]</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137624</th>\n",
       "      <td>[concernant les chiffres des PIN en insécurité...</td>\n",
       "      <td>246776</td>\n",
       "      <td>['Food Security']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Number Of People In...</td>\n",
       "      <td>[]</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137653</th>\n",
       "      <td>’après les résultats du 18ème cycle de l’analy...</td>\n",
       "      <td>246775</td>\n",
       "      <td>['Food Security']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Number Of People In...</td>\n",
       "      <td>[]</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137670</th>\n",
       "      <td>[données de juillet 2020 dans les 6 territoire...</td>\n",
       "      <td>274225</td>\n",
       "      <td>['Food Security']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Number Of People In...</td>\n",
       "      <td>[]</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137679</th>\n",
       "      <td>De acuerdo con el Panorama de Necesidades Huma...</td>\n",
       "      <td>283071</td>\n",
       "      <td>['Protection']</td>\n",
       "      <td>['Humanitarian Conditions-&gt;Number Of People In...</td>\n",
       "      <td>[]</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61420 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  excerpt  entry_id  \\\n",
       "0       260 frontline health staff including medical d...    165573   \n",
       "1       The SNFI Cluster updated its recommendations o...    161070   \n",
       "2       Reported measures taken cope with problems usi...    165654   \n",
       "3       To monitor Infection Control & Prevention (IPC...    165576   \n",
       "5       Although most workers we interviewed know abou...    165558   \n",
       "...                                                   ...       ...   \n",
       "137605  Près de 1,6 millions de personnes déplacées ou...    246754   \n",
       "137624  [concernant les chiffres des PIN en insécurité...    246776   \n",
       "137653  ’après les résultats du 18ème cycle de l’analy...    246775   \n",
       "137670  [données de juillet 2020 dans les 6 territoire...    274225   \n",
       "137679  De acuerdo con el Panorama de Necesidades Huma...    283071   \n",
       "\n",
       "                  sectors                                      subpillars_2d  \\\n",
       "0              ['Health']  ['Capacities & Response->Number Of People Reac...   \n",
       "1                ['WASH']  ['Priority Interventions->Expressed By Humanit...   \n",
       "2                ['WASH']     ['Humanitarian Conditions->Coping Mechanisms']   \n",
       "3              ['Health']  ['Capacities & Response->Number Of People Reac...   \n",
       "5              ['Health']  ['Capacities & Response->Number Of People Reac...   \n",
       "...                   ...                                                ...   \n",
       "137605     ['Protection']  ['Humanitarian Conditions->Number Of People In...   \n",
       "137624  ['Food Security']  ['Humanitarian Conditions->Number Of People In...   \n",
       "137653  ['Food Security']  ['Humanitarian Conditions->Number Of People In...   \n",
       "137670  ['Food Security']  ['Humanitarian Conditions->Number Of People In...   \n",
       "137679     ['Protection']  ['Humanitarian Conditions->Number Of People In...   \n",
       "\n",
       "       subpillars_1d language  \n",
       "0                 []       en  \n",
       "1                 []       en  \n",
       "2                 []       en  \n",
       "3                 []       en  \n",
       "5                 []       en  \n",
       "...              ...      ...  \n",
       "137605            []       fr  \n",
       "137624            []       fr  \n",
       "137653            []       fr  \n",
       "137670            []       fr  \n",
       "137679            []       es  \n",
       "\n",
       "[61420 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_primary_tags_entires = df_present.entry_id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6956"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(df_specific_needs.entry_id)).intersection(set(list(df_tot.entry_id))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(\n",
    "    df_tot[['entry_id', 'language']],\n",
    "    df_specific_needs,\n",
    "    on='entry_id',\n",
    "    how='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 584/584 [00:05<00:00, 116.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "tmp = []\n",
    "for text in tqdm(not_labeled_data.excerpt):\n",
    "    lang = detect(text)\n",
    "    tmp.append(lang)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('../../../data/secondary_tags/specific_needs_groups_final_with_language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-4-a77cc146d96d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-a77cc146d96d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_subs = pd.read_csv('../../../data/secondary_tags/specific_needs_groups_final_with_language.csv')£\u001b[0m\n\u001b[0m                                                                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "df_subs = pd.read_csv('../../../data/secondary_tags/specific_needs_groups_final_with_language.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df_subs[df_subs.language=='en']\n",
    "fr_df = df_subs[df_subs.language=='fr']\n",
    "es_df = df_subs[df_subs.language=='es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9179ca9c80d4f48825976fb7188eb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c784b33e084af88c9260acc3dd6911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b03998fc1ea452fab12ae32834c72be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "430a97829bcd46048b79fb6f83df124c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1475588c565b4f0aa373f6ca8b52545a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f08001c18be43bcbac39ea6ac8d7f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 569/1255 [19:15<26:46,  2.34s/it]  Token indices sequence length is longer than the specified maximum sequence length for this model (1486 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your input_length: 1486 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "100%|██████████| 1255/1255 [47:58<00:00,  2.29s/it] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translation = TranslationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "fr_to_en_texts = []\n",
    "false_inds = []\n",
    "for text in tqdm(fr_df.excerpt):\n",
    "    try:\n",
    "        translated_text = translation(text, max_length=512)[0]['translation_text']\n",
    "        fr_to_en_texts.append(translated_text)\n",
    "    except IndexError :\n",
    "        false_inds.append(text)\n",
    "        pass\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fr_df = fr_df.drop(fr_df.index[[569]])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"en_from_fr = fr_df.copy()\n",
    "en_from_fr['excerpt'] = fr_to_en_texts\n",
    "en_from_fr.to_csv('../../../data/secondary_tags/augmented_data/en_from_fr.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc22a98bb08e469f863f2f25305e20f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/786k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22063be88b4641339461f095e21d2b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/793k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e26c524bd584d7a9292687b52ae9175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5703672187cc44b09e8047015da276b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>>zlm_Latn<<', '>>mfe<<', '>>hat<<', '>>pap<<', '>>ast<<', '>>cat<<', '>>ind<<', '>>glg<<', '>>wln<<', '>>spa<<', '>>fra<<', '>>ron<<', '>>por<<', '>>ita<<', '>>oci<<', '>>arg<<', '>>min<<']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6145b19e8343411fa721750383173c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c630d3caffd40b2af340a309ff26394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/295M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[\"c'est une phrase en anglais que nous voulons traduire en français\",\n",
       " 'Isto deve ir para o português',\n",
       " 'esto al español']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "src_text = [\n",
    "    '>>fra<< this is a sentence in english that we want to translate to french',\n",
    "    '>>por<< This should go to portuguese',\n",
    "    '>>esp<< And this to Spanish'\n",
    "]\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-roa'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = MarianMTModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range (10):\n",
    "    translated = model.generate(**tokenizer(src_text, return_tensors=\"pt\", padding=True))\n",
    "    [tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13704462bdd4fd4b83176945b98071e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2037d32f6844e6f82819c29dc2b8623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71992dbd8b74482a83646cd18408cf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619743550f854bbe895dc9fc93cbb04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f3c3d226144e2e9ee43b4027dd5824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc58ac3a928144c1a5ab5c51803178c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
    "from transformers import TranslationPipeline\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
    "translation = TranslationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C'est un exemple de traduction\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation(['This is an example of translation', 'This is a sentence'], max_length=512)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C'est une phrase.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation(['This is a sentence'], max_length=512)[0]['translation_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86247f97e4da4574a9cc35a83dbfe0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592c11a1dc0642a190075bf4d099c453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83832a2be7e40488b89db0c61b14339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a276aa7622c4e5fa2108b43362a5315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/826k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d239c27287064631a87db5767d01cdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3550bb29ed4c97840789d4c1ee90b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 38/2352 [01:20<1:24:31,  2.19s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (790 > 512). Running this sequence through the model will result in indexing errors\n",
      "Your input_length: 790 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 10%|█         | 246/2352 [10:41<3:27:14,  5.90s/it]Your input_length: 481 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 29%|██▉       | 679/2352 [25:15<38:07,  1.37s/it]  Your input_length: 469 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 36%|███▌      | 842/2352 [31:12<24:30,  1.03it/s]  Your input_length: 1287 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 482 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 38%|███▊      | 893/2352 [33:01<44:50,  1.84s/it]  Your input_length: 622 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 42%|████▏     | 984/2352 [36:40<1:22:54,  3.64s/it]Your input_length: 606 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 42%|████▏     | 991/2352 [36:47<34:55,  1.54s/it]  Your input_length: 632 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 45%|████▌     | 1069/2352 [39:49<45:56,  2.15s/it]  Your input_length: 845 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 55%|█████▍    | 1285/2352 [48:27<44:30,  2.50s/it]  Your input_length: 509 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 55%|█████▌    | 1305/2352 [49:30<1:11:36,  4.10s/it]Your input_length: 500 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 56%|█████▌    | 1320/2352 [50:22<1:03:39,  3.70s/it]Your input_length: 507 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 56%|█████▋    | 1327/2352 [51:02<1:40:44,  5.90s/it]Your input_length: 587 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 57%|█████▋    | 1332/2352 [51:11<46:30,  2.74s/it]  Your input_length: 598 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "Your input_length: 485 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 66%|██████▌   | 1552/2352 [1:00:32<44:27,  3.33s/it]Your input_length: 633 is bigger than 0.9 * max_length: 512. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      "100%|██████████| 2352/2352 [1:33:44<00:00,  2.39s/it]  \n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
    "translation = TranslationPipeline(model=model, tokenizer=tokenizer)\n",
    "\n",
    "es_to_en_texts = []\n",
    "false_inds = []\n",
    "excerpt_list = list(es_df.excerpt)\n",
    "for i in tqdm(range(len(excerpt_list))):\n",
    "    try:\n",
    "        translated_text = translation(excerpt_list[i], max_length=512)[0]['translation_text']\n",
    "        es_to_en_texts.append(translated_text)\n",
    "    except IndexError :\n",
    "        false_inds.append(i)\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len (false_inds)>0:\n",
    "    es_df = es_df.drop(es_df.index[false_inds])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#es_df = es_df.iloc[:531]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_from_es = es_df.copy()\n",
    "en_from_es['excerpt'] = es_to_en_texts\n",
    "en_from_es.drop(columns=['Unnamed: 0']).to_csv('../../../data/secondary_tags/augmented_data/en_from_es.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>language</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>specific_needs_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24453</td>\n",
       "      <td>es</td>\n",
       "      <td>In vast areas of southern Venezuela, Colombian...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>10628</td>\n",
       "      <td>es</td>\n",
       "      <td>Reasons for migrating: The main reason identif...</td>\n",
       "      <td>['Female Head of Household']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>10631</td>\n",
       "      <td>es</td>\n",
       "      <td>Migration status: The majority of the women in...</td>\n",
       "      <td>['Female Head of Household']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>10634</td>\n",
       "      <td>es</td>\n",
       "      <td>Living conditions: One more element that requi...</td>\n",
       "      <td>['Female Head of Household']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>63910</td>\n",
       "      <td>es</td>\n",
       "      <td>Since the beginning of the year, the UN has di...</td>\n",
       "      <td>['Pregnant or Lactating Women']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>6170</td>\n",
       "      <td>341895</td>\n",
       "      <td>es</td>\n",
       "      <td>This situation increases the likelihood of cla...</td>\n",
       "      <td>['Indigenous people']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6986</th>\n",
       "      <td>6986</td>\n",
       "      <td>341898</td>\n",
       "      <td>es</td>\n",
       "      <td>Protection: The presence of the security force...</td>\n",
       "      <td>['Indigenous people']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>6997</td>\n",
       "      <td>341902</td>\n",
       "      <td>es</td>\n",
       "      <td>The confinement of the communities was confirm...</td>\n",
       "      <td>['Indigenous people']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>6999</td>\n",
       "      <td>341903</td>\n",
       "      <td>es</td>\n",
       "      <td>The delivery of immediate food kits by the may...</td>\n",
       "      <td>['Indigenous people']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7009</th>\n",
       "      <td>7009</td>\n",
       "      <td>341904</td>\n",
       "      <td>es</td>\n",
       "      <td>After activating the rapid response identifica...</td>\n",
       "      <td>['Indigenous people']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2343 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  entry_id language  \\\n",
       "3              3     24453       es   \n",
       "6              6     10628       es   \n",
       "7              7     10631       es   \n",
       "9              9     10634       es   \n",
       "24            24     63910       es   \n",
       "...          ...       ...      ...   \n",
       "6170        6170    341895       es   \n",
       "6986        6986    341898       es   \n",
       "6997        6997    341902       es   \n",
       "6999        6999    341903       es   \n",
       "7009        7009    341904       es   \n",
       "\n",
       "                                                excerpt  \\\n",
       "3     In vast areas of southern Venezuela, Colombian...   \n",
       "6     Reasons for migrating: The main reason identif...   \n",
       "7     Migration status: The majority of the women in...   \n",
       "9     Living conditions: One more element that requi...   \n",
       "24    Since the beginning of the year, the UN has di...   \n",
       "...                                                 ...   \n",
       "6170  This situation increases the likelihood of cla...   \n",
       "6986  Protection: The presence of the security force...   \n",
       "6997  The confinement of the communities was confirm...   \n",
       "6999  The delivery of immediate food kits by the may...   \n",
       "7009  After activating the rapid response identifica...   \n",
       "\n",
       "                specific_needs_groups  \n",
       "3                      ['Minorities']  \n",
       "6        ['Female Head of Household']  \n",
       "7        ['Female Head of Household']  \n",
       "9        ['Female Head of Household']  \n",
       "24    ['Pregnant or Lactating Women']  \n",
       "...                               ...  \n",
       "6170            ['Indigenous people']  \n",
       "6986            ['Indigenous people']  \n",
       "6997            ['Indigenous people']  \n",
       "6999            ['Indigenous people']  \n",
       "7009            ['Indigenous people']  \n",
       "\n",
       "[2343 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_from_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en_from_fr.csv',\n",
       " 'es_from_fr_second_part.csv',\n",
       " 'es_from_en.csv',\n",
       " 'fr_from_en_second_part.csv',\n",
       " 'fr_from_es_second_part.csv',\n",
       " 'specific_needs_groups_final_with_language.csv',\n",
       " 'fr_from_es_first_part.csv',\n",
       " 'en_from_es.csv',\n",
       " 'fr_from_en_first_part.csv',\n",
       " 'es_from_fr_first_part.csv',\n",
       " 'es_from_fr_third_part.csv']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir()\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'specific_needs_groups_final_with_language.csv'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files.pop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('specific_needs_groups_final_with_language.csv', index_col=0)[\n",
    "    ['entry_id', 'excerpt', 'specific_needs_groups']\n",
    "]\n",
    "\n",
    "for name in files:\n",
    "    df_tmp = pd.read_csv(name, index_col=0)[['entry_id', 'excerpt', 'specific_needs_groups']]\n",
    "    final_df = pd.concat([final_df, df_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>specific_needs_groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>133321</td>\n",
       "      <td>In Syria, UNHCR provided guidance to partners ...</td>\n",
       "      <td>['Persons with Disability']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25684</td>\n",
       "      <td>HelpAge’s country team and partners are reachi...</td>\n",
       "      <td>['Persons with Disability']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88087</td>\n",
       "      <td>During May and June, health sector partners ca...</td>\n",
       "      <td>['Persons with Disability']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24453</td>\n",
       "      <td>En vastas áreas del sur de Venezuela, guerrill...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27008</td>\n",
       "      <td>The UN Office for the Coordination of Humanita...</td>\n",
       "      <td>['Pregnant or Lactating Women']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>234525</td>\n",
       "      <td>Entre su población, estimada en más de 20 mill...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>209497</td>\n",
       "      <td>55 de cada 100 centros de salud entrevistados ...</td>\n",
       "      <td>['GBV survivors']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7131</th>\n",
       "      <td>342780</td>\n",
       "      <td>El jueves, violentos enfrentamientos, cuyas im...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7132</th>\n",
       "      <td>342779</td>\n",
       "      <td>La comunidad islámica de RD Congo, que represe...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>342781</td>\n",
       "      <td>Treinta acusados fueron condenados a muerte el...</td>\n",
       "      <td>['Minorities']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21416 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id                                            excerpt  \\\n",
       "0       133321  In Syria, UNHCR provided guidance to partners ...   \n",
       "1        25684  HelpAge’s country team and partners are reachi...   \n",
       "2        88087  During May and June, health sector partners ca...   \n",
       "3        24453  En vastas áreas del sur de Venezuela, guerrill...   \n",
       "4        27008  The UN Office for the Coordination of Humanita...   \n",
       "...        ...                                                ...   \n",
       "6957    234525  Entre su población, estimada en más de 20 mill...   \n",
       "6965    209497  55 de cada 100 centros de salud entrevistados ...   \n",
       "7131    342780  El jueves, violentos enfrentamientos, cuyas im...   \n",
       "7132    342779  La comunidad islámica de RD Congo, que represe...   \n",
       "7134    342781  Treinta acusados fueron condenados a muerte el...   \n",
       "\n",
       "                specific_needs_groups  \n",
       "0         ['Persons with Disability']  \n",
       "1         ['Persons with Disability']  \n",
       "2         ['Persons with Disability']  \n",
       "3                      ['Minorities']  \n",
       "4     ['Pregnant or Lactating Women']  \n",
       "...                               ...  \n",
       "6957                   ['Minorities']  \n",
       "6965                ['GBV survivors']  \n",
       "7131                   ['Minorities']  \n",
       "7132                   ['Minorities']  \n",
       "7134                   ['Minorities']  \n",
       "\n",
       "[21416 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['specific_needs_groups'] = final_df['specific_needs_groups'].apply(\n",
    "    lambda x: x.replace('Religious minority', 'Minorities')\\\n",
    "                .replace('Ethnic minority', 'Minorities')\\\n",
    "                .replace('Stateless', 'People with irregular status')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../augmented_specific_needs_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7540 [00:00<?, ?it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 12%|█▏        | 921/7540 [00:00<00:00, 9204.37it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 24%|██▍       | 1842/7540 [00:00<00:00, 8295.61it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 36%|███▌      | 2678/7540 [00:00<00:00, 8212.72it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 46%|████▋     | 3503/7540 [00:00<00:00, 8131.36it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 58%|█████▊    | 4350/7540 [00:00<00:00, 8248.17it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 70%|██████▉   | 5245/7540 [00:00<00:00, 8474.79it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 81%|████████▏ | 6138/7540 [00:00<00:00, 8620.04it/s]Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      "Detector is not able to detect the language reliably.\n",
      " 93%|█████████▎| 7032/7540 [00:00<00:00, 8719.32it/s]Detector is not able to detect the language reliably.\n",
      "100%|██████████| 7540/7540 [00:00<00:00, 8639.16it/s]\n"
     ]
    }
   ],
   "source": [
    "languages = []\n",
    "for text_tmp in tqdm(df_full.excerpt):\n",
    "    try:\n",
    "        lg = Detector(text_tmp).languages[0]\n",
    "\n",
    "        languages.append(lg.name)\n",
    "    except:\n",
    "        languages.append('UNKNOWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['language'] = pd.Series(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_wanted_languages(x):\n",
    "    if x=='English' or x=='French'\n",
    "\n",
    "df_full = df_full[df_full.language.apply()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full.to_csv('../../../data/frameworks_data/data_v0.5.1/data_v0.5.1_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_df = df_full[df_full.language=='French']\n",
    "fr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462dce278d834e3cbe1dcb8f2cc7fb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850f78ee2524a37879d3abde5381d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f97a1a7f8e04d1fb18dcb07d3493e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc3c346f52e462181b899b4cedcfd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small', return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_to_en_t5 = []\n",
    "for text in tqdm(fr_df.excerpt):\n",
    "    input_ids = tokenizer(\"translate French to English: \"+text, return_tensors=\"pt\").input_ids  # Batch size 1\n",
    "\n",
    "    outputs = model.generate(input_ids)\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    fr_to_en_t5.append(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 213/584 [01:24<02:26,  2.53it/s]\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 429: Too Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-501c0c8cb4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext_tmp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_labeled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_tmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlanguages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36mdetect_language\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/textblob/translate.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, source, host, type_)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"q\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'{url}&sl=auto&tk={tk}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_calculate_tk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/textblob/translate.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, url, host, type_, data)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhost\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_proxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m             \u001b[0mhttp_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_302\u001b[0;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mhttp_error_301\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_303\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_307\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_error_302\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    641\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
     ]
    }
   ],
   "source": [
    "languages = []\n",
    "for text_tmp in tqdm(not_labeled_data.excerpt):\n",
    "    b = TextBlob(text_tmp)\n",
    "    languages.append(b.detect_language())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df_subs[df_subs.language=='en']\n",
    "fr_df = df_subs[df_subs.language=='fr']\n",
    "es_df = df_subs[df_subs.language=='es']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1) code to\n",
    "\n",
    "fr -> es\n",
    "es -> fr\n",
    "en -> es\n",
    "en -> fr\n",
    "fr -> en\n",
    "es -> en\n",
    "\n",
    "2) detect language in text and apply language\n",
    "\n",
    "3) Merge models: demographic groups, sectors, 2d subpillars\n",
    "\n",
    "4) Augment data for 1d subpillars, specific needs groups\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:843: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8885e33193496e946eaaa78842c416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e4c76199334641beccf84fa1233ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/332M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e692b6f872bd427285f333c6fe51a229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514372ceb3b84b7996528f70f43c6984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100a08e571274efcbebc0cc3778fb225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/819k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d83ebb81b92451fadec001292f438f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"Helsinki-NLP/opus-mt-fr-es\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = TranslationPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [00:56<01:27,  3.14s/it]Your input_length: 335 is bigger than 0.9 * max_length: 256. You might consider increasing your max_length manually, e.g. translator('...', max_length=400)\n",
      " 48%|████▊     | 24/50 [01:07<01:13,  2.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4e836422b1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfr_to_es_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexcerpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtranslated_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'translation_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfr_to_es_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, return_tensors, return_text, clean_up_tokenization_spaces, truncation, src_lang, tgt_lang, *args, **generate_kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_placement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_and_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtruncation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_lang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_lang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, inputs, return_tensors, return_text, clean_up_tokenization_spaces, generate_kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         generations = self.model.generate(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1051\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_encoder_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             )\n\u001b[0;32m-> 1053\u001b[0;31m             return self.beam_search(\n\u001b[0m\u001b[1;32m   1054\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                 \u001b[0mbeam_scorer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1833\u001b[0m             \u001b[0mnext_token_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1835\u001b[0;31m             next_token_scores, next_tokens = torch.topk(\n\u001b[0m\u001b[1;32m   1836\u001b[0m                 \u001b[0mnext_token_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlargest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1837\u001b[0m             )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fr_to_es_texts = []\n",
    "for text in tqdm(fr_df.excerpt.sample(n=50)):\n",
    "    translated_text = translation(text, max_length=256)[0]['translation_text']\n",
    "    fr_to_es_texts.append(translated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
