{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n!pip install s3fs'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "!pip install s3fs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('..', '..', '..', \"data\", \"frameworks_data\", \"data_v0.4.4\", \"data_v0.4.4_train.csv\")\n",
    "VAL_PATH = os.path.join('..', '..', '..', \"data\", \"frameworks_data\", \"data_v0.4.4\", \"data_v0.4.4_val.csv\")\n",
    "TEST_PATH = os.path.join('..', '..', '..', \"data\", \"frameworks_data\", \"data_v0.4.4\", \"data_v0.4.4_test.csv\")\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.concat([pd.read_csv(TEST_PATH), pd.read_csv(VAL_PATH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = False  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
    "    train_df = train_df.sample(n=1000)\n",
    "    val_df = val_df.sample(n=1000)\n",
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-subpillars-model-test-mlflow\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "\n",
    "train_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "val_df.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "\n",
    "hyperparameters={\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
    "    'experiment_name': \"pl-2d-subpilllars\",\n",
    "    'max_len': 256,\n",
    "    'epochs': 5,\n",
    "    'model_name': 'microsoft/xtremedistil-l6-h384-uncased',\n",
    "    'tokenizer_name': 'microsoft/xtremedistil-l6-h384-uncased',\n",
    "    'dropout_rate': 0.2,\n",
    "    'pred_threshold':0.4,\n",
    "    'output_length': 384,\n",
    "    'learning_rate': 7e-5,\n",
    "    'training_column':'subpillars'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_mlflow.py',\n",
    "    source_dir=str('../../../scripts/training/selim/multiclass-lightning'),\n",
    "    output_path=str(DEV_BUCKET/'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-02 11:56:23 Starting - Starting the training job...\n",
      "2021-08-02 11:56:55 Starting - Launching requested ML instancesProfilerReport-1627905380: InProgress\n",
      "......\n",
      "2021-08-02 11:57:48 Starting - Preparing the instances for training......\n",
      "2021-08-02 11:58:59 Downloading - Downloading input data...\n",
      "2021-08-02 11:59:28 Training - Downloading the training image......................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-08-02 12:03:22,799 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-08-02 12:03:22,822 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-08-02 12:03:25,877 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-08-02 12:03:26,322 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.8.2\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4.0\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.8\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.4.1\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm==4.41.1\n",
      "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting nlpaug==1.1.6\n",
      "  Downloading nlpaug-1.1.6-py3-none-any.whl (405 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk==3.2.5\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.18.0\n",
      "  Downloading mlflow-1.18.0-py3-none-any.whl (14.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.7.6-cp36-cp36m-manylinux2014_x86_64.whl (722 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (4.6.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.17\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (3.17.3)\u001b[0m\n",
      "\u001b[34mCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\u001b[0m\n",
      "\u001b[34mCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (8.3.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (1.6.0)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.22-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting Flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow==1.18.0->-r requirements.txt (line 8)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.18.0->-r requirements.txt (line 8)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=4.0.0->mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy->mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.34.0-py2.py3-none-any.whl (152 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (21.2.0)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.18.0->-r requirements.txt (line 8)) (3.0.1)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=3.0->Flask->mlflow==1.18.0->-r requirements.txt (line 8)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.8.2->-r requirements.txt (line 1)) (3.5.0)\u001b[0m\n",
      "\u001b[34mCollecting prometheus_client\n",
      "  Downloading prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.8.2->-r requirements.txt (line 1)) (1.0.1)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, alembic, databricks-cli, termcolor, wrapt, idna-ssl, prometheus-flask-exporter\n",
      "  Building wheel for nltk (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.2.5-py3-none-any.whl size=1392140 sha256=eede5e10ca7896f5df16ee3e51f859a2b872fd2fb430c2e0cf9db77e75a6c9c0\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/7f/71/cb36468789a03b5e2908281c8e1ce093e6860258b6b61677d8\n",
      "  Building wheel for alembic (setup.py): started\n",
      "  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=6a1ac7c54dcab87676352b67a01d494e9bb28c2c747c4914da2b6e4f0f3d82eb\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
      "  Building wheel for databricks-cli (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100556 sha256=2a7aa39bff0e50085a7d94afa214ce914a6a5296257774ba7b3fb6f6da20535f\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/88/95/bd32d0e2dc0cf30e55574faab3118df2bb9ebebc60978c147b\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=9daccd963c565db04600bdd3f56caaa79cfe2ef848e40931d1c7a02e8af5c63a\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69750 sha256=92a889cf3d9bf2a3658db32ab8739103985694fcb57199c78fba315ec2259074\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for idna-ssl (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=b65c48392c56237d134d36e16a777d9959044c1ade585e01b3c2a27ee1b2f1fb\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): started\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17398 sha256=93a07bf143ebbfe2f59404acec11ce50e145dc0fc4e527c48d7d73674eb042f0\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/77/e8/3ca90b66243b0b58d5a5323a3da02cc8c5daf1de7a65141701\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk alembic databricks-cli termcolor wrapt idna-ssl prometheus-flask-exporter\u001b[0m\n",
      "\u001b[34mInstalling collected packages: typing-extensions, six, pyasn1-modules, oauthlib, multidict, cachetools, yarl, smmap, requests-oauthlib, numpy, itsdangerous, idna-ssl, google-auth, async-timeout, tqdm, tensorboard-plugin-wit, sqlalchemy, regex, python-editor, prometheus-client, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, Flask, filelock, aiohttp, absl-py, wrapt, torchmetrics, tokenizers, termcolor, tensorflow-estimator, tensorboard, sqlparse, sacremoses, querystring-parser, pyDeprecate, prometheus-flask-exporter, opt-einsum, keras-preprocessing, huggingface-hub, h5py, gunicorn, gitpython, gast, flatbuffers, entrypoints, docker, databricks-cli, astunparse, alembic, transformers, tensorflow, pytorch-lightning, nltk, nlpaug, mlflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.51.0\n",
      "    Uninstalling tqdm-4.51.0:\n",
      "      Successfully uninstalled tqdm-4.51.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\u001b[0m\n",
      "\n",
      "2021-08-02 12:04:30 Training - Training image download completed. Training in progress.\u001b[34mSuccessfully installed Flask-2.0.1 Mako-1.1.4 absl-py-0.13.0 aiohttp-3.7.4.post0 alembic-1.4.1 astunparse-1.6.3 async-timeout-3.0.1 cachetools-4.2.2 databricks-cli-0.14.3 docker-5.0.0 entrypoints-0.3 filelock-3.0.12 flatbuffers-1.12 gast-0.3.3 gitdb-4.0.7 gitpython-3.1.18 google-auth-1.34.0 google-auth-oauthlib-0.4.5 grpcio-1.32.0 gunicorn-20.1.0 h5py-2.10.0 huggingface-hub-0.0.12 idna-ssl-1.1.0 itsdangerous-2.0.1 keras-preprocessing-1.1.2 markdown-3.3.4 mlflow-1.18.0 multidict-5.1.0 nlpaug-1.1.6 nltk-3.2.5 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 prometheus-client-0.11.0 prometheus-flask-exporter-0.18.2 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 python-editor-1.0.4 pytorch-lightning-1.3.8 querystring-parser-1.2.4 regex-2021.7.6 requests-oauthlib-1.3.0 sacremoses-0.0.45 six-1.15.0 smmap-4.0.0 sqlalchemy-1.4.22 sqlparse-0.4.1 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 tokenizers-0.10.3 torchmetrics-0.4.1 tqdm-4.41.1 transformers-4.8.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-02 12:04:27,807 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout_rate\": 0.2,\n",
      "        \"experiment_name\": \"pl-2d-subpilllars\",\n",
      "        \"max_len\": 256,\n",
      "        \"model_name\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"output_length\": 384,\n",
      "        \"tokenizer_name\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"epochs\": 5,\n",
      "        \"learning_rate\": 7e-05,\n",
      "        \"pred_threshold\": 0.4,\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\n",
      "        \"training_column\": \"subpillars\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout_rate\":0.2,\"epochs\":5,\"experiment_name\":\"pl-2d-subpilllars\",\"learning_rate\":7e-05,\"max_len\":256,\"model_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"training_column\":\"subpillars\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout_rate\":0.2,\"epochs\":5,\"experiment_name\":\"pl-2d-subpilllars\",\"learning_rate\":7e-05,\"max_len\":256,\"model_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"training_column\":\"subpillars\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/pytorch-2021-08-02-13-51-00-163-subpillars-model-test-mlflow/source/sourcedir.tar.gz\",\"module_name\":\"train_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout_rate\",\"0.2\",\"--epochs\",\"5\",\"--experiment_name\",\"pl-2d-subpilllars\",\"--learning_rate\",\"7e-05\",\"--max_len\",\"256\",\"--model_name\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--output_length\",\"384\",\"--pred_threshold\",\"0.4\",\"--tokenizer_name\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"--training_column\",\"subpillars\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=pl-2d-subpilllars\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=256\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_LENGTH=384\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER_NAME=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=7e-05\u001b[0m\n",
      "\u001b[34mSM_HP_PRED_THRESHOLD=0.4\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_COLUMN=subpillars\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_mlflow.py --dropout_rate 0.2 --epochs 5 --experiment_name pl-2d-subpilllars --learning_rate 7e-05 --max_len 256 --model_name microsoft/xtremedistil-l6-h384-uncased --output_length 384 --pred_threshold 0.4 --tokenizer_name microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --training_column subpillars\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[nltk_data] Downloading package averaged_perceptron_tagger to\u001b[0m\n",
      "\u001b[34m[nltk_data]     /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package wordnet to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/wordnet.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package omw to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/omw.zip.\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s][2021-08-02 12:06:21.224 algo-1:79 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.290 algo-1:79 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.290 algo-1:79 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.291 algo-1:79 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.291 algo-1:79 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.291 algo-1:79 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.embeddings.word_embeddings.weight count_params:11720448\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.embeddings.position_embeddings.weight count_params:196608\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.embeddings.token_type_embeddings.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.embeddings.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.embeddings.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.467 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.468 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.0.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.469 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.1.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.470 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.471 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.2.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.472 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.3.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.473 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.474 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.4.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.475 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.encoder.layer.5.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.476 algo-1:79 INFO hook.py:591] name:model.l0.pooler.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l0.pooler.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l1.weight count_params:57600\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l1.bias count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l2.weight count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l2.bias count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l4.weight count_params:3000\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.477 algo-1:79 INFO hook.py:591] name:model.l4.bias count_params:20\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.478 algo-1:79 INFO hook.py:593] Total Trainable Params: 22774286\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.478 algo-1:79 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-08-02 12:06:21.481 algo-1:79 INFO hook.py:488] Hook is writing from the hook with pid: 79\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1731 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1731 [00:00<?, ?it/s] #015Epoch 0:   2%|▏         | 30/1731 [00:02<02:28, 11.42it/s]#015Epoch 0:   2%|▏         | 30/1731 [00:02<02:28, 11.42it/s, loss=11.5, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.464]#015Epoch 0:   3%|▎         | 60/1731 [00:04<02:14, 12.39it/s, loss=11.5, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.464]#015Epoch 0:   3%|▎         | 60/1731 [00:04<02:14, 12.39it/s, loss=2.52, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.519]#015Epoch 0:   5%|▌         | 90/1731 [00:07<02:08, 12.77it/s, loss=2.52, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.519]#015Epoch 0:   5%|▌         | 90/1731 [00:07<02:08, 12.77it/s, loss=1.81, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.558]#015Epoch 0:   7%|▋         | 120/1731 [00:09<02:04, 12.91it/s, loss=1.81, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.558]#015Epoch 0:   7%|▋         | 120/1731 [00:09<02:04, 12.91it/s, loss=1.48, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.498]#015Epoch 0:   9%|▊         | 150/1731 [00:11<02:00, 13.10it/s, loss=1.48, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.498]#015Epoch 0:   9%|▊         | 150/1731 [00:11<02:00, 13.10it/s, loss=1.43, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.487]#015Epoch 0:  10%|█         | 180/1731 [00:13<01:58, 13.11it/s, loss=1.43, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.487]#015Epoch 0:  10%|█         | 180/1731 [00:13<01:58, 13.11it/s, loss=1.37, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.489]#015Epoch 0:  12%|█▏        | 210/1731 [00:15<01:55, 13.17it/s, loss=1.37, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.489]#015Epoch 0:  12%|█▏        | 210/1731 [00:15<01:55, 13.17it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.527]#015Epoch 0:  14%|█▍        | 240/1731 [00:18<01:52, 13.23it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.527]#015Epoch 0:  14%|█▍        | 240/1731 [00:18<01:52, 13.23it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.490]#015Epoch 0:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.490]#015Epoch 0:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=1.45, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511]#015Epoch 0:  17%|█▋        | 300/1731 [00:22<01:47, 13.29it/s, loss=1.45, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511]#015Epoch 0:  17%|█▋        | 300/1731 [00:22<01:47, 13.29it/s, loss=1.57, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.493]#015Epoch 0:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=1.57, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.493]#015Epoch 0:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=1.09, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.499]#015Epoch 0:  21%|██        | 360/1731 [00:27<01:42, 13.31it/s, loss=1.09, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.499]#015Epoch 0:  21%|██        | 360/1731 [00:27<01:42, 13.31it/s, loss=1.15, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.536]#015Epoch 0:  23%|██▎       | 390/1731 [00:29<01:40, 13.35it/s, loss=1.15, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.536]#015Epoch 0:  23%|██▎       | 390/1731 [00:29<01:40, 13.35it/s, loss=1.35, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.494]#015Epoch 0:  24%|██▍       | 420/1731 [00:31<01:38, 13.34it/s, loss=1.35, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.494]#015Epoch 0:  24%|██▍       | 420/1731 [00:31<01:38, 13.34it/s, loss=1.21, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.507]#015Epoch 0:  26%|██▌       | 450/1731 [00:33<01:35, 13.36it/s, loss=1.21, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.507]#015Epoch 0:  26%|██▌       | 450/1731 [00:33<01:35, 13.36it/s, loss=1.8, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.567] #015Epoch 0:  28%|██▊       | 480/1731 [00:35<01:33, 13.35it/s, loss=1.8, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.567]#015Epoch 0:  28%|██▊       | 480/1731 [00:35<01:33, 13.35it/s, loss=0.853, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.545]#015Epoch 0:  29%|██▉       | 510/1731 [00:38<01:31, 13.33it/s, loss=0.853, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.545]#015Epoch 0:  29%|██▉       | 510/1731 [00:38<01:31, 13.33it/s, loss=1.5, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.480]  #015Epoch 0:  31%|███       | 540/1731 [00:40<01:29, 13.35it/s, loss=1.5, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.480]#015Epoch 0:  31%|███       | 540/1731 [00:40<01:29, 13.35it/s, loss=1.24, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.490]#015Epoch 0:  33%|███▎      | 570/1731 [00:42<01:27, 13.32it/s, loss=1.24, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.490]#015Epoch 0:  33%|███▎      | 570/1731 [00:42<01:27, 13.32it/s, loss=1.87, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511]#015Epoch 0:  35%|███▍      | 600/1731 [00:45<01:24, 13.33it/s, loss=1.87, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511]#015Epoch 0:  35%|███▍      | 600/1731 [00:45<01:24, 13.33it/s, loss=1.67, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.508]#015Epoch 0:  36%|███▋      | 630/1731 [00:47<01:22, 13.33it/s, loss=1.67, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.508]#015Epoch 0:  36%|███▋      | 630/1731 [00:47<01:22, 13.33it/s, loss=0.773, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.597]#015Epoch 0:  38%|███▊      | 660/1731 [00:49<01:20, 13.33it/s, loss=0.773, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.597]#015Epoch 0:  38%|███▊      | 660/1731 [00:49<01:20, 13.33it/s, loss=1.31, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.551] #015Epoch 0:  40%|███▉      | 690/1731 [00:51<01:17, 13.35it/s, loss=1.31, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.551]#015Epoch 0:  40%|███▉      | 690/1731 [00:51<01:17, 13.35it/s, loss=0.912, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.575]#015Epoch 0:  42%|████▏     | 720/1731 [00:53<01:15, 13.35it/s, loss=0.912, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.575]#015Epoch 0:  42%|████▏     | 720/1731 [00:53<01:15, 13.35it/s, loss=1.31, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511] #015Epoch 0:  43%|████▎     | 750/1731 [00:56<01:13, 13.37it/s, loss=1.31, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.511]#015Epoch 0:  43%|████▎     | 750/1731 [00:56<01:13, 13.37it/s, loss=0.934, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.521]#015Epoch 0:  45%|████▌     | 780/1731 [00:58<01:11, 13.37it/s, loss=0.934, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.521]#015Epoch 0:  45%|████▌     | 780/1731 [00:58<01:11, 13.37it/s, loss=1.09, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.523] #015Epoch 0:  47%|████▋     | 810/1731 [01:00<01:08, 13.37it/s, loss=1.09, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.523]#015Epoch 0:  47%|████▋     | 810/1731 [01:00<01:08, 13.37it/s, loss=0.917, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.553]#015Epoch 0:  49%|████▊     | 840/1731 [01:02<01:06, 13.39it/s, loss=0.917, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.553]#015Epoch 0:  49%|████▊     | 840/1731 [01:02<01:06, 13.39it/s, loss=1.57, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.517] #015Epoch 0:  50%|█████     | 870/1731 [01:04<01:04, 13.39it/s, loss=1.57, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.517]#015Epoch 0:  50%|█████     | 870/1731 [01:04<01:04, 13.39it/s, loss=1.55, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.505]#015Epoch 0:  52%|█████▏    | 900/1731 [01:07<01:01, 13.40it/s, loss=1.55, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.505]#015Epoch 0:  52%|█████▏    | 900/1731 [01:07<01:01, 13.40it/s, loss=0.965, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.507]#015Epoch 0:  54%|█████▎    | 930/1731 [01:09<00:59, 13.40it/s, loss=0.965, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.507]#015Epoch 0:  54%|█████▎    | 930/1731 [01:09<00:59, 13.40it/s, loss=1.02, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.534] #015Epoch 0:  55%|█████▌    | 960/1731 [01:11<00:57, 13.40it/s, loss=1.02, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.534]#015Epoch 0:  55%|█████▌    | 960/1731 [01:11<00:57, 13.40it/s, loss=1.56, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.595]#015Epoch 0:  57%|█████▋    | 990/1731 [01:13<00:55, 13.42it/s, loss=1.56, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.595]#015Epoch 0:  57%|█████▋    | 990/1731 [01:13<00:55, 13.42it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.603]#015Epoch 0:  59%|█████▉    | 1020/1731 [01:16<00:53, 13.41it/s, loss=1.29, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.603]#015Epoch 0:  59%|█████▉    | 1020/1731 [01:16<00:53, 13.41it/s, loss=1.07, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.582]#015Epoch 0:  61%|██████    | 1050/1731 [01:18<00:50, 13.42it/s, loss=1.07, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.582]#015Epoch 0:  61%|██████    | 1050/1731 [01:18<00:50, 13.42it/s, loss=1.41, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.603]#015Epoch 0:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.41it/s, loss=1.41, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.603]#015Epoch 0:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.41it/s, loss=0.874, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.560]#015Epoch 0:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.41it/s, loss=0.874, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.560]#015Epoch 0:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.41it/s, loss=1.43, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.560] #015Epoch 0:  66%|██████▌   | 1140/1731 [01:24<00:44, 13.42it/s, loss=1.43, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.560]#015Epoch 0:  66%|██████▌   | 1140/1731 [01:24<00:44, 13.42it/s, loss=1.07, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.595]#015Epoch 0:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.42it/s, loss=1.07, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.595]#015Epoch 0:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.42it/s, loss=1.82, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.601]#015Epoch 0:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.42it/s, loss=1.82, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.601]#015Epoch 0:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.42it/s, loss=0.852, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.621]#015Epoch 0:  71%|███████   | 1230/1731 [01:31<00:37, 13.42it/s, loss=0.852, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.621]#015Epoch 0:  71%|███████   | 1230/1731 [01:31<00:37, 13.42it/s, loss=0.994, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.701]#015Epoch 0:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.42it/s, loss=0.994, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.701]#015Epoch 0:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.42it/s, loss=1.01, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.656] #015Epoch 0:  75%|███████▍  | 1290/1731 [01:36<00:32, 13.44it/s, loss=1.01, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.656]#015Epoch 0:  75%|███████▍  | 1290/1731 [01:36<00:32, 13.44it/s, loss=1.37, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.682]#015Epoch 0:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.43it/s, loss=1.37, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.682]#015Epoch 0:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.43it/s, loss=0.615, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.605]#015Epoch 0:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.43it/s, loss=0.615, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.605]#015Epoch 0:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.43it/s, loss=0.811, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.640]#015Epoch 0:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.42it/s, loss=0.811, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.640]#015Epoch 0:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.42it/s, loss=1.26, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.651] #015Epoch 0:  81%|████████▏ | 1410/1731 [01:45<00:23, 13.41it/s, loss=1.26, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.651]#015Epoch 0:  81%|████████▏ | 1410/1731 [01:45<00:23, 13.41it/s, loss=1.01, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.658]#015Epoch 0:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.42it/s, loss=1.01, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.658]#015Epoch 0:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.42it/s, loss=0.904, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.633]#015Epoch 0:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.42it/s, loss=0.904, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.633]#015Epoch 0:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.42it/s, loss=0.86, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.572] #015Epoch 0:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.42it/s, loss=0.86, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.572]#015Epoch 0:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.42it/s, loss=1.18, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.620]#015Epoch 0:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.42it/s, loss=1.18, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.620]#015Epoch 0:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.42it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]#015Epoch 0:  90%|█████████ | 1560/1731 [01:54<00:12, 13.61it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/193 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  16%|█▌        | 30/193 [00:01<00:06, 23.58it/s]#033[A#015Epoch 0:  92%|█████████▏| 1590/1731 [01:55<00:10, 13.72it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating:  31%|███       | 60/193 [00:02<00:05, 24.77it/s]#033[A#015Epoch 0:  94%|█████████▎| 1620/1731 [01:56<00:08, 13.85it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating:  47%|████▋     | 90/193 [00:03<00:04, 25.66it/s]#033[A#015Epoch 0:  95%|█████████▌| 1650/1731 [01:58<00:05, 13.98it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating:  62%|██████▏   | 120/193 [00:04<00:02, 26.32it/s]#033[A#015Epoch 0:  97%|█████████▋| 1680/1731 [01:59<00:03, 14.10it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating:  78%|███████▊  | 150/193 [00:05<00:01, 26.86it/s]#033[A#015Epoch 0:  99%|█████████▉| 1710/1731 [02:00<00:01, 14.23it/s, loss=0.726, v_num=0, val_f1_epoch=0.0681, val_loss_epoch=0.690, train_f1=0.590]\u001b[0m\n",
      "\u001b[34m#015Validating:  93%|█████████▎| 180/193 [00:06<00:00, 27.13it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 193/193 [00:07<00:00, 27.72it/s]#033[A#015Epoch 0: 100%|██████████| 1731/1731 [02:01<00:00, 14.21it/s, loss=0.69, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.644, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.69, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.644, val_f1_step=0.803, val_loss_step=0.129]           #015Epoch 1:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.69, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.644, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   2%|▏         | 30/1731 [00:02<02:17, 12.39it/s, loss=0.69, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.644, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   2%|▏         | 30/1731 [00:02<02:17, 12.38it/s, loss=1.65, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.720, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   3%|▎         | 60/1731 [00:04<02:07, 13.15it/s, loss=1.65, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.720, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   3%|▎         | 60/1731 [00:04<02:07, 13.14it/s, loss=1.49, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.711, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   5%|▌         | 90/1731 [00:06<02:03, 13.25it/s, loss=1.49, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.711, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   5%|▌         | 90/1731 [00:06<02:03, 13.25it/s, loss=1.21, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.576, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   7%|▋         | 120/1731 [00:08<02:00, 13.34it/s, loss=1.21, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.576, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   7%|▋         | 120/1731 [00:08<02:00, 13.33it/s, loss=0.846, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.632, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   9%|▊         | 150/1731 [00:11<01:57, 13.47it/s, loss=0.846, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.632, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:   9%|▊         | 150/1731 [00:11<01:57, 13.47it/s, loss=1.18, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.593, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  10%|█         | 180/1731 [00:13<01:55, 13.48it/s, loss=1.18, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.593, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  10%|█         | 180/1731 [00:13<01:55, 13.48it/s, loss=1.12, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.664, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  12%|█▏        | 210/1731 [00:15<01:52, 13.53it/s, loss=1.12, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.664, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  12%|█▏        | 210/1731 [00:15<01:52, 13.53it/s, loss=0.839, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  14%|█▍        | 240/1731 [00:17<01:50, 13.52it/s, loss=0.839, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.629, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  14%|█▍        | 240/1731 [00:17<01:50, 13.52it/s, loss=0.782, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.651, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  16%|█▌        | 270/1731 [00:19<01:48, 13.51it/s, loss=0.782, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.651, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  16%|█▌        | 270/1731 [00:19<01:48, 13.51it/s, loss=0.861, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.546, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  17%|█▋        | 300/1731 [00:22<01:45, 13.56it/s, loss=0.861, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.546, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  17%|█▋        | 300/1731 [00:22<01:45, 13.56it/s, loss=0.89, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.645, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  19%|█▉        | 330/1731 [00:24<01:43, 13.56it/s, loss=0.89, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.645, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  19%|█▉        | 330/1731 [00:24<01:43, 13.56it/s, loss=0.844, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.709, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  21%|██        | 360/1731 [00:26<01:40, 13.59it/s, loss=0.844, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.709, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  21%|██        | 360/1731 [00:26<01:40, 13.58it/s, loss=0.801, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.664, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  23%|██▎       | 390/1731 [00:28<01:38, 13.57it/s, loss=0.801, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.664, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  23%|██▎       | 390/1731 [00:28<01:38, 13.57it/s, loss=0.876, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.655, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  24%|██▍       | 420/1731 [00:30<01:36, 13.56it/s, loss=0.876, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.655, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  24%|██▍       | 420/1731 [00:30<01:36, 13.56it/s, loss=1.14, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.661, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  26%|██▌       | 450/1731 [00:33<01:34, 13.55it/s, loss=1.14, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.661, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  26%|██▌       | 450/1731 [00:33<01:34, 13.55it/s, loss=0.858, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.672, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  28%|██▊       | 480/1731 [00:35<01:32, 13.51it/s, loss=0.858, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.672, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  28%|██▊       | 480/1731 [00:35<01:32, 13.51it/s, loss=0.787, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.643, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  29%|██▉       | 510/1731 [00:37<01:30, 13.51it/s, loss=0.787, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.643, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  29%|██▉       | 510/1731 [00:37<01:30, 13.51it/s, loss=1.93, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  31%|███       | 540/1731 [00:40<01:28, 13.48it/s, loss=1.93, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  31%|███       | 540/1731 [00:40<01:28, 13.48it/s, loss=0.787, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  33%|███▎      | 570/1731 [00:42<01:26, 13.48it/s, loss=0.787, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  33%|███▎      | 570/1731 [00:42<01:26, 13.48it/s, loss=1.24, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.597, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  35%|███▍      | 600/1731 [00:44<01:23, 13.49it/s, loss=1.24, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.597, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  35%|███▍      | 600/1731 [00:44<01:23, 13.49it/s, loss=0.789, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  36%|███▋      | 630/1731 [00:46<01:21, 13.49it/s, loss=0.789, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  36%|███▋      | 630/1731 [00:46<01:21, 13.49it/s, loss=0.902, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.697, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  38%|███▊      | 660/1731 [00:48<01:19, 13.51it/s, loss=0.902, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.697, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  38%|███▊      | 660/1731 [00:48<01:19, 13.51it/s, loss=0.81, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.636, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  40%|███▉      | 690/1731 [00:51<01:17, 13.51it/s, loss=0.81, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.636, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  40%|███▉      | 690/1731 [00:51<01:17, 13.51it/s, loss=0.713, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.676, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  42%|████▏     | 720/1731 [00:53<01:14, 13.50it/s, loss=0.713, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.676, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  42%|████▏     | 720/1731 [00:53<01:14, 13.50it/s, loss=0.705, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.725, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  43%|████▎     | 750/1731 [00:55<01:12, 13.52it/s, loss=0.705, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.725, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  43%|████▎     | 750/1731 [00:55<01:12, 13.52it/s, loss=0.745, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  45%|████▌     | 780/1731 [00:57<01:10, 13.50it/s, loss=0.745, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.657, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  45%|████▌     | 780/1731 [00:57<01:10, 13.50it/s, loss=0.674, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.701, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  47%|████▋     | 810/1731 [00:59<01:08, 13.52it/s, loss=0.674, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.701, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  47%|████▋     | 810/1731 [00:59<01:08, 13.52it/s, loss=0.741, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  49%|████▊     | 840/1731 [01:02<01:05, 13.51it/s, loss=0.741, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  49%|████▊     | 840/1731 [01:02<01:05, 13.51it/s, loss=0.681, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.711, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  50%|█████     | 870/1731 [01:04<01:03, 13.51it/s, loss=0.681, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.711, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  50%|█████     | 870/1731 [01:04<01:03, 13.51it/s, loss=2.37, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.732, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  52%|█████▏    | 900/1731 [01:06<01:01, 13.52it/s, loss=2.37, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.732, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  52%|█████▏    | 900/1731 [01:06<01:01, 13.52it/s, loss=0.95, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.730, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  54%|█████▎    | 930/1731 [01:08<00:59, 13.51it/s, loss=0.95, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.730, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  54%|█████▎    | 930/1731 [01:08<00:59, 13.51it/s, loss=0.875, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  55%|█████▌    | 960/1731 [01:10<00:57, 13.52it/s, loss=0.875, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  55%|█████▌    | 960/1731 [01:10<00:57, 13.52it/s, loss=2, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.625, val_f1_step=0.803, val_loss_step=0.129]    #015Epoch 1:  57%|█████▋    | 990/1731 [01:13<00:54, 13.50it/s, loss=2, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.625, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  57%|█████▋    | 990/1731 [01:13<00:54, 13.50it/s, loss=0.641, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.730, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  59%|█████▉    | 1020/1731 [01:15<00:52, 13.51it/s, loss=0.641, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.730, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  59%|█████▉    | 1020/1731 [01:15<00:52, 13.51it/s, loss=1.75, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.679, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  61%|██████    | 1050/1731 [01:17<00:50, 13.51it/s, loss=1.75, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.679, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  61%|██████    | 1050/1731 [01:17<00:50, 13.51it/s, loss=1.67, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.682, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  62%|██████▏   | 1080/1731 [01:19<00:48, 13.51it/s, loss=1.67, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.682, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  62%|██████▏   | 1080/1731 [01:19<00:48, 13.51it/s, loss=1.02, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.750, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  64%|██████▍   | 1110/1731 [01:22<00:45, 13.52it/s, loss=1.02, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.750, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  64%|██████▍   | 1110/1731 [01:22<00:45, 13.52it/s, loss=1.35, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.707, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.52it/s, loss=1.35, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.707, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.52it/s, loss=0.855, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.686, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  68%|██████▊   | 1170/1731 [01:26<00:41, 13.52it/s, loss=0.855, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.686, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  68%|██████▊   | 1170/1731 [01:26<00:41, 13.52it/s, loss=0.76, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.725, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  69%|██████▉   | 1200/1731 [01:28<00:39, 13.52it/s, loss=0.76, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.725, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  69%|██████▉   | 1200/1731 [01:28<00:39, 13.52it/s, loss=1.27, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.582, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  71%|███████   | 1230/1731 [01:30<00:37, 13.52it/s, loss=1.27, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.582, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  71%|███████   | 1230/1731 [01:30<00:37, 13.52it/s, loss=1.29, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.701, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  73%|███████▎  | 1260/1731 [01:33<00:34, 13.53it/s, loss=1.29, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.701, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  73%|███████▎  | 1260/1731 [01:33<00:34, 13.53it/s, loss=1.57, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.673, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.52it/s, loss=1.57, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.673, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.52it/s\u001b[0m\n",
      "\u001b[34m, loss=1.21, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.748, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  76%|███████▋  | 1320/1731 [01:37<00:30, 13.50it/s, loss=1.21, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.748, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  76%|███████▋  | 1320/1731 [01:37<00:30, 13.50it/s, loss=0.869, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.706, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.49it/s, loss=0.869, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.706, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.49it/s, loss=0.704, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.48it/s, loss=0.704, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.48it/s, loss=0.619, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.49it/s, loss=0.619, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.710, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.49it/s, loss=1.64, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  83%|████████▎ | 1440/1731 [01:46<00:21, 13.49it/s, loss=1.64, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.650, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  83%|████████▎ | 1440/1731 [01:46<00:21, 13.49it/s, loss=1.06, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.48it/s, loss=1.06, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.639, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.48it/s, loss=0.695, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.681, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.49it/s, loss=0.695, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.681, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.49it/s, loss=1.17, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.803, val_loss_step=0.129] #015Epoch 1:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.49it/s, loss=1.17, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.694, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.49it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]#015Epoch 1:  90%|█████████ | 1560/1731 [01:54<00:12, 13.67it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/193 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  16%|█▌        | 30/193 [00:01<00:06, 23.74it/s]#033[A#015Epoch 1:  92%|█████████▏| 1590/1731 [01:55<00:10, 13.78it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating:  31%|███       | 60/193 [00:02<00:05, 24.89it/s]#033[A#015Epoch 1:  94%|█████████▎| 1620/1731 [01:56<00:07, 13.92it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating:  47%|████▋     | 90/193 [00:03<00:04, 25.71it/s]#033[A#015Epoch 1:  95%|█████████▌| 1650/1731 [01:57<00:05, 14.04it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating:  62%|██████▏   | 120/193 [00:04<00:02, 26.37it/s]#033[A#015Epoch 1:  97%|█████████▋| 1680/1731 [01:58<00:03, 14.17it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating:  78%|███████▊  | 150/193 [00:05<00:01, 26.89it/s]#033[A#015Epoch 1:  99%|█████████▉| 1710/1731 [01:59<00:01, 14.29it/s, loss=0.872, v_num=0, val_f1_epoch=0.672, val_loss_epoch=0.186, train_f1=0.743, val_f1_step=0.803, val_loss_step=0.129]\u001b[0m\n",
      "\u001b[34m#015Validating:  93%|█████████▎| 180/193 [00:06<00:00, 27.15it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 193/193 [00:07<00:00, 27.76it/s]#033[A#015Epoch 1: 100%|██████████| 1731/1731 [02:01<00:00, 14.28it/s, loss=0.904, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.940, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.904, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.940, val_f1_step=0.863, val_loss_step=0.105]           #015Epoch 2:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.904, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.940, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   2%|▏         | 30/1731 [00:02<02:19, 12.18it/s, loss=0.904, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.940, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   2%|▏         | 30/1731 [00:02<02:19, 12.18it/s, loss=0.694, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.729, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   3%|▎         | 60/1731 [00:04<02:08, 12.97it/s, loss=0.694, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.729, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   3%|▎         | 60/1731 [00:04<02:08, 12.97it/s, loss=0.841, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.732, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   5%|▌         | 90/1731 [00:06<02:05, 13.10it/s, loss=0.841, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.732, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   5%|▌         | 90/1731 [00:06<02:05, 13.09it/s, loss=0.754, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.671, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   7%|▋         | 120/1731 [00:09<02:01, 13.30it/s, loss=0.754, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.671, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   7%|▋         | 120/1731 [00:09<02:01, 13.30it/s, loss=0.732, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.728, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   9%|▊         | 150/1731 [00:11<01:58, 13.33it/s, loss=0.732, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.728, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:   9%|▊         | 150/1731 [00:11<01:58, 13.33it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.771, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  10%|█         | 180/1731 [00:13<01:56, 13.33it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.771, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  10%|█         | 180/1731 [00:13<01:56, 13.33it/s, loss=0.725, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.675, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  10%|█         | 180/1731 [00:24<03:27,  7.47it/s, loss=0.725, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.675, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  12%|█▏        | 210/1731 [00:36<04:20,  5.83it/s, loss=0.725, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.675, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  12%|█▏        | 210/1731 [00:36<04:20,  5.83it/s, loss=1.35, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.752, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  14%|█▍        | 240/1731 [00:38<03:58,  6.26it/s, loss=1.35, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.752, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  14%|█▍        | 240/1731 [00:38<03:58,  6.26it/s, loss=0.697, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.685, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  16%|█▌        | 270/1731 [00:40<03:39,  6.66it/s, loss=0.697, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.685, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  16%|█▌        | 270/1731 [00:40<03:39,  6.66it/s, loss=0.73, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.678, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  17%|█▋        | 300/1731 [00:42<03:23,  7.01it/s, loss=0.73, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.678, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  17%|█▋        | 300/1731 [00:42<03:24,  7.01it/s, loss=0.756, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.730, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  19%|█▉        | 330/1731 [00:44<03:11,  7.33it/s, loss=0.756, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.730, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  19%|█▉        | 330/1731 [00:44<03:11,  7.33it/s, loss=0.579, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.646, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  21%|██        | 360/1731 [00:47<02:59,  7.63it/s, loss=0.579, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.646, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  21%|██        | 360/1731 [00:47<02:59,  7.63it/s, loss=0.852, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.721, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  23%|██▎       | 390/1731 [00:49<02:49,  7.89it/s, loss=0.852, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.721, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  23%|██▎       | 390/1731 [00:49<02:49,  7.89it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.725, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  24%|██▍       | 420/1731 [00:51<02:41,  8.14it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.725, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  24%|██▍       | 420/1731 [00:51<02:41,  8.14it/s, loss=1.21, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.706, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  26%|██▌       | 450/1731 [00:53<02:33,  8.36it/s, loss=1.21, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.706, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  26%|██▌       | 450/1731 [00:53<02:33,  8.36it/s, loss=1.69, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.603, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  28%|██▊       | 480/1731 [00:56<02:26,  8.56it/s, loss=1.69, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.603, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  28%|██▊       | 480/1731 [00:56<02:26,  8.56it/s, loss=0.69, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.719, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  29%|██▉       | 510/1731 [00:58<02:19,  8.76it/s, loss=0.69, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.719, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  29%|██▉       | 510/1731 [00:58<02:19,  8.76it/s, loss=0.709, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.719, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  31%|███       | 540/1731 [01:00<02:13,  8.93it/s, loss=0.709, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.719, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  31%|███       | 540/1731 [01:00<02:13,  8.93it/s, loss=0.721, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.747, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  33%|███▎      | 570/1731 [01:02<02:07,  9.10it/s, loss=0.721, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.747, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  33%|███▎      | 570/1731 [01:02<02:07,  9.10it/s, loss=0.887, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.662, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  35%|███▍      | 600/1731 [01:04<02:02,  9.25it/s, loss=0.887, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.662, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  35%|███▍      | 600/1731 [01:04<02:02,  9.25it/s, loss=0.634, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.658, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  36%|███▋      | 630/1731 [01:07<01:57,  9.38it/s, loss=0.634, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.658, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  36%|███▋      | 630/1731 [01:07<01:57,  9.38it/s, loss=0.575, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.781, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  38%|███▊      | 660/1731 [01:09<01:52,  9.52it/s, loss=0.575, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.781, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  38%|███▊      | 660/1731 [01:09<01:52,  9.52it/s, loss=0.543, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.688, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  40%|███▉      | 690/1731 [01:11<01:47,  9.64it/s, loss=0.543, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.688, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  40%|███▉      | 690/1731 [01:11<01:47,  9.64it/s, loss=0.837, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.705, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  42%|████▏     | 720/1731 [01:13<01:43,  9.76it/s, loss=0.837, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.705, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  42%|████▏     | 720/1731 [01:13<01:43,  9.76it/s, loss=1.2, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.819, val_f1_step=0.863, val_loss_step=0.105]  #015Epoch 2:  43%|████▎     | 750/1731 [01:16<01:39,  9.87it/s, loss=1.2, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.819, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  43%|████▎     | 750/1731 [01:16<01:39,  9.87it/s, loss=1.64, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.763, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  45%|████▌     | 780/1731 [01:18<01:35,  9.96it/s, loss=1.64, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.763, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  45%|████▌     | 780/1731 [01:18<01:35,  9.96it/s, loss=0.619, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.738, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  47%|████▋     | 810/1731 [01:20<01:31, 10.07it/s, loss=0.619, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.738, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  47%|████▋     | 810/1731 [01:20<01:31, 10.07it/s, loss=1.86, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.739, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  49%|████▊     | 840/1731 [01:22<01:27, 10.16it/s, loss=1.86, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.739, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  49%|████▊     | 840/1731 [01:22<01:27, 10.16it/s, loss=0.798, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.715, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  50%|█████     | 870/1731 [01:24<01:23, 10.26it/s, loss=0.798, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.715, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  50%|█████     | 870/1731 [01:24<01:23, 10.26it/s, loss=1.26, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.669, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  52%|█████▏    | 900/1731 [01:27<01:20, 10.34it/s, loss=1.26, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.669, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  52%|█████▏    | 900/1731 [01:27<01:20, 10.34it/s, loss=1.4, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.699, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  54%|█████▎    | 930/1731 [01:29<01:16, 10.41it/s, loss=1.4, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.699, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  54%|█████▎    | 930/1731 [01:29<01:16, 10.41it/s, loss=0.887, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.715, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  55%|█████▌    | 960/1731 [01:31<01:13, 10.50it/s, loss=0.887, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.715, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  55%|█████▌    | 960/1731 [01:31<01:13, 10.50it/s, loss=0.909, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.673, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  57%|█████▋    | 990/1731 [01:33<01:10, 10.56it/s, loss=0.909, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.673, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  57%|█████▋    | 990/1731 [01:33<01:10, 10.56it/s, loss=1.14, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.720, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  59%|█████▉    | 1020/1731 [01:36<01:06, 10.62it/s, loss=1.14, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.720, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  59%|█████▉    | 1020/1731 [01:36<01:06, 10.62it/s, loss=0.67, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.745, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  61%|██████    | 1050/1731 [01:38<01:03, 10.68it/s, loss=0.67, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.745, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  61%|██████    | 1050/1731 [01:38<01:03, 10.68it/s, loss=0.741, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.737, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  62%|██████▏   | 1080/1731 [01:40<01:00, 10.74it/s, loss=0.741, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.737, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  62%|██████▏   | 1080/1731 [01:40<01:00, 10.74it/s, loss=1.29, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.723, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  64%|██████▍   | 1110/1731 [01:42<00:57, 10.80it/s, loss=1.29, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.723, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  64%|██████▍   | 1110/1731 [01:42<00:57, 10.80it/s, loss=0.71, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.762, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  66%|██████▌   | 1140/1731 [01:44<00:54, 10.86it/s, loss=0.71, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.762, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  66%|██████▌   | 1140/1731 [01:44<00:54, 10.86it/s, loss=1.4, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.819, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  68%|██████▊   | 1170/1731 [01:47<00:51, 10.92it/s, loss=1.4, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.819, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  68%|██████▊   | 1170/1731 [01:47<00:51, 10.92it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.672, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  69%|██████▉   | 1200/1731 [01:49<00:48, 10.97it/s, loss=1.12, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.672, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  69%|██████▉   | 1200/1731 [01:49<00:48, 10.97it/s, loss=1.19, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.670, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  71%|███████   | 1230/1731 [01:51<00:45, 11.02it/s, loss=1.19, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.670, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  71%|███████   | 1230/1731 [01:51<00:45, 11.02it/s, loss=1.03, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.743, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  73%|███████▎  | 1260/1731 [01:53<00:42, 11.07it/s, loss=1.03, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.743, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  73%|███████▎  | 1260/1731 [01:53<00:42, 11.07it/s, loss=1.14, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.805, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  75%|███████▍  | 1290/1731 [01:56<00:39, 11.12it/s, loss=1.14,\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.805, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  75%|███████▍  | 1290/1731 [01:56<00:39, 11.11it/s, loss=0.71, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.769, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  76%|███████▋  | 1320/1731 [01:58<00:36, 11.16it/s, loss=0.71, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.769, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  76%|███████▋  | 1320/1731 [01:58<00:36, 11.16it/s, loss=0.561, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.700, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  78%|███████▊  | 1350/1731 [02:00<00:34, 11.20it/s, loss=0.561, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.700, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  78%|███████▊  | 1350/1731 [02:00<00:34, 11.20it/s, loss=0.815, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.717, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  80%|███████▉  | 1380/1731 [02:02<00:31, 11.24it/s, loss=0.815, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.717, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  80%|███████▉  | 1380/1731 [02:02<00:31, 11.24it/s, loss=1.09, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.713, val_f1_step=0.863, val_loss_step=0.105] #015Epoch 2:  81%|████████▏ | 1410/1731 [02:04<00:28, 11.29it/s, loss=1.09, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.713, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  81%|████████▏ | 1410/1731 [02:04<00:28, 11.29it/s, loss=1.01, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.757, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  83%|████████▎ | 1440/1731 [02:07<00:25, 11.33it/s, loss=1.01, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.757, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  83%|████████▎ | 1440/1731 [02:07<00:25, 11.33it/s, loss=1.41, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.723, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  85%|████████▍ | 1470/1731 [02:09<00:22, 11.37it/s, loss=1.41, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.723, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  85%|████████▍ | 1470/1731 [02:09<00:22, 11.37it/s, loss=1.13, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.654, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  87%|████████▋ | 1500/1731 [02:11<00:20, 11.40it/s, loss=1.13, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.654, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  87%|████████▋ | 1500/1731 [02:11<00:20, 11.40it/s, loss=1.45, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.748, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  88%|████████▊ | 1530/1731 [02:13<00:17, 11.43it/s, loss=1.45, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.748, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  88%|████████▊ | 1530/1731 [02:13<00:17, 11.43it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]#015Epoch 2:  90%|█████████ | 1560/1731 [02:14<00:14, 11.60it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/193 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  16%|█▌        | 30/193 [00:01<00:06, 23.39it/s]#033[A#015Epoch 2:  92%|█████████▏| 1590/1731 [02:15<00:12, 11.71it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating:  31%|███       | 60/193 [00:02<00:05, 24.60it/s]#033[A#015Epoch 2:  94%|█████████▎| 1620/1731 [02:16<00:09, 11.84it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating:  47%|████▋     | 90/193 [00:03<00:04, 25.49it/s]#033[A#015Epoch 2:  95%|█████████▌| 1650/1731 [02:17<00:06, 11.96it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating:  62%|██████▏   | 120/193 [00:04<00:02, 26.19it/s]#033[A#015Epoch 2:  97%|█████████▋| 1680/1731 [02:19<00:04, 12.08it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating:  78%|███████▊  | 150/193 [00:05<00:01, 26.71it/s]#033[A#015Epoch 2:  99%|█████████▉| 1710/1731 [02:20<00:01, 12.21it/s, loss=0.608, v_num=0, val_f1_epoch=0.727, val_loss_epoch=0.165, train_f1=0.770, val_f1_step=0.863, val_loss_step=0.105]\u001b[0m\n",
      "\u001b[34m#015Validating:  93%|█████████▎| 180/193 [00:06<00:00, 26.99it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 193/193 [00:07<00:00, 27.63it/s]#033[A#015Epoch 2: 100%|██████████| 1731/1731 [02:21<00:00, 12.22it/s, loss=0.611, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.940, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 2:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.611, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.940, val_f1_step=0.892, val_loss_step=0.0966]           #015Epoch 3:   0%|          | 0/1731 [00:00<?, ?it/s, loss=0.611, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.940, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   2%|▏         | 30/1731 [00:02<02:16, 12.47it/s, loss=0.611, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.940, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   2%|▏         | 30/1731 [00:02<02:16, 12.46it/s, loss=1.03, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.780, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:   3%|▎         | 60/1731 [00:04<02:08, 12.97it/s, loss=1.03, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.780, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   3%|▎         | 60/1731 [00:04<02:08, 12.97it/s, loss=0.559, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.732, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   5%|▌         | 90/1731 [00:06<02:05, 13.08it/s, loss=0.559, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.732, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   5%|▌         | 90/1731 [00:06<02:05, 13.08it/s, loss=0.987, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.788, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   7%|▋         | 120/1731 [00:09<02:01, 13.25it/s, loss=0.987, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.788, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   7%|▋         | 120/1731 [00:09<02:01, 13.25it/s, loss=0.752, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.724, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   9%|▊         | 150/1731 [00:11<01:59, 13.24it/s, loss=0.752, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.724, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:   9%|▊         | 150/1731 [00:11<01:59, 13.23it/s, loss=0.651, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.805, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  10%|█         | 180/1731 [00:13<01:57, 13.25it/s, loss=0.651, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.805, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  10%|█         | 180/1731 [00:13<01:57, 13.25it/s, loss=1.56, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.728, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  12%|█▏        | 210/1731 [00:15<01:55, 13.21it/s, loss=1.56, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.728, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  12%|█▏        | 210/1731 [00:15<01:55, 13.21it/s, loss=0.702, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.702, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  14%|█▍        | 240/1731 [00:18<01:52, 13.21it/s, loss=0.702, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.702, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  14%|█▍        | 240/1731 [00:18<01:52, 13.21it/s, loss=0.803, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=0.803, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=1.71, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.737, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  17%|█▋        | 300/1731 [00:22<01:48, 13.24it/s, loss=1.71, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.737, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  17%|█▋        | 300/1731 [00:22<01:48, 13.24it/s, loss=0.663, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.623, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=0.663, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.623, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=1.12, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.742, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  21%|██        | 360/1731 [00:27<01:42, 13.31it/s, loss=1.12, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.742, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  21%|██        | 360/1731 [00:27<01:42, 13.31it/s, loss=0.621, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.774, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  23%|██▎       | 390/1731 [00:29<01:40, 13.32it/s, loss=0.621, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.774, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  23%|██▎       | 390/1731 [00:29<01:40, 13.32it/s, loss=0.582, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.763, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  24%|██▍       | 420/1731 [00:31<01:38, 13.36it/s, loss=0.582, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.763, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  24%|██▍       | 420/1731 [00:31<01:38, 13.36it/s, loss=1.07, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.857, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  26%|██▌       | 450/1731 [00:33<01:35, 13.36it/s, loss=1.07, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.857, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  26%|██▌       | 450/1731 [00:33<01:35, 13.36it/s, loss=0.759, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.716, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  28%|██▊       | 480/1731 [00:35<01:33, 13.39it/s, loss=0.759, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.716, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  28%|██▊       | 480/1731 [00:35<01:33, 13.39it/s, loss=0.963, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.686, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  29%|██▉       | 510/1731 [00:38<01:31, 13.39it/s, loss=0.963, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.686, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  29%|██▉       | 510/1731 [00:38<01:31, 13.39it/s, loss=0.524, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.756, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  31%|███       | 540/1731 [00:40<01:28, 13.39it/s, loss=0.524, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.756, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  31%|███       | 540/1731 [00:40<01:28, 13.39it/s, loss=0.538, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.759, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  33%|███▎      | 570/1731 [00:42<01:26, 13.41it/s, loss=0.538, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.759, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  33%|███▎      | 570/1731 [00:42<01:26, 13.41it/s, loss=0.586, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.715, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  35%|███▍      | 600/1731 [00:44<01:24, 13.40it/s, loss=0.586, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.715, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  35%|███▍      | 600/1731 [00:44<01:24, 13.40it/s, loss=0.626, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.727, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  36%|███▋      | 630/1731 [00:46<01:22, 13.42it/s, loss=0.626, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.727, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  36%|███▋      | 630/1731 [00:46<01:22, 13.42it/s, loss=0.766, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.787, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  38%|███▊      | 660/1731 [00:49<01:19, 13.42it/s, loss=0.766, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.787, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  38%|███▊      | 660/1731 [00:49<01:19, 13.42it/s, loss=1.1, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.736, val_f1_step=0.892, val_loss_step=0.0966]  #015Epoch 3:  40%|███▉      | 690/1731 [00:51<01:17, 13.42it/s, loss=1.1, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.736, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  40%|███▉      | 690/1731 [00:51<01:17, 13.42it/s, loss=0.829, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.694, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  42%|████▏     | 720/1731 [00:53<01:15, 13.44it/s, loss=0.829, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.694, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  42%|████▏     | 720/1731 [00:53<01:15, 13.44it/s, loss=0.721, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.737, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  43%|████▎     | 750/1731 [00:55<01:13, 13.44it/s, loss=0.721, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.737, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  43%|████▎     | 750/1731 [00:55<01:13, 13.44it/s, loss=1.04, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.790, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  45%|████▌     | 780/1731 [00:57<01:10, 13.46it/s, loss=1.04, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.790, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  45%|████▌     | 780/1731 [00:57<01:10, 13.46it/s, loss=1.18, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.778, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  47%|████▋     | 810/1731 [01:00<01:08, 13.45it/s, loss=1.18, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.778, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  47%|████▋     | 810/1731 [01:00<01:08, 13.45it/s, loss=0.733, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.750, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  49%|████▊     | 840/1731 [01:02<01:06, 13.45it/s, loss=0.733, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.750, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  49%|████▊     | 840/1731 [01:02<01:06, 13.45it/s, loss=0.951, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.716, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  50%|█████     | 870/1731 [01:04<01:03, 13.46it/s, loss=0.951, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.716, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  50%|█████     | 870/1731 [01:04<01:03, 13.46it/s, loss=0.583, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.747, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  52%|█████▏    | 900/1731 [01:06<01:01, 13.46it/s, loss=0.583, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.747, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  52%|█████▏    | 900/1731 [01:06<01:01, 13.46it/s, loss=0.65, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  54%|█████▎    | 930/1731 [01:09<00:59, 13.48it/s, loss=0.65, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  54%|█████▎    | 930/1731 [01:09<00:59, 13.48it/s, loss=0.633, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.710, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  55%|█████▌    | 960/1731 [01:11<00:57, 13.47it/s, loss=0.633, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.710, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  55%|█████▌    | 960/1731 [01:11<00:57, 13.47it/s, loss=0.537, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.766, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  57%|█████▋    | 990/1731 [01:13<00:55, 13.44it/s, loss=0.537, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.766, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  57%|█████▋    | 990/1731 [01:13<00:55, 13.44it/s, loss=0.551, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.762, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  59%|█████▉    | 1020/1731 [01:15<00:52, 13.45it/s, loss=0.551, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.762, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  59%|█████▉    | 1020/1731 [01:15<00:52, 13.45it/s, loss=0.686, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.743, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  61%|██████    | 1050/1731 [01:18<00:50, 13.44it/s, loss=0.686, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.743, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  61%|██████    | 1050/1731 [01:18<00:50, 13.44it/s, loss=0.875, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.707, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.45it/s, loss=0.875, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.707, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.45it/s, loss=0.94, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.760, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.44it/s, loss=0.94, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.760, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.44it/s, loss=0.663, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.770, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.44it/s, loss=0.663, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.770, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.44it/s, loss=1.93, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.718, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.45it/s, loss=1.93, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.718, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.45it/s, loss=0.805, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.45it/s, loss=0.805, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.746, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.45it/s, loss=0.657, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.740, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  71%|███████   | 1230/1731 [01:31<00:37, 13.45it/s, loss=0.657, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.740, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  71%|███████   | 1230/1731 [01:31<00:37, 13.45it/s, loss=0.736, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.787, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.45it/s, loss=0.736, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.787, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.44it/s, loss=0.627, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.725, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.44it/s, loss=0.627, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.725, val_\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mf1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.44it/s, loss=1.04, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.764, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.45it/s, loss=1.04, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.764, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.45it/s, loss=1.11, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.736, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.45it/s, loss=1.11, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.736, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.45it/s, loss=1.53, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.740, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.46it/s, loss=1.53, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.740, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.46it/s, loss=0.827, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.711, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.45it/s, loss=0.827, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.711, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.45it/s, loss=0.666, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.801, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.45it/s, loss=0.666, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.801, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.45it/s, loss=0.953, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.725, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.46it/s, loss=0.953, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.725, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.46it/s, loss=1.63, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.739, val_f1_step=0.892, val_loss_step=0.0966] #015Epoch 3:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.45it/s, loss=1.63, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.739, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.45it/s, loss=0.51, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.733, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.45it/s, loss=0.51, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.733, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.45it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]#015Epoch 3:  90%|█████████ | 1560/1731 [01:54<00:12, 13.63it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/193 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  16%|█▌        | 30/193 [00:01<00:06, 23.30it/s]#033[A#015Epoch 3:  92%|█████████▏| 1590/1731 [01:55<00:10, 13.74it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating:  31%|███       | 60/193 [00:02<00:05, 24.46it/s]#033[A#015Epoch 3:  94%|█████████▎| 1620/1731 [01:56<00:08, 13.87it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating:  47%|████▋     | 90/193 [00:03<00:04, 25.35it/s]#033[A#015Epoch 3:  95%|█████████▌| 1650/1731 [01:57<00:05, 13.99it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating:  62%|██████▏   | 120/193 [00:04<00:02, 26.06it/s]#033[A#015Epoch 3:  97%|█████████▋| 1680/1731 [01:58<00:03, 14.12it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating:  78%|███████▊  | 150/193 [00:05<00:01, 26.58it/s]#033[A#015Epoch 3:  99%|█████████▉| 1710/1731 [02:00<00:01, 14.24it/s, loss=0.613, v_num=0, val_f1_epoch=0.734, val_loss_epoch=0.160, train_f1=0.761, val_f1_step=0.892, val_loss_step=0.0966]\u001b[0m\n",
      "\u001b[34m#015Validating:  93%|█████████▎| 180/193 [00:06<00:00, 26.87it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 193/193 [00:07<00:00, 27.50it/s]#033[A#015Epoch 3: 100%|██████████| 1731/1731 [02:01<00:00, 14.23it/s, loss=1.07, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.880, val_f1_step=0.871, val_loss_step=0.0923] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 3:   0%|          | 0/1731 [00:00<?, ?it/s, loss=1.07, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.880, val_f1_step=0.871, val_loss_step=0.0923]           #015Epoch 4:   0%|          | 0/1731 [00:00<?, ?it/s, loss=1.07, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.880, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   2%|▏         | 30/1731 [00:02<02:15, 12.56it/s, loss=1.07, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.880, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   2%|▏         | 30/1731 [00:02<02:15, 12.56it/s, loss=0.538, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   3%|▎         | 60/1731 [00:04<02:10, 12.85it/s, loss=0.538, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   3%|▎         | 60/1731 [00:04<02:10, 12.85it/s, loss=0.596, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.732, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   5%|▌         | 90/1731 [00:06<02:06, 13.01it/s, loss=0.596, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.732, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   5%|▌         | 90/1731 [00:06<02:06, 13.01it/s, loss=0.657, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.696, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   7%|▋         | 120/1731 [00:09<02:03, 13.05it/s, loss=0.657, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.696, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   7%|▋         | 120/1731 [00:09<02:03, 13.05it/s, loss=0.513, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.786, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   9%|▊         | 150/1731 [00:11<02:02, 12.96it/s, loss=0.513, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.786, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:   9%|▊         | 150/1731 [00:11<02:02, 12.96it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.708, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  10%|█         | 180/1731 [00:13<01:58, 13.10it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.708, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  10%|█         | 180/1731 [00:13<01:58, 13.10it/s, loss=0.722, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.772, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  12%|█▏        | 210/1731 [00:16<01:55, 13.12it/s, loss=0.722, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.772, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  12%|█▏        | 210/1731 [00:16<01:55, 13.12it/s, loss=0.713, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.758, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  14%|█▍        | 240/1731 [00:18<01:52, 13.22it/s, loss=0.713, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.758, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  14%|█▍        | 240/1731 [00:18<01:52, 13.22it/s, loss=0.603, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.757, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=0.603, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.757, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  16%|█▌        | 270/1731 [00:20<01:50, 13.24it/s, loss=0.67, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  17%|█▋        | 300/1731 [00:22<01:47, 13.25it/s, loss=0.67, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  17%|█▋        | 300/1731 [00:22<01:47, 13.25it/s, loss=1.61, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=1.61, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  19%|█▉        | 330/1731 [00:24<01:45, 13.30it/s, loss=0.889, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.675, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  21%|██        | 360/1731 [00:27<01:43, 13.31it/s, loss=0.889, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.675, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  21%|██        | 360/1731 [00:27<01:43, 13.31it/s, loss=0.538, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.664, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  23%|██▎       | 390/1731 [00:29<01:40, 13.35it/s, loss=0.538, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.664, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  23%|██▎       | 390/1731 [00:29<01:40, 13.35it/s, loss=0.992, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.731, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  24%|██▍       | 420/1731 [00:31<01:38, 13.34it/s, loss=0.992, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.731, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  24%|██▍       | 420/1731 [00:31<01:38, 13.34it/s, loss=0.628, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.800, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  26%|██▌       | 450/1731 [00:33<01:35, 13.35it/s, loss=0.628, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.800, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  26%|██▌       | 450/1731 [00:33<01:35, 13.35it/s, loss=0.781, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.732, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  28%|██▊       | 480/1731 [00:35<01:33, 13.38it/s, loss=0.781, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.732, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  28%|██▊       | 480/1731 [00:35<01:33, 13.38it/s, loss=1.01, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.767, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  29%|██▉       | 510/1731 [00:38<01:31, 13.38it/s, loss=1.01, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.767, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  29%|██▉       | 510/1731 [00:38<01:31, 13.38it/s, loss=0.656, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.772, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  31%|███       | 540/1731 [00:40<01:28, 13.40it/s, loss=0.656, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.772, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  31%|███       | 540/1731 [00:40<01:28, 13.40it/s, loss=0.448, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  33%|███▎      | 570/1731 [00:42<01:26, 13.40it/s, loss=0.448, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.788, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  33%|███▎      | 570/1731 [00:42<01:26, 13.40it/s, loss=0.93, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.730, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  35%|███▍      | 600/1731 [00:44<01:24, 13.39it/s, loss=0.93, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.730, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  35%|███▍      | 600/1731 [00:44<01:24, 13.39it/s, loss=0.914, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.753, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  36%|███▋      | 630/1731 [00:46<01:22, 13.42it/s, loss=0.914, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.753, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  36%|███▋      | 630/1731 [00:46<01:22, 13.42it/s, loss=0.508, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.754, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  38%|███▊      | 660/1731 [00:49<01:19, 13.42it/s, loss=0.508, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.754, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  38%|███▊      | 660/1731 [00:49<01:19, 13.42it/s, loss=0.681, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.742, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  40%|███▉      | 690/1731 [00:51<01:17, 13.43it/s, loss=0.681, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.742, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  40%|███▉      | 690/1731 [00:51<01:17, 13.43it/s, loss=0.592, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.791, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  42%|████▏     | 720/1731 [00:53<01:15, 13.42it/s, loss=0.592, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.791, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  42%|████▏     | 720/1731 [00:53<01:15, 13.42it/s, loss=0.634, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.722, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  43%|████▎     | 750/1731 [00:55<01:13, 13.42it/s, loss=0.634, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.722, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  43%|████▎     | 750/1731 [00:55<01:13, 13.42it/s, loss=1.85, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.775, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  45%|████▌     | 780/1731 [00:58<01:10, 13.43it/s, loss=1.85, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.775, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  45%|████▌     | 780/1731 [00:58<01:10, 13.43it/s, loss=0.478, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.777, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  47%|████▋     | 810/1731 [01:00<01:08, 13.43it/s, loss=0.478, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.777, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  47%|████▋     | 810/1731 [01:00<01:08, 13.43it/s, loss=0.539, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.620, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  49%|████▊     | 840/1731 [01:02<01:06, 13.45it/s, loss=0.539, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.620, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  49%|████▊     | 840/1731 [01:02<01:06, 13.45it/s, loss=1.54, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  50%|█████     | 870/1731 [01:04<01:04, 13.44it/s, loss=1.54, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  50%|█████     | 870/1731 [01:04<01:04, 13.44it/s, loss=0.98, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.747, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  52%|█████▏    | 900/1731 [01:07<01:01, 13.43it/s, loss=0.98, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.747, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  52%|█████▏    | 900/1731 [01:07<01:01, 13.43it/s, loss=0.726, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.748, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  54%|█████▎    | 930/1731 [01:09<00:59, 13.44it/s, loss=0.726, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.748, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  54%|█████▎    | 930/1731 [01:09<00:59, 13.44it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.752, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  55%|█████▌    | 960/1731 [01:11<00:57, 13.41it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.752, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  55%|█████▌    | 960/1731 [01:11<00:57, 13.41it/s, loss=0.518, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.742, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  57%|█████▋    | 990/1731 [01:13<00:55, 13.42it/s, loss=0.518, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.742, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  57%|█████▋    | 990/1731 [01:13<00:55, 13.42it/s, loss=0.978, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.748, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  59%|█████▉    | 1020/1731 [01:16<00:52, 13.42it/s, loss=0.978, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.748, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  59%|█████▉    | 1020/1731 [01:16<00:52, 13.42it/s, loss=0.705, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.718, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  61%|██████    | 1050/1731 [01:18<00:50, 13.42it/s, loss=0.705, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.718, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  61%|██████    | 1050/1731 [01:18<00:50, 13.42it/s, loss=0.601, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.802, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.43it/s, loss=0.601, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.802, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  62%|██████▏   | 1080/1731 [01:20<00:48, 13.43it/s, loss=0.521, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.712, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.43it/s, loss=0.521, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.712, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  64%|██████▍   | 1110/1731 [01:22<00:46, 13.43it/s, loss=0.51, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.754, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.44it/s, loss=0.51, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.754, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  66%|██████▌   | 1140/1731 [01:24<00:43, 13.44it/s, loss=1.36, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.710, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.44it/s, loss=1.36, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.710, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  68%|██████▊   | 1170/1731 [01:27<00:41, 13.44it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.720, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.44it/s, loss=1.16, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.720, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  69%|██████▉   | 1200/1731 [01:29<00:39, 13.44it/s, loss=0.571, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.736, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  71%|███████   | 1230/1731 [01:31<00:37, 13.44it/s, loss=0.571, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.736, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  71%|███████   | 1230/1731 [01:31<00:37, 13.44it/s, loss=1.06, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.702, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.44it/s, loss=1.06, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.702, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  73%|███████▎  | 1260/1731 [01:33<00:35, 13.44it/s, loss=0.801, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.673, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.45it/s, loss=0.801, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.673, val_f1_step\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m=0.871, val_loss_step=0.0923]#015Epoch 4:  75%|███████▍  | 1290/1731 [01:35<00:32, 13.45it/s, loss=0.494, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.45it/s, loss=0.494, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  76%|███████▋  | 1320/1731 [01:38<00:30, 13.45it/s, loss=0.532, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.786, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.44it/s, loss=0.532, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.786, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  78%|███████▊  | 1350/1731 [01:40<00:28, 13.44it/s, loss=0.494, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.697, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.45it/s, loss=0.494, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.697, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  80%|███████▉  | 1380/1731 [01:42<00:26, 13.45it/s, loss=0.658, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.818, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.45it/s, loss=0.658, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.818, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  81%|████████▏ | 1410/1731 [01:44<00:23, 13.45it/s, loss=1.31, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.679, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.46it/s, loss=1.31, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.679, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  83%|████████▎ | 1440/1731 [01:47<00:21, 13.46it/s, loss=0.526, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.777, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.45it/s, loss=0.526, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.777, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  85%|████████▍ | 1470/1731 [01:49<00:19, 13.45it/s, loss=0.983, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.45it/s, loss=0.983, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.785, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  87%|████████▋ | 1500/1731 [01:51<00:17, 13.45it/s, loss=1.33, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.765, val_f1_step=0.871, val_loss_step=0.0923] #015Epoch 4:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.45it/s, loss=1.33, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.765, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  88%|████████▊ | 1530/1731 [01:53<00:14, 13.45it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]#015Epoch 4:  90%|█████████ | 1560/1731 [01:54<00:12, 13.64it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/193 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  16%|█▌        | 30/193 [00:01<00:07, 22.90it/s]#033[A#015Epoch 4:  92%|█████████▏| 1590/1731 [01:55<00:10, 13.74it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating:  31%|███       | 60/193 [00:02<00:05, 24.17it/s]#033[A#015Epoch 4:  94%|█████████▎| 1620/1731 [01:56<00:08, 13.87it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating:  47%|████▋     | 90/193 [00:03<00:04, 25.22it/s]#033[A#015Epoch 4:  95%|█████████▌| 1650/1731 [01:57<00:05, 14.00it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating:  62%|██████▏   | 120/193 [00:04<00:02, 25.99it/s]#033[A#015Epoch 4:  97%|█████████▋| 1680/1731 [01:58<00:03, 14.13it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating:  78%|███████▊  | 150/193 [00:05<00:01, 26.45it/s]#033[A#015Epoch 4:  99%|█████████▉| 1710/1731 [01:59<00:01, 14.25it/s, loss=1.02, v_num=0, val_f1_epoch=0.744, val_loss_epoch=0.156, train_f1=0.735, val_f1_step=0.871, val_loss_step=0.0923]\u001b[0m\n",
      "\u001b[34m#015Validating:  93%|█████████▎| 180/193 [00:06<00:00, 26.83it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 193/193 [00:07<00:00, 27.48it/s]#033[A#015Epoch 4: 100%|██████████| 1731/1731 [02:01<00:00, 14.24it/s, loss=1.29, v_num=0, val_f1_epoch=0.751, val_loss_epoch=0.154, train_f1=1.000, val_f1_step=0.891, val_loss_step=0.0886]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 4: 100%|██████████| 1731/1731 [02:02<00:00, 14.09it/s, loss=1.29, v_num=0, val_f1_epoch=0.751, val_loss_epoch=0.154, train_f1=1.000, val_f1_step=0.891, val_loss_step=0.0886]\u001b[0m\n",
      "\u001b[34m(11168, 20)\u001b[0m\n",
      "\u001b[34m(11168, 20)\u001b[0m\n",
      "\u001b[34m2021-08-02 12:04:33.310979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34mINFO:root:reading, preprocessing data\u001b[0m\n",
      "\u001b[34m2021/08/02 12:04:37 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896777042856 acquired on /root/.cache/huggingface/transformers/31d6577412393ebb07c02de876b2d1397fcae2d85cb053b588145f6869ab1a15.44cd178af39e607af310bc4cc48a944f5e5f746b372c161b32511f0fd585789b.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/526 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 526/526 [00:00<00:00, 532kB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896777042856 released on /root/.cache/huggingface/transformers/31d6577412393ebb07c02de876b2d1397fcae2d85cb053b588145f6869ab1a15.44cd178af39e607af310bc4cc48a944f5e5f746b372c161b32511f0fd585789b.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896812424048 acquired on /root/.cache/huggingface/transformers/a9c548057d82391e2bd98d883850cb32ebea77d731e8aef568b3a62626fcb8b3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 39.1MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896812424048 released on /root/.cache/huggingface/transformers/a9c548057d82391e2bd98d883850cb32ebea77d731e8aef568b3a62626fcb8b3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896797665488 acquired on /root/.cache/huggingface/transformers/b374e0476158ea0103ff70e6aba1af0f3eb008f2b864df9cefd392d127704aea.e8dbc1ac6bd489742b5b870482beb10cbda5561261f41884487a4f8424b346dd.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]#015Downloading:   5%|▍         | 4.24M/90.9M [00:00<00:02, 42.4MB/s]#015Downloading:  10%|▉         | 8.84M/90.9M [00:00<00:01, 43.4MB/s]#015Downloading:  15%|█▍        | 13.6M/90.9M [00:00<00:01, 44.6MB/s]#015Downloading:  19%|█▉        | 17.5M/90.9M [00:00<00:01, 42.7MB/s]#015Downloading:  24%|██▍       | 22.2M/90.9M [00:00<00:01, 43.8MB/s]#015Downloading:  30%|██▉       | 27.1M/90.9M [00:00<00:01, 45.5MB/s]#015Downloading:  35%|███▌      | 32.2M/90.9M [00:00<00:01, 46.8MB/s]#015Downloading:  41%|████      | 37.3M/90.9M [00:00<00:01, 48.0MB/s]#015Downloading:  47%|████▋     | 42.4M/90.9M [00:00<00:00, 49.0MB/s]#015Downloading:  52%|█████▏    | 47.6M/90.9M [00:01<00:00, 49.7MB/s]#015Downloading:  58%|█████▊    | 52.6M/90.9M [00:01<00:00, 49.8MB/s]#015Downloading:  63%|██████▎   | 57.7M/90.9M [00:01<00:00, 50.3MB/s]#015Downloading:  69%|██████▉   | 62.9M/90.9M [00:01<00:00, 50.7MB/s]#015Downloading:  75%|███████▍  | 68.1M/90.9M [00:01<00:00, 51.1MB/s]#015Downloading:  81%|████████  | 73.3M/90.9M [00:01<00:00, 51.4MB/s]#015Downloading:  86%|████████▋ | 78.5M/90.9M [00:01<00:00, 51.7MB/s]#015Downloading:  92%|█████████▏| 83.8M/90.9M [00:01<00:00, 51.9MB/s]#015Downloading:  98%|█████████▊| 89.1M/90.9M [00:01<00:00, 52.2MB/s]#015Downloading: 100%|██████████| 90.9M/90.9M [00:01<00:00, 49.5MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139896797665488 released on /root/.cache/huggingface/transformers/b374e0476158ea0103ff70e6aba1af0f3eb008f2b864df9cefd392d127704aea.e8dbc1ac6bd489742b5b870482beb10cbda5561261f41884487a4f8424b346dd.lock\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[34mEpoch 0, global step 1537: val_f1 reached 0.67188 (best 0.67188), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l6-h384-uncased/model_subpillars.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 1, global step 3075: val_f1 reached 0.72719 (best 0.72719), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l6-h384-uncased/model_subpillars.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 2, global step 4613: val_f1 reached 0.73356 (best 0.73356), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l6-h384-uncased/model_subpillars.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 3, global step 6151: val_f1 reached 0.74354 (best 0.74354), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l6-h384-uncased/model_subpillars.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 4, global step 7689: val_f1 reached 0.75131 (best 0.75131), saving model to \"/opt/ml/model/checkpoints-subpillars-microsoft-xtremedistil-l6-h384-uncased/model_subpillars.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mFIT Profiler Report\n",
      "\u001b[0m\n",
      "\u001b[34mAction                             #011|  Mean duration (s)#011|Num calls      #011|  Total time (s) #011|  Percentage %   #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mTotal                              #011|  -              #011|_              #011|  739.78         #011|  100 %          #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mrun_training_epoch                 #011|  126.76         #011|5              #011|  633.81         #011|  85.675         #011|\u001b[0m\n",
      "\u001b[34mrun_training_batch                 #011|  0.071254       #011|7690           #011|  547.95         #011|  74.069         #011|\u001b[0m\n",
      "\u001b[34moptimizer_step_and_closure_0       #011|  0.070825       #011|7690           #011|  544.64         #011|  73.622         #011|\u001b[0m\n",
      "\u001b[34mtraining_step_and_backward         #011|  0.060996       #011|7690           #011|  469.06         #011|  63.405         #011|\u001b[0m\n",
      "\u001b[34m2021-08-02 12:17:18,456 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mbackward                           #011|  0.03534        #011|7690           #011|  271.77         #011|  36.736         #011|\u001b[0m\n",
      "\u001b[34mmodel_forward                      #011|  0.023901       #011|7690           #011|  183.8          #011|  24.845         #011|\u001b[0m\n",
      "\u001b[34mtraining_step                      #011|  0.023587       #011|7690           #011|  181.38         #011|  24.519         #011|\u001b[0m\n",
      "\u001b[34mevaluation_step_and_end            #011|  0.034798       #011|967            #011|  33.65          #011|  4.5486         #011|\u001b[0m\n",
      "\u001b[34mvalidation_step                    #011|  0.034566       #011|967            #011|  33.425         #011|  4.5183         #011|\u001b[0m\n",
      "\u001b[34mget_train_batch                    #011|  0.0031643      #011|7690           #011|  24.334         #011|  3.2893         #011|\u001b[0m\n",
      "\u001b[34mon_validation_end                  #011|  0.98236        #011|6              #011|  5.8941         #011|  0.79674        #011|\u001b[0m\n",
      "\u001b[34mcache_result                       #011|  2.3106e-05     #011|33728          #011|  0.77931        #011|  0.10534        #011|\u001b[0m\n",
      "\u001b[34mon_train_batch_end                 #011|  9.5625e-05     #011|7690           #011|  0.73536        #011|  0.099402       #011|\u001b[0m\n",
      "\u001b[34mon_train_start                     #011|  0.66083        #011|1              #011|  0.66083        #011|  0.089329       #011|\u001b[0m\n",
      "\u001b[34mon_after_backward                  #011|  2.8929e-05     #011|7690           #011|  0.22246        #011|  0.030071       #011|\u001b[0m\n",
      "\u001b[34mon_batch_start                     #011|  2.7354e-05     #011|7690           #011|  0.21036        #011|  0.028435       #011|\u001b[0m\n",
      "\u001b[34mon_before_zero_grad                #011|  2.3748e-05     #011|7690           #011|  0.18262        #011|  0.024686       #011|\u001b[0m\n",
      "\u001b[34mon_batch_end                       #011|  2.3731e-05     #011|7690           #011|  0.18249        #011|  0.024669       #011|\u001b[0m\n",
      "\u001b[34mon_train_batch_start               #011|  1.8875e-05     #011|7690           #011|  0.14515        #011|  0.019621       #011|\u001b[0m\n",
      "\u001b[34mtraining_step_end                  #011|  1.5922e-05     #011|7690           #011|  0.12244        #011|  0.01655        #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_end            #011|  5.6383e-05     #011|967            #011|  0.054523       #011|  0.0073701      #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_start          #011|  2.6224e-05     #011|967            #011|  0.025359       #011|  0.0034279      #011|\u001b[0m\n",
      "\u001b[34mvalidation_step_end                #011|  1.5078e-05     #011|967            #011|  0.014581       #011|  0.001971       #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_end            #011|  0.00071862     #011|6              #011|  0.0043117      #011|  0.00058283     #011|\u001b[0m\n",
      "\u001b[34mon_validation_start                #011|  0.00062435     #011|6              #011|  0.0037461      #011|  0.00050638     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_start               #011|  0.00061617     #011|5              #011|  0.0030809      #011|  0.00041646     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_end                 #011|  0.00027166     #011|5              #011|  0.0013583      #011|  0.00018361     #011|\u001b[0m\n",
      "\u001b[34mon_train_end                       #011|  0.00085542     #011|1              #011|  0.00085542     #011|  0.00011563     #011|\u001b[0m\n",
      "\u001b[34mon_epoch_start                     #011|  3.3916e-05     #011|11             #011|  0.00037307     #011|  5.043e-05      #011|\u001b[0m\n",
      "\u001b[34mon_epoch_end                       #011|  2.4075e-05     #011|11             #011|  0.00026483     #011|  3.5798e-05     #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_start          #011|  1.9392e-05     #011|6              #011|  0.00011635     #011|  1.5728e-05     #011|\u001b[0m\n",
      "\u001b[34mon_fit_start                       #011|  3.3102e-05     #011|1              #011|  3.3102e-05     #011|  4.4746e-06     #011|\u001b[0m\n",
      "\u001b[34mon_before_accelerator_backend_setup#011|  1.8413e-05     #011|1              #011|  1.8413e-05     #011|  2.489e-06      #011|\u001b[0m\n",
      "\u001b[34mon_train_dataloader                #011|  1.503e-05      #011|1              #011|  1.503e-05      #011|  2.0317e-06     #011|\u001b[0m\n",
      "\u001b[34mon_val_dataloader                  #011|  1.453e-05      #011|1              #011|  1.453e-05      #011|  1.9641e-06     #011|\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/192 [00:00<?, ?it/s]#015  1%|          | 1/192 [00:00<00:47,  4.05it/s]#015  2%|▏         | 4/192 [00:00<00:34,  5.46it/s]#015  4%|▎         | 7/192 [00:00<00:25,  7.22it/s]#015  5%|▌         | 10/192 [00:00<00:19,  9.35it/s]#015  7%|▋         | 14/192 [00:00<00:15, 11.82it/s]#015  9%|▉         | 18/192 [00:00<00:12, 14.49it/s]#015 11%|█▏        | 22/192 [00:00<00:09, 17.22it/s]#015 14%|█▎        | 26/192 [00:01<00:08, 19.78it/s]#015 16%|█▌        | 30/192 [00:01<00:07, 22.18it/s]#015 18%|█▊        | 34/192 [00:01<00:06, 24.23it/s]#015 20%|█▉        | 38/192 [00:01<00:05, 25.89it/s]#015 22%|██▏       | 42/192 [00:01<00:05, 27.16it/s]#015 24%|██▍       | 46/192 [00:01<00:05, 28.17it/s]#015 26%|██▌       | 50/192 [00:01<00:04, 28.87it/s]#015 28%|██▊       | 54/192 [00:01<00:04, 29.41it/s]#015 30%|███       | 58/192 [00:02<00:04, 29.86it/s]#015 32%|███▏      | 62/192 [00:02<00:04, 30.16it/s]#015 34%|███▍      | 66/192 [00:02<00:04, 30.38it/s]#015 36%|███▋      | 70/192 [00:02<00:04, 30.43it/s]#015 39%|███▊      | 74/192 [00:02<00:03, 30.37it/s]#015 41%|████      | 78/192 [00:02<00:03, 30.47it/s]#015 43%|████▎     | 82/192 [00:02<00:03, 30.67it/s]#015 45%|████▍     | 86/192 [00:03<00:03, 30.60it/s]#015 47%|████▋     | 90/192 [00:03<00:03, 30.63it/s]#015 49%|████▉     | 94/192 [00:03<00:03, 30.64it/s]#015 51%|█████     | 98/192 [00:03<00:03, 30.78it/s]#015 53%|█████▎    | 102/192 [00:03<00:02, 30.75it/s]#015 55%|█████▌    | 106/192 [00:03<00:02, 30.75it/s]#015 57%|█████▋    | 110/192 [00:03<00:02, 30.58it/s]#015 59%|█████▉    | 114/192 [00:03<00:02, 30.59it/s]#015 61%|██████▏   | 118/192 [00:04<00:02, 30.77it/s]#015 64%|██████▎   | 122/192 [00:04<00:02, 30.71it/s]#015 66%|██████▌   | 126/192 [00:04<00:02, 30.91it/s]#015 68%|██████▊   | 130/192 [00:04<00:02, 30.93it/s]#015 70%|██████▉   | 134/192 [00:04<00:01, 30.97it/s]#015 72%|███████▏  | 138/192 [00:04<00:01, 31.06it/s]#015 74%|███████▍  | 142/192 [00:04<00:01, 30.96it/s]#015 76%|███████▌  | 146/192 [00:04<00:01, 30.56it/s]#015 78%|███████▊  | 150/192 [00:05<00:01, 30.55it/s]#015 80%|████████  | 154/192 [00:05<00:01, 30.55it/s]#015 82%|████████▏ | 158/192 [00:05<00:01, 30.67it/s]#015 84%|████████▍ | 162/192 [00:05<00:00, 30.29it/s]#015 86%|████████▋ | 166/192 [00:05<00:00, 30.58it/s]#015 89%|████████▊ | 170/192 [00:05<00:00, 30.80it/s]#015 91%|█████████ | 174/192 [00:05<00:00, 30.75it/s]#015 93%|█████████▎| 178/192 [00:06<00:00, 30.53it/s]#015 95%|█████████▍| 182/192 [00:06<00:00, 30.55it/s]#015 97%|█████████▋| 186/192 [00:06<00:00, 30.75it/s]#015 99%|█████████▉| 190/192 [00:06<00:00, 30.79it/s]#015193it [00:06, 29.50it/s]                         \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-08-02 12:17:34 Uploading - Uploading generated training model\n",
      "2021-08-02 12:18:15 Completed - Training job completed\n",
      "ProfilerReport-1627905380: IssuesFound\n",
      "Training seconds: 1141\n",
      "Billable seconds: 1141\n"
     ]
    }
   ],
   "source": [
    "# Fit the estimator\n",
    "\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
