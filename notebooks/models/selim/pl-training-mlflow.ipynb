{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'data_v0.7.1'\n",
    ")\n",
    "\n",
    "train_val_df = pd.read_csv(os.path.join(DATA_PATH, 'new_columns_train_val.csv')).drop_duplicates()\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'new_columns_test_v0.7.1.csv'))[['excerpt']]\n",
    "\n",
    "\"\"\"DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'subsectors', 'training_data'\n",
    ")\n",
    "\n",
    "train_val_df = pd.read_csv(os.path.join(DATA_PATH, 'train_subsectors.csv')).drop_duplicates()\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_subsectors.csv'))[['excerpt']]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from ast import literal_eval\n",
    "\n",
    "train_val_df['target'] = train_val_df['target'].apply(\n",
    "    lambda x: [item for item in literal_eval(x) if 'first_level' in item]\n",
    ")\n",
    "train_val_df.to_csv(os.path.join(DATA_PATH, 'tmp_train_val.csv'))\n",
    "\n",
    "\"\"\"\n",
    "#train_val_df = pd.read_csv(os.path.join(DATA_PATH, 'tmp_train_val.csv'))\n",
    "#train_val_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "len(list(set(flatten(train_val_df['target'].apply(literal_eval)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['excerpt', 'entry_id', 'target']\n",
    "train_val_df = train_val_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsectors_list = [\n",
    "    \"subsector->Education->Learning Environment\",\n",
    "    \"subsector->Education->Teachers and Education Personnel\",\n",
    "    \"subsector->Education->Teaching and Learning\",\n",
    "    \"subsector->Health->Health care\",\n",
    "    \"subsector->Health->Health status\",\n",
    "    \"subsector->Livelihoods->Expenditures\",\n",
    "    \"subsector->Livelihoods->Income\",\n",
    "    \"subsector->Livelihoods->Productive Assets\",\n",
    "    \"subsector->Livelihoods->Skills & Qualifications\",\n",
    "    \"subsector->Nutrition->Nutrition services\",\n",
    "    \"subsector->Nutrition->Nutrition status\",\n",
    "    \"subsector->Protection->Child Protection\",\n",
    "    \"subsector->Protection->Civil and Political Rights\",\n",
    "    \"subsector->Protection->Documentation\",\n",
    "    \"subsector->Protection->Freedom of Movement\",\n",
    "    \"subsector->Protection->Housing Land and Property\",\n",
    "    \"subsector->Protection->Human Trafficking\",\n",
    "    \"subsector->Protection->Human rights\",\n",
    "    \"subsector->Protection->Justice and Rule of Law\",\n",
    "    \"subsector->Protection->Mines and UXOs\",\n",
    "    \"subsector->Protection->Physical Safety and Security\",\n",
    "    \"subsector->Protection->Sexual and Gender Based Violence\",\n",
    "    \"subsector->Shelter->Domestic Living Space\",\n",
    "    \"subsector->Shelter->Dwelling Enveloppe\",\n",
    "    \"subsector->Shelter->Housing Land and Property\",\n",
    "    \"subsector->Shelter->Non Food Items\",\n",
    "    \"subsector->WASH->Hygiene\",\n",
    "    \"subsector->WASH->Sanitation\",\n",
    "    \"subsector->WASH->Vector control\",\n",
    "    \"subsector->WASH->Waste management\",\n",
    "    \"subsector->WASH->Water Supply\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sample = False  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
    "    train_val_df = train_val_df.sample(n=20_000)\n",
    "\n",
    "\"\"\"#tmp, for test\n",
    "train_val_df['target'] = train_val_df['target'].apply(\n",
    "    lambda x: str(random.sample(subsectors_list, 2) + literal_eval(x))\n",
    ")\"\"\"\n",
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-all-models\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "train_val_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "print('finished uploading train val df.')\n",
    "test_df.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]\n",
    "\n",
    "# CPU instances\n",
    "instances = [\n",
    "    'ml.c4.2xlarge',\n",
    "    'ml.c4.4xlarge',\n",
    "    'ml.c5n.2xlarge'\n",
    "]\n",
    "\n",
    "# https://aws.amazon.com/sagemaker/pricing/instance-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = \"ml.p3.2xlarge\"\n",
    "relabeled_columns = \"none\" # one of ['none', 'sectors', 'secondary_tags', 'subsector']\n",
    "if relabeled_columns=='none':\n",
    "    experiment_name = \"pl-deep-deployment\"\n",
    "else:\n",
    "    experiment_name = \"pl-relabling\"\n",
    "\n",
    "#experiment_name = 'zero_shot_testing'\n",
    "\n",
    "run_name = \"model_small_first_release_data\" #\"ENDPOINT_TESTING\"# \"all_tags_final\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"tracking_uri\": MLFLOW_SERVER,\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"max_len\": 128,\n",
    "    \"epochs\": 5,\n",
    "    #\"model_name\": \"xlm-roberta-base\",\n",
    "    #\"tokenizer_name\": \"xlm-roberta-base\",\n",
    "    #\"output_length\": 768,\n",
    "    \"model_name\": \"nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large\",\n",
    "    \"tokenizer_name\": \"nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large\",\n",
    "    \"output_length\": 384,\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 10e-5,\n",
    "    \"weight_decay\": 1e-2,\n",
    "    \"instance_type\": instance_type,\n",
    "    \"f_beta\": 0.8,\n",
    "    \"nb_repetitions\": 1,\n",
    "    \"run_name\": run_name,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"val_batch_size\": 128,\n",
    "    \"n_freezed_layers\": 1,\n",
    "    \"relabeled_columns\": relabeled_columns\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train_mlflow.py\",\n",
    "    source_dir=str(\n",
    "        \"../../../scripts/training/selim/multiclass-lightning/MultitaskAllInOne\"\n",
    "    ),\n",
    "    output_path=str(DEV_BUCKET / \"models/\"),\n",
    "    code_location=str(input_path),\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    job_name=job_name,\n",
    "    #     train_instance_count=2,\n",
    "    #     train_instance_type=\"ml.c4.xlarge\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the estimator\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
