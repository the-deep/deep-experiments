{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(x):\n",
    "    if str(x)=='nan':\n",
    "        return {}\n",
    "    if str(x)=='[None]':\n",
    "        return {}\n",
    "    if type(x)==list:\n",
    "        return x\n",
    "    else:\n",
    "        return literal_eval(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CCA data\n",
    "\"\"\"DATA_PATH = os.path.join(\"..\", \"..\", \"..\", \"data\", \"frameworks_data\", \"development_cca\")\n",
    "experiment_name = 'pl-cca'\n",
    "train_val_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"train_val_data.csv.gz\"), compression=\"gzip\"\n",
    ").drop_duplicates()\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, \"test_data.csv.gz\"), compression=\"gzip\")\n",
    "\"\"\"\n",
    "\n",
    "# deployed data version\n",
    "DATA_PATH = os.path.join(\"..\", \"..\", \"..\", \"data\", \"frameworks_data\", \"data_v0.8\")\n",
    "experiment_name = \"classification_v0_8\"\n",
    "\n",
    "kept_cols = [\n",
    "    \"en\",\n",
    "    \"fr\",\n",
    "    \"es\",\n",
    "    \"pt\",\n",
    "    \"entry_id\",\n",
    "    \"project_id\",\n",
    "    \"nlp_tags\",\n",
    "    \"original_language\",\n",
    "]  # , 'analysis_framework_id']\n",
    "\n",
    "all_data = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"hum_data_v0.8.csv.gz\"), compression=\"gzip\"\n",
    ").drop_duplicates()\n",
    "all_data = all_data[all_data.confidentiality == \"unprotected\"][kept_cols].rename(\n",
    "    columns={\"nlp_tags\": \"target\"}\n",
    ")\n",
    "\n",
    "# subsectors\n",
    "\"\"\"DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'subsectors', 'training_data'\n",
    ")\n",
    "experiment_name = 'pl-subsectors'\n",
    "train_val_df = pd.read_csv(os.path.join(DATA_PATH, 'train_subsectors.csv')).drop_duplicates()\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_subsectors.csv'))[['entry_id', 'excerpt', 'target']]\n",
    "train_val_df.shape[0], test_df.shape[0]\"\"\"\n",
    "\n",
    "# livelihoods\n",
    "\"\"\"DATA_PATH = os.path.join(\n",
    "    \"..\", \"..\", \"..\", \"data\", \"frameworks_data\", \"livelihoods_subsectors\"\n",
    ")\n",
    "experiment_name = \"pl-livelihoods\"\n",
    "train_val_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"livelihoods_subsectors_labeled.csv\"), lineterminator=\"\\n\"\n",
    ").drop_duplicates()\n",
    "test_df = pd.read_csv(\n",
    "    os.path.join(\n",
    "        DATA_PATH, \"livelihoods_en_subsectors_unlabeled.csv\"\n",
    "    ), lineterminator=\"\\n\"\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"hum_mapping_sheet = pd.read_csv(os.path.join(DATA_PATH, \"hum_mapping_sheet_nov2022.csv\"))\n",
    "\n",
    "relevant_cols = [\n",
    "    \"Original first level\",\n",
    "    \"Original second level\",\n",
    "    \"NLP Type\",\n",
    "    \"NLP first level\",\n",
    "    \"NLP second level\",\n",
    "    \"NLP third level\",\n",
    "]\n",
    "\n",
    "livelihood_mapping = hum_mapping_sheet[\n",
    "    hum_mapping_sheet[\"Original first level\"] == \"livelihoods\"\n",
    "][relevant_cols].drop_duplicates()\n",
    "\n",
    "livelihoods_mapping_dict = {\n",
    "    f\"subsectors->{row['Original first level']}->{row['Original second level']}\": f\"subsectors->{row['NLP first level']}->{row['NLP second level']}\"\n",
    "    for i, row in livelihood_mapping.iterrows()\n",
    "}\n",
    "\n",
    "train_val_df['target'] = train_val_df['target'].apply(\n",
    "    lambda x: [livelihoods_mapping_dict[item.lower()] for item in custom_eval(x)]\n",
    ")\n",
    "\n",
    "train_val_df[\"target\"] = train_val_df[\"target\"].apply(\n",
    "    lambda x: str([item for item in custom_eval(x) if \"secondary\" not in item])\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = False\n",
    "\n",
    "if sample:\n",
    "    all_data = all_data.sample(n=5_000)\n",
    "\n",
    "print(all_data.shape)\n",
    "\n",
    "job_name = f\"pytorch-{formatted_time()}-entry-classification\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "all_data.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]\n",
    "\n",
    "# CPU instances\n",
    "instances = [\n",
    "    'ml.c4.2xlarge',\n",
    "    'ml.c4.4xlarge',\n",
    "    'ml.c5n.2xlarge'\n",
    "]\n",
    "\n",
    "# https://aws.amazon.com/sagemaker/pricing/instance-types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type = \"ml.p3.2xlarge\"\n",
    "run_name = experiment_name  # \"ENDPOINT_TESTING\"# \"all_tags_final\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"tracking_uri\": MLFLOW_SERVER,\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"max_len\": 150,\n",
    "    \"delete_long_excerpts\": \"false\",\n",
    "    \"apply_preprocessing\": \"false\",\n",
    "    \"explainability\": \"false\",\n",
    "    \"predictions_on_test_set\": \"false\",# \"true\" if not all([sample_test, sample_train]) else \"false\",\n",
    "    \"epochs\": 1 if sample else 3,\n",
    "    # \"model_name\": \"xlm-roberta-base\",\n",
    "    # \"tokenizer_name\": \"xlm-roberta-base\",\n",
    "    # \"output_length\": 768,\n",
    "    \"model_name\": \"nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large\",\n",
    "    \"tokenizer_name\": \"nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large\",\n",
    "    \"output_length\": 384,\n",
    "    \"dropout\": 0.2,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 5e-3,\n",
    "    \"instance_type\": instance_type,\n",
    "    \"f_beta\": 1,\n",
    "    \"nb_repetitions\": 1,\n",
    "    \"run_name\": run_name,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"val_batch_size\": 128,\n",
    "    \"n_freezed_layers\": 1,\n",
    "    \"loss_gamma\": 2,\n",
    "    \"proportions_pow\": 1,\n",
    "    \"min_entries_per_proj\": 30 if sample else 1_000,\n",
    "    \"relabling_min_ratio\": 1,\n",
    "    \"apply_relabling\": \"true\"\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=str(\n",
    "        \"../../../scripts/training/selim/entry_classification/MultitaskWithRelabling\"\n",
    "    ),\n",
    "    output_path=str(DEV_BUCKET / \"models/\"),\n",
    "    code_location=str(input_path),\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py3\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    job_name=job_name,\n",
    "    debugger_hook_config=False\n",
    "    #     train_instance_count=2,\n",
    "    #     train_instance_type=\"ml.c4.xlarge\",\n",
    ")\n",
    "\n",
    "fit_arguments = {\"train\": str(input_path), \"test\": str(input_path)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit the estimator\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
