{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n\\n!pip install s3fs\\n!pip install smdebug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/home/selim/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'data_v0.7.1'\n",
    ")\n",
    "\n",
    "tot_df = pd.read_csv(os.path.join(DATA_PATH, 'new_columns_train_val.csv')).drop_duplicates()\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'new_columns_test_v0.7.1.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'gender_kw_pred', 'age_kw_pred',\n",
       "       'affected_groups_level_3_kw', 'gender_snorkel', 'excerpt',\n",
       "       'analysis_framework_id', 'lead_id', 'project_id', 'verified', 'sectors',\n",
       "       'subpillars_2d', 'subpillars_1d', 'geo_location',\n",
       "       'specific_needs_groups', 'severity', 'info_date', 'reliability',\n",
       "       'affected_groups_level_0', 'affected_groups_level_1',\n",
       "       'affected_groups_level_2', 'affected_groups_level_3_original',\n",
       "       'age_original', 'gender_original', 'source_type', 'url', 'website',\n",
       "       'pillars_1d', 'pillars_2d', 'Casualties', 'Context', 'Covid-19',\n",
       "       'Displacement', 'Humanitarian Access', 'Information And Communication',\n",
       "       'Shock/Event', 'At Risk', 'Capacities & Response',\n",
       "       'Humanitarian Conditions', 'Impact', 'Priority Interventions',\n",
       "       'Priority Needs', 'affected_groups', 'subpillars', 'secondary_tags',\n",
       "       'present_age', 'present_gender', 'present_affected_groups_level_3',\n",
       "       'present_tags'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"learning_rates = {\\n    'present_prim_tags': 5e-5,\\n    'sectors': 8e-5,\\n    'pillars_1d': 0.85,\\n    'pillars_2d': 0.81,\\n    'subpillars_2d_part1': 0.8, \\n   'subpillars_2d_part2': 0.72,\\n   'subpillars_1d_part1': 0.89,\\n   'subpillars_1d_part2': 0.85,\\n   'subpillars_1d_part3': 0.84,\\n    'gender': 0.84,\\n    'age': 0.84,\\n    'specific_needs_groups': 0.79,\\n    'affected_groups_levels_2_3': 0.99,\\n    'gender_snorkel': 0.87,\\n    'subpillars_1d': 0.7,\\n    'subpillars_2d': 0.7,\\n    'prim_tags_level1': 0.7,\\n    'subpillars_second_part': 0.7,\\n    'subpillars_first_part': 0.7\\n}\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"learning_rates = {\n",
    "    'present_prim_tags': 5e-5,\n",
    "    'sectors': 8e-5,\n",
    "    'pillars_1d': 0.85,\n",
    "    'pillars_2d': 0.81,\n",
    "    'subpillars_2d_part1': 0.8, \n",
    "   'subpillars_2d_part2': 0.72,\n",
    "   'subpillars_1d_part1': 0.89,\n",
    "   'subpillars_1d_part2': 0.85,\n",
    "   'subpillars_1d_part3': 0.84,\n",
    "    'gender': 0.84,\n",
    "    'age': 0.84,\n",
    "    'specific_needs_groups': 0.79,\n",
    "    'affected_groups_levels_2_3': 0.99,\n",
    "    'gender_snorkel': 0.87,\n",
    "    'subpillars_1d': 0.7,\n",
    "    'subpillars_2d': 0.7,\n",
    "    'prim_tags_level1': 0.7,\n",
    "    'subpillars_second_part': 0.7,\n",
    "    'subpillars_first_part': 0.7\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = ['excerpt', 'entry_id',\\n           'present_tags',\\n           'sectors',\\n           'pillars_2d',\\n           'pillars_1d',\\n           'subpillars_1d_part1',\\n           'subpillars_1d_part2', \\n           'subpillars_1d_part3', \\n           'subpillars_2d_part1',\\n           'subpillars_2d_part2'\\n        ]\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"columns = ['excerpt', 'entry_id',\n",
    "           'present_tags',\n",
    "           'sectors',\n",
    "           'pillars_2d',\n",
    "           'pillars_1d',\n",
    "           'subpillars_1d_part1',\n",
    "           'subpillars_1d_part2', \n",
    "           'subpillars_1d_part3', \n",
    "           'subpillars_2d_part1',\n",
    "           'subpillars_2d_part2'\n",
    "        ]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['excerpt', 'entry_id', 'subpillars', 'sectors', 'secondary_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"columns = [\\n    'excerpt', 'entry_id',\\n    'present_age',\\n    'present_gender',\\n    'present_affected_groups_level_3',\\n    'gender_kw_pred', \\n    'age_kw_pred',\\n       'affected_groups_level_3_kw', \\n       'age_original', \\n       'gender_original', \\n        'affected_groups_level_3_original', \\n        'gender_snorkel'\\n]\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"columns = [\n",
    "    'excerpt', 'entry_id',\n",
    "    'present_age',\n",
    "    'present_gender',\n",
    "    'present_affected_groups_level_3',\n",
    "    'gender_kw_pred', \n",
    "    'age_kw_pred',\n",
    "       'affected_groups_level_3_kw', \n",
    "       'age_original', \n",
    "       'gender_original', \n",
    "        'affected_groups_level_3_original', \n",
    "        'gender_snorkel'\n",
    "]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tot_df = tot_df[columns]\n",
    "test_df = test_df[['excerpt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['excerpt', 'entry_id', 'subpillars', 'sectors', 'secondary_tags'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = True  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
    "    tot_df = tot_df.sample(n=50_000)\n",
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-all-models\"  # change it as you prefer\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "\n",
    "tot_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "test_df.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "instance_type='ml.p3.2xlarge'\n",
    "\n",
    "hyperparameters={\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
    "    'experiment_name': \"pl-all-models-experiments\",\n",
    "    'max_len': 256,\n",
    "    'epochs': 1,\n",
    "    'model_name': \"microsoft/xtremedistil-l6-h256-uncased\",\n",
    "    'tokenizer_name': \"microsoft/xtremedistil-l6-h256-uncased\",\n",
    "    'output_length': 256,\n",
    "    'learning_rate': 3e-5,\n",
    "    'training_names':','.join(columns[2:]),\n",
    "    \"instance_type\": instance_type,\n",
    "    'beta_f1': 0.7,\n",
    "    'nb_repetitions': 1,\n",
    "    'run_name': 'all_tags_test'\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_mlflow.py',\n",
    "    source_dir=str(\n",
    "        '../../../scripts/training/selim/multiclass-lightning/multitask_Tree_like_Architecture'\n",
    "    ),\n",
    "    output_path=str(DEV_BUCKET/'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version=\"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-31 11:44:15 Starting - Starting the training job...\n",
      "2022-01-31 11:44:17 Starting - Launching requested ML instancesProfilerReport-1643629451: InProgress\n",
      "......\n",
      "2022-01-31 11:45:34 Starting - Preparing the instances for training.........\n",
      "2022-01-31 11:47:34 Downloading - Downloading input data\n",
      "2022-01-31 11:47:34 Training - Downloading the training image.................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-01-31 11:50:25,288 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-01-31 11:50:25,310 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-01-31 11:50:28,350 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-01-31 11:50:28,736 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.8.2\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4.0\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\u001b[0m\n",
      "\n",
      "2022-01-31 11:50:35 Training - Training image download completed. Training in progress.\u001b[34mCollecting pytorch-lightning==1.3.8\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.4.1\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm==4.41.1\n",
      "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.18.0\n",
      "  Downloading mlflow-1.18.0-py3-none-any.whl (14.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.49.1\n",
      "  Downloading sagemaker-2.49.1.tar.gz (421 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3fs==2021.07.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mCollecting smdebug==1.0.11\n",
      "  Downloading smdebug-1.0.11-py2.py3-none-any.whl (269 kB)\u001b[0m\n",
      "\u001b[34mCollecting scikit-multilearn==0.2.0\n",
      "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle==2.0.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (4.8.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (2.26.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (3.4.0)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.1.18-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.36.2)\u001b[0m\n",
      "\u001b[34mCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.17\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (3.19.1)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (8.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 6)) (0.3)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 6)) (8.0.3)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Flask in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 6)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.7-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 6)) (2021.3)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34m  Preparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.31-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 6)) (1.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 7)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 7)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 8)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.16.32 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 8)) (1.20.24)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 8)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 8)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 8)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiobotocore>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from s3fs==2021.07.0->-r requirements.txt (line 9)) (2.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug==1.0.11->-r requirements.txt (line 10)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aioitertools>=0.5.1 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (0.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp>=3.3.1 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.23.25,>=1.23.24 in /opt/conda/lib/python3.6/site-packages (from aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (1.23.24)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow==1.18.0->-r requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 8)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 8)) (0.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.18.0->-r requirements.txt (line 6)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=4.0.0->mlflow==1.18.0->-r requirements.txt (line 6)) (1.2.3)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.8.2->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 1)) (3.0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug==1.0.11->-r requirements.txt (line 10)) (0.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy->mlflow==1.18.0->-r requirements.txt (line 6)) (1.1.2)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.5.0-py2.py3-none-any.whl (157 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (58.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.18.0->-r requirements.txt (line 6)) (3.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.18.0->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 8)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 8)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 8)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 8)) (1.6.6.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from prometheus-flask-exporter->mlflow==1.18.0->-r requirements.txt (line 6)) (0.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (4.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna-ssl>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (5.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 9)) (0.13.0)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=3.0->Flask->mlflow==1.18.0->-r requirements.txt (line 6)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: sagemaker, alembic, databricks-cli, termcolor, wrapt\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.49.1-py2.py3-none-any.whl size=591938 sha256=3c6b77b4ec4d548c0776e132f6faaab845e3e0b8440b5ec88b77f3372952a5b6\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/af/ea/8ff5943a87155df5b184e54474fbf2b59b75e5c172854643c6\n",
      "  Building wheel for alembic (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=ad87f2eca1ac9be11c7999820d2e355755e850c506d754db340699deb14ac87a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=187af8750a105cd4915358007488493c51f85fea95e87a3b831ce9e38245d732\n",
      "  Stored in directory: /root/.cache/pip/wheels/f5/cf/28/d354903b6e02a075cec67cfb2414321d2beed2cc428fe26478\n",
      "  Building wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=c25ecaccf1674221e539227cf99e0d9b779e5fec97978225eb5c14ec54d26705\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69769 sha256=e0c4a0a93f8f051b3ee273e1faedb4e49098c8d236be10acd01585777fdf765b\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\u001b[0m\n",
      "\u001b[34mSuccessfully built sagemaker alembic databricks-cli termcolor wrapt\u001b[0m\n",
      "\u001b[34mInstalling collected packages: typing-extensions, six, pyasn1-modules, oauthlib, cachetools, smmap, requests-oauthlib, numpy, google-auth, wrapt, tqdm, tensorboard-plugin-wit, tensorboard-data-server, sqlalchemy, regex, python-editor, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, absl-py, torchmetrics, tokenizers, termcolor, tensorflow-estimator, tensorboard, sqlparse, sacremoses, querystring-parser, pyDeprecate, prometheus-flask-exporter, opt-einsum, keras-preprocessing, huggingface-hub, h5py, gunicorn, gitpython, gast, flatbuffers, docker, databricks-cli, astunparse, alembic, transformers, tensorflow, smdebug, scikit-multilearn, scikit-learn, sagemaker, pytorch-lightning, mlflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.13.3\n",
      "    Uninstalling wrapt-1.13.3:\n",
      "      Successfully uninstalled wrapt-1.13.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.61.2\n",
      "    Uninstalling tqdm-4.61.2:\n",
      "      Successfully uninstalled tqdm-4.61.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\n",
      "      Successfully uninstalled h5py-2.8.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.9\n",
      "    Uninstalling smdebug-1.0.9:\n",
      "      Successfully uninstalled smdebug-1.0.9\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\u001b[0m\n",
      "\u001b[34m    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.72.0\n",
      "    Uninstalling sagemaker-2.72.0:\n",
      "      Successfully uninstalled sagemaker-2.72.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.1.6 absl-py-0.15.0 alembic-1.4.1 astunparse-1.6.3 cachetools-4.2.4 databricks-cli-0.16.2 docker-5.0.3 flatbuffers-1.12 gast-0.3.3 gitdb-4.0.9 gitpython-3.1.18 google-auth-2.5.0 google-auth-oauthlib-0.4.6 grpcio-1.32.0 gunicorn-20.1.0 h5py-2.10.0 huggingface-hub-0.0.12 keras-preprocessing-1.1.2 markdown-3.3.6 mlflow-1.18.0 numpy-1.19.5 oauthlib-3.2.0 opt-einsum-3.3.0 prometheus-flask-exporter-0.18.7 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 python-editor-1.0.4 pytorch-lightning-1.3.8 querystring-parser-1.2.4 regex-2022.1.18 requests-oauthlib-1.3.1 sacremoses-0.0.47 sagemaker-2.49.1 scikit-learn-0.22.2.post1 scikit-multilearn-0.2.0 six-1.15.0 smdebug-1.0.11 smmap-5.0.0 sqlalchemy-1.4.31 sqlparse-0.4.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 tokenizers-0.10.3 torchmetrics-0.4.1 tqdm-4.41.1 transformers-4.8.2 typing-extensions-3.7.4.3 wrapt-1.12.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2022-01-31 11:51:32,950 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"experiment_name\": \"pl-all-models-experiments\",\n",
      "        \"max_len\": 256,\n",
      "        \"training_names\": \"subpillars,sectors,secondary_tags\",\n",
      "        \"model_name\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "        \"output_length\": 256,\n",
      "        \"beta_f1\": 0.7,\n",
      "        \"tokenizer_name\": \"microsoft/xtremedistil-l6-h256-uncased\",\n",
      "        \"nb_repetitions\": 1,\n",
      "        \"epochs\": 1,\n",
      "        \"instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"learning_rate\": 3e-05,\n",
      "        \"run_name\": \"all_tags_test\",\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2022-01-31-12-44-03-734-all-models\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-01-31-12-44-03-734-all-models/pytorch-2022-01-31-12-44-03-734-all-models/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"beta_f1\":0.7,\"epochs\":1,\"experiment_name\":\"pl-all-models-experiments\",\"instance_type\":\"ml.p3.2xlarge\",\"learning_rate\":3e-05,\"max_len\":256,\"model_name\":\"microsoft/xtremedistil-l6-h256-uncased\",\"nb_repetitions\":1,\"output_length\":256,\"run_name\":\"all_tags_test\",\"tokenizer_name\":\"microsoft/xtremedistil-l6-h256-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"training_names\":\"subpillars,sectors,secondary_tags\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-01-31-12-44-03-734-all-models/pytorch-2022-01-31-12-44-03-734-all-models/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"beta_f1\":0.7,\"epochs\":1,\"experiment_name\":\"pl-all-models-experiments\",\"instance_type\":\"ml.p3.2xlarge\",\"learning_rate\":3e-05,\"max_len\":256,\"model_name\":\"microsoft/xtremedistil-l6-h256-uncased\",\"nb_repetitions\":1,\"output_length\":256,\"run_name\":\"all_tags_test\",\"tokenizer_name\":\"microsoft/xtremedistil-l6-h256-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"training_names\":\"subpillars,sectors,secondary_tags\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2022-01-31-12-44-03-734-all-models\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2022-01-31-12-44-03-734-all-models/pytorch-2022-01-31-12-44-03-734-all-models/source/sourcedir.tar.gz\",\"module_name\":\"train_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--beta_f1\",\"0.7\",\"--epochs\",\"1\",\"--experiment_name\",\"pl-all-models-experiments\",\"--instance_type\",\"ml.p3.2xlarge\",\"--learning_rate\",\"3e-05\",\"--max_len\",\"256\",\"--model_name\",\"microsoft/xtremedistil-l6-h256-uncased\",\"--nb_repetitions\",\"1\",\"--output_length\",\"256\",\"--run_name\",\"all_tags_test\",\"--tokenizer_name\",\"microsoft/xtremedistil-l6-h256-uncased\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"--training_names\",\"subpillars,sectors,secondary_tags\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=pl-all-models-experiments\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=256\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_NAMES=subpillars,sectors,secondary_tags\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=microsoft/xtremedistil-l6-h256-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_LENGTH=256\u001b[0m\n",
      "\u001b[34mSM_HP_BETA_F1=0.7\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER_NAME=microsoft/xtremedistil-l6-h256-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_NB_REPETITIONS=1\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_INSTANCE_TYPE=ml.p3.2xlarge\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=3e-05\u001b[0m\n",
      "\u001b[34mSM_HP_RUN_NAME=all_tags_test\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_mlflow.py --beta_f1 0.7 --epochs 1 --experiment_name pl-all-models-experiments --instance_type ml.p3.2xlarge --learning_rate 3e-05 --max_len 256 --model_name microsoft/xtremedistil-l6-h256-uncased --nb_repetitions 1 --output_length 256 --run_name all_tags_test --tokenizer_name microsoft/xtremedistil-l6-h256-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --training_names subpillars,sectors,secondary_tags\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s][2022-01-31 11:53:01.114 algo-1:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:01.152 algo-1:68 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:01.153 algo-1:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:01.154 algo-1:68 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:01.154 algo-1:68 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:01.154 algo-1:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.066 algo-1:68 INFO hook.py:594] name:model.l0.embeddings.word_embeddings.weight count_params:7813632\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.066 algo-1:68 INFO hook.py:594] name:model.l0.embeddings.position_embeddings.weight count_params:131072\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.066 algo-1:68 INFO hook.py:594] name:model.l0.embeddings.token_type_embeddings.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.066 algo-1:68 INFO hook.py:594] name:model.l0.embeddings.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.embeddings.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.067 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.068 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.0.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.069 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.1.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.070 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.071 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.072 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.2.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.073 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.074 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.3.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.075 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.4.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.076 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.query.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.query.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.key.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.key.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.value.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.value.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.077 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.intermediate.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.intermediate.dense.bias count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.output.dense.weight count_params:262144\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.output.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.output.LayerNorm.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.encoder.layer.5.output.LayerNorm.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.pooler.dense.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.078 algo-1:68 INFO hook.py:594] name:model.l0.pooler.dense.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.LayerNorm_backbone.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.LayerNorm_backbone.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.LayerNorm_specific_hidden.weight count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.LayerNorm_specific_hidden.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.0.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.0.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.1.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.1.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.2.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.2.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.3.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.079 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.3.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.4.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.4.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.5.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.5.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.6.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.6.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.7.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.7.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.080 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.8.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.8.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.9.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.9.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.10.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.10.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.11.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.11.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.12.weight count_params:65536\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.specific_hidden_layer.12.bias count_params:256\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.output_layer.0.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.output_layer.0.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.081 algo-1:68 INFO hook.py:594] name:model.output_layer.1.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.1.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.2.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.2.bias count_params:3\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.3.weight count_params:1792\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.3.bias count_params:7\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.4.weight count_params:1792\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.4.bias count_params:7\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.5.weight count_params:1280\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.082 algo-1:68 INFO hook.py:594] name:model.output_layer.5.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.6.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.6.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.7.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.7.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.8.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.8.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.9.weight count_params:1024\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.9.bias count_params:4\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.10.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.10.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.11.weight count_params:512\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.083 algo-1:68 INFO hook.py:594] name:model.output_layer.11.bias count_params:2\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.084 algo-1:68 INFO hook.py:594] name:model.output_layer.12.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.084 algo-1:68 INFO hook.py:594] name:model.output_layer.12.bias count_params:3\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.084 algo-1:68 INFO hook.py:596] Total Trainable Params: 13619507\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.084 algo-1:68 INFO hook.py:423] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-01-31 11:53:02.088 algo-1:68 INFO hook.py:486] Hook is writing from the hook with pid: 68\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1563 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s] #015Epoch 0:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s]#015Epoch 0:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s, loss=0.0904, v_num=0, val_loss=0.222]#015Epoch 0:   5%|▌         | 80/1563 [00:15<04:41,  5.27it/s, loss=0.0904, v_num=0, val_loss=0.222]#015Epoch 0:   5%|▌         | 80/1563 [00:15<04:41,  5.27it/s, loss=0.0557, v_num=0, val_loss=0.222]#015Epoch 0:   8%|▊         | 120/1563 [00:22<04:29,  5.34it/s, loss=0.0557, v_num=0, val_loss=0.222]#015Epoch 0:   8%|▊         | 120/1563 [00:22<04:29,  5.34it/s, loss=0.047, v_num=0, val_loss=0.222] #015Epoch 0:  10%|█         | 160/1563 [00:29<04:20,  5.38it/s, loss=0.047, v_num=0, val_loss=0.222]#015Epoch 0:  10%|█         | 160/1563 [00:29<04:20,  5.38it/s, loss=0.0413, v_num=0, val_loss=0.222]#015Epoch 0:  13%|█▎        | 200/1563 [00:37<04:12,  5.39it/s, loss=0.0413, v_num=0, val_loss=0.222]#015Epoch 0:  13%|█▎        | 200/1563 [00:37<04:12,  5.39it/s, loss=0.0377, v_num=0, val_loss=0.222]#015Epoch 0:  15%|█▌        | 240/1563 [00:44<04:06,  5.38it/s, loss=0.0377, v_num=0, val_loss=0.222]#015Epoch 0:  15%|█▌        | 240/1563 [00:44<04:06,  5.38it/s, loss=0.0353, v_num=0, val_loss=0.222]#015Epoch 0:  18%|█▊        | 280/1563 [00:52<03:58,  5.38it/s, loss=0.0353, v_num=0, val_loss=0.222]#015Epoch 0:  18%|█▊        | 280/1563 [00:52<03:58,  5.38it/s, loss=0.0338, v_num=0, val_loss=0.222]#015Epoch 0:  20%|██        | 320/1563 [00:59<03:50,  5.39it/s, loss=0.0338, v_num=0, val_loss=0.222]#015Epoch 0:  20%|██        | 320/1563 [00:59<03:50,  5.39it/s, loss=0.0321, v_num=0, val_loss=0.222]#015Epoch 0:  23%|██▎       | 360/1563 [01:06<03:42,  5.40it/s, loss=0.0321, v_num=0, val_loss=0.222]#015Epoch 0:  23%|██▎       | 360/1563 [01:06<03:42,  5.40it/s, loss=0.0311, v_num=0, val_loss=0.222]#015Epoch 0:  26%|██▌       | 400/1563 [01:13<03:35,  5.41it/s, loss=0.0311, v_num=0, val_loss=0.222]#015Epoch 0:  26%|██▌       | 400/1563 [01:13<03:35,  5.41it/s, loss=0.031, v_num=0, val_loss=0.222] #015Epoch 0:  28%|██▊       | 440/1563 [01:21<03:27,  5.41it/s, loss=0.031, v_num=0, val_loss=0.222]#015Epoch 0:  28%|██▊       | 440/1563 [01:21<03:27,  5.41it/s, loss=0.0301, v_num=0, val_loss=0.222]#015Epoch 0:  31%|███       | 480/1563 [01:28<03:20,  5.40it/s, loss=0.0301, v_num=0, val_loss=0.222]#015Epoch 0:  31%|███       | 480/1563 [01:28<03:20,  5.40it/s, loss=0.0301, v_num=0, val_loss=0.222]#015Epoch 0:  33%|███▎      | 520/1563 [01:36<03:13,  5.40it/s, loss=0.0301, v_num=0, val_loss=0.222]#015Epoch 0:  33%|███▎      | 520/1563 [01:36<03:13,  5.40it/s, loss=0.0291, v_num=0, val_loss=0.222]#015Epoch 0:  36%|███▌      | 560/1563 [01:44<03:06,  5.38it/s, loss=0.0291, v_num=0, val_loss=0.222]#015Epoch 0:  36%|███▌      | 560/1563 [01:44<03:06,  5.38it/s, loss=0.0288, v_num=0, val_loss=0.222]#015Epoch 0:  38%|███▊      | 600/1563 [01:51<02:58,  5.38it/s, loss=0.0288, v_num=0, val_loss=0.222]#015Epoch 0:  38%|███▊      | 600/1563 [01:51<02:58,  5.38it/s, loss=0.0268, v_num=0, val_loss=0.222]#015Epoch 0:  41%|████      | 640/1563 [01:58<02:51,  5.38it/s, loss=0.0268, v_num=0, val_loss=0.222]#015Epoch 0:  41%|████      | 640/1563 [01:58<02:51,  5.38it/s, loss=0.0268, v_num=0, val_loss=0.222]#015Epoch 0:  44%|████▎     | 680/1563 [02:06<02:44,  5.38it/s, loss=0.0268, v_num=0, val_loss=0.222]#015Epoch 0:  44%|████▎     | 680/1563 [02:06<02:44,  5.38it/s, loss=0.0275, v_num=0, val_loss=0.222]#015Epoch 0:  46%|████▌     | 720/1563 [02:13<02:36,  5.38it/s, loss=0.0275, v_num=0, val_loss=0.222]#015Epoch 0:  46%|████▌     | 720/1563 [02:13<02:36,  5.38it/s, loss=0.0273, v_num=0, val_loss=0.222]#015Epoch 0:  49%|████▊     | 760/1563 [02:21<02:29,  5.38it/s, loss=0.0273, v_num=0, val_loss=0.222]#015Epoch 0:  49%|████▊     | 760/1563 [02:21<02:29,  5.38it/s, loss=0.026, v_num=0, val_loss=0.222] #015Epoch 0:  51%|█████     | 800/1563 [02:28<02:21,  5.38it/s, loss=0.026, v_num=0, val_loss=0.222]#015Epoch 0:  51%|█████     | 800/1563 [02:28<02:21,  5.38it/s, loss=0.0274, v_num=0, val_loss=0.222]#015Epoch 0:  54%|█████▎    | 840/1563 [02:36<02:14,  5.37it/s, loss=0.0274, v_num=0, val_loss=0.222]#015Epoch 0:  54%|█████▎    | 840/1563 [02:36<02:14,  5.37it/s, loss=0.0265, v_num=0, val_loss=0.222]#015Epoch 0:  56%|█████▋    | 880/1563 [02:43<02:07,  5.37it/s, loss=0.0265, v_num=0, val_loss=0.222]#015Epoch 0:  56%|█████▋    | 880/1563 [02:43<02:07,  5.37it/s, loss=0.0254, v_num=0, val_loss=0.222]#015Epoch 0:  59%|█████▉    | 920/1563 [02:51<01:59,  5.37it/s, loss=0.0254, v_num=0, val_loss=0.222]#015Epoch 0:  59%|█████▉    | 920/1563 [02:51<01:59,  5.37it/s, loss=0.0259, v_num=0, val_loss=0.222]#015Epoch 0:  61%|██████▏   | 960/1563 [02:58<01:52,  5.37it/s, loss=0.0259, v_num=0, val_loss=0.222]#015Epoch 0:  61%|██████▏   | 960/1563 [02:58<01:52,  5.37it/s, loss=0.0248, v_num=0, val_loss=0.222]#015Epoch 0:  64%|██████▍   | 1000/1563 [03:06<01:44,  5.38it/s, loss=0.0248, v_num=0, val_loss=0.222]#015Epoch 0:  64%|██████▍   | 1000/1563 [03:06<01:44,  5.38it/s, loss=0.0255, v_num=0, val_loss=0.222]#015Epoch 0:  67%|██████▋   | 1040/1563 [03:13<01:37,  5.38it/s, loss=0.0255, v_num=0, val_loss=0.222]#015Epoch 0:  67%|██████▋   | 1040/1563 [03:13<01:37,  5.38it/s, loss=0.0247, v_num=0, val_loss=0.222]#015Epoch 0:  69%|██████▉   | 1080/1563 [03:20<01:29,  5.38it/s, loss=0.0247, v_num=0, val_loss=0.222]#015Epoch 0:  69%|██████▉   | 1080/1563 [03:20<01:29,  5.38it/s, loss=0.0249, v_num=0, val_loss=0.222]#015Epoch 0:  72%|███████▏  | 1120/1563 [03:28<01:22,  5.38it/s, loss=0.0249, v_num=0, val_loss=0.222]#015Epoch 0:  72%|███████▏  | 1120/1563 [03:28<01:22,  5.38it/s, loss=0.0246, v_num=0, val_loss=0.222]#015Epoch 0:  74%|███████▍  | 1160/1563 [03:35<01:14,  5.39it/s, loss=0.0246, v_num=0, val_loss=0.222]#015Epoch 0:  74%|███████▍  | 1160/1563 [03:35<01:14,  5.39it/s, loss=0.0243, v_num=0, val_loss=0.222]#015Epoch 0:  77%|███████▋  | 1200/1563 [03:42<01:07,  5.38it/s, loss=0.0243, v_num=0, val_loss=0.222]#015Epoch 0:  77%|███████▋  | 1200/1563 [03:42<01:07,  5.38it/s, loss=0.0244, v_num=0, val_loss=0.222]#015Epoch 0:  79%|███████▉  | 1240/1563 [03:50<01:00,  5.38it/s, loss=0.0244, v_num=0, val_loss=0.222]#015Epoch 0:  79%|███████▉  | 1240/1563 [03:50<01:00,  5.38it/s, loss=0.0241, v_num=0, val_loss=0.222]#015Epoch 0:  82%|████████▏ | 1280/1563 [03:52<00:51,  5.49it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.81it/s]#033[A#015Epoch 0:  84%|████████▍ | 1320/1563 [03:55<00:43,  5.60it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.26it/s]#033[A#015Epoch 0:  87%|████████▋ | 1360/1563 [03:57<00:35,  5.72it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.72it/s]#033[A#015Epoch 0:  90%|████████▉ | 1400/1563 [04:00<00:27,  5.83it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 17.10it/s]#033[A#015Epoch 0:  92%|█████████▏| 1440/1563 [04:02<00:20,  5.94it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 17.34it/s]#033[A#015Epoch 0:  95%|█████████▍| 1480/1563 [04:04<00:13,  6.05it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:13<00:04, 17.41it/s]#033[A#015Epoch 0:  97%|█████████▋| 1520/1563 [04:06<00:06,  6.16it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.39it/s]#033[A#015Epoch 0: 100%|█████████▉| 1560/1563 [04:09<00:00,  6.26it/s, loss=0.0241, v_num=0, val_loss=0.222]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:17<00:00, 17.41it/s]#033[A#015Epoch 0: 100%|██████████| 1563/1563 [04:10<00:00,  6.23it/s, loss=0.0235, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0235, v_num=0, val_loss=0.0381, train_loss=0.0334]           #015Epoch 1:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0235, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s, loss=0.0235, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s, loss=0.0245, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   5%|▌         | 80/1563 [00:15<04:42,  5.25it/s, loss=0.0245, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   5%|▌         | 80/1563 [00:15<04:42,  5.24it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   8%|▊         | 120/1563 [00:22<04:31,  5.31it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:   8%|▊         | 120/1563 [00:22<04:32,  5.31it/s, loss=0.0247, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  10%|█         | 160/1563 [00:30<04:24,  5.31it/s, loss=0.0247, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  10%|█         | 160/1563 [00:30<04:24,  5.31it/s, loss=0.0237, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  13%|█▎        | 200/1563 [00:37<04:15,  5.33it/s, loss=0.0237, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  13%|█▎        | 200/1563 [00:37<04:15,  5.33it/s, loss=0.023, v_num=0, val_loss=0.0381, train_loss=0.0334] #015Epoch 1:  15%|█▌        | 240/1563 [00:44<04:07,  5.34it/s, loss=0.023, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  15%|█▌        | 240/1563 [00:44<04:07,  5.34it/s, loss=0.023, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  18%|█▊        | 280/1563 [00:52<04:00,  5.34it/s, loss=0.023, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  18%|█▊        | 280/1563 [00:52<04:00,  5.34it/s, loss=0.0221, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.0221, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.0229, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.0229, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.0224, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  26%|██▌       | 400/1563 [01:14<03:37,  5.34it/s, loss=0.0224, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  26%|██▌       | 400/1563 [01:14<03:37,  5.34it/s, loss=0.0229, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  28%|██▊       | 440/1563 [01:22<03:30,  5.35it/s, loss=0.0229, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  28%|██▊       | 440/1563 [01:22<03:30,  5.35it/s, loss=0.0225, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  31%|███       | 480/1563 [01:30<03:23,  5.33it/s, loss=0.0225, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  31%|███       | 480/1563 [01:30<03:23,  5.33it/s, loss=0.0233, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  33%|███▎      | 520/1563 [01:37<03:15,  5.33it/s, loss=0.0233, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  33%|███▎      | 520/1563 [01:37<03:15,  5.33it/s, loss=0.0233, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  36%|███▌      | 560/1563 [01:45<03:08,  5.33it/s, loss=0.0233, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  36%|███▌      | 560/1563 [01:45<03:08,  5.33it/s, loss=0.0227, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0227, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0222, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  41%|████      | 640/1563 [01:59<02:53,  5.33it/s, loss=0.0222, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  41%|████      | 640/1563 [01:59<02:53,  5.33it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  44%|████▎     | 680/1563 [02:07<02:45,  5.34it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  44%|████▎     | 680/1563 [02:07<02:45,  5.34it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  46%|████▌     | 720/1563 [02:14<02:37,  5.34it/s, loss=0.0231, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  46%|████▌     | 720/1563 [02:14<02:37,  5.34it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  51%|█████     | 800/1563 [02:29<02:23,  5.33it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  51%|█████     | 800/1563 [02:29<02:23,  5.33it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0223, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  56%|█████▋    | 880/1563 [02:44<02:07,  5.34it/s, loss=0.0223, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  56%|█████▋    | 880/1563 [02:44<02:07,  5.34it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  59%|█████▉    | 920/1563 [02:52<02:00,  5.34it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  59%|█████▉    | 920/1563 [02:52<02:00,  5.34it/s, loss=0.0213, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0213, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.0217, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.021, v_num=0, val_loss=0.0381, train_loss=0.0334] #015Epoch 1:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.021, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.35it/s, loss=0.0215, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.35it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  72%|███████▏  | 1120/1563 [03:29<01:23,  5.34it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  72%|███████▏  | 1120/1563 [03:29<01:23,  5.34it/s, loss=0.0221, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.34it/s, loss=0.0221, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.34it/s, loss=0.0212, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.34it/s, loss=0.0212, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.34it/s, loss=0.0205, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0205, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]#015Epoch 1:  82%|████████▏ | 1280/1563 [03:54<00:51,  5.46it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.80it/s]#033[A#015Epoch 1:  84%|████████▍ | 1320/1563 [03:56<00:43,  5.57it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.27it/s]#033[A#015Epoch 1:  87%|████████▋ | 1360/1563 [03:59<00:35,  5.69it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.55it/s]#033[A#015Epoch 1:  90%|████████▉ | 1400/1563 [04:01<00:28,  5.80it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 16.79it/s]#033[A#015Epoch 1:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.91it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.89it/s]#033[A#015Epoch 1:  95%|█████████▍| 1480/1563 [04:06<00:13,  6.01it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:14<00:04, 17.01it/s]#033[A#015Epoch 1:  97%|█████████▋| 1520/1563 [04:08<00:07,  6.12it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.07it/s]#033[A#015Epoch 1: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.22it/s, loss=0.0216, v_num=0, val_loss=0.0381, train_loss=0.0334]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.24it/s]#033[A#015Epoch 1: 100%|██████████| 1563/1563 [04:12<00:00,  6.19it/s, loss=0.021, v_num=0, val_loss=0.0346, train_loss=0.0224] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.021, v_num=0, val_loss=0.0346, train_loss=0.0224]           #015Epoch 2:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.021, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:   3%|▎         | 40/1563 [00:07<04:53,  5.20it/s, loss=0.021, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:   3%|▎         | 40/1563 [00:07<04:53,  5.20it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224] #015Epoch 2:   5%|▌         | 80/1563 [00:15<04:42,  5.25it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:   5%|▌         | 80/1563 [00:15<04:42,  5.25it/s, loss=0.0206, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:   8%|▊         | 120/1563 [00:22<04:34,  5.26it/s, loss=0.0206, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:   8%|▊         | 120/1563 [00:22<04:34,  5.26it/s, loss=0.0211, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  10%|█         | 160/1563 [00:30<04:25,  5.28it/s, loss=0.0211, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  10%|█         | 160/1563 [00:30<04:25,  5.28it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]  #015Epoch 2:  13%|█▎        | 200/1563 [00:37<04:16,  5.30it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  13%|█▎        | 200/1563 [00:37<04:16,  5.30it/s, loss=0.0206, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  15%|█▌        | 240/1563 [00:45<04:09,  5.31it/s, loss=0.0206, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  15%|█▌        | 240/1563 [00:45<04:09,  5.31it/s, loss=0.0209, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.0209, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.0211, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  20%|██        | 320/1563 [01:00<03:53,  5.32it/s, loss=0.0211, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  20%|██        | 320/1563 [01:00<03:53,  5.32it/s, loss=0.0216, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.0216, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]  #015Epoch 2:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  28%|██▊       | 440/1563 [01:22<03:30,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  28%|██▊       | 440/1563 [01:22<03:30,  5.33it/s, loss=0.0204, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  31%|███       | 480/1563 [01:30<03:23,  5.32it/s, loss=0.0204, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  31%|███       | 480/1563 [01:30<03:23,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  33%|███▎      | 520/1563 [01:37<03:15,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  33%|███▎      | 520/1563 [01:37<03:15,  5.32it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  36%|███▌      | 560/1563 [01:45<03:08,  5.32it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  36%|███▌      | 560/1563 [01:45<03:08,  5.32it/s, loss=0.0203, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0203, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0202, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0202, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0203, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0203, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0198, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  46%|████▌     | 720/1563 [02:15<02:38,  5.32it/s, loss=0.0198, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  46%|████▌     | 720/1563 [02:15<02:38,  5.32it/s, loss=0.0199, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  49%|████▊     | 760/1563 [02:22<02:30,  5.32it/s, loss=0.0199, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  49%|████▊     | 760/1563 [02:22<02:30,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  51%|█████     | 800/1563 [02:30<02:23,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  51%|█████     | 800/1563 [02:30<02:23,  5.32it/s, loss=0.0204, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  54%|█████▎    | 840/1563 [02:37<02:15,  5.32it/s, loss=0.0204, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  54%|█████▎    | 840/1563 [02:37<02:15,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  56%|█████▋    | 880/1563 [02:45<02:08,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  56%|█████▋    | 880/1563 [02:45<02:08,  5.32it/s, loss=0.0196, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.0196, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]  #015Epoch 2:  61%|██████▏   | 960/1563 [03:00<01:53,  5.33it/s, loss=0.02, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  61%|██████▏   | 960/1563 [03:00<01:53,  5.33it/s, loss=0.0205, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.33it/s, loss=0.0205, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  67%|██████▋   | 1040/1563 [03:15<01:38,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  67%|██████▋   | 1040/1563 [03:15<01:38,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.32it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  72%|███████▏  | 1120/1563 [03:30<01:23,  5.32it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  72%|███████▏  | 1120/1563 [03:30<01:23,  5.32it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.33it/s, loss=0.0195, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.33it/s, loss=0.0199, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  77%|███████▋  | 1200/1563 [03:45<01:08,  5.33it/s, loss=0.0199, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  77%|███████▋  | 1200/1563 [03:45<01:08,  5.33it/s, loss=0.0196, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.33it/s, loss=0.0196, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.33it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]#015Epoch 2:  82%|████████▏ | 1280/1563 [03:55<00:51,  5.44it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.71it/s]#033[A#015Epoch 2:  84%|████████▍ | 1320/1563 [03:57<00:43,  5.55it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.15it/s]#033[A#015Epoch 2:  87%|████████▋ | 1360/1563 [04:00<00:35,  5.67it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.50it/s]#033[A#015Epoch 2:  90%|████████▉ | 1400/1563 [04:02<00:28,  5.78it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 16.81it/s]#033[A#015Epoch 2:  92%|█████████▏| 1440/1563 [04:04<00:20,  5.89it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.97it/s]#033[A#015Epoch 2:  95%|█████████▍| 1480/1563 [04:06<00:13,  5.99it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:13<00:04, 17.23it/s]#033[A#015Epoch 2:  97%|█████████▋| 1520/1563 [04:09<00:07,  6.10it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.17it/s]#033[A#015Epoch 2: 100%|█████████▉| 1560/1563 [04:11<00:00,  6.20it/s, loss=0.0201, v_num=0, val_loss=0.0346, train_loss=0.0224]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.36it/s]#033[A#015Epoch 2: 100%|██████████| 1563/1563 [04:13<00:00,  6.17it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 2:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]           #015Epoch 3:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   3%|▎         | 40/1563 [00:08<05:07,  4.95it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   3%|▎         | 40/1563 [00:08<05:07,  4.95it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   5%|▌         | 80/1563 [00:15<04:49,  5.13it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   5%|▌         | 80/1563 [00:15<04:49,  5.13it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   8%|▊         | 120/1563 [00:23<04:36,  5.22it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:   8%|▊         | 120/1563 [00:23<04:36,  5.22it/s, loss=0.0196, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  10%|█         | 160/1563 [00:30<04:26,  5.26it/s, loss=0.0196, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  10%|█         | 160/1563 [00:30<04:26,  5.26it/s, loss=0.0175, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  13%|█▎        | 200/1563 [00:37<04:17,  5.29it/s, loss=0.0175, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  13%|█▎        | 200/1563 [00:37<04:17,  5.29it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  15%|█▌        | 240/1563 [00:45<04:09,  5.30it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  15%|█▌        | 240/1563 [00:45<04:09,  5.30it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  23%|██▎       | 360/1563 [01:07<03:46,  5.31it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  23%|██▎       | 360/1563 [01:07<03:46,  5.31it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  26%|██▌       | 400/1563 [01:15<03:39,  5.31it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  26%|██▌       | 400/1563 [01:15<03:39,  5.31it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  28%|██▊       | 440/1563 [01:22<03:31,  5.31it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  28%|██▊       | 440/1563 [01:22<03:31,  5.31it/s, loss=0.019, v_num=0, val_loss=0.0338, train_loss=0.0202] #015Epoch 3:  31%|███       | 480/1563 [01:30<03:23,  5.32it/s, loss=0.019, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  31%|███       | 480/1563 [01:30<03:23,  5.32it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  33%|███▎      | 520/1563 [01:37<03:16,  5.32it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  33%|███▎      | 520/1563 [01:37<03:16,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  36%|███▌      | 560/1563 [01:45<03:08,  5.32it/s, loss=0.0201, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  36%|███▌      | 560/1563 [01:45<03:08,  5.32it/s, loss=0.0202, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0202, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0193, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0193, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  46%|████▌     | 720/1563 [02:15<02:38,  5.33it/s, loss=0.0192, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  46%|████▌     | 720/1563 [02:15<02:38,  5.33it/s, loss=0.0188, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  49%|████▊     | 760/1563 [02:22<02:30,  5.33it/s, loss=0.0188, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  49%|████▊     | 760/1563 [02:22<02:30,  5.33it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  51%|█████     | 800/1563 [02:30<02:23,  5.33it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  51%|█████     | 800/1563 [02:30<02:23,  5.33it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  54%|█████▎    | 840/1563 [02:37<02:15,  5.33it/s, loss=0.0191, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  54%|█████▎    | 840/1563 [02:37<02:15,  5.33it/s, loss=0.0186, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  56%|█████▋    | 880/1563 [02:45<02:08,  5.33it/s, loss=0.0186, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  56%|█████▋    | 880/1563 [02:45<02:08,  5.33it/s, loss=0.0184, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.0184, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  61%|██████▏   | 960/1563 [03:00<01:53,  5.33it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  61%|██████▏   | 960/1563 [03:00<01:53,  5.33it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.33it/s, loss=0.0189, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.33it/s, loss=0.0187, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  67%|██████▋   | 1040/1563 [03:15<01:38,  5.33it/s, loss=0.0187, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  67%|██████▋   | 1040/1563 [03:15<01:38,  5.33it/s, loss=0.0187, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.33it/s, loss=0.0187, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.33it/s, loss=0.0186, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  72%|███████▏  | 1120/1563 [03:30<01:23,  5.33it/s, loss=0.0186, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  72%|███████▏  | 1120/1563 [03:30<01:23,  5.33it/s, loss=0.0181, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.33it/s, loss=0.0181, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.33it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  77%|███████▋  | 1200/1563 [03:45<01:08,  5.33it/s, loss=0.0197, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  77%|███████▋  | 1200/1563 [03:45<01:08,  5.33it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.33it/s, loss=0.0195, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.33it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]#015Epoch 3:  82%|████████▏ | 1280/1563 [03:54<00:51,  5.45it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:16, 16.14it/s]#033[A#015Epoch 3:  84%|████████▍ | 1320/1563 [03:57<00:43,  5.56it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.36it/s]#033[A#015Epoch 3:  87%|████████▋ | 1360/1563 [03:59<00:35,  5.67it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.33it/s]#033[A#015Epoch 3:  90%|████████▉ | 1400/1563 [04:02<00:28,  5.78it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:09, 16.60it/s]#033[A#015Epoch 3:  92%|█████████▏| 1440/1563 [04:04<00:20,  5.89it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.83it/s]#033[A#015Epoch 3:  95%|█████████▍| 1480/1563 [04:06<00:13,  5.99it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:14<00:04, 16.98it/s]#033[A#015Epoch 3:  97%|█████████▋| 1520/1563 [04:09<00:07,  6.10it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.06it/s]#033[A#015Epoch 3: 100%|█████████▉| 1560/1563 [04:11<00:00,  6.20it/s, loss=0.0182, v_num=0, val_loss=0.0338, train_loss=0.0202]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.28it/s]#033[A#015Epoch 3: 100%|██████████| 1563/1563 [04:13<00:00,  6.17it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 3:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189]           #015Epoch 4:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   3%|▎         | 40/1563 [00:07<04:52,  5.20it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   3%|▎         | 40/1563 [00:07<04:52,  5.20it/s, loss=0.0191, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   5%|▌         | 80/1563 [00:15<04:40,  5.29it/s, loss=0.0191, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   5%|▌         | 80/1563 [00:15<04:40,  5.29it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   8%|▊         | 120/1563 [00:22<04:30,  5.33it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:   8%|▊         | 120/1563 [00:22<04:30,  5.33it/s, loss=0.0179, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  10%|█         | 160/1563 [00:29<04:22,  5.34it/s, loss=0.0179, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  10%|█         | 160/1563 [00:29<04:22,  5.34it/s, loss=0.0181, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  13%|█▎        | 200/1563 [00:37<04:14,  5.35it/s, loss=0.0181, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  13%|█▎        | 200/1563 [00:37<04:14,  5.35it/s, loss=0.0174, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  15%|█▌        | 240/1563 [00:44<04:07,  5.35it/s, loss=0.0174, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  15%|█▌        | 240/1563 [00:44<04:07,  5.35it/s, loss=0.0187, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  18%|█▊        | 280/1563 [00:52<04:00,  5.34it/s, loss=0.0187, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  18%|█▊        | 280/1563 [00:52<04:00,  5.34it/s, loss=0.017, v_num=0, val_loss=0.032, train_loss=0.0189] #015Epoch 4:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.017, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.0178, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.0178, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189] #015Epoch 4:  26%|██▌       | 400/1563 [01:14<03:37,  5.34it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  26%|██▌       | 400/1563 [01:14<03:37,  5.34it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0181, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  31%|███       | 480/1563 [01:29<03:22,  5.34it/s, loss=0.0181, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  31%|███       | 480/1563 [01:29<03:22,  5.34it/s, loss=0.0179, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  33%|███▎      | 520/1563 [01:37<03:15,  5.34it/s, loss=0.0179, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  33%|███▎      | 520/1563 [01:37<03:15,  5.34it/s, loss=0.0172, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  36%|███▌      | 560/1563 [01:44<03:07,  5.34it/s, loss=0.0172, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  36%|███▌      | 560/1563 [01:44<03:07,  5.34it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  38%|███▊      | 600/1563 [01:52<03:00,  5.33it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  41%|████      | 640/1563 [01:59<02:52,  5.34it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  41%|████      | 640/1563 [01:59<02:52,  5.34it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  44%|████▎     | 680/1563 [02:07<02:45,  5.34it/s, loss=0.0186, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  44%|████▎     | 680/1563 [02:07<02:45,  5.34it/s, loss=0.0176, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  46%|████▌     | 720/1563 [02:14<02:37,  5.34it/s, loss=0.0176, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  46%|████▌     | 720/1563 [02:14<02:37,  5.34it/s, loss=0.0176, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0176, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  51%|█████     | 800/1563 [02:29<02:22,  5.34it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  51%|█████     | 800/1563 [02:29<02:22,  5.34it/s, loss=0.0177, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0177, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  56%|█████▋    | 880/1563 [02:44<02:07,  5.34it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  56%|█████▋    | 880/1563 [02:44<02:07,  5.34it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  59%|█████▉    | 920/1563 [02:52<02:00,  5.33it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  61%|██████▏   | 960/1563 [02:59<01:53,  5.33it/s, loss=0.0183, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  61%|██████▏   | 960/1563 [02:59<01:53,  5.33it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189] #015Epoch 4:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.018, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0185, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0182, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.34it/s, loss=0.0182, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.34it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.35it/s, loss=0.0175, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.35it/s, loss=0.0168, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.35it/s, loss=0.0168, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.35it/s, loss=0.0189, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.34it/s, loss=0.0189, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.34it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]#015Epoch 4:  82%|████████▏ | 1280/1563 [03:54<00:51,  5.46it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.65it/s]#033[A#015Epoch 4:  84%|████████▍ | 1320/1563 [03:57<00:43,  5.57it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.12it/s]#033[A#015Epoch 4:  87%|████████▋ | 1360/1563 [03:59<00:35,  5.68it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.47it/s]#033[A#015Epoch 4:  90%|████████▉ | 1400/1563 [04:01<00:28,  5.79it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 16.89it/s]#033[A#015Epoch 4:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.90it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 17.16it/s]#033[A#015Epoch 4:  95%|█████████▍| 1480/1563 [04:06<00:13,  6.01it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:13<00:04, 17.29it/s]#033[A#015Epoch 4:  97%|█████████▋| 1520/1563 [04:08<00:07,  6.12it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.29it/s]#033[A#015Epoch 4: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.22it/s, loss=0.0188, v_num=0, val_loss=0.032, train_loss=0.0189]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:17<00:00, 17.46it/s]#033[A#015Epoch 4: 100%|██████████| 1563/1563 [04:12<00:00,  6.19it/s, loss=0.0186, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 4:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0186, v_num=0, val_loss=0.0317, train_loss=0.018]           #015Epoch 5:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0186, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s, loss=0.0186, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   3%|▎         | 40/1563 [00:07<04:54,  5.17it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   5%|▌         | 80/1563 [00:15<04:42,  5.24it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   5%|▌         | 80/1563 [00:15<04:42,  5.24it/s, loss=0.0178, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   8%|▊         | 120/1563 [00:22<04:32,  5.29it/s, loss=0.0178, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:   8%|▊         | 120/1563 [00:22<04:32,  5.29it/s, loss=0.0172, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  10%|█         | 160/1563 [00:30<04:24,  5.31it/s, loss=0.0172, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  10%|█         | 160/1563 [00:30<04:24,  5.31it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  13%|█▎        | 200/1563 [00:37<04:17,  5.28it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  13%|█▎        | 200/1563 [00:37<04:17,  5.28it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  15%|█▌        | 240/1563 [00:45<04:10,  5.29it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  15%|█▌        | 240/1563 [00:45<04:10,  5.29it/s, loss=0.0175, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  18%|█▊        | 280/1563 [00:52<04:01,  5.30it/s, loss=0.0175, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  18%|█▊        | 280/1563 [00:52<04:01,  5.30it/s, loss=0.0184, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0184, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  26%|██▌       | 400/1563 [01:14<03:37,  5.35it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  26%|██▌       | 400/1563 [01:14<03:37,  5.35it/s, loss=0.018, v_num=0, val_loss=0.0317, train_loss=0.018] #015Epoch 5:  28%|██▊       | 440/1563 [01:22<03:29,  5.36it/s, loss=0.018, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  28%|██▊       | 440/1563 [01:22<03:29,  5.36it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  31%|███       | 480/1563 [01:29<03:21,  5.37it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  31%|███       | 480/1563 [01:29<03:21,  5.37it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.0171, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.0171, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.0175, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  38%|███▊      | 600/1563 [01:52<03:00,  5.35it/s, loss=0.0175, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  38%|███▊      | 600/1563 [01:52<03:00,  5.35it/s, loss=0.018, v_num=0, val_loss=0.0317, train_loss=0.018] #015Epoch 5:  41%|████      | 640/1563 [01:59<02:52,  5.35it/s, loss=0.018, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  41%|████      | 640/1563 [01:59<02:52,  5.35it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.0169, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0176, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  49%|████▊     | 760/1563 [02:21<02:29,  5.36it/s, loss=0.0176, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  49%|████▊     | 760/1563 [02:21<02:29,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  51%|█████     | 800/1563 [02:29<02:22,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  51%|█████     | 800/1563 [02:29<02:22,  5.36it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  59%|█████▉    | 920/1563 [02:51<01:59,  5.36it/s, loss=0.0174, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  59%|█████▉    | 920/1563 [02:51<01:59,  5.36it/s, loss=0.0179, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0179, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0177, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.36it/s, loss=0.0177, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.36it/s, loss=0.0172, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  67%|██████▋   | 1040/1563 [03:13<01:37,  5.36it/s, loss=0.0172, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  67%|██████▋   | 1040/1563 [03:13<01:37,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  72%|███████▏  | 1120/1563 [03:28<01:22,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  72%|███████▏  | 1120/1563 [03:28<01:22,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.0181, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.0176, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0176, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]#015Epoch 5:  82%|████████▏ | 1280/1563 [03:53<00:51,  5.47it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.92it/s]#033[A#015Epoch 5:  84%|████████▍ | 1320/1563 [03:56<00:43,  5.58it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.39it/s]#033[A#015Epoch 5:  87%|████████▋ | 1360/1563 [03:58<00:35,  5.70it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.63it/s]#033[A#015Epoch 5:  90%|████████▉ | 1400/1563 [04:01<00:28,  5.81it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:09, 16.25it/s]#033[A#015Epoch 5:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.91it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.64it/s]#033[A#015Epoch 5:  95%|█████████▍| 1480/1563 [04:05<00:13,  6.02it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:14<00:04, 16.99it/s]#033[A#015Epoch 5:  97%|█████████▋| 1520/1563 [04:08<00:07,  6.12it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.28it/s]#033[A#015Epoch 5: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.23it/s, loss=0.0168, v_num=0, val_loss=0.0317, train_loss=0.018]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.53it/s]#033[A#015Epoch 5: 100%|██████████| 1563/1563 [04:12<00:00,  6.20it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 5:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]           #015Epoch 6:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   3%|▎         | 40/1563 [00:07<04:50,  5.24it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   3%|▎         | 40/1563 [00:07<04:50,  5.24it/s, loss=0.0171, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   5%|▌         | 80/1563 [00:15<04:38,  5.32it/s, loss=0.0171, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   5%|▌         | 80/1563 [00:15<04:38,  5.32it/s, loss=0.0163, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   8%|▊         | 120/1563 [00:22<04:33,  5.27it/s, loss=0.0163, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:   8%|▊         | 120/1563 [00:22<04:33,  5.27it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  10%|█         | 160/1563 [00:30<04:25,  5.28it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  10%|█         | 160/1563 [00:30<04:25,  5.28it/s, loss=0.0161, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  13%|█▎        | 200/1563 [00:37<04:17,  5.30it/s, loss=0.0161, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  13%|█▎        | 200/1563 [00:37<04:17,  5.30it/s, loss=0.0172, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  15%|█▌        | 240/1563 [00:45<04:08,  5.31it/s, loss=0.0172, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  15%|█▌        | 240/1563 [00:45<04:08,  5.31it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  18%|█▊        | 280/1563 [00:52<04:01,  5.32it/s, loss=0.017, v_num=0, val_loss=0.0318, train_loss=0.0173] #015Epoch 6:  20%|██        | 320/1563 [01:00<03:53,  5.33it/s, loss=0.017, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  20%|██        | 320/1563 [01:00<03:53,  5.33it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  23%|██▎       | 360/1563 [01:07<03:45,  5.34it/s, loss=0.0172, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  26%|██▌       | 400/1563 [01:14<03:37,  5.35it/s, loss=0.0172, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  26%|██▌       | 400/1563 [01:14<03:37,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0159, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  31%|███       | 480/1563 [01:29<03:22,  5.35it/s, loss=0.0161, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  31%|███       | 480/1563 [01:29<03:22,  5.35it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  36%|███▌      | 560/1563 [01:44<03:07,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  36%|███▌      | 560/1563 [01:44<03:07,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  38%|███▊      | 600/1563 [01:52<02:59,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  38%|███▊      | 600/1563 [01:52<02:59,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  41%|████      | 640/1563 [01:59<02:52,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  41%|████      | 640/1563 [01:59<02:52,  5.36it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  44%|████▎     | 680/1563 [02:06<02:44,  5.37it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  44%|████▎     | 680/1563 [02:06<02:44,  5.37it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  46%|████▌     | 720/1563 [02:13<02:36,  5.37it/s, loss=0.0169, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  46%|████▌     | 720/1563 [02:13<02:36,  5.37it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  49%|████▊     | 760/1563 [02:21<02:29,  5.37it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  49%|████▊     | 760/1563 [02:21<02:29,  5.37it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  51%|█████     | 800/1563 [02:29<02:22,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  51%|█████     | 800/1563 [02:29<02:22,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  54%|█████▎    | 840/1563 [02:36<02:14,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  54%|█████▎    | 840/1563 [02:36<02:14,  5.36it/s, loss=0.018, v_num=0, val_loss=0.0318, train_loss=0.0173] #015Epoch 6:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.018, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  59%|█████▉    | 920/1563 [02:51<01:59,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  59%|█████▉    | 920/1563 [02:51<01:59,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.36it/s, loss=0.0168, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.36it/s, loss=0.0167, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.35it/s, loss=0.0162, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.35it/s, loss=0.016, v_num=0, val_loss=0.0318, train_loss=0.0173] #015Epoch 6:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.016, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.016, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.016, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0166, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.35it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]#015Epoch 6:  82%|████████▏ | 1280/1563 [03:53<00:51,  5.47it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:16, 16.00it/s]#033[A#015Epoch 6:  84%|████████▍ | 1320/1563 [03:56<00:43,  5.58it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.49it/s]#033[A#015Epoch 6:  87%|████████▋ | 1360/1563 [03:58<00:35,  5.70it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:06<00:11, 16.91it/s]#033[A#015Epoch 6:  90%|████████▉ | 1400/1563 [04:00<00:28,  5.81it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 17.18it/s]#033[A#015Epoch 6:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.92it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 17.42it/s]#033[A#015Epoch 6:  95%|█████████▍| 1480/1563 [04:05<00:13,  6.03it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:13<00:04, 17.59it/s]#033[A#015Epoch 6:  97%|█████████▋| 1520/1563 [04:07<00:07,  6.14it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:15<00:01, 17.52it/s]#033[A#015Epoch 6: 100%|█████████▉| 1560/1563 [04:09<00:00,  6.24it/s, loss=0.0157, v_num=0, val_loss=0.0318, train_loss=0.0173]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:17<00:00, 17.62it/s]#033[A#015Epoch 6: 100%|██████████| 1563/1563 [04:11<00:00,  6.21it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 6:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]           #015Epoch 7:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   3%|▎         | 40/1563 [00:07<04:56,  5.14it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   3%|▎         | 40/1563 [00:07<04:56,  5.14it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   5%|▌         | 80/1563 [00:15<04:44,  5.21it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   5%|▌         | 80/1563 [00:15<04:44,  5.21it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   8%|▊         | 120/1563 [00:22<04:33,  5.27it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:   8%|▊         | 120/1563 [00:22<04:33,  5.27it/s, loss=0.016, v_num=0, val_loss=0.0316, train_loss=0.0167] #015Epoch 7:  10%|█         | 160/1563 [00:30<04:24,  5.30it/s, loss=0.016, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  10%|█         | 160/1563 [00:30<04:24,  5.30it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  13%|█▎        | 200/1563 [00:37<04:16,  5.32it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  13%|█▎        | 200/1563 [00:37<04:16,  5.32it/s, loss=0.0152, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  15%|█▌        | 240/1563 [00:45<04:08,  5.33it/s, loss=0.0152, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  15%|█▌        | 240/1563 [00:45<04:08,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  18%|█▊        | 280/1563 [00:52<04:00,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  18%|█▊        | 280/1563 [00:52<04:00,  5.33it/s, loss=0.0163, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.0163, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  20%|██        | 320/1563 [00:59<03:52,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  23%|██▎       | 360/1563 [01:07<03:45,  5.33it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  28%|██▊       | 440/1563 [01:22<03:30,  5.34it/s, loss=0.0168, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  31%|███       | 480/1563 [01:29<03:22,  5.34it/s, loss=0.0168, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  31%|███       | 480/1563 [01:29<03:22,  5.34it/s, loss=0.0158, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  33%|███▎      | 520/1563 [01:37<03:15,  5.34it/s, loss=0.0158, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  33%|███▎      | 520/1563 [01:37<03:15,  5.34it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.0169, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  38%|███▊      | 600/1563 [01:52<02:59,  5.35it/s, loss=0.0169, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  38%|███▊      | 600/1563 [01:52<02:59,  5.35it/s, loss=0.0165, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  41%|████      | 640/1563 [01:59<02:52,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  41%|████      | 640/1563 [01:59<02:52,  5.36it/s, loss=0.017, v_num=0, val_loss=0.0316, train_loss=0.0167] #015Epoch 7:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.017, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0167, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  49%|████▊     | 760/1563 [02:22<02:30,  5.35it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  49%|████▊     | 760/1563 [02:22<02:30,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  51%|█████     | 800/1563 [02:29<02:22,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  51%|█████     | 800/1563 [02:29<02:22,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.0159, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.0156, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  56%|█████▋    | 880/1563 [02:44<02:07,  5.36it/s, loss=0.0165, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  59%|█████▉    | 920/1563 [02:51<02:00,  5.35it/s, loss=0.0165, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  59%|█████▉    | 920/1563 [02:51<02:00,  5.35it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0166, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  61%|██████▏   | 960/1563 [02:59<01:52,  5.36it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.36it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  64%|██████▍   | 1000/1563 [03:06<01:45,  5.35it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.35it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.35it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.35it/s, loss=0.0171, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  69%|██████▉   | 1080/1563 [03:21<01:30,  5.35it/s, loss=0.0156, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.36it/s, loss=0.0155, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  77%|███████▋  | 1200/1563 [03:43<01:07,  5.36it/s, loss=0.0155, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  77%|███████▋  | 1200/1563 [03:43<01:07,  5.36it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.36it/s, loss=0.0161, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.36it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]#015Epoch 7:  82%|████████▏ | 1280/1563 [03:53<00:51,  5.48it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.63it/s]#033[A#015Epoch 7:  84%|████████▍ | 1320/1563 [03:56<00:43,  5.59it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.15it/s]#033[A#015Epoch 7:  87%|████████▋ | 1360/1563 [03:58<00:35,  5.70it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.46it/s]#033[A#015Epoch 7:  90%|████████▉ | 1400/1563 [04:00<00:28,  5.81it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:09, 16.72it/s]#033[A#015Epoch 7:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.92it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.93it/s]#033[A#015Epoch 7:  95%|█████████▍| 1480/1563 [04:05<00:13,  6.03it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:14<00:04, 17.02it/s]#033[A#015Epoch 7:  97%|█████████▋| 1520/1563 [04:07<00:07,  6.13it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 16.87it/s]#033[A#015Epoch 7: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.23it/s, loss=0.0162, v_num=0, val_loss=0.0316, train_loss=0.0167]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.23it/s]#033[A#015Epoch 7: 100%|██████████| 1563/1563 [04:12<00:00,  6.20it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 7:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]           #015Epoch 8:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   3%|▎         | 40/1563 [00:07<04:53,  5.19it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   3%|▎         | 40/1563 [00:07<04:53,  5.19it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   5%|▌         | 80/1563 [00:15<04:40,  5.29it/s, loss=0.0161, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   5%|▌         | 80/1563 [00:15<04:40,  5.29it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   8%|▊         | 120/1563 [00:22<04:31,  5.31it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:   8%|▊         | 120/1563 [00:22<04:31,  5.31it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  10%|█         | 160/1563 [00:30<04:23,  5.33it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  10%|█         | 160/1563 [00:30<04:23,  5.33it/s, loss=0.0152, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  13%|█▎        | 200/1563 [00:37<04:15,  5.33it/s, loss=0.0152, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  13%|█▎        | 200/1563 [00:37<04:15,  5.33it/s, loss=0.0159, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  15%|█▌        | 240/1563 [00:45<04:08,  5.32it/s, loss=0.0159, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  15%|█▌        | 240/1563 [00:45<04:08,  5.32it/s, loss=0.016, v_num=0, val_loss=0.0313, train_loss=0.0162] #015Epoch 8:  18%|█▊        | 280/1563 [00:52<04:00,  5.32it/s, loss=0.016, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  18%|█▊        | 280/1563 [00:52<04:00,  5.32it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  20%|██        | 320/1563 [01:00<03:53,  5.31it/s, loss=0.0157, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  23%|██▎       | 360/1563 [01:07<03:46,  5.32it/s, loss=0.0157, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  23%|██▎       | 360/1563 [01:07<03:46,  5.32it/s, loss=0.0151, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.0151, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  26%|██▌       | 400/1563 [01:15<03:38,  5.33it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  28%|██▊       | 440/1563 [01:22<03:30,  5.33it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  28%|██▊       | 440/1563 [01:22<03:30,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  31%|███       | 480/1563 [01:30<03:23,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  31%|███       | 480/1563 [01:30<03:23,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  33%|███▎      | 520/1563 [01:37<03:15,  5.33it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  33%|███▎      | 520/1563 [01:37<03:15,  5.33it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  36%|███▌      | 560/1563 [01:45<03:08,  5.33it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  36%|███▌      | 560/1563 [01:45<03:08,  5.33it/s, loss=0.0162, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  38%|███▊      | 600/1563 [01:52<03:00,  5.34it/s, loss=0.0162, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  38%|███▊      | 600/1563 [01:52<03:00,  5.34it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  41%|████      | 640/1563 [02:00<02:53,  5.33it/s, loss=0.0164, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0164, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  44%|████▎     | 680/1563 [02:07<02:45,  5.33it/s, loss=0.0165, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  46%|████▌     | 720/1563 [02:15<02:38,  5.33it/s, loss=0.0165, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  46%|████▌     | 720/1563 [02:15<02:38,  5.33it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  49%|████▊     | 760/1563 [02:22<02:30,  5.34it/s, loss=0.0146, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  51%|█████     | 800/1563 [02:29<02:22,  5.34it/s, loss=0.0146, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  51%|█████     | 800/1563 [02:29<02:22,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  54%|█████▎    | 840/1563 [02:37<02:15,  5.34it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  56%|█████▋    | 880/1563 [02:44<02:07,  5.35it/s, loss=0.0153, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  56%|█████▋    | 880/1563 [02:44<02:07,  5.35it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  59%|█████▉    | 920/1563 [02:52<02:00,  5.35it/s, loss=0.0155, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  59%|█████▉    | 920/1563 [02:52<02:00,  5.35it/s, loss=0.0152, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0152, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.0159, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0159, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0162, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.35it/s, loss=0.0162, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  72%|███████▏  | 1120/1563 [03:29<01:22,  5.35it/s, loss=0.0154, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.35it/s, loss=0.0154, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  74%|███████▍  | 1160/1563 [03:36<01:15,  5.35it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.36it/s, loss=0.0157, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.36it/s, loss=0.0157, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  79%|███████▉  | 1240/1563 [03:51<01:00,  5.36it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]#015Epoch 8:  82%|████████▏ | 1280/1563 [03:53<00:51,  5.48it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.24it/s]#033[A#015Epoch 8:  84%|████████▍ | 1320/1563 [03:56<00:43,  5.58it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 15.78it/s]#033[A#015Epoch 8:  87%|████████▋ | 1360/1563 [03:58<00:35,  5.70it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.29it/s]#033[A#015Epoch 8:  90%|████████▉ | 1400/1563 [04:01<00:28,  5.81it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:09, 16.59it/s]#033[A#015Epoch 8:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.92it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 16.76it/s]#033[A#015Epoch 8:  95%|█████████▍| 1480/1563 [04:05<00:13,  6.03it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:14<00:04, 16.92it/s]#033[A#015Epoch 8:  97%|█████████▋| 1520/1563 [04:07<00:07,  6.13it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.12it/s]#033[A#015Epoch 8: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.23it/s, loss=0.0158, v_num=0, val_loss=0.0313, train_loss=0.0162]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:18<00:00, 17.20it/s]#033[A#015Epoch 8: 100%|██████████| 1563/1563 [04:12<00:00,  6.20it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 8:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]           #015Epoch 9:   0%|          | 0/1563 [00:00<?, ?it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   3%|▎         | 40/1563 [00:07<04:45,  5.34it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   3%|▎         | 40/1563 [00:07<04:45,  5.34it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   5%|▌         | 80/1563 [00:14<04:35,  5.38it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   5%|▌         | 80/1563 [00:14<04:35,  5.38it/s, loss=0.0157, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   8%|▊         | 120/1563 [00:22<04:27,  5.39it/s, loss=0.0157, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:   8%|▊         | 120/1563 [00:22<04:27,  5.39it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  10%|█         | 160/1563 [00:29<04:20,  5.39it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  10%|█         | 160/1563 [00:29<04:20,  5.39it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  13%|█▎        | 200/1563 [00:37<04:12,  5.39it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  13%|█▎        | 200/1563 [00:37<04:12,  5.39it/s, loss=0.0138, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  15%|█▌        | 240/1563 [00:44<04:06,  5.38it/s, loss=0.0138, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  15%|█▌        | 240/1563 [00:44<04:06,  5.38it/s, loss=0.0145, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  18%|█▊        | 280/1563 [00:52<03:59,  5.36it/s, loss=0.0145, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  18%|█▊        | 280/1563 [00:52<03:59,  5.36it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  20%|██        | 320/1563 [00:59<03:51,  5.36it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  20%|██        | 320/1563 [00:59<03:51,  5.36it/s, loss=0.0145, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  23%|██▎       | 360/1563 [01:07<03:44,  5.36it/s, loss=0.0145, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  23%|██▎       | 360/1563 [01:07<03:44,  5.36it/s, loss=0.0157, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  26%|██▌       | 400/1563 [01:14<03:37,  5.36it/s, loss=0.0157, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  26%|██▌       | 400/1563 [01:14<03:37,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  28%|██▊       | 440/1563 [01:22<03:29,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  28%|██▊       | 440/1563 [01:22<03:29,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  31%|███       | 480/1563 [01:29<03:22,  5.36it/s, loss=0.0156, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  31%|███       | 480/1563 [01:29<03:22,  5.36it/s, loss=0.0158, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.0158, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  33%|███▎      | 520/1563 [01:37<03:14,  5.36it/s, loss=0.016, v_num=0, val_loss=0.0317, train_loss=0.0157] #015Epoch 9:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.016, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  36%|███▌      | 560/1563 [01:44<03:07,  5.35it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  38%|███▊      | 600/1563 [01:52<03:00,  5.35it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  38%|███▊      | 600/1563 [01:52<03:00,  5.35it/s, loss=0.0154, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  41%|████      | 640/1563 [01:59<02:52,  5.35it/s, loss=0.0154, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  41%|████      | 640/1563 [01:59<02:52,  5.35it/s, loss=0.0163, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.0163, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  44%|████▎     | 680/1563 [02:07<02:44,  5.35it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  46%|████▌     | 720/1563 [02:14<02:37,  5.35it/s, loss=0.0148, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  49%|████▊     | 760/1563 [02:22<02:30,  5.35it/s, loss=0.0148, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  49%|████▊     | 760/1563 [02:22<02:30,  5.35it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  51%|█████     | 800/1563 [02:29<02:22,  5.35it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  51%|█████     | 800/1563 [02:29<02:22,  5.35it/s, loss=0.0149, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.0149, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  54%|█████▎    | 840/1563 [02:36<02:15,  5.35it/s, loss=0.015, v_num=0, val_loss=0.0317, train_loss=0.0157] #015Epoch 9:  56%|█████▋    | 880/1563 [02:44<02:07,  5.35it/s, loss=0.015, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  56%|█████▋    | 880/1563 [02:44<02:07,  5.35it/s, loss=0.0154, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  59%|█████▉    | 920/1563 [02:52<02:00,  5.34it/s, loss=0.0154, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  59%|█████▉    | 920/1563 [02:52<02:00,  5.34it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  61%|██████▏   | 960/1563 [02:59<01:52,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  64%|██████▍   | 1000/1563 [03:07<01:45,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  67%|██████▋   | 1040/1563 [03:14<01:37,  5.34it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  69%|██████▉   | 1080/1563 [03:22<01:30,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  72%|███████▏  | 1120/1563 [03:29<01:23,  5.34it/s, loss=0.0161, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  72%|███████▏  | 1120/1563 [03:29<01:23,  5.34it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.34it/s, loss=0.0151, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  74%|███████▍  | 1160/1563 [03:37<01:15,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.34it/s, loss=0.0147, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  77%|███████▋  | 1200/1563 [03:44<01:07,  5.34it/s, loss=0.016, v_num=0, val_loss=0.0317, train_loss=0.0157] #015Epoch 9:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.34it/s, loss=0.016, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  79%|███████▉  | 1240/1563 [03:52<01:00,  5.34it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]#015Epoch 9:  82%|████████▏ | 1280/1563 [03:54<00:51,  5.46it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/311 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  13%|█▎        | 40/311 [00:02<00:17, 15.87it/s]#033[A#015Epoch 9:  84%|████████▍ | 1320/1563 [03:57<00:43,  5.57it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating:  26%|██▌       | 80/311 [00:04<00:14, 16.38it/s]#033[A#015Epoch 9:  87%|████████▋ | 1360/1563 [03:59<00:35,  5.68it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating:  39%|███▊      | 120/311 [00:07<00:11, 16.68it/s]#033[A#015Epoch 9:  90%|████████▉ | 1400/1563 [04:01<00:28,  5.79it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  51%|█████▏    | 160/311 [00:09<00:08, 16.90it/s]#033[A#015Epoch 9:  92%|█████████▏| 1440/1563 [04:03<00:20,  5.90it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating:  64%|██████▍   | 200/311 [00:11<00:06, 17.14it/s]#033[A#015Epoch 9:  95%|█████████▍| 1480/1563 [04:06<00:13,  6.01it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating:  77%|███████▋  | 240/311 [00:13<00:04, 17.34it/s]#033[A#015Epoch 9:  97%|█████████▋| 1520/1563 [04:08<00:07,  6.12it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating:  90%|█████████ | 280/311 [00:16<00:01, 17.31it/s]#033[A#015Epoch 9: 100%|█████████▉| 1560/1563 [04:10<00:00,  6.22it/s, loss=0.0152, v_num=0, val_loss=0.0317, train_loss=0.0157]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 311/311 [00:17<00:00, 17.42it/s]#033[A#015Epoch 9: 100%|██████████| 1563/1563 [04:12<00:00,  6.19it/s, loss=0.0146, v_num=0, val_loss=0.032, train_loss=0.0152] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 9: 100%|██████████| 1563/1563 [04:12<00:00,  6.19it/s, loss=0.0146, v_num=0, val_loss=0.032, train_loss=0.0152]\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1303 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1303 [00:00<?, ?it/s] #015Epoch 0:   3%|▎         | 40/1303 [00:06<03:32,  5.95it/s]#015Epoch 0:   3%|▎         | 40/1303 [00:06<03:32,  5.95it/s, loss=0.0801, v_num=0, val_loss=0.221]#015Epoch 0:   6%|▌         | 80/1303 [00:13<03:21,  6.08it/s, loss=0.0801, v_num=0, val_loss=0.221]#015Epoch 0:   6%|▌         | 80/1303 [00:13<03:21,  6.08it/s, loss=0.0719, v_num=0, val_loss=0.221]#015Epoch 0:   9%|▉         | 120/1303 [00:19<03:12,  6.13it/s, loss=0.0719, v_num=0, val_loss=0.221]#015Epoch 0:   9%|▉         | 120/1303 [00:19<03:12,  6.13it/s, loss=0.0722, v_num=0, val_loss=0.221]#015Epoch 0:  12%|█▏        | 160/1303 [00:26<03:06,  6.13it/s, loss=0.0722, v_num=0, val_loss=0.221]#015Epoch 0:  12%|█▏        | 160/1303 [00:26<03:06,  6.13it/s, loss=0.0743, v_num=0, val_loss=0.221]#015Epoch 0:  15%|█▌        | 200/1303 [00:32<03:00,  6.12it/s, loss=0.0743, v_num=0, val_loss=0.221]#015Epoch 0:  15%|█▌        | 200/1303 [00:32<03:00,  6.12it/s, loss=0.0714, v_num=0, val_loss=0.221]#015Epoch 0:  18%|█▊        | 240/1303 [00:39<02:53,  6.12it/s, loss=0.0714, v_num=0, val_loss=0.221]#015Epoch 0:  18%|█▊        | 240/1303 [00:39<02:53,  6.12it/s, loss=0.07, v_num=0, val_loss=0.221]  #015Epoch 0:  21%|██▏       | 280/1303 [00:45<02:46,  6.14it/s, loss=0.07, v_num=0, val_loss=0.221]#015Epoch 0:  21%|██▏       | 280/1303 [00:45<02:46,  6.14it/s, loss=0.0738, v_num=0, val_loss=0.221]#015Epoch 0:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.0738, v_num=0, val_loss=0.221]#015Epoch 0:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.073, v_num=0, val_loss=0.221] #015Epoch 0:  28%|██▊       | 360/1303 [00:58<02:33,  6.13it/s, loss=0.073, v_num=0, val_loss=0.221]#015Epoch 0:  28%|██▊       | 360/1303 [00:58<02:33,  6.13it/s, loss=0.0732, v_num=0, val_loss=0.221]#015Epoch 0:  31%|███       | 400/1303 [01:05<02:27,  6.13it/s, loss=0.0732, v_num=0, val_loss=0.221]#015Epoch 0:  31%|███       | 400/1303 [01:05<02:27,  6.13it/s, loss=0.0704, v_num=0, val_loss=0.221]#015Epoch 0:  34%|███▍      | 440/1303 [01:11<02:20,  6.13it/s, loss=0.0704, v_num=0, val_loss=0.221]#015Epoch 0:  34%|███▍      | 440/1303 [01:11<02:20,  6.13it/s, loss=0.0658, v_num=0, val_loss=0.221]#015Epoch 0:  37%|███▋      | 480/1303 [01:18<02:14,  6.14it/s, loss=0.0658, v_num=0, val_loss=0.221]#015Epoch 0:  37%|███▋      | 480/1303 [01:18<02:14,  6.14it/s, loss=0.0627, v_num=0, val_loss=0.221]#015Epoch 0:  40%|███▉      | 520/1303 [01:24<02:07,  6.14it/s, loss=0.0627, v_num=0, val_loss=0.221]#015Epoch 0:  40%|███▉      | 520/1303 [01:24<02:07,  6.14it/s, loss=0.0613, v_num=0, val_loss=0.221]#015Epoch 0:  43%|████▎     | 560/1303 [01:31<02:00,  6.14it/s, loss=0.0613, v_num=0, val_loss=0.221]#015Epoch 0:  43%|████▎     | 560/1303 [01:31<02:00,  6.14it/s, loss=0.055, v_num=0, val_loss=0.221] #015Epoch 0:  46%|████▌     | 600/1303 [01:37<01:54,  6.14it/s, loss=0.055, v_num=0, val_loss=0.221]#015Epoch 0:  46%|████▌     | 600/1303 [01:37<01:54,  6.14it/s, loss=0.054, v_num=0, val_loss=0.221]#015Epoch 0:  49%|████▉     | 640/1303 [01:44<01:47,  6.15it/s, loss=0.054, v_num=0, val_loss=0.221]#015Epoch 0:  49%|████▉     | 640/1303 [01:44<01:47,  6.15it/s, loss=0.0548, v_num=0, val_loss=0.221]#015Epoch 0:  52%|█████▏    | 680/1303 [01:50<01:41,  6.14it/s, loss=0.0548, v_num=0, val_loss=0.221]#015Epoch 0:  52%|█████▏    | 680/1303 [01:50<01:41,  6.14it/s, loss=0.0538, v_num=0, val_loss=0.221]#015Epoch 0:  55%|█████▌    | 720/1303 [01:57<01:35,  6.13it/s, loss=0.0538, v_num=0, val_loss=0.221]#015Epoch 0:  55%|█████▌    | 720/1303 [01:57<01:35,  6.13it/s, loss=0.0512, v_num=0, val_loss=0.221]#015Epoch 0:  58%|█████▊    | 760/1303 [02:03<01:28,  6.13it/s, loss=0.0512, v_num=0, val_loss=0.221]#015Epoch 0:  58%|█████▊    | 760/1303 [02:03<01:28,  6.13it/s, loss=0.0492, v_num=0, val_loss=0.221]#015Epoch 0:  61%|██████▏   | 800/1303 [02:10<01:21,  6.14it/s, loss=0.0492, v_num=0, val_loss=0.221]#015Epoch 0:  61%|██████▏   | 800/1303 [02:10<01:21,  6.14it/s, loss=0.0479, v_num=0, val_loss=0.221]#015Epoch 0:  64%|██████▍   | 840/1303 [02:16<01:15,  6.14it/s, loss=0.0479, v_num=0, val_loss=0.221]#015Epoch 0:  64%|██████▍   | 840/1303 [02:16<01:15,  6.14it/s, loss=0.0494, v_num=0, val_loss=0.221]#015Epoch 0:  68%|██████▊   | 880/1303 [02:23<01:08,  6.14it/s, loss=0.0494, v_num=0, val_loss=0.221]#015Epoch 0:  68%|██████▊   | 880/1303 [02:23<01:08,  6.14it/s, loss=0.0501, v_num=0, val_loss=0.221]#015Epoch 0:  71%|███████   | 920/1303 [02:29<01:02,  6.14it/s, loss=0.0501, v_num=0, val_loss=0.221]#015Epoch 0:  71%|███████   | 920/1303 [02:29<01:02,  6.14it/s, loss=0.0493, v_num=0, val_loss=0.221]#015Epoch 0:  74%|███████▎  | 960/1303 [02:36<00:55,  6.15it/s, loss=0.0493, v_num=0, val_loss=0.221]#015Epoch 0:  74%|███████▎  | 960/1303 [02:36<00:55,  6.15it/s, loss=0.0465, v_num=0, val_loss=0.221]#015Epoch 0:  77%|███████▋  | 1000/1303 [02:42<00:49,  6.15it/s, loss=0.0465, v_num=0, val_loss=0.221]#015Epoch 0:  77%|███████▋  | 1000/1303 [02:42<00:49,  6.15it/s, loss=0.0512, v_num=0, val_loss=0.221]#015Epoch 0:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.14it/s, loss=0.0512, v_num=0, val_loss=0.221]#015Epoch 0:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.14it/s, loss=0.0457, v_num=0, val_loss=0.221]#015Epoch 0:  83%|████████▎ | 1080/1303 [02:55<00:36,  6.14it/s, loss=0.0457, v_num=0, val_loss=0.221]#015Epoch 0:  83%|████████▎ | 1080/1303 [02:55<00:36,  6.14it/s, loss=0.0451, v_num=0, val_loss=0.221]#015Epoch 0:  86%|████████▌ | 1120/1303 [02:59<00:29,  6.24it/s, loss=0.0451, v_num=0, val_loss=0.221]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.64it/s]#033[A#015Epoch 0:  89%|████████▉ | 1160/1303 [03:01<00:22,  6.39it/s, loss=0.0451, v_num=0, val_loss=0.221]\u001b[0m\n",
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 19.29it/s]#033[A#015Epoch 0:  92%|█████████▏| 1200/1303 [03:03<00:15,  6.54it/s, loss=0.0451, v_num=0, val_loss=0.221]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:06<00:04, 19.64it/s]#033[A#015Epoch 0:  95%|█████████▌| 1240/1303 [03:05<00:09,  6.68it/s, loss=0.0451, v_num=0, val_loss=0.221]\u001b[0m\n",
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:07<00:02, 19.96it/s]#033[A#015Epoch 0:  98%|█████████▊| 1280/1303 [03:07<00:03,  6.83it/s, loss=0.0451, v_num=0, val_loss=0.221]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:09<00:00, 20.26it/s]#033[A#015Epoch 0: 100%|██████████| 1303/1303 [03:09<00:00,  6.88it/s, loss=0.0471, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0471, v_num=0, val_loss=0.051, train_loss=0.0613]           #015Epoch 1:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0471, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   3%|▎         | 40/1303 [00:06<03:28,  6.07it/s, loss=0.0471, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   3%|▎         | 40/1303 [00:06<03:28,  6.07it/s, loss=0.0441, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   6%|▌         | 80/1303 [00:13<03:19,  6.12it/s, loss=0.0441, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   6%|▌         | 80/1303 [00:13<03:19,  6.12it/s, loss=0.0466, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   9%|▉         | 120/1303 [00:19<03:13,  6.12it/s, loss=0.0466, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:   9%|▉         | 120/1303 [00:19<03:13,  6.12it/s, loss=0.0454, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  12%|█▏        | 160/1303 [00:26<03:06,  6.13it/s, loss=0.0454, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  12%|█▏        | 160/1303 [00:26<03:06,  6.13it/s, loss=0.043, v_num=0, val_loss=0.051, train_loss=0.0613] #015Epoch 1:  15%|█▌        | 200/1303 [00:32<02:59,  6.13it/s, loss=0.043, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  15%|█▌        | 200/1303 [00:32<02:59,  6.13it/s, loss=0.0425, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  18%|█▊        | 240/1303 [00:39<02:53,  6.14it/s, loss=0.0425, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  18%|█▊        | 240/1303 [00:39<02:53,  6.14it/s, loss=0.0447, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  21%|██▏       | 280/1303 [00:45<02:47,  6.12it/s, loss=0.0447, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  21%|██▏       | 280/1303 [00:45<02:47,  6.12it/s, loss=0.0432, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.0432, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.0454, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  28%|██▊       | 360/1303 [00:58<02:34,  6.12it/s, loss=0.0454, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  28%|██▊       | 360/1303 [00:58<02:34,  6.12it/s, loss=0.0415, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0415, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0424, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0424, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0411, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  37%|███▋      | 480/1303 [01:18<02:14,  6.13it/s, loss=0.0411, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  37%|███▋      | 480/1303 [01:18<02:14,  6.13it/s, loss=0.0413, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  40%|███▉      | 520/1303 [01:24<02:07,  6.13it/s, loss=0.0413, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  40%|███▉      | 520/1303 [01:24<02:07,  6.13it/s, loss=0.041, v_num=0, val_loss=0.051, train_loss=0.0613] #015Epoch 1:  43%|████▎     | 560/1303 [01:31<02:01,  6.14it/s, loss=0.041, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  43%|████▎     | 560/1303 [01:31<02:01,  6.14it/s, loss=0.0432, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  46%|████▌     | 600/1303 [01:37<01:54,  6.13it/s, loss=0.0432, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  46%|████▌     | 600/1303 [01:37<01:54,  6.13it/s, loss=0.0389, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0389, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0428, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0428, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0423, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.0423, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.0391, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  58%|█████▊    | 760/1303 [02:04<01:28,  6.12it/s, loss=0.0391, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  58%|█████▊    | 760/1303 [02:04<01:28,  6.12it/s, loss=0.0378, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  61%|██████▏   | 800/1303 [02:10<01:22,  6.12it/s, loss=0.0378, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  61%|██████▏   | 800/1303 [02:10<01:22,  6.12it/s, loss=0.0419, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  64%|██████▍   | 840/1303 [02:17<01:15,  6.12it/s, loss=0.0419, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  64%|██████▍   | 840/1303 [02:17<01:15,  6.12it/s, loss=0.0427, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  68%|██████▊   | 880/1303 [02:23<01:09,  6.12it/s, loss=0.0427, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  68%|██████▊   | 880/1303 [02:23<01:09,  6.12it/s, loss=0.041, v_num=0, val_loss=0.051, train_loss=0.0613] #015Epoch 1:  71%|███████   | 920/1303 [02:30<01:02,  6.12it/s, loss=0.041, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  71%|███████   | 920/1303 [02:30<01:02,  6.12it/s, loss=0.0419, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  74%|███████▎  | 960/1303 [02:36<00:55,  6.13it/s, loss=0.0419, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  74%|███████▎  | 960/1303 [02:36<00:55,  6.13it/s, loss=0.0421, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  77%|███████▋  | 1000/1303 [02:43<00:49,  6.12it/s, loss=0.0421, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  77%|███████▋  | 1000/1303 [02:43<00:49,  6.12it/s, loss=0.0427, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.12it/s, loss=0.0427, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.12it/s, loss=0.0398, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  83%|████████▎ | 1080/1303 [02:56<00:36,  6.12it/s, loss=0.0398, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  83%|████████▎ | 1080/1303 [02:56<00:36,  6.12it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]#015Epoch 1:  86%|████████▌ | 1120/1303 [03:00<00:29,  6.22it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.81it/s]#033[A#015Epoch 1:  89%|████████▉ | 1160/1303 [03:02<00:22,  6.36it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 19.39it/s]#033[A#015Epoch 1:  92%|█████████▏| 1200/1303 [03:04<00:15,  6.51it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:05<00:04, 19.90it/s]#033[A#015Epoch 1:  95%|█████████▌| 1240/1303 [03:06<00:09,  6.66it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n",
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:07<00:02, 20.08it/s]#033[A#015Epoch 1:  98%|█████████▊| 1280/1303 [03:08<00:03,  6.81it/s, loss=0.0407, v_num=0, val_loss=0.051, train_loss=0.0613]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:09<00:00, 20.16it/s]#033[A#015Epoch 1: 100%|██████████| 1303/1303 [03:10<00:00,  6.85it/s, loss=0.0387, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0387, v_num=0, val_loss=0.0459, train_loss=0.0421]           #015Epoch 2:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0387, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   3%|▎         | 40/1303 [00:06<03:35,  5.87it/s, loss=0.0387, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   3%|▎         | 40/1303 [00:06<03:35,  5.87it/s, loss=0.0379, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   6%|▌         | 80/1303 [00:13<03:24,  5.99it/s, loss=0.0379, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   6%|▌         | 80/1303 [00:13<03:24,  5.99it/s, loss=0.0403, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   9%|▉         | 120/1303 [00:19<03:15,  6.06it/s, loss=0.0403, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:   9%|▉         | 120/1303 [00:19<03:15,  6.06it/s, loss=0.038, v_num=0, val_loss=0.0459, train_loss=0.0421] #015Epoch 2:  12%|█▏        | 160/1303 [00:26<03:07,  6.10it/s, loss=0.038, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  12%|█▏        | 160/1303 [00:26<03:07,  6.10it/s, loss=0.0395, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0395, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0375, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  18%|█▊        | 240/1303 [00:39<02:54,  6.09it/s, loss=0.0375, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  18%|█▊        | 240/1303 [00:39<02:54,  6.09it/s, loss=0.0384, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  21%|██▏       | 280/1303 [00:45<02:47,  6.10it/s, loss=0.0384, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  21%|██▏       | 280/1303 [00:45<02:47,  6.10it/s, loss=0.0418, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  25%|██▍       | 320/1303 [00:52<02:40,  6.11it/s, loss=0.0418, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  25%|██▍       | 320/1303 [00:52<02:40,  6.11it/s, loss=0.037, v_num=0, val_loss=0.0459, train_loss=0.0421] #015Epoch 2:  28%|██▊       | 360/1303 [00:58<02:34,  6.12it/s, loss=0.037, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  28%|██▊       | 360/1303 [00:58<02:34,  6.12it/s, loss=0.0389, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0389, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0377, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0377, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0365, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  37%|███▋      | 480/1303 [01:18<02:14,  6.12it/s, loss=0.0365, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  37%|███▋      | 480/1303 [01:18<02:14,  6.12it/s, loss=0.0392, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  40%|███▉      | 520/1303 [01:24<02:07,  6.13it/s, loss=0.0392, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  40%|███▉      | 520/1303 [01:24<02:07,  6.13it/s, loss=0.039, v_num=0, val_loss=0.0459, train_loss=0.0421] #015Epoch 2:  43%|████▎     | 560/1303 [01:31<02:01,  6.11it/s, loss=0.039, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  43%|████▎     | 560/1303 [01:31<02:01,  6.11it/s, loss=0.0364, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  46%|████▌     | 600/1303 [01:38<01:54,  6.12it/s, loss=0.0364, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  46%|████▌     | 600/1303 [01:38<01:54,  6.12it/s, loss=0.0385, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0385, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0401, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0401, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0368, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  55%|█████▌    | 720/1303 [01:57<01:35,  6.13it/s, loss=0.0368, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  55%|█████▌    | 720/1303 [01:57<01:35,  6.13it/s, loss=0.0401, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  58%|█████▊    | 760/1303 [02:03<01:28,  6.13it/s, loss=0.0401, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  58%|█████▊    | 760/1303 [02:03<01:28,  6.13it/s, loss=0.0398, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  61%|██████▏   | 800/1303 [02:10<01:21,  6.13it/s, loss=0.0398, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  61%|██████▏   | 800/1303 [02:10<01:21,  6.13it/s, loss=0.0347, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  64%|██████▍   | 840/1303 [02:16<01:15,  6.14it/s, loss=0.0347, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  64%|██████▍   | 840/1303 [02:16<01:15,  6.14it/s, loss=0.0347, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  68%|██████▊   | 880/1303 [02:23<01:08,  6.14it/s, loss=0.0347, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  68%|██████▊   | 880/1303 [02:23<01:08,  6.14it/s, loss=0.0356, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  71%|███████   | 920/1303 [02:29<01:02,  6.14it/s, loss=0.0356, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  71%|███████   | 920/1303 [02:29<01:02,  6.14it/s, loss=0.0337, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  74%|███████▎  | 960/1303 [02:36<00:55,  6.14it/s, loss=0.0337, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  74%|███████▎  | 960/1303 [02:36<00:55,  6.14it/s, loss=0.0356, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  77%|███████▋  | 1000/1303 [02:42<00:49,  6.15it/s, loss=0.0356, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  77%|███████▋  | 1000/1303 [02:42<00:49,  6.15it/s, loss=0.0362, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.15it/s, loss=0.0362, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.15it/s, loss=0.0364, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  83%|████████▎ | 1080/1303 [02:55<00:36,  6.15it/s, loss=0.0364, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  83%|████████▎ | 1080/1303 [02:55<00:36,  6.15it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]#015Epoch 2:  86%|████████▌ | 1120/1303 [02:59<00:29,  6.25it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.37it/s]#033[A#015Epoch 2:  89%|████████▉ | 1160/1303 [03:01<00:22,  6.40it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n",
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 18.96it/s]#033[A#015Epoch 2:  92%|█████████▏| 1200/1303 [03:03<00:15,  6.55it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:06<00:04, 19.39it/s]#033[A#015Epoch 2:  95%|█████████▌| 1240/1303 [03:05<00:09,  6.69it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:08<00:02, 19.74it/s]#033[A#015Epoch 2:  98%|█████████▊| 1280/1303 [03:07<00:03,  6.84it/s, loss=0.0369, v_num=0, val_loss=0.0459, train_loss=0.0421]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:09<00:00, 20.15it/s]#033[A#015Epoch 2: 100%|██████████| 1303/1303 [03:09<00:00,  6.89it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 2:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]           #015Epoch 3:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   3%|▎         | 40/1303 [00:06<03:36,  5.83it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   3%|▎         | 40/1303 [00:06<03:36,  5.83it/s, loss=0.0346, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   6%|▌         | 80/1303 [00:13<03:24,  5.98it/s, loss=0.0346, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   6%|▌         | 80/1303 [00:13<03:24,  5.98it/s, loss=0.0347, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   9%|▉         | 120/1303 [00:19<03:16,  6.01it/s, loss=0.0347, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:   9%|▉         | 120/1303 [00:19<03:16,  6.01it/s, loss=0.0363, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  12%|█▏        | 160/1303 [00:26<03:09,  6.03it/s, loss=0.0363, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  12%|█▏        | 160/1303 [00:26<03:09,  6.03it/s, loss=0.0354, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0354, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0339, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  18%|█▊        | 240/1303 [00:39<02:54,  6.10it/s, loss=0.0339, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  18%|█▊        | 240/1303 [00:39<02:54,  6.10it/s, loss=0.0355, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  21%|██▏       | 280/1303 [00:45<02:47,  6.11it/s, loss=0.0355, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  21%|██▏       | 280/1303 [00:45<02:47,  6.11it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.0361, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  25%|██▍       | 320/1303 [00:52<02:40,  6.12it/s, loss=0.0355, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  28%|██▊       | 360/1303 [00:58<02:34,  6.11it/s, loss=0.0355, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  28%|██▊       | 360/1303 [00:58<02:34,  6.11it/s, loss=0.0345, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0345, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  31%|███       | 400/1303 [01:05<02:27,  6.12it/s, loss=0.0385, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0385, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  34%|███▍      | 440/1303 [01:11<02:21,  6.12it/s, loss=0.0359, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  37%|███▋      | 480/1303 [01:18<02:14,  6.11it/s, loss=0.0359, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  37%|███▋      | 480/1303 [01:18<02:14,  6.11it/s, loss=0.0354, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  40%|███▉      | 520/1303 [01:25<02:08,  6.10it/s, loss=0.0354, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  40%|███▉      | 520/1303 [01:25<02:08,  6.10it/s, loss=0.0364, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  43%|████▎     | 560/1303 [01:31<02:01,  6.10it/s, loss=0.0364, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  43%|████▎     | 560/1303 [01:31<02:01,  6.10it/s, loss=0.0321, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  46%|████▌     | 600/1303 [01:38<01:55,  6.11it/s, loss=0.0321, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  46%|████▌     | 600/1303 [01:38<01:55,  6.11it/s, loss=0.0389, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0389, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  49%|████▉     | 640/1303 [01:44<01:48,  6.12it/s, loss=0.0358, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0358, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0339, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.0339, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.0337, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  58%|█████▊    | 760/1303 [02:04<01:28,  6.13it/s, loss=0.0337, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  58%|█████▊    | 760/1303 [02:04<01:28,  6.13it/s, loss=0.0367, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  61%|██████▏   | 800/1303 [02:10<01:22,  6.13it/s, loss=0.0367, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  61%|██████▏   | 800/1303 [02:10<01:22,  6.13it/s, loss=0.0388, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  64%|██████▍   | 840/1303 [02:16<01:15,  6.13it/s, loss=0.0388, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  64%|██████▍   | 840/1303 [02:16<01:15,  6.13it/s, loss=0.0338, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  68%|██████▊   | 880/1303 [02:23<01:09,  6.13it/s, loss=0.0338, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  68%|██████▊   | 880/1303 [02:23<01:09,  6.13it/s, loss=0.0329, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  71%|███████   | 920/1303 [02:30<01:02,  6.13it/s, loss=0.0329, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  71%|███████   | 920/1303 [02:30<01:02,  6.13it/s, loss=0.0362, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  74%|███████▎  | 960/1303 [02:36<00:55,  6.13it/s, loss=0.0362, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  74%|███████▎  | 960/1303 [02:36<00:55,  6.13it/s, loss=0.0346, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  77%|███████▋  | 1000/1303 [02:43<00:49,  6.13it/s, loss=0.0346, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  77%|███████▋  | 1000/1303 [02:43<00:49,  6.13it/s, loss=0.033, v_num=0, val_loss=0.0441, train_loss=0.0378] #015Epoch 3:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.13it/s, loss=0.033, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  80%|███████▉  | 1040/1303 [02:49<00:42,  6.13it/s, loss=0.037, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  83%|████████▎ | 1080/1303 [02:56<00:36,  6.13it/s, loss=0.037, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  83%|████████▎ | 1080/1303 [02:56<00:36,  6.13it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]#015Epoch 3:  86%|████████▌ | 1120/1303 [02:59<00:29,  6.23it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.79it/s]#033[A#015Epoch 3:  89%|████████▉ | 1160/1303 [03:01<00:22,  6.38it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 19.42it/s]#033[A#015Epoch 3:  92%|█████████▏| 1200/1303 [03:03<00:15,  6.53it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:05<00:04, 19.76it/s]#033[A#015Epoch 3:  95%|█████████▌| 1240/1303 [03:05<00:09,  6.68it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:07<00:02, 20.13it/s]#033[A#015Epoch 3:  98%|█████████▊| 1280/1303 [03:07<00:03,  6.82it/s, loss=0.035, v_num=0, val_loss=0.0441, train_loss=0.0378]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:09<00:00, 20.37it/s]#033[A#015Epoch 3: 100%|██████████| 1303/1303 [03:09<00:00,  6.87it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                             #033[A#015Epoch 3:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]           #015Epoch 4:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:   3%|▎         | 40/1303 [00:06<03:37,  5.81it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:   3%|▎         | 40/1303 [00:06<03:37,  5.81it/s, loss=0.035, v_num=0, val_loss=0.0414, train_loss=0.0354] #015Epoch 4:   6%|▌         | 80/1303 [00:13<03:26,  5.92it/s, loss=0.035, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:   6%|▌         | 80/1303 [00:13<03:26,  5.92it/s, loss=0.0322, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:   9%|▉         | 120/1303 [00:19<03:17,  6.00it/s, loss=0.0322, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:   9%|▉         | 120/1303 [00:19<03:17,  6.00it/s, loss=0.0327, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  12%|█▏        | 160/1303 [00:26<03:09,  6.04it/s, loss=0.0327, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  12%|█▏        | 160/1303 [00:26<03:09,  6.04it/s, loss=0.0341, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0341, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  15%|█▌        | 200/1303 [00:32<03:01,  6.08it/s, loss=0.0349, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  18%|█▊        | 240/1303 [00:39<02:54,  6.08it/s, loss=0.0349, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  18%|█▊        | 240/1303 [00:39<02:54,  6.08it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  21%|██▏       | 280/1303 [00:46<02:48,  6.08it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  21%|██▏       | 280/1303 [00:46<02:48,  6.08it/s, loss=0.0354, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  25%|██▍       | 320/1303 [00:52<02:41,  6.09it/s, loss=0.0354, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  25%|██▍       | 320/1303 [00:52<02:41,  6.09it/s, loss=0.0345, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  28%|██▊       | 360/1303 [00:59<02:34,  6.09it/s, loss=0.0345, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  28%|██▊       | 360/1303 [00:59<02:34,  6.09it/s, loss=0.0323, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  31%|███       | 400/1303 [01:05<02:27,  6.11it/s, loss=0.0323, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  31%|███       | 400/1303 [01:05<02:27,  6.11it/s, loss=0.0312, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  34%|███▍      | 440/1303 [01:12<02:21,  6.09it/s, loss=0.0312, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  34%|███▍      | 440/1303 [01:12<02:21,  6.09it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  37%|███▋      | 480/1303 [01:18<02:14,  6.10it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  37%|███▋      | 480/1303 [01:18<02:14,  6.10it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  40%|███▉      | 520/1303 [01:25<02:08,  6.11it/s, loss=0.0344, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  40%|███▉      | 520/1303 [01:25<02:08,  6.11it/s, loss=0.0331, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  43%|████▎     | 560/1303 [01:31<02:01,  6.11it/s, loss=0.0331, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  43%|████▎     | 560/1303 [01:31<02:01,  6.11it/s, loss=0.0313, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  46%|████▌     | 600/1303 [01:38<01:54,  6.12it/s, loss=0.0313, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  46%|████▌     | 600/1303 [01:38<01:54,  6.12it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  49%|████▉     | 640/1303 [01:44<01:48,  6.13it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  49%|████▉     | 640/1303 [01:44<01:48,  6.13it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  52%|█████▏    | 680/1303 [01:51<01:41,  6.12it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  55%|█████▌    | 720/1303 [01:57<01:35,  6.12it/s, loss=0.032, v_num=0, val_loss=0.0414, train_loss=0.0354] #015Epoch 4:  58%|█████▊    | 760/1303 [02:04<01:28,  6.12it/s, loss=0.032, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  58%|█████▊    | 760/1303 [02:04<01:28,  6.12it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  61%|██████▏   | 800/1303 [02:11<01:22,  6.11it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  61%|██████▏   | 800/1303 [02:11<01:22,  6.11it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  64%|██████▍   | 840/1303 [02:17<01:15,  6.10it/s, loss=0.0319, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  64%|██████▍   | 840/1303 [02:17<01:15,  6.10it/s, loss=0.0313, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  68%|██████▊   | 880/1303 [02:24<01:09,  6.10it/s, loss=0.0313, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  68%|██████▊   | 880/1303 [02:24<01:09,  6.10it/s, loss=0.0337, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  71%|███████   | 920/1303 [02:30<01:02,  6.10it/s, loss=0.0337, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  71%|███████   | 920/1303 [02:30<01:02,  6.10it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  74%|███████▎  | 960/1303 [02:37<00:56,  6.10it/s, loss=0.0326, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  74%|███████▎  | 960/1303 [02:37<00:56,  6.10it/s, loss=0.0315, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  77%|███████▋  | 1000/1303 [02:44<00:49,  6.10it/s, loss=0.0315, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  77%|███████▋  | 1000/1303 [02:44<00:49,  6.10it/s, loss=0.0349, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  80%|███████▉  | 1040/1303 [02:50<00:43,  6.09it/s, loss=0.0349, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  80%|███████▉  | 1040/1303 [02:50<00:43,  6.09it/s, loss=0.0343, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  83%|████████▎ | 1080/1303 [02:57<00:36,  6.09it/s, loss=0.0343, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  83%|████████▎ | 1080/1303 [02:57<00:36,  6.09it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]#015Epoch 4:  86%|████████▌ | 1120/1303 [03:00<00:29,  6.19it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.34it/s]#033[A#015Epoch 4:  89%|████████▉ | 1160/1303 [03:03<00:22,  6.33it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n",
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 18.93it/s]#033[A#015Epoch 4:  92%|█████████▏| 1200/1303 [03:05<00:15,  6.48it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:06<00:04, 19.27it/s]#033[A#015Epoch 4:  95%|█████████▌| 1240/1303 [03:07<00:09,  6.63it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n",
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:08<00:02, 19.52it/s]#033[A#015Epoch 4:  98%|█████████▊| 1280/1303 [03:09<00:03,  6.77it/s, loss=0.0357, v_num=0, val_loss=0.0414, train_loss=0.0354]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:10<00:00, 19.71it/s]#033[A#015Epoch 4: 100%|██████████| 1303/1303 [03:11<00:00,  6.82it/s, loss=0.0323, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 4:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0323, v_num=0, val_loss=0.0426, train_loss=0.0331]           #015Epoch 5:   0%|          | 0/1303 [00:00<?, ?it/s, loss=0.0323, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:   3%|▎         | 40/1303 [00:07<03:41,  5.69it/s, loss=0.0323, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:   3%|▎         | 40/1303 [00:07<03:42,  5.69it/s, loss=0.029, v_num=0, val_loss=0.0426, train_loss=0.0331] #015Epoch 5:   6%|▌         | 80/1303 [00:13<03:29,  5.84it/s, loss=0.029, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:   6%|▌         | 80/1303 [00:13<03:29,  5.84it/s, loss=0.0318, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:   9%|▉         | 120/1303 [00:20<03:20,  5.90it/s, loss=0.0318, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:   9%|▉         | 120/1303 [00:20<03:20,  5.90it/s, loss=0.0331, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  12%|█▏        | 160/1303 [00:26<03:12,  5.95it/s, loss=0.0331, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  12%|█▏        | 160/1303 [00:26<03:12,  5.95it/s, loss=0.0358, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  15%|█▌        | 200/1303 [00:33<03:04,  5.97it/s, loss=0.0358, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  15%|█▌        | 200/1303 [00:33<03:04,  5.97it/s, loss=0.0337, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  18%|█▊        | 240/1303 [00:40<02:57,  5.98it/s, loss=0.0337, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  18%|█▊        | 240/1303 [00:40<02:57,  5.98it/s, loss=0.0317, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  21%|██▏       | 280/1303 [00:46<02:50,  5.98it/s, loss=0.0317, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  21%|██▏       | 280/1303 [00:46<02:50,  5.98it/s, loss=0.0336, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  25%|██▍       | 320/1303 [00:53<02:43,  5.99it/s, loss=0.0336, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  25%|██▍       | 320/1303 [00:53<02:43,  5.99it/s, loss=0.0312, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  28%|██▊       | 360/1303 [01:00<02:37,  5.98it/s, loss=0.0312, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  28%|██▊       | 360/1303 [01:00<02:37,  5.98it/s, loss=0.032, v_num=0, val_loss=0.0426, train_loss=0.0331] #015Epoch 5:  31%|███       | 400/1303 [01:06<02:30,  5.99it/s, loss=0.032, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  31%|███       | 400/1303 [01:06<02:30,  5.99it/s, loss=0.0332, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  34%|███▍      | 440/1303 [01:13<02:24,  5.99it/s, loss=0.0332, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  34%|███▍      | 440/1303 [01:13<02:24,  5.99it/s, loss=0.0322, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  37%|███▋      | 480/1303 [01:20<02:17,  5.99it/s, loss=0.0322, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  37%|███▋      | 480/1303 [01:20<02:17,  5.99it/s, loss=0.0339, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  40%|███▉      | 520/1303 [01:26<02:10,  6.00it/s, loss=0.0339, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  40%|███▉      | 520/1303 [01:26<02:10,  6.00it/s, loss=0.0296, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  43%|████▎     | 560/1303 [01:33<02:03,  6.00it/s, loss=0.0296, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  43%|████▎     | 560/1303 [01:33<02:03,  6.00it/s, loss=0.0288, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  46%|████▌     | 600/1303 [01:40<01:57,  6.00it/s, loss=0.0288, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  46%|████▌     | 600/1303 [01:40<01:57,  6.00it/s, loss=0.0332, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  49%|████▉     | 640/1303 [01:46<01:50,  6.00it/s, loss=0.0332, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  49%|████▉     | 640/1303 [01:46<01:50,  6.00it/s, loss=0.0334, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  52%|█████▏    | 680/1303 [01:53<01:43,  6.00it/s, loss=0.0334, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  52%|█████▏    | 680/1303 [01:53<01:43,  6.00it/s, loss=0.0291, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  55%|█████▌    | 720/1303 [01:59<01:37,  6.00it/s, loss=0.0291, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  55%|█████▌    | 720/1303 [01:59<01:37,  6.00it/s, loss=0.029, v_num=0, val_loss=0.0426, train_loss=0.0331] #015Epoch 5:  58%|█████▊    | 760/1303 [02:06<01:30,  6.00it/s, loss=0.029, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  58%|█████▊    | 760/1303 [02:06<01:30,  6.00it/s, loss=0.0321, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  61%|██████▏   | 800/1303 [02:13<01:23,  6.00it/s, loss=0.0321, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  61%|██████▏   | 800/1303 [02:13<01:23,  6.00it/s, loss=0.0312, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  64%|██████▍   | 840/1303 [02:19<01:17,  6.00it/s, loss=0.0312, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  64%|██████▍   | 840/1303 [02:19<01:17,  6.00it/s, loss=0.036, v_num=0, val_loss=0.0426, train_loss=0.0331] #015Epoch 5:  68%|██████▊   | 880/1303 [02:26<01:10,  6.01it/s, loss=0.036, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  68%|██████▊   | 880/1303 [02:26<01:10,  6.01it/s, loss=0.0337, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  71%|███████   | 920/1303 [02:33<01:03,  6.01it/s, loss=0.0337, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  71%|███████   | 920/1303 [02:33<01:03,  6.01it/s, loss=0.0317, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  74%|███████▎  | 960/1303 [02:39<00:57,  6.01it/s, loss=0.0317, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  74%|███████▎  | 960/1303 [02:39<00:57,  6.01it/s, loss=0.0299, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  77%|███████▋  | 1000/1303 [02:46<00:50,  6.01it/s, loss=0.0299, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  77%|███████▋  | 1000/1303 [02:46<00:50,  6.01it/s, loss=0.0329, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  80%|███████▉  | 1040/1303 [02:52<00:43,  6.02it/s, loss=0.0329, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  80%|███████▉  | 1040/1303 [02:52<00:43,  6.02it/s, loss=0.0309, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  83%|████████▎ | 1080/1303 [02:59<00:37,  6.01it/s, loss=0.0309, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  83%|████████▎ | 1080/1303 [02:59<00:37,  6.01it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]#015Epoch 5:  86%|████████▌ | 1120/1303 [03:03<00:29,  6.11it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/202 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  20%|█▉        | 40/202 [00:02<00:08, 18.29it/s]#033[A#015Epoch 5:  89%|████████▉ | 1160/1303 [03:05<00:22,  6.25it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015Validating:  40%|███▉      | 80/202 [00:04<00:06, 18.96it/s]#033[A#015Epoch 5:  92%|█████████▏| 1200/1303 [03:07<00:16,  6.40it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015Validating:  59%|█████▉    | 120/202 [00:06<00:04, 19.24it/s]#033[A#015Epoch 5:  95%|█████████▌| 1240/1303 [03:09<00:09,  6.54it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015Validating:  79%|███████▉  | 160/202 [00:08<00:02, 19.48it/s]#033[A#015Epoch 5:  98%|█████████▊| 1280/1303 [03:11<00:03,  6.68it/s, loss=0.0311, v_num=0, val_loss=0.0426, train_loss=0.0331]\u001b[0m\n",
      "\u001b[34m#015Validating:  99%|█████████▉| 200/202 [00:10<00:00, 19.76it/s]#033[A#015Epoch 5: 100%|██████████| 1303/1303 [03:13<00:00,  6.73it/s, loss=0.029, v_num=0, val_loss=0.0417, train_loss=0.0315] \u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 5: 100%|██████████| 1303/1303 [03:13<00:00,  6.73it/s, loss=0.029, v_num=0, val_loss=0.0417, train_loss=0.0315]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1564 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1564 [00:00<?, ?it/s] #015Epoch 0:   3%|▎         | 40/1564 [00:07<04:28,  5.69it/s]#015Epoch 0:   3%|▎         | 40/1564 [00:07<04:28,  5.69it/s, loss=0.0767, v_num=0, val_loss=0.202]#015Epoch 0:   5%|▌         | 80/1564 [00:13<04:13,  5.84it/s, loss=0.0767, v_num=0, val_loss=0.202]#015Epoch 0:   5%|▌         | 80/1564 [00:13<04:13,  5.84it/s, loss=0.051, v_num=0, val_loss=0.202] #015Epoch 0:   8%|▊         | 120/1564 [00:20<04:07,  5.83it/s, loss=0.051, v_num=0, val_loss=0.202]#015Epoch 0:   8%|▊         | 120/1564 [00:20<04:07,  5.83it/s, loss=0.0468, v_num=0, val_loss=0.202]#015Epoch 0:  10%|█         | 160/1564 [00:27<03:59,  5.86it/s, loss=0.0468, v_num=0, val_loss=0.202]#015Epoch 0:  10%|█         | 160/1564 [00:27<03:59,  5.86it/s, loss=0.0449, v_num=0, val_loss=0.202]#015Epoch 0:  13%|█▎        | 200/1564 [00:34<03:52,  5.88it/s, loss=0.0449, v_num=0, val_loss=0.202]#015Epoch 0:  13%|█▎        | 200/1564 [00:34<03:52,  5.87it/s, loss=0.0456, v_num=0, val_loss=0.202]#015Epoch 0:  15%|█▌        | 240/1564 [00:40<03:44,  5.89it/s, loss=0.0456, v_num=0, val_loss=0.202]#015Epoch 0:  15%|█▌        | 240/1564 [00:40<03:44,  5.89it/s, loss=0.0425, v_num=0, val_loss=0.202]#015Epoch 0:  18%|█▊        | 280/1564 [00:47<03:37,  5.90it/s, loss=0.0425, v_num=0, val_loss=0.202]#015Epoch 0:  18%|█▊        | 280/1564 [00:47<03:37,  5.90it/s, loss=0.043, v_num=0, val_loss=0.202] #015Epoch 0:  20%|██        | 320/1564 [00:54<03:30,  5.90it/s, loss=0.043, v_num=0, val_loss=0.202]#015Epoch 0:  20%|██        | 320/1564 [00:54<03:30,  5.90it/s, loss=0.0391, v_num=0, val_loss=0.202]#015Epoch 0:  23%|██▎       | 360/1564 [01:00<03:23,  5.91it/s, loss=0.0391, v_num=0, val_loss=0.202]#015Epoch 0:  23%|██▎       | 360/1564 [01:00<03:23,  5.91it/s, loss=0.0388, v_num=0, val_loss=0.202]#015Epoch 0:  26%|██▌       | 400/1564 [01:07<03:17,  5.90it/s, loss=0.0388, v_num=0, val_loss=0.202]#015Epoch 0:  26%|██▌       | 400/1564 [01:07<03:17,  5.90it/s, loss=0.0367, v_num=0, val_loss=0.202]#015Epoch 0:  28%|██▊       | 440/1564 [01:14<03:10,  5.90it/s, loss=0.0367, v_num=0, val_loss=0.202]#015Epoch 0:  28%|██▊       | 440/1564 [01:14<03:10,  5.90it/s, loss=0.0343, v_num=0, val_loss=0.202]#015Epoch 0:  31%|███       | 480/1564 [01:21<03:04,  5.89it/s, loss=0.0343, v_num=0, val_loss=0.202]#015Epoch 0:  31%|███       | 480/1564 [01:21<03:04,  5.89it/s, loss=0.0373, v_num=0, val_loss=0.202]#015Epoch 0:  33%|███▎      | 520/1564 [01:28<02:57,  5.89it/s, loss=0.0373, v_num=0, val_loss=0.202]#015Epoch 0:  33%|███▎      | 520/1564 [01:28<02:57,  5.89it/s, loss=0.0361, v_num=0, val_loss=0.202]#015Epoch 0:  36%|███▌      | 560/1564 [01:35<02:50,  5.89it/s, loss=0.0361, v_num=0, val_loss=0.202]#015Epoch 0:  36%|███▌      | 560/1564 [01:35<02:50,  5.89it/s, loss=0.0338, v_num=0, val_loss=0.202]#015Epoch 0:  38%|███▊      | 600/1564 [01:41<02:43,  5.88it/s, loss=0.0338, v_num=0, val_loss=0.202]#015Epoch 0:  38%|███▊      | 600/1564 [01:41<02:43,  5.88it/s, loss=0.0337, v_num=0, val_loss=0.202]#015Epoch 0:  41%|████      | 640/1564 [01:48<02:37,  5.88it/s, loss=0.0337, v_num=0, val_loss=0.202]#015Epoch 0:  41%|████      | 640/1564 [01:48<02:37,  5.88it/s, loss=0.0323, v_num=0, val_loss=0.202]#015Epoch 0:  43%|████▎     | 680/1564 [01:55<02:30,  5.88it/s, loss=0.0323, v_num=0, val_loss=0.202]#015Epoch 0:  43%|████▎     | 680/1564 [01:55<02:30,  5.88it/s, loss=0.0341, v_num=0, val_loss=0.202]#015Epoch 0:  46%|████▌     | 720/1564 [02:02<02:23,  5.88it/s, loss=0.0341, v_num=0, val_loss=0.202]#015Epoch 0:  46%|████▌     | 720/1564 [02:02<02:23,  5.88it/s, loss=0.0318, v_num=0, val_loss=0.202]#015Epoch 0:  49%|████▊     | 760/1564 [02:09<02:16,  5.89it/s, loss=0.0318, v_num=0, val_loss=0.202]#015Epoch 0:  49%|████▊     | 760/1564 [02:09<02:16,  5.89it/s, loss=0.031, v_num=0, val_loss=0.202] #015Epoch 0:  51%|█████     | 800/1564 [02:15<02:09,  5.90it/s, loss=0.031, v_num=0, val_loss=0.202]#015Epoch 0:  51%|█████     | 800/1564 [02:15<02:09,  5.90it/s, loss=0.0298, v_num=0, val_loss=0.202]#015Epoch 0:  54%|█████▎    | 840/1564 [02:22<02:02,  5.89it/s, loss=0.0298, v_num=0, val_loss=0.202]#015Epoch 0:  54%|█████▎    | 840/1564 [02:22<02:02,  5.89it/s, loss=0.0308, v_num=0, val_loss=0.202]#015Epoch 0:  56%|█████▋    | 880/1564 [02:29<01:56,  5.89it/s, loss=0.0308, v_num=0, val_loss=0.202]#015Epoch 0:  56%|█████▋    | 880/1564 [02:29<01:56,  5.89it/s, loss=0.0277, v_num=0, val_loss=0.202]#015Epoch 0:  59%|█████▉    | 920/1564 [02:36<01:49,  5.90it/s, loss=0.0277, v_num=0, val_loss=0.202]#015Epoch 0:  59%|█████▉    | 920/1564 [02:36<01:49,  5.90it/s, loss=0.0282, v_num=0, val_loss=0.202]#015Epoch 0:  61%|██████▏   | 960/1564 [02:42<01:42,  5.90it/s, loss=0.0282, v_num=0, val_loss=0.202]#015Epoch 0:  61%|██████▏   | 960/1564 [02:42<01:42,  5.90it/s, loss=0.0293, v_num=0, val_loss=0.202]#015Epoch 0:  64%|██████▍   | 1000/1564 [02:49<01:35,  5.90it/s, loss=0.0293, v_num=0, val_loss=0.202]#015Epoch 0:  64%|██████▍   | 1000/1564 [02:49<01:35,  5.90it/s, loss=0.0261, v_num=0, val_loss=0.202]#015Epoch 0:  66%|██████▋   | 1040/1564 [02:56<01:28,  5.90it/s, loss=0.0261, v_num=0, val_loss=0.202]#015Epoch 0:  66%|██████▋   | 1040/1564 [02:56<01:28,  5.90it/s, loss=0.0269, v_num=0, val_loss=0.202]#015Epoch 0:  69%|██████▉   | 1080/1564 [03:03<01:22,  5.90it/s, loss=0.0269, v_num=0, val_loss=0.202]#015Epoch 0:  69%|██████▉   | 1080/1564 [03:03<01:22,  5.90it/s, loss=0.0289, v_num=0, val_loss=0.202]#015Epoch 0:  72%|███████▏  | 1120/1564 [03:09<01:15,  5.90it/s, loss=0.0289, v_num=0, val_loss=0.202]#015Epoch 0:  72%|███████▏  | 1120/1564 [03:09<01:15,  5.90it/s, loss=0.029, v_num=0, val_loss=0.202] #015Epoch 0:  74%|███████▍  | 1160/1564 [03:16<01:08,  5.91it/s, loss=0.029, v_num=0, val_loss=0.202]#015Epoch 0:  74%|███████▍  | 1160/1564 [03:16<01:08,  5.91it/s, loss=0.0259, v_num=0, val_loss=0.202]#015Epoch 0:  77%|███████▋  | 1200/1564 [03:23<01:01,  5.90it/s, loss=0.0259, v_num=0, val_loss=0.202]#015Epoch 0:  77%|███████▋  | 1200/1564 [03:23<01:01,  5.90it/s, loss=0.0258, v_num=0, val_loss=0.202]#015Epoch 0:  79%|███████▉  | 1240/1564 [03:30<00:54,  5.90it/s, loss=0.0258, v_num=0, val_loss=0.202]#015Epoch 0:  79%|███████▉  | 1240/1564 [03:30<00:54,  5.90it/s, loss=0.0263, v_num=0, val_loss=0.202]#015Epoch 0:  82%|████████▏ | 1280/1564 [03:35<00:47,  5.93it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/290 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  14%|█▍        | 40/290 [00:02<00:14, 17.73it/s]#033[A#015Epoch 0:  84%|████████▍ | 1320/1564 [03:38<00:40,  6.05it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  28%|██▊       | 80/290 [00:04<00:11, 18.33it/s]#033[A#015Epoch 0:  87%|████████▋ | 1360/1564 [03:40<00:33,  6.18it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  41%|████▏     | 120/290 [00:06<00:09, 18.77it/s]#033[A#015Epoch 0:  90%|████████▉ | 1400/1564 [03:42<00:26,  6.30it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  55%|█████▌    | 160/290 [00:08<00:06, 19.12it/s]#033[A#015Epoch 0:  92%|█████████▏| 1440/1564 [03:44<00:19,  6.43it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  69%|██████▉   | 200/290 [00:10<00:04, 19.25it/s]#033[A#015Epoch 0:  95%|█████████▍| 1480/1564 [03:46<00:12,  6.54it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  83%|████████▎ | 240/290 [00:12<00:02, 19.29it/s]#033[A#015Epoch 0:  97%|█████████▋| 1520/1564 [03:48<00:06,  6.66it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 280/290 [00:14<00:00, 19.45it/s]#033[A#015Epoch 0: 100%|█████████▉| 1560/1564 [03:50<00:00,  6.78it/s, loss=0.0263, v_num=0, val_loss=0.202]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 290/290 [00:14<00:00, 19.88it/s]#033[A#015Epoch 0: 100%|██████████| 1564/1564 [03:50<00:00,  6.78it/s, loss=0.0277, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1564 [00:00<?, ?it/s, loss=0.0277, v_num=0, val_loss=0.0419, train_loss=0.0366]           #015Epoch 1:   0%|          | 0/1564 [00:00<?, ?it/s, loss=0.0277, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:   3%|▎         | 40/1564 [00:07<04:29,  5.66it/s, loss=0.0277, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:   3%|▎         | 40/1564 [00:07<04:29,  5.66it/s, loss=0.0262, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:   5%|▌         | 80/1564 [00:13<04:15,  5.81it/s, loss=0.0262, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:   5%|▌         | 80/1564 [00:13<04:15,  5.81it/s, loss=0.027, v_num=0, val_loss=0.0419, train_loss=0.0366] #015Epoch 1:   8%|▊         | 120/1564 [00:20<04:06,  5.86it/s, loss=0.027, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:   8%|▊         | 120/1564 [00:20<04:06,  5.86it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  10%|█         | 160/1564 [00:27<04:00,  5.84it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  10%|█         | 160/1564 [00:27<04:00,  5.84it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  13%|█▎        | 200/1564 [00:34<03:53,  5.85it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  13%|█▎        | 200/1564 [00:34<03:53,  5.85it/s, loss=0.0272, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  15%|█▌        | 240/1564 [00:40<03:46,  5.86it/s, loss=0.0272, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  15%|█▌        | 240/1564 [00:40<03:46,  5.86it/s, loss=0.0248, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  18%|█▊        | 280/1564 [00:47<03:38,  5.87it/s, loss=0.0248, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  18%|█▊        | 280/1564 [00:47<03:38,  5.87it/s, loss=0.0251, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  20%|██        | 320/1564 [00:54<03:31,  5.88it/s, loss=0.0251, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  20%|██        | 320/1564 [00:54<03:31,  5.88it/s, loss=0.0261, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  23%|██▎       | 360/1564 [01:01<03:24,  5.88it/s, loss=0.0261, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  23%|██▎       | 360/1564 [01:01<03:24,  5.88it/s, loss=0.0249, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  26%|██▌       | 400/1564 [01:08<03:17,  5.88it/s, loss=0.0249, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  26%|██▌       | 400/1564 [01:08<03:17,  5.88it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  28%|██▊       | 440/1564 [01:14<03:11,  5.88it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  28%|██▊       | 440/1564 [01:14<03:11,  5.88it/s, loss=0.0251, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  31%|███       | 480/1564 [01:21<03:04,  5.89it/s, loss=0.0251, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  31%|███       | 480/1564 [01:21<03:04,  5.89it/s, loss=0.0238, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  33%|███▎      | 520/1564 [01:28<02:57,  5.89it/s, loss=0.0238, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  33%|███▎      | 520/1564 [01:28<02:57,  5.89it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  36%|███▌      | 560/1564 [01:35<02:50,  5.89it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  36%|███▌      | 560/1564 [01:35<02:50,  5.89it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  38%|███▊      | 600/1564 [01:41<02:43,  5.89it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  38%|███▊      | 600/1564 [01:41<02:43,  5.89it/s, loss=0.0235, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  41%|████      | 640/1564 [01:48<02:36,  5.90it/s, loss=0.0235, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  41%|████      | 640/1564 [01:48<02:36,  5.90it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  43%|████▎     | 680/1564 [01:55<02:29,  5.90it/s, loss=0.0239, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  43%|████▎     | 680/1564 [01:55<02:29,  5.90it/s, loss=0.0244, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  46%|████▌     | 720/1564 [02:02<02:23,  5.90it/s, loss=0.0244, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  46%|████▌     | 720/1564 [02:02<02:23,  5.90it/s, loss=0.0233, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  49%|████▊     | 760/1564 [02:08<02:16,  5.90it/s, loss=0.0233, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  49%|████▊     | 760/1564 [02:08<02:16,  5.90it/s, loss=0.0244, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  51%|█████     | 800/1564 [02:15<02:09,  5.90it/s, loss=0.0244, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  51%|█████     | 800/1564 [02:15<02:09,  5.90it/s, loss=0.0227, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  54%|█████▎    | 840/1564 [02:22<02:02,  5.90it/s, loss=0.0227, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  54%|█████▎    | 840/1564 [02:22<02:02,  5.90it/s, loss=0.0215, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  56%|█████▋    | 880/1564 [02:29<01:56,  5.89it/s, loss=0.0215, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  56%|█████▋    | 880/1564 [02:29<01:56,  5.89it/s, loss=0.023, v_num=0, val_loss=0.0419, train_loss=0.0366] #015Epoch 1:  59%|█████▉    | 920/1564 [02:36<01:49,  5.89it/s, loss=0.023, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  59%|█████▉    | 920/1564 [02:36<01:49,  5.89it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  61%|██████▏   | 960/1564 [02:42<01:42,  5.89it/s, loss=0.0245, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  61%|██████▏   | 960/1564 [02:42<01:42,  5.89it/s, loss=0.0235, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  64%|██████▍   | 1000/1564 [02:49<01:35,  5.89it/s, loss=0.0235, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  64%|██████▍   | 1000/1564 [02:49<01:35,  5.89it/s, loss=0.0237, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  66%|██████▋   | 1040/1564 [02:56<01:28,  5.89it/s, loss=0.0237, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  66%|██████▋   | 1040/1564 [02:56<01:28,  5.89it/s, loss=0.0232, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  69%|██████▉   | 1080/1564 [03:03<01:22,  5.89it/s, loss=0.0232, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  69%|██████▉   | 1080/1564 [03:03<01:22,  5.89it/s, loss=0.0236, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  72%|███████▏  | 1120/1564 [03:10<01:15,  5.88it/s, loss=0.0236, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  72%|███████▏  | 1120/1564 [03:10<01:15,  5.88it/s, loss=0.0247, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  74%|███████▍  | 1160/1564 [03:17<01:08,  5.88it/s, loss=0.0247, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  74%|███████▍  | 1160/1564 [03:17<01:08,  5.88it/s, loss=0.0217, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  77%|███████▋  | 1200/1564 [03:24<01:01,  5.87it/s, loss=0.0217, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  77%|███████▋  | 1200/1564 [03:24<01:01,  5.87it/s, loss=0.0227, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  79%|███████▉  | 1240/1564 [03:31<00:55,  5.87it/s, loss=0.0227, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  79%|███████▉  | 1240/1564 [03:31<00:55,  5.87it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]#015Epoch 1:  82%|████████▏ | 1280/1564 [03:37<00:48,  5.89it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/290 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  14%|█▍        | 40/290 [00:02<00:14, 17.78it/s]#033[A#015Epoch 1:  84%|████████▍ | 1320/1564 [03:39<00:40,  6.01it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating:  28%|██▊       | 80/290 [00:04<00:11, 18.42it/s]#033[A#015Epoch 1:  87%|████████▋ | 1360/1564 [03:41<00:33,  6.14it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating:  41%|████▏     | 120/290 [00:06<00:09, 18.73it/s]#033[A#015Epoch 1:  90%|████████▉ | 1400/1564 [03:43<00:26,  6.26it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating:  55%|█████▌    | 160/290 [00:08<00:06, 19.11it/s]#033[A#015Epoch 1:  92%|█████████▏| 1440/1564 [03:45<00:19,  6.38it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  69%|██████▉   | 200/290 [00:10<00:04, 19.20it/s]#033[A#015Epoch 1:  95%|█████████▍| 1480/1564 [03:47<00:12,  6.50it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating:  83%|████████▎ | 240/290 [00:12<00:02, 19.30it/s]#033[A#015Epoch 1:  97%|█████████▋| 1520/1564 [03:49<00:06,  6.61it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 280/290 [00:14<00:00, 19.44it/s]#033[A#015Epoch 1: 100%|█████████▉| 1560/1564 [03:51<00:00,  6.73it/s, loss=0.0243, v_num=0, val_loss=0.0419, train_loss=0.0366]\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 290/290 [00:14<00:00, 19.97it/s]#033[A#015Epoch 1: 100%|██████████| 1564/1564 [03:52<00:00,  6.73it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024] \u001b[0m\n",
      "\n",
      "2022-01-31 13:05:55 Stopping - Stopping the training job\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1564 [00:00<?, ?it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024]           #015Epoch 2:   0%|          | 0/1564 [00:00<?, ?it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   3%|▎         | 40/1564 [00:07<04:34,  5.55it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   3%|▎         | 40/1564 [00:07<04:34,  5.55it/s, loss=0.0236, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   5%|▌         | 80/1564 [00:14<04:21,  5.67it/s, loss=0.0236, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   5%|▌         | 80/1564 [00:14<04:21,  5.67it/s, loss=0.0224, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   8%|▊         | 120/1564 [00:20<04:11,  5.73it/s, loss=0.0224, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:   8%|▊         | 120/1564 [00:20<04:11,  5.73it/s, loss=0.0193, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  10%|█         | 160/1564 [00:27<04:03,  5.77it/s, loss=0.0193, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  10%|█         | 160/1564 [00:27<04:03,  5.77it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  13%|█▎        | 200/1564 [00:34<03:56,  5.76it/s, loss=0.0231, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  13%|█▎        | 200/1564 [00:34<03:56,  5.76it/s, loss=0.0204, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  15%|█▌        | 240/1564 [00:41<03:48,  5.79it/s, loss=0.0204, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  15%|█▌        | 240/1564 [00:41<03:48,  5.79it/s, loss=0.0194, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  18%|█▊        | 280/1564 [00:48<03:41,  5.80it/s, loss=0.0194, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  18%|█▊        | 280/1564 [00:48<03:41,  5.80it/s, loss=0.0213, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  20%|██        | 320/1564 [00:55<03:33,  5.82it/s, loss=0.0213, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  20%|██        | 320/1564 [00:55<03:33,  5.82it/s, loss=0.0216, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  23%|██▎       | 360/1564 [01:01<03:26,  5.83it/s, loss=0.0216, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  23%|██▎       | 360/1564 [01:01<03:26,  5.83it/s, loss=0.022, v_num=0, val_loss=0.0386, train_loss=0.024] #015Epoch 2:  26%|██▌       | 400/1564 [01:08<03:19,  5.84it/s, loss=0.022, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  26%|██▌       | 400/1564 [01:08<03:19,  5.84it/s, loss=0.021, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  28%|██▊       | 440/1564 [01:15<03:12,  5.84it/s, loss=0.021, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  28%|██▊       | 440/1564 [01:15<03:12,  5.84it/s, loss=0.0217, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  31%|███       | 480/1564 [01:21<03:05,  5.85it/s, loss=0.0217, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  31%|███       | 480/1564 [01:21<03:05,  5.85it/s, loss=0.0207, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  33%|███▎      | 520/1564 [01:28<02:57,  5.87it/s, loss=0.0207, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  33%|███▎      | 520/1564 [01:28<02:57,  5.87it/s, loss=0.023, v_num=0, val_loss=0.0386, train_loss=0.024] #015Epoch 2:  36%|███▌      | 560/1564 [01:35<02:51,  5.86it/s, loss=0.023, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  36%|███▌      | 560/1564 [01:35<02:51,  5.86it/s, loss=0.0214, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  38%|███▊      | 600/1564 [01:42<02:43,  5.88it/s, loss=0.0214, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  38%|███▊      | 600/1564 [01:42<02:43,  5.88it/s, loss=0.0201, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  41%|████      | 640/1564 [01:48<02:37,  5.88it/s, loss=0.0201, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  41%|████      | 640/1564 [01:48<02:37,  5.88it/s, loss=0.0203, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  43%|████▎     | 680/1564 [01:55<02:30,  5.89it/s, loss=0.0203, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  43%|████▎     | 680/1564 [01:55<02:30,  5.89it/s, loss=0.0224, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  46%|████▌     | 720/1564 [02:02<02:23,  5.89it/s, loss=0.0224, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  46%|████▌     | 720/1564 [02:02<02:23,  5.89it/s, loss=0.0208, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  49%|████▊     | 760/1564 [02:08<02:16,  5.90it/s, loss=0.0208, v_num=0, val_loss=0.0386, train_loss=0.024]#015Epoch 2:  49%|████▊     | 760/1564 [02:08<02:16,  5.90it/s, loss=0.018, v_num=0, val_loss=0.0386, train_loss=0.024] \u001b[0m\n",
      "\n",
      "2022-01-31 13:08:16 Uploading - Uploading generated training model\n",
      "2022-01-31 13:08:59 Stopped - Training job stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job ended with status 'Stopped' rather than 'Completed'. This could mean the job timed out or stopped early for some other reason: Consider checking whether it completed as you expect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training seconds: 4907\n",
      "Billable seconds: 4907\n"
     ]
    }
   ],
   "source": [
    "# Fit the estimator\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
