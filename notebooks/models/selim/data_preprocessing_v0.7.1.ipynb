{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'data_v0.7.1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.read_csv(os.path.join(DATA_PATH, 'full_dataset_with_translations.csv'))\n",
    "test_data = pd.read_csv(os.path.join(DATA_PATH, 'test_v0.7.1.csv'))\n",
    "modified_age = pd.concat([\n",
    "    pd.read_csv(os.path.join(DATA_PATH, 'train_v0.7.1_gender_snorkel.csv')),\n",
    "    pd.read_csv(os.path.join(DATA_PATH, 'val_v0.7.1_gender_snorkel.csv'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.merge(\n",
    "    right=full_data,\n",
    "    left=modified_age,\n",
    "    on='entry_id',\n",
    "    how='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'gender_snorkel', 'excerpt', 'analysis_framework_id',\n",
       "       'lead_id', 'project_id', 'verified', 'sectors', 'subpillars_2d',\n",
       "       'subpillars_1d', 'geo_location', 'specific_needs_groups', 'severity',\n",
       "       'info_date', 'reliability', 'affected_groups_level_0',\n",
       "       'affected_groups_level_1', 'affected_groups_level_2',\n",
       "       'affected_groups_level_3', 'age', 'gender', 'source_type', 'url',\n",
       "       'website', 'lang', 'translation_en', 'translation_fr',\n",
       "       'translation_es'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['present_prim_tags'] = full_data.apply(\n",
    "    lambda x: [column for column in ['sectors','subpillars_2d', 'subpillars_1d'] if len(x[column])>2], axis=1\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['sectors'] = full_data.sectors.apply(\n",
    "    lambda x: [item for item in literal_eval(x) if item !='NOT_MAPPED']\n",
    ")\n",
    "full_data['subpillars_2d'] = full_data.subpillars_2d.apply(\n",
    "    lambda x: [item for item in literal_eval(x) if item !='NOT_MAPPED']\n",
    ")\n",
    "full_data['subpillars_1d'] = full_data.subpillars_1d.apply(\n",
    "    lambda x: [item for item in literal_eval(x) if item !='NOT_MAPPED']\n",
    ")\n",
    "full_data['pillars_1d'] = full_data.subpillars_1d.apply(\n",
    "    lambda x: list(np.unique([item.split('->')[0] for item in x]))\n",
    "               )\n",
    "\n",
    "full_data['pillars_2d'] = full_data.subpillars_2d.apply(\n",
    "    lambda x: list(np.unique([item.split('->')[0] for item in x]))\n",
    "               )\n",
    "\n",
    "full_data['prim_tags_level1'] = full_data.apply(\n",
    "    lambda x: flatten([\n",
    "        [f\"{column_name}->{tag}\" for tag in x[column_name]\n",
    "    ] for column_name in ['sectors', 'pillars_2d', 'pillars_1d']]), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523520101297879"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prop of positive examples in that\n",
    "full_data['present_prim_tags'].apply(lambda x: len(x)>0).sum() / full_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [sectors->Health, pillars_2d->Capacities & Res...\n",
       "1         [sectors->Education, pillars_2d->Humanitarian ...\n",
       "2         [sectors->Nutrition, sectors->Food Security, p...\n",
       "3         [pillars_1d->Displacement, pillars_1d->Humanit...\n",
       "4                                     [pillars_1d->Context]\n",
       "                                ...                        \n",
       "157945                                                   []\n",
       "157946                                                   []\n",
       "157947                                                   []\n",
       "157948                                                   []\n",
       "157949                                                   []\n",
       "Name: prim_tags_level1, Length: 157950, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['prim_tags_level1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subpillars_2d_part1'] = full_data.subpillars_2d.apply(\n",
    "    lambda x: [\n",
    "        item for item in x if item in [\n",
    "            'Humanitarian Conditions->Living Standards',\n",
    "             'Humanitarian Conditions->Physical And Mental Well Being',\n",
    "             'Impact->Impact On Systems, Services And Networks',\n",
    "             'Capacities & Response->International Response',\n",
    "             'Impact->Driver/Aggravating Factors',\n",
    "             'Impact->Impact On People',\n",
    "             'At Risk->Risk And Vulnerabilities'\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subpillars_2d_part2'] = full_data.subpillars_2d.apply(\n",
    "    lambda x: [\n",
    "        item for item in x if item in [\n",
    "            'Capacities & Response->National Response',\n",
    "             'Priority Interventions->Expressed By Humanitarian Staff',\n",
    "             'Humanitarian Conditions->Coping Mechanisms',\n",
    "             'Capacities & Response->Number Of People Reached/Response Gaps',\n",
    "             'Priority Needs->Expressed By Population',\n",
    "             'Impact->Number Of People Affected',\n",
    "             'Priority Needs->Expressed By Humanitarian Staff',\n",
    "             'Humanitarian Conditions->Number Of People In Need',\n",
    "             'Priority Interventions->Expressed By Population',\n",
    "             'Capacities & Response->Local Response', \n",
    "             'At Risk->Number Of People At Risk'\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subpillars_1d_part1'] = full_data.subpillars_1d.apply(\n",
    "    lambda x: [\n",
    "        item for item in x if item in [\n",
    "            'Displacement->Type/Numbers/Movements',\n",
    "             'Context->Security & Stability', \n",
    "             'Covid-19->Restriction Measures', \n",
    "             'Covid-19->Cases', \n",
    "             'Context->Economy', \n",
    "             'Shock/Event->Hazard & Threats', \n",
    "             'Casualties->Dead', \n",
    "             'Covid-19->Deaths', \n",
    "             'Context->Demography',\n",
    "             'Displacement->Local Integration'\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subpillars_1d_part2'] = full_data.subpillars_1d.apply(\n",
    "    lambda x: [\n",
    "        item for item in x if item in [\n",
    "            'Context->Legal & Policy', \n",
    "             'Context->Politics', \n",
    "             'Displacement->Push Factors', \n",
    "             'Covid-19->Vaccination', \n",
    "             'Shock/Event->Underlying/Aggravating Factors', \n",
    "             'Context->Socio Cultural', \n",
    "             'Humanitarian Access->Physical Constraints', \n",
    "             'Covid-19->Testing', \n",
    "             'Shock/Event->Type And Characteristics', \n",
    "             'Context->Environment', \n",
    "             'Humanitarian Access->Relief To Population'\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['subpillars_1d_part3'] = full_data.subpillars_1d.apply(\n",
    "    lambda x: [\n",
    "        item for item in x if item in [\n",
    "            'Information And Communication->Information Challenges And Barriers', \n",
    "             'Information And Communication->Communication Means And Preferences', \n",
    "             'Information And Communication->Knowledge And Info Gaps (Pop)',\n",
    "             'Casualties->Missing', \n",
    "             'Humanitarian Access->Population To Relief', \n",
    "             'Displacement->Pull Factors', \n",
    "             'Covid-19->Hospitalization & Care', \n",
    "             'Displacement->Intentions', \n",
    "             'Covid-19->Contact Tracing', \n",
    "             'Casualties->Injured', \n",
    "             'Information And Communication->Knowledge And Info Gaps (Hum)', \n",
    "             'Humanitarian Access->Number Of People Facing Humanitarian Access Constraints/Humanitarian Access Gaps'\n",
    "        ]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(x):\n",
    "    if str(x)=='nan':\n",
    "        return []\n",
    "    if type(x)==list:\n",
    "        return x\n",
    "    else:\n",
    "        return literal_eval(x)\n",
    "    \n",
    "full_data['affected_groups'] = full_data['affected_groups_level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['age'] = full_data.age.apply(custom_eval)\n",
    "full_data['gender'] = full_data.gender.apply(custom_eval)\n",
    "full_data['gender_snorkel'] = full_data.gender_snorkel.apply(custom_eval)\n",
    "full_data['specific_needs_groups'] = full_data.specific_needs_groups.apply(custom_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['present_sec_tags'] = full_data.apply(\n",
    "    lambda x: [column for column in [\n",
    "        'specific_needs_groups',\n",
    "        'affected_groups', \n",
    "        'age',\n",
    "        'gender_snorkel',\n",
    "        'gender'] if len(custom_eval(x[column]))>0], axis=1\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_groups_level_2_3_merger = {\n",
    "    'Asylum Seekers': 'Displaced->Asylum Seekers', \n",
    "    'Host': 'Non Displaced->Host', \n",
    "    'Non Host': 'Non Displaced->Non Host',\n",
    "    'IDP': 'Displaced->IDP', \n",
    "    'In Transit': 'Displaced->In Transit', \n",
    "    'Migrants': 'Displaced->Migrants',\n",
    "    'NOT_MAPPED': 'NOT_MAPPED',\n",
    "    'Others of Concern': 'Displaced->Others of Concern', \n",
    "    'Pendular': 'Displaced->Pendular',\n",
    "    'Permanent': 'Displaced->Permanent', \n",
    "    'Refugees': 'Displaced->Refugees', \n",
    "    'Returnees': 'Displaced->Returnees', \n",
    "    'Stateless': 'Displaced->Stateless'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_eval(x):\n",
    "    if type(x)==list:\n",
    "        return x\n",
    "    else:\n",
    "        return literal_eval(x)\n",
    "    \n",
    "full_data['affected_groups_level_3_nona'] = full_data['affected_groups_level_3'].apply(\n",
    "    lambda x: [] if str(x)=='nan' else x\n",
    ")\n",
    "full_data['affected_groups_levels_2_3'] = full_data['affected_groups_level_3_nona'].\\\n",
    "apply(\n",
    "    lambda x: [affected_groups_level_2_3_merger[item] for item in custom_eval(x) if item!='None']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"np.unique(flatten(full_data.affected_groups_level_0.dropna().apply(literal_eval).tolist()))\\nnp.unique(flatten(full_data.affected_groups_level_1.dropna().apply(literal_eval).tolist()))\\nnp.unique(flatten(full_data.affected_groups_level_2.dropna().apply(literal_eval).tolist()))\\nnp.unique(flatten(full_data['affected_groups_levels_2_3'].apply(custom_eval).tolist()))\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"np.unique(flatten(full_data.affected_groups_level_0.dropna().apply(literal_eval).tolist()))\n",
    "np.unique(flatten(full_data.affected_groups_level_1.dropna().apply(literal_eval).tolist()))\n",
    "np.unique(flatten(full_data.affected_groups_level_2.dropna().apply(literal_eval).tolist()))\n",
    "np.unique(flatten(full_data['affected_groups_levels_2_3'].apply(custom_eval).tolist()))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_full = full_data[~full_data.entry_id.isin(test_data.entry_id)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_df = train_val_full[['entry_id', 'translation_fr']]\\\n",
    "        .rename(columns={'translation_fr':'excerpt'}).dropna()\n",
    "en_df = train_val_full[['entry_id', 'translation_en']]\\\n",
    "        .rename(columns={'translation_en':'excerpt'}).dropna()\n",
    "es_df = train_val_full[['entry_id', 'translation_es']]\\\n",
    "        .rename(columns={'translation_es':'excerpt'}).dropna()\n",
    "\n",
    "augmented_data = pd.concat([en_df, fr_df, es_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = pd.merge(\n",
    "    right=train_val_full.drop(columns=[\n",
    "        'excerpt', 'translation_en', 'translation_fr', 'translation_es']\n",
    "                           ),\n",
    "    left=augmented_data[['entry_id', 'excerpt']],\n",
    "    on='entry_id',\n",
    "    how='right'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df = pd.concat([train_val_full, augmented_data]).drop(columns=[\n",
    "        'translation_en', 'translation_fr', 'translation_es', 'lang']\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df.to_csv(os.path.join(DATA_PATH, 'new_columns_train_val.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = full_data[full_data.entry_id.isin(test_data.entry_id)].drop(\n",
    "    columns=['translation_en', 'translation_fr', 'translation_es']\n",
    ")\n",
    "test_df['gender_snorkel'] = test_df['gender']\n",
    "test_df.to_csv(os.path.join(DATA_PATH, 'new_columns_test_v0.7.1.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422353, 36)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17202, 37)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entry_id', 'gender_snorkel', 'excerpt', 'analysis_framework_id',\n",
       "       'lead_id', 'project_id', 'verified', 'sectors', 'subpillars_2d',\n",
       "       'subpillars_1d', 'geo_location', 'specific_needs_groups', 'severity',\n",
       "       'info_date', 'reliability', 'affected_groups_level_0',\n",
       "       'affected_groups_level_1', 'affected_groups_level_2',\n",
       "       'affected_groups_level_3', 'age', 'gender', 'source_type', 'url',\n",
       "       'website', 'present_prim_tags', 'pillars_1d', 'pillars_2d',\n",
       "       'subpillars_2d_part1', 'subpillars_2d_part2', 'subpillars_1d_part1',\n",
       "       'subpillars_1d_part2', 'subpillars_1d_part3', 'affected_groups',\n",
       "       'present_sec_tags', 'affected_groups_level_3_nona',\n",
       "       'affected_groups_levels_2_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capacities & Response': 21492,\n",
       " 'Humanitarian Conditions': 46467,\n",
       " 'At Risk': 11245,\n",
       " 'Impact': 35473,\n",
       " 'Priority Needs': 3538,\n",
       " 'Priority Interventions': 5946,\n",
       " 'NOT_MAPPED': 20044}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter(flatten(full_data.pillars_2d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
