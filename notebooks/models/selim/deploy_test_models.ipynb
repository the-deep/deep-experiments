{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n!pip install s3fs\\n!pip install smdebug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from ast import literal_eval\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/10/28 12:18:24 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\n",
      "2021/10/28 12:18:25 INFO mlflow.sagemaker: No model data bucket specified, using the default bucket\n",
      "2021/10/28 12:18:26 INFO mlflow.sagemaker: Default bucket `mlflow-sagemaker-us-east-1-961104659532` already exists. Skipping creation.\n",
      "2021/10/28 12:20:25 INFO mlflow.sagemaker: tag response: {'ResponseMetadata': {'RequestId': '78D6C433NRZDKFD5', 'HostId': 'BqEb62UA4rLyG0PK3Ggc3kK3UAHQsYOSVhTKpIcBNNA/CoX7TJon+NPRrSW57XhLkW/y0ip/8S0=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'BqEb62UA4rLyG0PK3Ggc3kK3UAHQsYOSVhTKpIcBNNA/CoX7TJon+NPRrSW57XhLkW/y0ip/8S0=', 'x-amz-request-id': '78D6C433NRZDKFD5', 'date': 'Thu, 28 Oct 2021 10:20:26 GMT', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}}\n",
      "2021/10/28 12:20:25 INFO mlflow.sagemaker: Creating new endpoint with name: all-models-v1 ...\n",
      "2021/10/28 12:20:25 INFO mlflow.sagemaker: Created model with arn: arn:aws:sagemaker:us-east-1:961104659532:model/all-models-v1-model-48gkfqo4qeewolfbislvuq\n",
      "2021/10/28 12:20:26 INFO mlflow.sagemaker: Created endpoint configuration with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint-config/all-models-v1-config-7ly5dvaabqpgpblzwjqcxuw\n",
      "2021/10/28 12:20:26 INFO mlflow.sagemaker: Created endpoint with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint/all-models-v1\n"
     ]
    }
   ],
   "source": [
    "sagemaker.deploy(\n",
    "    'all-models-v1',\n",
    "    's3://deep-mlflow-artifact/19/0c982334d1e149c999707f79648bc08c/artifacts/pyfunc_models_all',\n",
    "    execution_role_arn=SAGEMAKER_ROLE_ARN,\n",
    "    image_url=\"961104659532.dkr.ecr.us-east-1.amazonaws.com/mlflow-pyfunc:latest\",\n",
    "    region_name=\"us-east-1\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    synchronous=False,\n",
    "    archive=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "multilabel_columns = [\n",
    "    #'sectors', \n",
    "    #'subpillars_2d', \n",
    "    #'subpillars_1d', \n",
    "    #'demographic_groups', \n",
    "    #'affected_groups', \n",
    "    'specific_needs_groups'\n",
    "    ]\n",
    "\n",
    "\n",
    "all_columns = [\n",
    "    #'sectors', \n",
    "    #'subpillars_2d', \n",
    "    #'subpillars_1d', \n",
    "    #'demographic_groups', \n",
    "    #'affected_groups', \n",
    "    'specific_needs_groups',\n",
    "    #'severity'\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_predictions(test_probas, thresholds_dict, nb_entries=100):  \n",
    "    \"\"\"\n",
    "    test_probas structure example: {\n",
    "        'sectors':[\n",
    "            {'Nutrition': 0.032076582, 'Shelter': 0.06674846}, \n",
    "            {'Cross': 0.21885818,'Education': 0.07529669}\n",
    "        ],\n",
    "        'demographic_groups':[\n",
    "            {'Children/Youth Female (5 to 17 years old)': 0.47860646, 'Children/Youth Male (5 to 17 years old)': 0.42560646},\n",
    "            {'Children/Youth Male (5 to 17 years old)': 0.47860646, 'Infants/Toddlers (<5 years old)': 0.85}\n",
    "        ],\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    }\n",
    "    \n",
    "    thresholds_dict structure example: {\n",
    "        'sectors':{\n",
    "            'Agriculture': 0.2,\n",
    "            'Cross': 0.02,\n",
    "            .\n",
    "            .\n",
    "        },\n",
    "        'subpillars_2d':{\n",
    "            'Humanitarian Conditions->Physical And Mental Well Being': 0.7,\n",
    "            .\n",
    "            .\n",
    "        },\n",
    "        .\n",
    "        .     \n",
    "    }\n",
    "    \n",
    "    First iteration:\n",
    "    - create dict which has the same structure as 'test_probas': \n",
    "    - contains ratio probability of output divided by the threshold\n",
    "    \n",
    "    Second iteration:\n",
    "    - keep ratios superior to 1 except:\n",
    "        - for subpillars_2d: when no ratio is superior to 1 but there is at least one prediction for sectors\n",
    "        - for severity (no threshold, just keep max if there is 'Humanitarian Conditions' in secondary tags outputs)\n",
    "    \"\"\"\n",
    "\n",
    "    #create dict of ratio between probability of output and threshold\n",
    "    ratio_proba_threshold = {}\n",
    "    for column in multilabel_columns:\n",
    "        preds_column = test_probas[column]\n",
    "        dict_keys = list(thresholds_dict[column].keys())\n",
    "\n",
    "        returned_values_column = []\n",
    "        for preds_sent in preds_column:\n",
    "            dict_entry = {key:preds_sent[key]/thresholds_dict[column][key] for key in dict_keys }\n",
    "            returned_values_column.append(dict_entry)\n",
    "        ratio_proba_threshold[column] = returned_values_column\n",
    "\n",
    "    predictions = {column:[] for column in all_columns}\n",
    "    for entry_nb in range (nb_entries):\n",
    "\n",
    "        # get the entries where the ratio is superior to 1 and put them in a dict {prediction:probability}\n",
    "        for column in multilabel_columns:\n",
    "            preds_column = ratio_proba_threshold[column][entry_nb]\n",
    "            preds_entry = [\n",
    "                sub_tag for sub_tag in list(preds_column.keys()) if ratio_proba_threshold[column][entry_nb][sub_tag]>1\n",
    "            ]\n",
    "\n",
    "            #postprocessing to keep only cross if more than one prediction\n",
    "            \"\"\"if column=='sectors' and len(preds_entry)>1:\n",
    "                preds_entry.append('Cross')\"\"\"\n",
    "\n",
    "            predictions[column].append(preds_entry)\n",
    "\n",
    "\n",
    "        #postprocess 'subpillars_2d'\n",
    "        \"\"\"if len(predictions['sectors'][entry_nb])>0 and len(predictions['subpillars_2d'][entry_nb])==0:\n",
    "            predictions['subpillars_2d'][entry_nb] = [\n",
    "                sub_tag for sub_tag in list(preds_column.keys()) if\\\n",
    "                        test_probas[column][entry_nb][sub_tag] == max(list(test_probas[column][entry_nb].values()))\n",
    "            ]\n",
    "\n",
    "        if len(predictions['sectors'][entry_nb])==0 and len(predictions['subpillars_2d'][entry_nb])>0:\n",
    "            predictions['subpillars_2d'][entry_nb] = []\"\"\"\n",
    "            \n",
    "        #severity  predictions and output\n",
    "        \"\"\"if 'Humanitarian Conditions' in str(predictions['subpillars_2d'][entry_nb]):\n",
    "            pred_severity = [\n",
    "                sub_tag for sub_tag in list(test_probas['severity'][entry_nb].keys()) if\\\n",
    "                test_probas['severity'][entry_nb][sub_tag] == max(list(test_probas['severity'][entry_nb].values()))\n",
    "            ]\n",
    "\n",
    "            predictions['severity'].append(pred_severity)\n",
    "        else:\n",
    "            predictions['severity'].append([])\"\"\"\n",
    "            \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_flat_matrix (column_of_columns, tag_to_id, nb_subtags):\n",
    "    matrix = [[\n",
    "        1 if tag_to_id[i] in column else 0 for i in range (nb_subtags)\n",
    "    ] for column in column_of_columns]\n",
    "    return flatten(matrix)\n",
    "\n",
    "def assess_performance (preds, groundtruth, subtags):\n",
    "    \n",
    "    nb_subtags = len(subtags)\n",
    "    tag_to_id = {i:subtags[i] for i in range (nb_subtags)}\n",
    "    groundtruth_col = get_flat_matrix( groundtruth, tag_to_id, nb_subtags)\n",
    "    preds_col = get_flat_matrix( preds, tag_to_id, nb_subtags)    \n",
    "    \n",
    "    results = {\n",
    "        'precision': metrics.precision_score(groundtruth_col, preds_col, average='macro'),\n",
    "        'recall': metrics.recall_score(groundtruth_col, preds_col, average='macro'),\n",
    "        'f1': metrics.fbeta_score(groundtruth_col, preds_col, 0.8, average='macro'),\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'entry_id', 'excerpt', 'analysis_framework_id', 'lead_id',\n",
       "       'project_id', 'verified', 'sectors', 'subpillars_2d', 'subpillars_1d',\n",
       "       'geo_location', 'specific_needs_groups', 'severity', 'info_date',\n",
       "       'demographic_groups', 'reliability', 'affected_groups', 'source_type',\n",
       "       'url', 'website', 'subpillars_2d_postprocessed',\n",
       "       'subpillars_1d_postprocessed', 'language', 'sectors_preprocessed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import timeit\n",
    "\n",
    "DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'data_v0.7','generated_dataset'\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_v0.7.csv'))\n",
    "\n",
    "preds_cols = [\n",
    "    'sectors_preprocessed', \n",
    "    #'subpillars_2d', \n",
    "    #'subpillars_1d',\n",
    "    'specific_needs_groups',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5384, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229b63aebf934a3b89614e712d5d5434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=54.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 100 1000 10\n",
      "groundtruth 100 1000 10\n",
      "predictions 100 1200 12\n",
      "groundtruth 100 1200 12\n",
      "predictions 84 840 10\n",
      "groundtruth 84 840 10\n",
      "predictions 84 1008 12\n",
      "groundtruth 84 1008 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "results = {col:{'precision':[],\n",
    "        'recall':[],\n",
    "        'f1': []\n",
    "               } for col in preds_cols}\n",
    "\n",
    "client = boto3.session.Session().client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "\n",
    "all_preds = []\n",
    "preds = []\n",
    "for i in tqdm(range(0,test_df.shape[0],100)):\n",
    "    test_tmp = test_df[i:i+100]\n",
    "    test_tmp = test_tmp[test_tmp['sectors'].apply(lambda x: 'Cross' not in literal_eval(x))]\n",
    "    data = test_tmp[['excerpt']]\n",
    "    input_json = data.to_json(orient=\"split\")\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName='all-models-v1',\n",
    "        Body=input_json,\n",
    "        ContentType=\"application/json; format=pandas-split\",\n",
    "    )\n",
    "    output = literal_eval(response[\"Body\"].read().decode(\"ascii\"))\n",
    "\n",
    "\n",
    "    preds = output[0]\n",
    "    thresholds = output[1]\n",
    "    final_preds = get_predictions(preds, thresholds, nb_entries = len(test_tmp))\n",
    "    all_preds.append(final_preds)\n",
    "\n",
    "    all_results = {}\n",
    "    for column in preds_cols:\n",
    "        \n",
    "        results_column = assess_performance (\n",
    "            final_preds[column], \n",
    "            test_tmp[column].apply(literal_eval).tolist(), \n",
    "            list(thresholds[column].keys()))\n",
    "\n",
    "        results[column]['f1'].append(results_column['f1'])\n",
    "        results[column]['recall'].append(results_column['recall'])\n",
    "        results[column]['precision'].append(results_column['precision'])\n",
    "    \n",
    "end = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to predict 9 tags: 0.006210952629271763\n"
     ]
    }
   ],
   "source": [
    "print('time to predict 9 tags:', (end - start) / (len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {column: {'f1': np.round(np.mean(results[column]['f1']), 3),\n",
    "                        'recall': np.round(np.mean(results[column]['recall']), 3),\n",
    "                        'precision': np.round(np.mean(results[column]['precision']), 3)}\n",
    "                       for column in preds_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sectors_preprocessed': {'f1': 0.483, 'recall': 0.509, 'precision': 0.467},\n",
       " 'specific_needs_groups': {'f1': 0.535, 'recall': 0.537, 'precision': 0.534}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'entry_id', 'excerpt', 'analysis_framework_id', 'lead_id',\n",
       "       'project_id', 'verified', 'sectors', 'subpillars_2d', 'subpillars_1d',\n",
       "       'geo_location', 'specific_needs_groups', 'severity', 'info_date',\n",
       "       'demographic_groups', 'reliability', 'affected_groups', 'source_type',\n",
       "       'url', 'website', 'subpillars_2d_postprocessed',\n",
       "       'subpillars_1d_postprocessed', 'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ratio_negative_examples_train_sectors\t0.079\n",
    "ratio_negative_examples_train_specific_needs_groups\t0.43\n",
    "ratio_negative_examples_val_sectors\t0.159\n",
    "ratio_negative_examples_val_specific_needs_groups\t0.86\n",
    "\n",
    "{'sectors': {'f1': 0.7804080268595655,\n",
    "  'recall': 0.735234683825175,\n",
    "  'precision': 0.8297208332571715},\n",
    " 'specific_needs_groups': {'f1': 0.5353509621965712,\n",
    "  'recall': 0.5370370370370371,\n",
    "  'precision': 0.5342824074074074}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French\n",
    "{'sectors': {'f1': 0.8106082312776003,\n",
    "  'recall': 0.7556102211307624,\n",
    "  'precision': 0.871518425690683},\n",
    " 'subpillars_2d': {'f1': 0.48666263534309856,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.47853985507246377},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48666263534309856,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.47853985507246377},\n",
    " 'subpillars_1d': {'f1': 0.49682228700546255,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4948156436487639},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.49682228700546255,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4948156436487639},\n",
    " 'specific_needs_groups': {'f1': 0.5776814931378339,\n",
    "  'recall': 0.6057078405372669,\n",
    "  'precision': 0.5705820085480773}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## es:\n",
    "{'sectors': {'f1': 0.7255359901310309,\n",
    "  'recall': 0.686175736789064,\n",
    "  'precision': 0.778796497427791},\n",
    " 'subpillars_2d': {'f1': 0.48429271589595213,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4747875},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48429271589595213,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4747875},\n",
    " 'subpillars_1d': {'f1': 0.49571411801277365,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4930147058823529},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.49571411801277365,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4930147058823529},\n",
    " 'specific_needs_groups': {'f1': 0.5378876984883212,\n",
    "  'recall': 0.5388369158791035,\n",
    "  'precision': 0.5395714732301624}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## english (partial)\n",
    "{'sectors': {'f1': 0.745366174594059,\n",
    "  'recall': 0.7014592113539624,\n",
    "  'precision': 0.7945457546843917},\n",
    " 'subpillars_2d': {'f1': 0.4863329548570536,\n",
    "  'recall': 0.5003407540387548,\n",
    "  'precision': 0.4843109065770831},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48670402859489476,\n",
    "  'recall': 0.5007639260944017,\n",
    "  'precision': 0.5085751836087464},\n",
    " 'subpillars_1d': {'f1': 0.4953352935458385,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.49239705882352947},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.4953352935458385,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.49239705882352947},\n",
    " 'specific_needs_groups': {'f1': 0.6435531044135325,\n",
    "  'recall': 0.6713744334322078,\n",
    "  'precision': 0.6345834181535146}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all languages\n",
    "{'sectors': {'f1': 0.7801520885183256,\n",
    "  'recall': 0.7373476698898899,\n",
    "  'precision': 0.8260876969189497},\n",
    " 'subpillars_2d': {'f1': 0.49836438284697837,\n",
    "  'recall': 0.5102698392229874,\n",
    "  'precision': 0.4953931126108611},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.5017884216090068,\n",
    "  'recall': 0.5117037791757205,\n",
    "  'precision': 0.5706896474229045},\n",
    " 'subpillars_1d': {'f1': 0.5056505310448632,\n",
    "  'recall': 0.5092592592592593,\n",
    "  'precision': 0.5033769063180827},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.5056505310448632,\n",
    "  'recall': 0.5092592592592593,\n",
    "  'precision': 0.5033769063180827},\n",
    " 'specific_needs_groups': {'f1': 0.5889316600070373,\n",
    "  'recall': 0.6478921832488638,\n",
    "  'precision': 0.5812163900505705}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "test_df = test_df[:100]\n",
    "\n",
    "\n",
    "thresholds['severity'] = {}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sectors': {'precision': 0.7932598039215686,\n",
       "  'recall': 0.7330291846413026,\n",
       "  'f1': 0.7653177724267002},\n",
       " 'subpillars_2d': {'precision': 0.47775,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.4861931592533757},\n",
       " 'subpillars_2d_postprocessed': {'precision': 0.47775,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.4861931592533757},\n",
       " 'subpillars_1d': {'precision': 0.4910294117647059,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49449156215685147},\n",
       " 'subpillars_1d_postprocessed': {'precision': 0.4910294117647059,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49449156215685147},\n",
       " 'specific_needs_groups': {'precision': 0.4970833333333333,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49821748696219037}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fasttext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "# https://fasttext.cc/docs/en/language-identification.html\n",
    "# https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "fmodel = fasttext.load_model('../../../../translator_model.bin')\n",
    "def lang_detect_ft(doc):\n",
    "    if isinstance(doc, str):\n",
    "        doc = re.sub(\"\\s+\", \" \", doc)\n",
    "        return fmodel.predict([doc])[0][0][0][len(\"__label__\"):]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['language'] = test_df.excerpt.apply(lang_detect_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
