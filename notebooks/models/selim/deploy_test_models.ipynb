{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n!pip install s3fs\\n!pip install smdebug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from ast import literal_eval\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/11/06 20:53:51 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\n",
      "2021/11/06 20:53:52 INFO mlflow.sagemaker: No model data bucket specified, using the default bucket\n",
      "2021/11/06 20:53:53 INFO mlflow.sagemaker: Default bucket `mlflow-sagemaker-us-east-1-961104659532` already exists. Skipping creation.\n",
      "2021/11/06 21:06:52 INFO mlflow.sagemaker: tag response: {'ResponseMetadata': {'RequestId': '4SGMF2HXB7T34WBQ', 'HostId': 'EtqqlSVPztyjp2YWwgkil5mi0VBpCcP2SuQwg2S4Lgwwj41iYkDPlQwG7EZJl+1r6qZQCfvvzs8=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'EtqqlSVPztyjp2YWwgkil5mi0VBpCcP2SuQwg2S4Lgwwj41iYkDPlQwG7EZJl+1r6qZQCfvvzs8=', 'x-amz-request-id': '4SGMF2HXB7T34WBQ', 'date': 'Sat, 06 Nov 2021 20:06:53 GMT', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}}\n",
      "2021/11/06 21:06:53 INFO mlflow.sagemaker: Creating new endpoint with name: all-models-testing-selim ...\n",
      "2021/11/06 21:06:53 INFO mlflow.sagemaker: Created model with arn: arn:aws:sagemaker:us-east-1:961104659532:model/all-models-testing-selim-model-obtg6oidqbo868a0jnckhw\n",
      "2021/11/06 21:06:54 INFO mlflow.sagemaker: Created endpoint configuration with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint-config/all-models-testing-selim-config-4lfbn4tysfw0ruygs05rha\n",
      "2021/11/06 21:06:54 INFO mlflow.sagemaker: Created endpoint with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint/all-models-testing-selim\n"
     ]
    }
   ],
   "source": [
    "sagemaker.deploy(\n",
    "    'all-models-testing-selim',\n",
    "    's3://deep-mlflow-artifact/16/047452da282a4b398410ff07687c64b7/artifacts/pyfunc_models_all',\n",
    "    execution_role_arn=SAGEMAKER_ROLE_ARN,\n",
    "    image_url=\"961104659532.dkr.ecr.us-east-1.amazonaws.com/mlflow-pyfunc:latest\",\n",
    "    region_name=\"us-east-1\",\n",
    "    instance_type=\"ml.g4dn.xlarge\",\n",
    "    synchronous=False,\n",
    "    archive=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "multilabel_columns = [\n",
    "    'sectors', \n",
    "    'subpillars_2d', \n",
    "    'subpillars_1d', \n",
    "    'age', \n",
    "    'gender', \n",
    "    'specific_needs_groups',\n",
    "    ]\n",
    "\n",
    "all_columns = multilabel_columns + ['severity']\n",
    "\n",
    "def get_predictions(test_probas, thresholds_dict, nb_entries=100):  \n",
    "    \"\"\"\n",
    "    test_probas structure example: {\n",
    "        'sectors':[\n",
    "            {'Nutrition': 0.032076582, 'Shelter': 0.06674846}, \n",
    "            {'Cross': 0.21885818,'Education': 0.07529669}\n",
    "        ],\n",
    "        'demographic_groups':[\n",
    "            {'Children/Youth Female (5 to 17 years old)': 0.47860646, 'Children/Youth Male (5 to 17 years old)': 0.42560646},\n",
    "            {'Children/Youth Male (5 to 17 years old)': 0.47860646, 'Infants/Toddlers (<5 years old)': 0.85}\n",
    "        ],\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    }\n",
    "    \n",
    "    thresholds_dict structure example: {\n",
    "        'sectors':{\n",
    "            'Agriculture': 0.2,\n",
    "            'Cross': 0.02,\n",
    "            .\n",
    "            .\n",
    "        },\n",
    "        'subpillars_2d':{\n",
    "            'Humanitarian Conditions->Physical And Mental Well Being': 0.7,\n",
    "            .\n",
    "            .\n",
    "        },\n",
    "        .\n",
    "        .     \n",
    "    }\n",
    "    \n",
    "    First iteration:\n",
    "    - create dict which has the same structure as 'test_probas': \n",
    "    - contains ratio probability of output divided by the threshold\n",
    "    \n",
    "    Second iteration:\n",
    "    - keep ratios superior to 1 except:\n",
    "        - for subpillars_2d: when no ratio is superior to 1 but there is at least one prediction for sectors\n",
    "        - for severity (no threshold, just keep max if there is 'Humanitarian Conditions' in secondary tags outputs)\n",
    "    \"\"\"\n",
    "\n",
    "    #create dict of ratio between probability of output and threshold\n",
    "    ratio_proba_threshold = {}\n",
    "    for column in all_columns + ['column_present']:\n",
    "        preds_column = test_probas[column]\n",
    "        dict_keys = list(thresholds_dict[column].keys())\n",
    "\n",
    "        returned_values_column = []\n",
    "        for preds_sent in preds_column:\n",
    "            dict_entry = {key:preds_sent[key]/thresholds_dict[column][key] for key in dict_keys }\n",
    "            returned_values_column.append(dict_entry)\n",
    "        ratio_proba_threshold[column] = returned_values_column\n",
    "\n",
    "    predictions = {column:[] for column in all_columns}\n",
    "    for entry_nb in range (nb_entries):\n",
    "        ratios_pos_neg_examples = ratio_proba_threshold['column_present'][entry_nb]\n",
    "        preds_pos_neg_examples = [\n",
    "            sub_tag for sub_tag in list(ratios_pos_neg_examples.keys()) if ratios_pos_neg_examples[sub_tag]>1\n",
    "        ]\n",
    "        # get the entries where the ratio is superior to 1 and put them in a dict {prediction:probability}\n",
    "        for column in multilabel_columns:\n",
    "            if column not in preds_pos_neg_examples:\n",
    "                predictions[column].append([])\n",
    "            else:\n",
    "                preds_column = ratio_proba_threshold[column][entry_nb]\n",
    "                preds_entry = [\n",
    "                    sub_tag for sub_tag in list(preds_column.keys()) if preds_column[sub_tag]>1\n",
    "                ]\n",
    "\n",
    "                #postprocessing to keep only cross if more than one prediction\n",
    "                \"\"\"if column=='sectors' and len(preds_entry)>1:\n",
    "                    preds_entry.append('Cross')\"\"\"\n",
    "\n",
    "                if len(preds_entry)>1:\n",
    "                    preds_entry = [\n",
    "                        sub_tag for sub_tag in list(preds_column.keys())\\\n",
    "                            if preds_column[sub_tag]==max(list(preds_column.values()))\n",
    "                    ]\n",
    "\n",
    "                predictions[column].append(preds_entry)\n",
    "                \n",
    "\n",
    "\n",
    "        #postprocess 'subpillars_2d'\n",
    "        \"\"\"if len(predictions['sectors'][entry_nb])>0 and len(predictions['subpillars_2d'][entry_nb])==0:\n",
    "            predictions['subpillars_2d'][entry_nb] = [\n",
    "                sub_tag for sub_tag in list(preds_column.keys()) if\\\n",
    "                        test_probas[column][entry_nb][sub_tag] == max(list(test_probas[column][entry_nb].values()))\n",
    "            ]\n",
    "\n",
    "        if len(predictions['sectors'][entry_nb])==0 and len(predictions['subpillars_2d'][entry_nb])>0:\n",
    "            predictions['subpillars_2d'][entry_nb] = []\"\"\"\n",
    "            \n",
    "        #severity  predictions and output\n",
    "        if 'Humanitarian Conditions' in str(predictions['subpillars_2d'][entry_nb]):\n",
    "            preds_column = ratio_proba_threshold['severity'][entry_nb]\n",
    "            pred_severity = [\n",
    "                sub_tag for sub_tag in list(preds_column.keys())\\\n",
    "                    if preds_column[sub_tag]==max(list(preds_column.values()))\n",
    "            ]\n",
    "\n",
    "            predictions['severity'].append(pred_severity)\n",
    "        else:\n",
    "            predictions['severity'].append([])\n",
    "            \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_flat_matrix (column_of_columns, tag_to_id, nb_subtags):\n",
    "    matrix = [[\n",
    "        1 if tag_to_id[i] in column else 0 for i in range (nb_subtags)\n",
    "    ] for column in column_of_columns]\n",
    "    return flatten(matrix)\n",
    "\n",
    "def assess_performance (preds, groundtruth, subtags):\n",
    "    \n",
    "    nb_subtags = len(subtags)\n",
    "    tag_to_id = {i:subtags[i] for i in range (nb_subtags)}\n",
    "    groundtruth_col = get_flat_matrix( groundtruth, tag_to_id, nb_subtags)\n",
    "    preds_col = get_flat_matrix( preds, tag_to_id, nb_subtags)    \n",
    "    \n",
    "    results = {\n",
    "        'precision': metrics.precision_score(groundtruth_col, preds_col, average='macro'),\n",
    "        'recall': metrics.recall_score(groundtruth_col, preds_col, average='macro'),\n",
    "        'f1': metrics.fbeta_score(groundtruth_col, preds_col, 0.8, average='macro'),\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import timeit\n",
    "\n",
    "DATA_PATH = os.path.join(\n",
    "    '..', '..', '..', \"data\", \"frameworks_data\", 'data_v0.7.1'\n",
    ")\n",
    "\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_v0.7.1.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17200, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601cf6f9f2c4483f8a459ac5a5d10dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error_code\": \"BAD_REQUEST\", \"message\": \"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 264, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py\\\", line 596, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/model.py\\\", line 257, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \\\"/opt/ml/model/code/inference.py\\\", line 39, in predict\\n    post_processed_results = get_predictions(raw_predictions, self.thresholds)\\n  File \\\"/opt/ml/model/code/get_outputs_user.py\\\", line 68, in get_predictions\\n    ratios_pos_neg_examples = ratio_proba_threshold['column_present'][entry_nb]\\nIndexError: list index out of range\\n\"}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/all-models-testing-selim in account 961104659532 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f5ba01fc0f13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     response = client.invoke_endpoint(\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mEndpointName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all-models-testing-selim'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\"error_code\": \"BAD_REQUEST\", \"message\": \"Encountered an unexpected error while evaluating the model. Verify that the serialized input Dataframe is compatible with the model for inference.\", \"stack_trace\": \"Traceback (most recent call last):\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/scoring_server/__init__.py\\\", line 264, in transformation\\n    raw_predictions = model.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/__init__.py\\\", line 596, in predict\\n    return self._model_impl.predict(data)\\n  File \\\"/miniconda/envs/custom_env/lib/python3.6/site-packages/mlflow/pyfunc/model.py\\\", line 257, in predict\\n    return self.python_model.predict(self.context, model_input)\\n  File \\\"/opt/ml/model/code/inference.py\\\", line 39, in predict\\n    post_processed_results = get_predictions(raw_predictions, self.thresholds)\\n  File \\\"/opt/ml/model/code/get_outputs_user.py\\\", line 68, in get_predictions\\n    ratios_pos_neg_examples = ratio_proba_threshold['column_present'][entry_nb]\\nIndexError: list index out of range\\n\"}\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/all-models-testing-selim in account 961104659532 for more information."
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "results = {col:{'precision':[],\n",
    "        'recall':[],\n",
    "        'f1': []} for col in all_columns }\n",
    "\n",
    "client = boto3.session.Session().client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "\n",
    "all_preds = []\n",
    "preds = []\n",
    "for i in tqdm(range(0,test_df.shape[0],100)):\n",
    "    test_tmp = test_df[i:i+100]\n",
    "    test_tmp = test_tmp[test_tmp['sectors'].apply(lambda x: 'Cross' not in literal_eval(x))]\n",
    "    data = test_tmp[['excerpt']]\n",
    "    input_json = data.to_json(orient=\"split\")\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName='all-models-testing-selim',\n",
    "        Body=input_json,\n",
    "        ContentType=\"application/json; format=pandas-split\",\n",
    "    )\n",
    "    output = literal_eval(response[\"Body\"].read().decode(\"ascii\"))\n",
    "\n",
    "\n",
    "    final_preds = output[2]\n",
    "    #thresholds = output[1]\n",
    "    #final_preds = get_predictions(preds, thresholds, nb_entries = len(test_tmp))\n",
    "    all_preds.append(final_preds)\n",
    "\n",
    "    all_results = {}\n",
    "    for column in all_columns:\n",
    "        \n",
    "        results_column = assess_performance (\n",
    "            final_preds[column], \n",
    "            test_tmp[column].apply(literal_eval).tolist(), \n",
    "            list(thresholds[column].keys())\n",
    "        )\n",
    "\n",
    "        results[column]['f1'].append(results_column['f1'])\n",
    "        results[column]['recall'].append(results_column['recall'])\n",
    "        results[column]['precision'].append(results_column['precision'])\n",
    "\n",
    "end = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to predict 9 tags: 0.006210952629271763\n"
     ]
    }
   ],
   "source": [
    "print('time to predict 9 tags:', (end - start) / (len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_scores = {column: {'f1': np.round(np.mean(results[column]['f1']), 3),\n",
    "                        'recall': np.round(np.mean(results[column]['recall']), 3),\n",
    "                        'precision': np.round(np.mean(results[column]['precision']), 3)}\n",
    "                       for column in all_columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sectors': {'f1': 0.76, 'recall': 0.745, 'precision': 0.776},\n",
       " 'subpillars_2d': {'f1': 0.526, 'recall': 0.522, 'precision': 0.537},\n",
       " 'subpillars_1d': {'f1': 0.499, 'recall': 0.501, 'precision': 0.517},\n",
       " 'age': {'f1': 0.682, 'recall': 0.679, 'precision': 0.696},\n",
       " 'gender': {'f1': 0.686, 'recall': 0.688, 'precision': 0.71},\n",
       " 'specific_needs_groups': {'f1': 0.508, 'recall': 0.509, 'precision': 0.507},\n",
       " 'severity': {'f1': 0.567, 'recall': 0.563, 'precision': 0.574}}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'entry_id', 'excerpt', 'analysis_framework_id', 'lead_id',\n",
       "       'project_id', 'verified', 'sectors', 'subpillars_2d', 'subpillars_1d',\n",
       "       'geo_location', 'specific_needs_groups', 'severity', 'info_date',\n",
       "       'demographic_groups', 'reliability', 'affected_groups', 'source_type',\n",
       "       'url', 'website', 'subpillars_2d_postprocessed',\n",
       "       'subpillars_1d_postprocessed', 'language'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ratio_negative_examples_train_sectors\t0.079\n",
    "ratio_negative_examples_train_specific_needs_groups\t0.43\n",
    "ratio_negative_examples_val_sectors\t0.159\n",
    "ratio_negative_examples_val_specific_needs_groups\t0.86\n",
    "\n",
    "{'sectors': {'f1': 0.7804080268595655,\n",
    "  'recall': 0.735234683825175,\n",
    "  'precision': 0.8297208332571715},\n",
    " 'specific_needs_groups': {'f1': 0.5353509621965712,\n",
    "  'recall': 0.5370370370370371,\n",
    "  'precision': 0.5342824074074074}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## French\n",
    "{'sectors': {'f1': 0.8106082312776003,\n",
    "  'recall': 0.7556102211307624,\n",
    "  'precision': 0.871518425690683},\n",
    " 'subpillars_2d': {'f1': 0.48666263534309856,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.47853985507246377},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48666263534309856,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.47853985507246377},\n",
    " 'subpillars_1d': {'f1': 0.49682228700546255,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4948156436487639},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.49682228700546255,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4948156436487639},\n",
    " 'specific_needs_groups': {'f1': 0.5776814931378339,\n",
    "  'recall': 0.6057078405372669,\n",
    "  'precision': 0.5705820085480773}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## es:\n",
    "{'sectors': {'f1': 0.7255359901310309,\n",
    "  'recall': 0.686175736789064,\n",
    "  'precision': 0.778796497427791},\n",
    " 'subpillars_2d': {'f1': 0.48429271589595213,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4747875},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48429271589595213,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4747875},\n",
    " 'subpillars_1d': {'f1': 0.49571411801277365,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4930147058823529},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.49571411801277365,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.4930147058823529},\n",
    " 'specific_needs_groups': {'f1': 0.5378876984883212,\n",
    "  'recall': 0.5388369158791035,\n",
    "  'precision': 0.5395714732301624}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## english (partial)\n",
    "{'sectors': {'f1': 0.745366174594059,\n",
    "  'recall': 0.7014592113539624,\n",
    "  'precision': 0.7945457546843917},\n",
    " 'subpillars_2d': {'f1': 0.4863329548570536,\n",
    "  'recall': 0.5003407540387548,\n",
    "  'precision': 0.4843109065770831},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.48670402859489476,\n",
    "  'recall': 0.5007639260944017,\n",
    "  'precision': 0.5085751836087464},\n",
    " 'subpillars_1d': {'f1': 0.4953352935458385,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.49239705882352947},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.4953352935458385,\n",
    "  'recall': 0.5,\n",
    "  'precision': 0.49239705882352947},\n",
    " 'specific_needs_groups': {'f1': 0.6435531044135325,\n",
    "  'recall': 0.6713744334322078,\n",
    "  'precision': 0.6345834181535146}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## all languages\n",
    "{'sectors': {'f1': 0.7801520885183256,\n",
    "  'recall': 0.7373476698898899,\n",
    "  'precision': 0.8260876969189497},\n",
    " 'subpillars_2d': {'f1': 0.49836438284697837,\n",
    "  'recall': 0.5102698392229874,\n",
    "  'precision': 0.4953931126108611},\n",
    " 'subpillars_2d_postprocessed': {'f1': 0.5017884216090068,\n",
    "  'recall': 0.5117037791757205,\n",
    "  'precision': 0.5706896474229045},\n",
    " 'subpillars_1d': {'f1': 0.5056505310448632,\n",
    "  'recall': 0.5092592592592593,\n",
    "  'precision': 0.5033769063180827},\n",
    " 'subpillars_1d_postprocessed': {'f1': 0.5056505310448632,\n",
    "  'recall': 0.5092592592592593,\n",
    "  'precision': 0.5033769063180827},\n",
    " 'specific_needs_groups': {'f1': 0.5889316600070373,\n",
    "  'recall': 0.6478921832488638,\n",
    "  'precision': 0.5812163900505705}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "test_df = test_df[:100]\n",
    "\n",
    "\n",
    "thresholds['severity'] = {}\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sectors': {'precision': 0.7932598039215686,\n",
       "  'recall': 0.7330291846413026,\n",
       "  'f1': 0.7653177724267002},\n",
       " 'subpillars_2d': {'precision': 0.47775,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.4861931592533757},\n",
       " 'subpillars_2d_postprocessed': {'precision': 0.47775,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.4861931592533757},\n",
       " 'subpillars_1d': {'precision': 0.4910294117647059,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49449156215685147},\n",
       " 'subpillars_1d_postprocessed': {'precision': 0.4910294117647059,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49449156215685147},\n",
       " 'specific_needs_groups': {'precision': 0.4970833333333333,\n",
       "  'recall': 0.5,\n",
       "  'f1': 0.49821748696219037}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(1==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import fasttext\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "# https://fasttext.cc/docs/en/language-identification.html\n",
    "# https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\n",
    "fmodel = fasttext.load_model('../../../../translator_model.bin')\n",
    "def lang_detect_ft(doc):\n",
    "    if isinstance(doc, str):\n",
    "        doc = re.sub(\"\\s+\", \" \", doc)\n",
    "        return fmodel.predict([doc])[0][0][0][len(\"__label__\"):]\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['language'] = test_df.excerpt.apply(lang_detect_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
