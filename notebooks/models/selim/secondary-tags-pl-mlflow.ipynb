{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These requirements are necessary if you launch this notebook from SageMaker instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install mlflow\\n!pip install pytorch-lightning\\n!pip install transformers\\n!pip install tqdm\\n!pip install sagemaker\\n!pip install s3fs\\n!pip install smdebug'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"!pip install mlflow\n",
    "!pip install pytorch-lightning\n",
    "!pip install transformers\n",
    "!pip install tqdm\n",
    "!pip install sagemaker\n",
    "!pip install s3fs\n",
    "!pip install smdebug\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "from typing import Any, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:49:30.843642Z",
     "start_time": "2021-06-01T14:49:30.663973Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torchmetrics\n",
    "from torchmetrics.functional import accuracy, f1, auroc\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.core.decorators import auto_move_data\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from matplotlib import rc\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from transformers.optimization import (\n",
    "    Adafactor,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local constants, regarding the data, MLFlow server, paths, etc..: use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from deep.constants import *\n",
    "from deep.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the data you want. We advise the `pandas` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T14:57:29.882333Z",
     "start_time": "2021-06-01T14:57:28.547379Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('..', '..', '..', \"data\", \"data_secondary_tags\", \"severity_tags.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, index_col=0, lineterminator='\\n')\n",
    "df['severity'] = df['tag_value'].apply(lambda x: [x])\n",
    "df[['entry_id', 'excerpt', 'severity']].to_csv('severity_final.csv')\n",
    "df = pd.read_csv('severity_final.csv', index_col=0)\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128263</th>\n",
       "      <td>27251</td>\n",
       "      <td>• Figures for Chimoio urban area were omitted ...</td>\n",
       "      <td>['No problem']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464404</th>\n",
       "      <td>248212</td>\n",
       "      <td>[1st Nov2020,North east Nigeria]FOOD AND NUTRI...</td>\n",
       "      <td>['Major']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entry_id                                            excerpt  \\\n",
       "128263     27251  • Figures for Chimoio urban area were omitted ...   \n",
       "464404    248212  [1st Nov2020,North east Nigeria]FOOD AND NUTRI...   \n",
       "\n",
       "              severity  \n",
       "128263  ['No problem']  \n",
       "464404       ['Major']  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-27T15:42:32.024647Z",
     "start_time": "2021-05-27T15:42:31.984694Z"
    }
   },
   "source": [
    "### Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:29:20.899415Z",
     "start_time": "2021-06-09T08:29:19.327852Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/selim/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to upload data to an S3 bucket. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.201910Z",
     "start_time": "2021-06-09T08:29:28.837139Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample = False  # To make the computations faster, sample = True.\n",
    "\n",
    "if sample:\n",
    "    train_df = train_df.sample(n=1000)\n",
    "    val_df = val_df.sample(n=1000)\n",
    "    \n",
    "job_name = f\"pytorch-{formatted_time()}-subpillars-model-test-mlflow\"  # cannot be changed\n",
    "input_path = DEV_BUCKET / 'training' / 'input_data' / job_name  # Do not change this\n",
    "\n",
    "train_path = str(input_path / 'train.pickle')\n",
    "val_path = str(input_path / 'val.pickle')\n",
    "\n",
    "\n",
    "train_df.to_pickle(train_path, protocol=4)  # protocol 4 is necessary, since SageMaker uses python 3.6\n",
    "val_df.to_pickle(val_path, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.284096Z",
     "start_time": "2021-06-09T08:31:43.206457Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU instances\n",
    "\n",
    "instances = [\n",
    "    'ml.p2.xlarge',\n",
    "    'ml.p3.2xlarge'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters are passed as command line arguments to the training script. \n",
    "\n",
    "You can add/change them as you like. It's important to keep the `tracking_uri` and the `experiment_name` which are used by MLFlow.\n",
    "\n",
    "The class `PyTorch` is part of the `SageMaker` python API. The parameters are important and you should probably not change most of them. The ones you may want to change are:\n",
    "\n",
    "- `instance_type`, specify the instance you want\n",
    "- `source_dir`, specify your script directory. Try to use global variable as much as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.458886Z",
     "start_time": "2021-06-09T08:31:43.304626Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "\n",
    "hyperparameters={\n",
    "    'tracking_uri': MLFLOW_SERVER,\n",
    "    'max_len': 512,\n",
    "    'epochs': 5,\n",
    "    'model_name': 'microsoft/xtremedistil-l6-h384-uncased',\n",
    "    'tokenizer_name': 'microsoft/xtremedistil-l6-h384-uncased',\n",
    "    'dropout_rate': 0.3,\n",
    "    'pred_threshold':0.4,\n",
    "    'output_length': 384,\n",
    "    'learning_rate': 7e-5,\n",
    "    'experiment_name': \"pl-severity\",\n",
    "    'training_column':'severity',\n",
    "    'multiclass_bool':False,\n",
    "    'train_with_whole_dataset':True\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point='train_mlflow.py',\n",
    "    source_dir=str('../../../scripts/training/selim/multiclass-lightning'),\n",
    "    output_path=str(DEV_BUCKET/'models/'),\n",
    "    code_location=str(input_path),\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    framework_version='1.8',\n",
    "    py_version='py36',\n",
    "    hyperparameters = hyperparameters,\n",
    "    job_name=job_name,\n",
    "#     train_instance_count=2,\n",
    "#     train_instance_type=\"ml.c4.xlarge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:43.482969Z",
     "start_time": "2021-06-09T08:31:43.459884Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit_arguments = {\n",
    "    'train': str(input_path),\n",
    "    'test': str(input_path)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T08:31:45.995868Z",
     "start_time": "2021-06-09T08:31:43.484212Z"
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-27 11:35:20 Starting - Starting the training job...\n",
      "2021-08-27 11:35:49 Starting - Launching requested ML instancesProfilerReport-1630064117: InProgress\n",
      "...\n",
      "2021-08-27 11:36:22 Starting - Preparing the instances for training.........\n",
      "2021-08-27 11:38:14 Downloading - Downloading input data\n",
      "2021-08-27 11:38:14 Training - Downloading the training image.........................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2021-08-27 11:42:33,985 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2021-08-27 11:42:34,009 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2021-08-27 11:42:34,018 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2021-08-27 11:42:34,359 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.8.2\n",
      "  Downloading transformers-4.8.2-py3-none-any.whl (2.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow==2.4.0\n",
      "  Downloading tensorflow-2.4.0-cp36-cp36m-manylinux2010_x86_64.whl (394.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.3.8\n",
      "  Downloading pytorch_lightning-1.3.8-py3-none-any.whl (813 kB)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics==0.4.1\n",
      "  Downloading torchmetrics-0.4.1-py3-none-any.whl (234 kB)\u001b[0m\n",
      "\u001b[34mCollecting tqdm==4.41.1\n",
      "  Downloading tqdm-4.41.1-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting nlpaug==1.1.6\n",
      "  Downloading nlpaug-1.1.6-py3-none-any.whl (405 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk==3.2.5\n",
      "  Downloading nltk-3.2.5.tar.gz (1.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting mlflow==1.18.0\n",
      "  Downloading mlflow-1.18.0-py3-none-any.whl (14.2 MB)\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn==0.22.2.post1\n",
      "  Downloading scikit_learn-0.22.2.post1-cp36-cp36m-manylinux1_x86_64.whl (7.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting sagemaker==2.49.1\n",
      "  Downloading sagemaker-2.49.1.tar.gz (421 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3fs==2021.07.0\n",
      "  Downloading s3fs-2021.7.0-py3-none-any.whl (25 kB)\u001b[0m\n",
      "\u001b[34mCollecting smdebug==1.0.11\n",
      "  Downloading smdebug-1.0.11-py2.py3-none-any.whl (269 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (21.0)\u001b[0m\n",
      "\u001b[34mCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (4.6.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.8.27-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (1.19.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (2.25.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.8.2->-r requirements.txt (line 1)) (0.8)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.35.1)\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\u001b[0m\n",
      "\u001b[34mCollecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34mCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (0.2.0)\u001b[0m\n",
      "\u001b[34mCollecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.4.0->-r requirements.txt (line 2)) (3.17.3)\u001b[0m\n",
      "\u001b[34mCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\u001b[0m\n",
      "\u001b[34mCollecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting numpy>=1.17\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (2021.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow!=8.3.0 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (8.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (0.18.2)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.6/site-packages (from pytorch-lightning==1.3.8->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy\n",
      "  Downloading SQLAlchemy-1.4.23-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.5)\u001b[0m\n",
      "\u001b[34mCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (2021.1)\u001b[0m\n",
      "\u001b[34mCollecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting entrypoints\n",
      "  Downloading entrypoints-0.3-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting Flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (1.6.0)\u001b[0m\n",
      "\u001b[34mCollecting gitpython>=2.1.0\n",
      "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.6/site-packages (from mlflow==1.18.0->-r requirements.txt (line 8)) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.1-py3-none-any.whl (42 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 9)) (1.5.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn==0.22.2.post1->-r requirements.txt (line 9)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 10)) (21.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.16.32 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 10)) (1.17.110)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 10)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 10)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.6/site-packages (from sagemaker==2.49.1->-r requirements.txt (line 10)) (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting aiobotocore>=1.0.1\n",
      "  Downloading aiobotocore-1.4.1.tar.gz (52 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument>=3.1.3 in /opt/conda/lib/python3.6/site-packages (from smdebug==1.0.11->-r requirements.txt (line 12)) (3.4.2)\u001b[0m\n",
      "\u001b[34mCollecting botocore<1.20.107,>=1.20.106\n",
      "  Downloading botocore-1.20.106-py2.py3-none-any.whl (7.7 MB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp>=3.3.1\n",
      "  Downloading aiohttp-3.7.4.post0-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34mCollecting aioitertools>=0.5.1\n",
      "  Downloading aioitertools-0.8.0-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp36-cp36m-manylinux2014_x86_64.whl (293 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<5.0,>=2.0 in /opt/conda/lib/python3.6/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 11)) (3.0.4)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\u001b[0m\n",
      "\u001b[34mCollecting idna-ssl>=1.0\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting Mako\n",
      "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34mCollecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from alembic<=1.4.1->mlflow==1.18.0->-r requirements.txt (line 8)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 10)) (0.4.2)\u001b[0m\n",
      "\u001b[34mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.18.30-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34mCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-08-27 11:43:15 Training - Training image download completed. Training in progress.\u001b[34mCollecting boto3>=1.16.32\n",
      "  Downloading boto3-1.18.29-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.28-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.27-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.26-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.16.32->sagemaker==2.49.1->-r requirements.txt (line 10)) (0.10.0)\n",
      "  Downloading boto3-1.18.25-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.24-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.23-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.22-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.21-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.20-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.19-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.18-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.17-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.16-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.15-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.14-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.13-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.12-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.11-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.10-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.9-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.8-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.7-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.6-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.5-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.4-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.3-py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.18.2-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.1-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.18.0-py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.17.112-py2.py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.17.111-py2.py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34m  Downloading boto3-1.17.109-py2.py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.17.108-py2.py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.17.107-py2.py3-none-any.whl (131 kB)\n",
      "  Downloading boto3-1.17.106-py2.py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.6/site-packages (from botocore<1.20.107,>=1.20.106->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 11)) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.6/site-packages (from databricks-cli>=0.8.7->mlflow==1.18.0->-r requirements.txt (line 8)) (0.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=4.0.0->mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.6/site-packages (from idna-ssl>=1.0->aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs==2021.07.0->-r requirements.txt (line 11)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.8.2->-r requirements.txt (line 1)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.8.2->-r requirements.txt (line 1)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from pyinstrument>=3.1.3->smdebug==1.0.11->-r requirements.txt (line 12)) (0.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.8.2->-r requirements.txt (line 1)) (2021.5.30)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.6/site-packages (from sqlalchemy->mlflow==1.18.0->-r requirements.txt (line 8)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0->-r requirements.txt (line 2)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.6/site-packages (from Flask->mlflow==1.18.0->-r requirements.txt (line 8)) (3.0.1)\u001b[0m\n",
      "\u001b[34mCollecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=3.0->Flask->mlflow==1.18.0->-r requirements.txt (line 8)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 10)) (1.6.6.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill>=0.3.4 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 10)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 10)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess>=0.70.12 in /opt/conda/lib/python3.6/site-packages (from pathos->sagemaker==2.49.1->-r requirements.txt (line 10)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mCollecting prometheus_client\n",
      "  Downloading prometheus_client-0.11.0-py2.py3-none-any.whl (56 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: nltk, sagemaker, aiobotocore, alembic, databricks-cli, idna-ssl, termcolor, wrapt, prometheus-flask-exporter\n",
      "  Building wheel for nltk (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for nltk (setup.py): finished with status 'done'\n",
      "  Created wheel for nltk: filename=nltk-3.2.5-py3-none-any.whl size=1392144 sha256=da7fcaf0414b164eca37153d3239f3072dfd5423b4b411abbb6e4f3f5e03ba0e\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/7f/71/cb36468789a03b5e2908281c8e1ce093e6860258b6b61677d8\n",
      "  Building wheel for sagemaker (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for sagemaker (setup.py): finished with status 'done'\n",
      "  Created wheel for sagemaker: filename=sagemaker-2.49.1-py2.py3-none-any.whl size=591917 sha256=3398aac13f235f1d0a2cc7dc48109320cc2e76d481a20d1a99e60d2c300222bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/af/ea/8ff5943a87155df5b184e54474fbf2b59b75e5c172854643c6\n",
      "  Building wheel for aiobotocore (setup.py): started\n",
      "  Building wheel for aiobotocore (setup.py): finished with status 'done'\n",
      "  Created wheel for aiobotocore: filename=aiobotocore-1.4.1-py3-none-any.whl size=49822 sha256=9713edd486288c8b455b0ad1c3ae9aa9f52115d31a7abad991e5da43c5c41154\n",
      "  Stored in directory: /root/.cache/pip/wheels/0e/ee/c0/a79457b0bdf63d19a62fb58df7d8f760e5e4811ef2f7058436\n",
      "  Building wheel for alembic (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for alembic (setup.py): finished with status 'done'\n",
      "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=21e4945a43f9ff9553a23b089bcd87da99905e7a1a364fd0d27f6b5370226426\n",
      "  Stored in directory: /root/.cache/pip/wheels/e9/7b/aa/e18c983d8236b141f85838ba0f8e4e4ae9bcf7f1e00ff726ec\n",
      "  Building wheel for databricks-cli (setup.py): started\n",
      "  Building wheel for databricks-cli (setup.py): finished with status 'done'\n",
      "  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105259 sha256=b6c71f97e6506a8ba43c627d8e66a74b7212ad541fc0965eab11ce6c214da666\n",
      "  Stored in directory: /root/.cache/pip/wheels/c0/0b/2a/ba06e44bcbf2a48da34fde3c3ebcf5f7d5ef8cb975f9571305\n",
      "  Building wheel for idna-ssl (setup.py): started\n",
      "  Building wheel for idna-ssl (setup.py): finished with status 'done'\n",
      "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=f56342dc9f486a675af5e9e220a5e9ee574ac83e99203d43258aff5099eb904d\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for termcolor (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=088f36fefc81ca47d900f7fb34780e3c251442c9172186c4da7642dd3cbf0ebd\n",
      "  Stored in directory: /root/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "  Building wheel for wrapt (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl size=69750 sha256=c4af8790629b080aa801ea77d910e04ebe14575bde4438ae6b5ec93dd0bedc38\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/42/7f/23cae9ff6ef66798d00dc5d659088e57dbba01566f6c60db63\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): started\n",
      "  Building wheel for prometheus-flask-exporter (setup.py): finished with status 'done'\n",
      "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17398 sha256=735b9f02816889bbf29e05ae2358054b5e5edb5d85bf0ef85f0bef6aefe8b4d9\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/77/e8/3ca90b66243b0b58d5a5323a3da02cc8c5daf1de7a65141701\u001b[0m\n",
      "\u001b[34mSuccessfully built nltk sagemaker aiobotocore alembic databricks-cli idna-ssl termcolor wrapt prometheus-flask-exporter\u001b[0m\n",
      "\u001b[34mInstalling collected packages: six, typing-extensions, pyasn1-modules, oauthlib, multidict, cachetools, yarl, smmap, requests-oauthlib, numpy, itsdangerous, idna-ssl, google-auth, botocore, async-timeout, wrapt, tqdm, tensorboard-plugin-wit, tensorboard-data-server, sqlalchemy, regex, python-editor, prometheus-client, markdown, Mako, grpcio, google-auth-oauthlib, gitdb, Flask, filelock, aioitertools, aiohttp, absl-py, torchmetrics, tokenizers, termcolor, tensorflow-estimator, tensorboard, sqlparse, sacremoses, querystring-parser, pyDeprecate, prometheus-flask-exporter, opt-einsum, keras-preprocessing, huggingface-hub, h5py, gunicorn, gitpython, gast, flatbuffers, entrypoints, docker, databricks-cli, boto3, astunparse, alembic, aiobotocore, transformers, tensorflow, smdebug, scikit-learn, sagemaker, s3fs, pytorch-lightning, nltk, nlpaug, mlflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.20.110\u001b[0m\n",
      "\u001b[34m    Uninstalling botocore-1.20.110:\n",
      "      Successfully uninstalled botocore-1.20.110\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.51.0\n",
      "    Uninstalling tqdm-4.51.0:\n",
      "      Successfully uninstalled tqdm-4.51.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.8.0\n",
      "    Uninstalling h5py-2.8.0:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled h5py-2.8.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.17.110\n",
      "    Uninstalling boto3-1.17.110:\n",
      "      Successfully uninstalled boto3-1.17.110\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: smdebug\n",
      "    Found existing installation: smdebug 1.0.9\n",
      "    Uninstalling smdebug-1.0.9:\n",
      "      Successfully uninstalled smdebug-1.0.9\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.48.2\n",
      "    Uninstalling sagemaker-2.48.2:\n",
      "      Successfully uninstalled sagemaker-2.48.2\u001b[0m\n",
      "\u001b[34m  Attempting uninstall: s3fs\n",
      "    Found existing installation: s3fs 0.4.2\n",
      "    Uninstalling s3fs-0.4.2:\n",
      "      Successfully uninstalled s3fs-0.4.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed Flask-2.0.1 Mako-1.1.5 absl-py-0.13.0 aiobotocore-1.4.1 aiohttp-3.7.4.post0 aioitertools-0.8.0 alembic-1.4.1 astunparse-1.6.3 async-timeout-3.0.1 boto3-1.17.106 botocore-1.20.106 cachetools-4.2.2 databricks-cli-0.15.0 docker-5.0.0 entrypoints-0.3 filelock-3.0.12 flatbuffers-1.12 gast-0.3.3 gitdb-4.0.7 gitpython-3.1.18 google-auth-1.35.0 google-auth-oauthlib-0.4.5 grpcio-1.32.0 gunicorn-20.1.0 h5py-2.10.0 huggingface-hub-0.0.12 idna-ssl-1.1.0 itsdangerous-2.0.1 keras-preprocessing-1.1.2 markdown-3.3.4 mlflow-1.18.0 multidict-5.1.0 nlpaug-1.1.6 nltk-3.2.5 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 prometheus-client-0.11.0 prometheus-flask-exporter-0.18.2 pyDeprecate-0.3.0 pyasn1-modules-0.2.8 python-editor-1.0.4 pytorch-lightning-1.3.8 querystring-parser-1.2.4 regex-2021.8.27 requests-oauthlib-1.3.0 s3fs-2021.7.0 sacremoses-0.0.45 sagemaker-2.49.1 scikit-learn-0.22.2.post1 six-1.15.0 smdebug-1.0.11 smmap-4.0.0 sqlalchemy-1.4.23 sqlparse-0.4.1 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.0 tensorflow-estimator-2.4.0 termcolor-1.1.0 tokenizers-0.10.3 torchmetrics-0.4.1 tqdm-4.41.1 transformers-4.8.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mawscli 1.19.110 requires botocore==1.20.110, but you have botocore 1.20.106 which is incompatible.\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-27 11:43:48,690 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout_rate\": 0.3,\n",
      "        \"experiment_name\": \"pl-severity\",\n",
      "        \"train_with_whole_dataset\": true,\n",
      "        \"multiclass_bool\": false,\n",
      "        \"max_len\": 512,\n",
      "        \"model_name\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"output_length\": 384,\n",
      "        \"tokenizer_name\": \"microsoft/xtremedistil-l6-h384-uncased\",\n",
      "        \"epochs\": 5,\n",
      "        \"learning_rate\": 7e-05,\n",
      "        \"pred_threshold\": 0.4,\n",
      "        \"tracking_uri\": \"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\n",
      "        \"training_column\": \"severity\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_mlflow\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_mlflow.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout_rate\":0.3,\"epochs\":5,\"experiment_name\":\"pl-severity\",\"learning_rate\":7e-05,\"max_len\":512,\"model_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"multiclass_bool\":false,\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_with_whole_dataset\":true,\"training_column\":\"severity\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_mlflow.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_mlflow\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout_rate\":0.3,\"epochs\":5,\"experiment_name\":\"pl-severity\",\"learning_rate\":7e-05,\"max_len\":512,\"model_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"multiclass_bool\":false,\"output_length\":384,\"pred_threshold\":0.4,\"tokenizer_name\":\"microsoft/xtremedistil-l6-h384-uncased\",\"tracking_uri\":\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"train_with_whole_dataset\":true,\"training_column\":\"severity\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-deep-experiments-dev/training/input_data/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/pytorch-2021-08-27-13-34-03-894-subpillars-model-test-mlflow/source/sourcedir.tar.gz\",\"module_name\":\"train_mlflow\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_mlflow.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout_rate\",\"0.3\",\"--epochs\",\"5\",\"--experiment_name\",\"pl-severity\",\"--learning_rate\",\"7e-05\",\"--max_len\",\"512\",\"--model_name\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--multiclass_bool\",\"False\",\"--output_length\",\"384\",\"--pred_threshold\",\"0.4\",\"--tokenizer_name\",\"microsoft/xtremedistil-l6-h384-uncased\",\"--tracking_uri\",\"http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\",\"--train_with_whole_dataset\",\"True\",\"--training_column\",\"severity\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT_RATE=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_EXPERIMENT_NAME=pl-severity\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_WITH_WHOLE_DATASET=true\u001b[0m\n",
      "\u001b[34mSM_HP_MULTICLASS_BOOL=false\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_NAME=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_LENGTH=384\u001b[0m\n",
      "\u001b[34mSM_HP_TOKENIZER_NAME=microsoft/xtremedistil-l6-h384-uncased\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=7e-05\u001b[0m\n",
      "\u001b[34mSM_HP_PRED_THRESHOLD=0.4\u001b[0m\n",
      "\u001b[34mSM_HP_TRACKING_URI=http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_COLUMN=severity\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_mlflow.py --dropout_rate 0.3 --epochs 5 --experiment_name pl-severity --learning_rate 7e-05 --max_len 512 --model_name microsoft/xtremedistil-l6-h384-uncased --multiclass_bool False --output_length 384 --pred_threshold 0.4 --tokenizer_name microsoft/xtremedistil-l6-h384-uncased --tracking_uri http://mlflow-deep-387470f3-1883319727.us-east-1.elb.amazonaws.com/ --train_with_whole_dataset True --training_column severity\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[nltk_data] Downloading package averaged_perceptron_tagger to\u001b[0m\n",
      "\u001b[34m[nltk_data]     /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package wordnet to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/wordnet.zip.\u001b[0m\n",
      "\u001b[34m[nltk_data] Downloading package omw to /root/nltk_data...\u001b[0m\n",
      "\u001b[34m[nltk_data]   Unzipping corpora/omw.zip.\u001b[0m\n",
      "\u001b[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s][2021-08-27 11:45:47.034 algo-1:91 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.070 algo-1:91 INFO profiler_config_parser.py:102] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.071 algo-1:91 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.072 algo-1:91 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.072 algo-1:91 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.072 algo-1:91 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.251 algo-1:91 INFO hook.py:594] name:model.l0.embeddings.word_embeddings.weight count_params:11720448\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.251 algo-1:91 INFO hook.py:594] name:model.l0.embeddings.position_embeddings.weight count_params:196608\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.embeddings.token_type_embeddings.weight count_params:768\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.embeddings.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.embeddings.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.252 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.0.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.253 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.254 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.1.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.255 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.256 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.2.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.257 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.3.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.258 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.259 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.4.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.query.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.query.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.key.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.key.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.value.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.self.value.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.260 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.attention.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.intermediate.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.intermediate.dense.bias count_params:1536\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.output.dense.weight count_params:589824\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.output.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.output.LayerNorm.weight count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.encoder.layer.5.output.LayerNorm.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.pooler.dense.weight count_params:147456\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l0.pooler.dense.bias count_params:384\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l1.weight count_params:57600\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.261 algo-1:91 INFO hook.py:594] name:model.l1.bias count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.262 algo-1:91 INFO hook.py:594] name:model.l2.weight count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.262 algo-1:91 INFO hook.py:594] name:model.l2.bias count_params:150\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.262 algo-1:91 INFO hook.py:594] name:model.l4.weight count_params:750\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.262 algo-1:91 INFO hook.py:594] name:model.l4.bias count_params:5\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.262 algo-1:91 INFO hook.py:596] Total Trainable Params: 22772021\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.263 algo-1:91 INFO hook.py:423] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2021-08-27 11:45:47.266 algo-1:91 INFO hook.py:486] Hook is writing from the hook with pid: 91\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                              #015#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/1355 [00:00<?, ?it/s]#015Epoch 0:   0%|          | 0/1355 [00:00<?, ?it/s] #015Epoch 0:   2%|▏         | 30/1355 [00:02<01:53, 11.71it/s]#015Epoch 0:   2%|▏         | 30/1355 [00:02<01:53, 11.71it/s, loss=3.32, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.550]#015Epoch 0:   4%|▍         | 60/1355 [00:04<01:42, 12.63it/s, loss=3.32, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.550]#015Epoch 0:   4%|▍         | 60/1355 [00:04<01:42, 12.63it/s, loss=2.06, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.570]#015Epoch 0:   7%|▋         | 90/1355 [00:06<01:36, 13.11it/s, loss=2.06, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.570]#015Epoch 0:   7%|▋         | 90/1355 [00:06<01:36, 13.11it/s, loss=1.4, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.651] #015Epoch 0:   9%|▉         | 120/1355 [00:09<01:33, 13.22it/s, loss=1.4, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.651]#015Epoch 0:   9%|▉         | 120/1355 [00:09<01:33, 13.22it/s, loss=1.35, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.652]#015Epoch 0:  11%|█         | 150/1355 [00:11<01:29, 13.40it/s, loss=1.35, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.652]#015Epoch 0:  11%|█         | 150/1355 [00:11<01:29, 13.40it/s, loss=1.34, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.561]#015Epoch 0:  13%|█▎        | 180/1355 [00:13<01:27, 13.38it/s, loss=1.34, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.561]#015Epoch 0:  13%|█▎        | 180/1355 [00:13<01:27, 13.38it/s, loss=1.39, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.675]#015Epoch 0:  15%|█▌        | 210/1355 [00:15<01:25, 13.33it/s, loss=1.39, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.675]#015Epoch 0:  15%|█▌        | 210/1355 [00:15<01:25, 13.33it/s, loss=1.26, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.576]#015Epoch 0:  18%|█▊        | 240/1355 [00:17<01:23, 13.42it/s, loss=1.26, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.576]#015Epoch 0:  18%|█▊        | 240/1355 [00:17<01:23, 13.42it/s, loss=0.719, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.649]#015Epoch 0:  20%|█▉        | 270/1355 [00:20<01:20, 13.45it/s, loss=0.719, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.649]#015Epoch 0:  20%|█▉        | 270/1355 [00:20<01:20, 13.45it/s, loss=1.32, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.644] #015Epoch 0:  22%|██▏       | 300/1355 [00:22<01:17, 13.54it/s, loss=1.32, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.644]#015Epoch 0:  22%|██▏       | 300/1355 [00:22<01:17, 13.54it/s, loss=0.695, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.651]#015Epoch 0:  24%|██▍       | 330/1355 [00:24<01:15, 13.56it/s, loss=0.695, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.651]#015Epoch 0:  24%|██▍       | 330/1355 [00:24<01:15, 13.56it/s, loss=0.947, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.637]#015Epoch 0:  27%|██▋       | 360/1355 [00:26<01:13, 13.58it/s, loss=0.947, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.637]#015Epoch 0:  27%|██▋       | 360/1355 [00:26<01:13, 13.58it/s, loss=1.62, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.654] #015Epoch 0:  29%|██▉       | 390/1355 [00:28<01:10, 13.64it/s, loss=1.62, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.654]#015Epoch 0:  29%|██▉       | 390/1355 [00:28<01:10, 13.64it/s, loss=1.47, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.675]#015Epoch 0:  31%|███       | 420/1355 [00:30<01:08, 13.62it/s, loss=1.47, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.675]#015Epoch 0:  31%|███       | 420/1355 [00:30<01:08, 13.62it/s, loss=1.03, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.701]#015Epoch 0:  33%|███▎      | 450/1355 [00:32<01:06, 13.65it/s, loss=1.03, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.701]#015Epoch 0:  33%|███▎      | 450/1355 [00:32<01:06, 13.65it/s, loss=0.698, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.602]#015Epoch 0:  35%|███▌      | 480/1355 [00:35<01:04, 13.65it/s, loss=0.698, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.602]#015Epoch 0:  35%|███▌      | 480/1355 [00:35<01:04, 13.65it/s, loss=1.22, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.788] #015Epoch 0:  38%|███▊      | 510/1355 [00:37<01:01, 13.67it/s, loss=1.22, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.788]#015Epoch 0:  38%|███▊      | 510/1355 [00:37<01:01, 13.67it/s, loss=0.996, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.730]#015Epoch 0:  40%|███▉      | 540/1355 [00:39<00:59, 13.70it/s, loss=0.996, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.730]#015Epoch 0:  40%|███▉      | 540/1355 [00:39<00:59, 13.70it/s, loss=1.54, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.634] #015Epoch 0:  42%|████▏     | 570/1355 [00:41<00:57, 13.71it/s, loss=1.54, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.634]#015Epoch 0:  42%|████▏     | 570/1355 [00:41<00:57, 13.71it/s, loss=1.29, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=1.29, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=1.19, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.684]#015Epoch 0:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=1.19, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.684]#015Epoch 0:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=1.62, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.740]#015Epoch 0:  49%|████▊     | 660/1355 [00:48<00:50, 13.73it/s, loss=1.62, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.740]#015Epoch 0:  49%|████▊     | 660/1355 [00:48<00:50, 13.73it/s, loss=1.13, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.589]#015Epoch 0:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=1.13, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.589]#015Epoch 0:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=1.4, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.713] #015Epoch 0:  53%|█████▎    | 720/1355 [00:52<00:46, 13.75it/s, loss=1.4, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.713]#015Epoch 0:  53%|█████▎    | 720/1355 [00:52<00:46, 13.75it/s, loss=1.01, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  55%|█████▌    | 750/1355 [00:54<00:43, 13.76it/s, loss=1.01, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  55%|█████▌    | 750/1355 [00:54<00:43, 13.76it/s, loss=1.08, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.713]#015Epoch 0:  58%|█████▊    | 780/1355 [00:56<00:41, 13.76it/s, loss=1.08, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.713]#015Epoch 0:  58%|█████▊    | 780/1355 [00:56<00:41, 13.76it/s, loss=1.29, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.706]#015Epoch 0:  60%|█████▉    | 810/1355 [00:58<00:39, 13.75it/s, loss=1.29, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.706]#015Epoch 0:  60%|█████▉    | 810/1355 [00:58<00:39, 13.75it/s, loss=1.09, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  62%|██████▏   | 840/1355 [01:01<00:37, 13.77it/s, loss=1.09, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.725]#015Epoch 0:  62%|██████▏   | 840/1355 [01:01<00:37, 13.77it/s, loss=0.626, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]#015Epoch 0:  64%|██████▍   | 870/1355 [01:03<00:35, 13.77it/s, loss=0.626, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]#015Epoch 0:  64%|██████▍   | 870/1355 [01:03<00:35, 13.77it/s, loss=0.726, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.638]#015Epoch 0:  66%|██████▋   | 900/1355 [01:05<00:33, 13.78it/s, loss=0.726, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.638]#015Epoch 0:  66%|██████▋   | 900/1355 [01:05<00:33, 13.78it/s, loss=1.11, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.701] #015Epoch 0:  69%|██████▊   | 930/1355 [01:07<00:30, 13.78it/s, loss=1.11, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.701]#015Epoch 0:  69%|██████▊   | 930/1355 [01:07<00:30, 13.78it/s, loss=0.91, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.670]#015Epoch 0:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=0.91, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.670]#015Epoch 0:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=1.03, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.735]#015Epoch 0:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=1.03, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.735]#015Epoch 0:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=1.63, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.743]#015Epoch 0:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.76it/s, loss=1.63, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.743]#015Epoch 0:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.76it/s, loss=0.712, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.787]#015Epoch 0:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.76it/s, loss=0.712, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.787]#015Epoch 0:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.76it/s, loss=1.51, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.816] #015Epoch 0:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.75it/s, loss=1.51, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.816]#015Epoch 0:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.75it/s, loss=1.04, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.682]#015Epoch 0:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.75it/s, loss=1.04, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.682]#015Epoch 0:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.75it/s, loss=0.929, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.750]#015Epoch 0:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.76it/s, loss=0.929, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.750]#015Epoch 0:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.76it/s, loss=0.673, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.699]#015Epoch 0:  86%|████████▋ | 1170/1355 [01:25<00:13, 13.76it/s, loss=0.673, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.699]#015Epoch 0:  86%|████████▋ | 1170/1355 [01:25<00:13, 13.76it/s, loss=0.621, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.745]#015Epoch 0:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.77it/s, loss=0.621, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.745]#015Epoch 0:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.77it/s, loss=1.22, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.777] #015Epoch 0:  91%|█████████ | 1230/1355 [01:29<00:09, 13.77it/s, loss=1.22, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.777]#015Epoch 0:  91%|█████████ | 1230/1355 [01:29<00:09, 13.77it/s, loss=0.6, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764] #015Epoch 0:  93%|█████████▎| 1260/1355 [01:29<00:06, 14.08it/s, loss=0.6, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/124 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  24%|██▍       | 30/124 [00:01<00:03, 23.98it/s]#033[A#015Epoch 0:  95%|█████████▌| 1290/1355 [01:30<00:04, 14.22it/s, loss=0.6, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]\u001b[0m\n",
      "\u001b[34m#015Validating:  48%|████▊     | 60/124 [00:02<00:02, 25.17it/s]#033[A#015Epoch 0:  97%|█████████▋| 1320/1355 [01:31<00:02, 14.38it/s, loss=0.6, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  73%|███████▎  | 90/124 [00:03<00:01, 26.03it/s]#033[A#015Epoch 0: 100%|█████████▉| 1350/1355 [01:32<00:00, 14.54it/s, loss=0.6, v_num=0, val_f1_epoch=0.167, val_loss_epoch=0.702, train_f1=0.764]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 120/124 [00:04<00:00, 26.65it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 124/124 [00:04<00:00, 28.11it/s]#033[A#015Epoch 0: 100%|██████████| 1355/1355 [01:34<00:00, 14.40it/s, loss=0.597, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.853, val_f1_step=0.844, val_loss_step=0.329]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 0:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.597, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.853, val_f1_step=0.844, val_loss_step=0.329]           #015Epoch 1:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.597, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.853, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   2%|▏         | 30/1355 [00:02<01:48, 12.25it/s, loss=0.597, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.853, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   2%|▏         | 30/1355 [00:02<01:48, 12.24it/s, loss=0.831, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   4%|▍         | 60/1355 [00:04<01:39, 13.00it/s, loss=0.831, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   4%|▍         | 60/1355 [00:04<01:39, 13.00it/s, loss=0.585, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   7%|▋         | 90/1355 [00:06<01:35, 13.23it/s, loss=0.585, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   7%|▋         | 90/1355 [00:06<01:35, 13.23it/s, loss=1.34, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:   9%|▉         | 120/1355 [00:08<01:32, 13.38it/s, loss=1.34, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:   9%|▉         | 120/1355 [00:08<01:32, 13.38it/s, loss=1.31, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  11%|█         | 150/1355 [00:11<01:29, 13.53it/s, loss=1.31, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  11%|█         | 150/1355 [00:11<01:29, 13.53it/s, loss=0.425, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.727, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  13%|█▎        | 180/1355 [00:13<01:26, 13.58it/s, loss=0.425, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.727, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  13%|█▎        | 180/1355 [00:13<01:26, 13.58it/s, loss=1.96, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  15%|█▌        | 210/1355 [00:15<01:23, 13.67it/s, loss=1.96, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  15%|█▌        | 210/1355 [00:15<01:23, 13.67it/s, loss=0.587, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.645, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  18%|█▊        | 240/1355 [00:17<01:21, 13.68it/s, loss=0.587, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.645, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  18%|█▊        | 240/1355 [00:17<01:21, 13.67it/s, loss=1.66, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  20%|█▉        | 270/1355 [00:19<01:19, 13.69it/s, loss=1.66, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  20%|█▉        | 270/1355 [00:19<01:19, 13.69it/s, loss=1.03, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.692, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  22%|██▏       | 300/1355 [00:21<01:16, 13.74it/s, loss=1.03, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.692, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  22%|██▏       | 300/1355 [00:21<01:16, 13.74it/s, loss=1.08, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.825, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  24%|██▍       | 330/1355 [00:24<01:14, 13.72it/s, loss=1.08, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.825, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  24%|██▍       | 330/1355 [00:24<01:14, 13.72it/s, loss=0.758, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  27%|██▋       | 360/1355 [00:26<01:12, 13.75it/s, loss=0.758, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  27%|██▋       | 360/1355 [00:26<01:12, 13.75it/s, loss=0.618, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.757, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  29%|██▉       | 390/1355 [00:28<01:10, 13.75it/s, loss=0.618, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.757, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  29%|██▉       | 390/1355 [00:28<01:10, 13.75it/s, loss=1.49, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.727, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  31%|███       | 420/1355 [00:30<01:08, 13.74it/s, loss=1.49, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.727, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  31%|███       | 420/1355 [00:30<01:08, 13.74it/s, loss=1.87, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.807, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  33%|███▎      | 450/1355 [00:32<01:05, 13.77it/s, loss=1.87, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.807, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  33%|███▎      | 450/1355 [00:32<01:05, 13.77it/s, loss=0.409, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.691, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  35%|███▌      | 480/1355 [00:34<01:03, 13.75it/s, loss=0.409, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.691, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  35%|███▌      | 480/1355 [00:34<01:03, 13.75it/s, loss=1, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.329]    #015Epoch 1:  38%|███▊      | 510/1355 [00:37<01:01, 13.78it/s, loss=1, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  38%|███▊      | 510/1355 [00:37<01:01, 13.78it/s, loss=0.588, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.801, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  40%|███▉      | 540/1355 [00:39<00:59, 13.75it/s, loss=0.588, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.801, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  40%|███▉      | 540/1355 [00:39<00:59, 13.75it/s, loss=1.2, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.872, val_f1_step=0.844, val_loss_step=0.329]  #015Epoch 1:  42%|████▏     | 570/1355 [00:41<00:57, 13.71it/s, loss=1.2, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.872, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  42%|████▏     | 570/1355 [00:41<00:57, 13.71it/s, loss=0.949, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  44%|████▍     | 600/1355 [00:43<00:54, 13.73it/s, loss=0.949, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  44%|████▍     | 600/1355 [00:43<00:54, 13.73it/s, loss=1.56, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.644, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=1.56, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.644, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=0.78, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  49%|████▊     | 660/1355 [00:47<00:50, 13.76it/s, loss=0.78, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  49%|████▊     | 660/1355 [00:47<00:50, 13.76it/s, loss=1.07, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.753, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=1.07, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.753, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=1.11, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.719, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  53%|█████▎    | 720/1355 [00:52<00:46, 13.74it/s, loss=1.11, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.719, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  53%|█████▎    | 720/1355 [00:52<00:46, 13.74it/s, loss=0.912, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  55%|█████▌    | 750/1355 [00:54<00:43, 13.75it/s, loss=0.912, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  55%|█████▌    | 750/1355 [00:54<00:43, 13.75it/s, loss=0.396, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.653, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  58%|█████▊    | 780/1355 [00:56<00:41, 13.74it/s, loss=0.396, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.653, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  58%|█████▊    | 780/1355 [00:56<00:41, 13.74it/s, loss=1.18, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  60%|█████▉    | 810/1355 [00:58<00:39, 13.76it/s, loss=1.18, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  60%|█████▉    | 810/1355 [00:58<00:39, 13.76it/s, loss=0.695, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.793, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  62%|██████▏   | 840/1355 [01:01<00:37, 13.76it/s, loss=0.695, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.793, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  62%|██████▏   | 840/1355 [01:01<00:37, 13.76it/s, loss=0.899, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  64%|██████▍   | 870/1355 [01:03<00:35, 13.75it/s, loss=0.899, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  64%|██████▍   | 870/1355 [01:03<00:35, 13.75it/s, loss=0.577, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.807, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  66%|██████▋   | 900/1355 [01:05<00:33, 13.77it/s, loss=0.577, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.807, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  66%|██████▋   | 900/1355 [01:05<00:33, 13.77it/s, loss=0.816, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.848, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  69%|██████▊   | 930/1355 [01:07<00:30, 13.77it/s, loss=0.816, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.848, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  69%|██████▊   | 930/1355 [01:07<00:30, 13.77it/s, loss=1.07, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.803, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=1.07, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.803, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=1.56, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=1.56, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=0.815, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.721, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.78it/s, loss=0.815, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.721, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.78it/s, loss=0.841, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.723, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.78it/s, loss=0.841, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.723, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.78it/s, loss=1.14, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.762, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.78it/s, loss=1.14, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.762, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.78it/s, loss=0.849, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.79it/s, loss=0.849, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.79it/s, loss=1.14, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.710, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.78it/s, loss=1.14, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.710, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.78it/s, loss=0.78, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  86%|████████▋ | 1170/1355 [01:24<00:13, 13.78it/s, loss=0.78, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  86%|████████▋ | 1170/1355 [01:24<00:13, 13.78it/s, loss=0.875, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  89%|████████▊ | 1200/1355 [01:26<00:11, 13.79it/s, loss=0.875, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  89%|████████▊ | 1200/1355 [01:26<00:11, 13.79it/s, loss=1.31, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.786, val_f1_step=0.844, val_loss_step=0.329] #015Epoch 1:  91%|█████████ | 1230/1355 [01:29<00:09, 13.79it/s, loss=1.31, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.786, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  91%|█████████ | 1230/1355 [01:29<00:09, 13.79it/s, loss=1.13, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]#015Epoch 1:  93%|█████████▎| 1260/1355 [01:29<00:06, 14.11it/s, loss=1.13, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/124 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  24%|██▍       | 30/124 [00:01<00:03, 23.63it/s]#033[A#015Epoch 1:  95%|█████████▌| 1290/1355 [01:30<00:04, 14.24it/s, loss=1.13, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]\u001b[0m\n",
      "\u001b[34m#015Validating:  48%|████▊     | 60/124 [00:02<00:02, 24.75it/s]#033[A#015Epoch 1:  97%|█████████▋| 1320/1355 [01:31<00:02, 14.40it/s, loss=1.13, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]\u001b[0m\n",
      "\u001b[34m#015Validating:  73%|███████▎  | 90/124 [00:03<00:01, 25.66it/s]#033[A#015Epoch 1: 100%|█████████▉| 1350/1355 [01:32<00:00, 14.56it/s, loss=1.13, v_num=0, val_f1_epoch=0.772, val_loss_epoch=0.302, train_f1=0.789, val_f1_step=0.844, val_loss_step=0.329]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 120/124 [00:04<00:00, 26.41it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 124/124 [00:04<00:00, 27.92it/s]#033[A#015Epoch 1: 100%|██████████| 1355/1355 [01:33<00:00, 14.42it/s, loss=1.14, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.242]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                             #033[A#015Epoch 1:   0%|          | 0/1355 [00:00<?, ?it/s, loss=1.14, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.242]           #015Epoch 2:   0%|          | 0/1355 [00:00<?, ?it/s, loss=1.14, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   2%|▏         | 30/1355 [00:02<01:46, 12.49it/s, loss=1.14, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   2%|▏         | 30/1355 [00:02<01:46, 12.49it/s, loss=0.778, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.765, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   4%|▍         | 60/1355 [00:04<01:42, 12.67it/s, loss=0.778, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.765, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   4%|▍         | 60/1355 [00:04<01:42, 12.67it/s, loss=0.918, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   7%|▋         | 90/1355 [00:06<01:38, 12.89it/s, loss=0.918, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   7%|▋         | 90/1355 [00:06<01:38, 12.88it/s, loss=0.972, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.713, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   9%|▉         | 120/1355 [00:09<01:33, 13.16it/s, loss=0.972, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.713, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:   9%|▉         | 120/1355 [00:09<01:33, 13.16it/s, loss=0.979, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.769, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  11%|█         | 150/1355 [00:11<01:31, 13.24it/s, loss=0.979, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.769, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  11%|█         | 150/1355 [00:11<01:31, 13.24it/s, loss=0.58, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.759, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  13%|█▎        | 180/1355 [00:13<01:27, 13.36it/s, loss=0.58, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.759, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  13%|█▎        | 180/1355 [00:13<01:27, 13.36it/s, loss=1.08, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.723, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  15%|█▌        | 210/1355 [00:15<01:25, 13.42it/s, loss=1.08, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.723, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  15%|█▌        | 210/1355 [00:15<01:25, 13.42it/s, loss=1.05, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.865, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  18%|█▊        | 240/1355 [00:17<01:22, 13.46it/s, loss=1.05, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.865, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  18%|█▊        | 240/1355 [00:17<01:22, 13.46it/s, loss=0.649, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  20%|█▉        | 270/1355 [00:19<01:20, 13.55it/s, loss=0.649, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  20%|█▉        | 270/1355 [00:19<01:20, 13.54it/s, loss=1.11, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.710, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  22%|██▏       | 300/1355 [00:22<01:17, 13.55it/s, loss=1.11, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.710, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  22%|██▏       | 300/1355 [00:22<01:17, 13.55it/s, loss=1.25, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.784, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  22%|██▏       | 300/1355 [00:39<02:18,  7.60it/s, loss=1.25, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.784, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  24%|██▍       | 330/1355 [00:44<02:18,  7.41it/s, loss=1.25, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.784, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  24%|██▍       | 330/1355 [00:44<02:18,  7.41it/s, loss=1.11, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  27%|██▋       | 360/1355 [00:46<02:09,  7.70it/s, loss=1.11, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  27%|██▋       | 360/1355 [00:46<02:09,  7.70it/s, loss=0.881, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  29%|██▉       | 390/1355 [00:48<02:01,  7.97it/s, loss=0.881, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  29%|██▉       | 390/1355 [00:48<02:01,  7.97it/s, loss=1.03, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  31%|███       | 420/1355 [00:51<01:53,  8.23it/s, loss=1.03, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  31%|███       | 420/1355 [00:51<01:53,  8.23it/s, loss=0.687, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  33%|███▎      | 450/1355 [00:53<01:47,  8.46it/s, loss=0.687, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  33%|███▎      | 450/1355 [00:53<01:47,  8.46it/s, loss=0.997, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.811, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  35%|███▌      | 480/1355 [00:55<01:40,  8.68it/s, loss=0.997, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.811, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  35%|███▌      | 480/1355 [00:55<01:40,  8.68it/s, loss=0.853, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  38%|███▊      | 510/1355 [00:57<01:35,  8.87it/s, loss=0.853, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  38%|███▊      | 510/1355 [00:57<01:35,  8.87it/s, loss=0.945, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  40%|███▉      | 540/1355 [00:59<01:30,  9.05it/s, loss=0.945, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  40%|███▉      | 540/1355 [00:59<01:30,  9.05it/s, loss=0.55, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  42%|████▏     | 570/1355 [01:01<01:25,  9.23it/s, loss=0.55, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  42%|████▏     | 570/1355 [01:01<01:25,  9.23it/s, loss=0.977, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.800, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  44%|████▍     | 600/1355 [01:04<01:20,  9.37it/s, loss=0.977, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.800, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  44%|████▍     | 600/1355 [01:04<01:20,  9.37it/s, loss=0.941, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.748, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  46%|████▋     | 630/1355 [01:06<01:16,  9.51it/s, loss=0.941, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.748, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  46%|████▋     | 630/1355 [01:06<01:16,  9.51it/s, loss=0.771, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  49%|████▊     | 660/1355 [01:08<01:12,  9.65it/s, loss=0.771, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  49%|████▊     | 660/1355 [01:08<01:12,  9.65it/s, loss=1.08, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  51%|█████     | 690/1355 [01:10<01:08,  9.77it/s, loss=1.08, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  51%|█████     | 690/1355 [01:10<01:08,  9.77it/s, loss=0.603, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.828, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  53%|█████▎    | 720/1355 [01:12<01:04,  9.90it/s, loss=0.603, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.828, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  53%|█████▎    | 720/1355 [01:12<01:04,  9.90it/s, loss=0.583, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.708, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  55%|█████▌    | 750/1355 [01:14<01:00, 10.00it/s, loss=0.583, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.708, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  55%|█████▌    | 750/1355 [01:14<01:00, 10.00it/s, loss=0.958, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.801, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  58%|█████▊    | 780/1355 [01:17<00:56, 10.12it/s, loss=0.958, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.801, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  58%|█████▊    | 780/1355 [01:17<00:56, 10.12it/s, loss=0.794, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  60%|█████▉    | 810/1355 [01:19<00:53, 10.22it/s, loss=0.794, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  60%|█████▉    | 810/1355 [01:19<00:53, 10.22it/s, loss=0.715, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  62%|██████▏   | 840/1355 [01:21<00:49, 10.31it/s, loss=0.715, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  62%|██████▏   | 840/1355 [01:21<00:49, 10.31it/s, loss=0.974, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.774, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  64%|██████▍   | 870/1355 [01:23<00:46, 10.41it/s, loss=0.974, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.774, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  64%|██████▍   | 870/1355 [01:23<00:46, 10.41it/s, loss=1.39, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.766, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  66%|██████▋   | 900/1355 [01:25<00:43, 10.49it/s, loss=1.39, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.766, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  66%|██████▋   | 900/1355 [01:25<00:43, 10.49it/s, loss=1.1, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  69%|██████▊   | 930/1355 [01:27<00:40, 10.57it/s, loss=1.1, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  69%|██████▊   | 930/1355 [01:27<00:40, 10.57it/s, loss=0.836, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  71%|███████   | 960/1355 [01:30<00:37, 10.65it/s, loss=0.836, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.823, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  71%|███████   | 960/1355 [01:30<00:37, 10.65it/s, loss=0.616, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.677, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  73%|███████▎  | 990/1355 [01:32<00:34, 10.72it/s, loss=0.616, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.677, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  73%|███████▎  | 990/1355 [01:32<00:34, 10.72it/s, loss=0.595, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.694, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  75%|███████▌  | 1020/1355 [01:34<00:31, 10.80it/s, loss=0.595, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.694, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  75%|███████▌  | 1020/1355 [01:34<00:31, 10.80it/s, loss=0.646, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  77%|███████▋  | 1050/1355 [01:36<00:28, 10.86it/s, loss=0.646, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  77%|███████▋  | 1050/1355 [01:36<00:28, 10.86it/s, loss=0.501, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.769, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  80%|███████▉  | 1080/1355 [01:38<00:25, 10.93it/s, loss=0.501, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.769, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  80%|███████▉  | 1080/1355 [01:38<00:25, 10.93it/s, loss=0.779, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  82%|████████▏ | 1110/1355 [01:40<00:22, 10.99it/s, loss=0.779, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  82%|████████▏ | 1110/1355 [01:40<00:22, 10.99it/s, loss=0.358, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.701, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  84%|████████▍ | 1140/1355 [01:43<00:19, 11.04it/s, loss=0.358, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.701, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  84%|████████▍ | 1140/1355 [01:43<00:19, 11.04it/s, loss=1.82, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.784, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  86%|████████▋ | 1170/1355 [01:45<00:16, 11.10it/s, loss=1.82, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.784, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  86%|████████▋ | 1170/1355 [01:45<00:16, 11.10it/s, loss=0.8, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.814, val_f1_step=0.844, val_loss_step=0.242] #015Epoch 2:  89%|████████▊ | 1200/1355 [01:47<00:13, 11.15it/s, loss=0.8, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.814, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  89%|████████▊ | 1200/1355 [01:47<00:13, 11.15it/s, loss=0.451, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.809, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  91%|█████████ | 1230/1355 [01:49<00:11, 11.21it/s, loss=0.451, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.809, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  91%|█████████ | 1230/1355 [01:49<00:11, 11.21it/s, loss=0.973, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]#015Epoch 2:  93%|█████████▎| 1260/1355 [01:49<00:08, 11.47it/s, loss=0.973, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/124 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  24%|██▍       | 30/124 [00:01<00:03, 23.89it/s]#033[A#015Epoch 2:  95%|█████████▌| 1290/1355 [01:51<00:05, 11.61it/s, loss=0.973, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]\u001b[0m\n",
      "\u001b[34m#015Validating:  48%|████▊     | 60/124 [00:02<00:02, 25.01it/s]#033[A#015Epoch 2:  97%|█████████▋| 1320/1355 [01:52<00:02, 11.77it/s, loss=0.973, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]\u001b[0m\n",
      "\u001b[34m#015Validating:  73%|███████▎  | 90/124 [00:03<00:01, 25.95it/s]#033[A#015Epoch 2: 100%|█████████▉| 1350/1355 [01:53<00:00, 11.92it/s, loss=0.973, v_num=0, val_f1_epoch=0.802, val_loss_epoch=0.266, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.242]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 120/124 [00:04<00:00, 26.53it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 124/124 [00:04<00:00, 27.91it/s]#033[A#015Epoch 2: 100%|██████████| 1355/1355 [01:54<00:00, 11.84it/s, loss=0.978, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.290]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015                                                             #033[A#015Epoch 2:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.978, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.290]           #015Epoch 3:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.978, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   2%|▏         | 30/1355 [00:02<01:47, 12.36it/s, loss=0.978, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   2%|▏         | 30/1355 [00:02<01:47, 12.36it/s, loss=1.04, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.638, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:   4%|▍         | 60/1355 [00:04<01:40, 12.95it/s, loss=1.04, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.638, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   4%|▍         | 60/1355 [00:04<01:40, 12.95it/s, loss=0.327, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   7%|▋         | 90/1355 [00:06<01:35, 13.30it/s, loss=0.327, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   7%|▋         | 90/1355 [00:06<01:35, 13.30it/s, loss=1.05, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.843, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:   9%|▉         | 120/1355 [00:09<01:33, 13.20it/s, loss=1.05, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.843, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:   9%|▉         | 120/1355 [00:09<01:33, 13.20it/s, loss=1, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.290]   #015Epoch 3:  11%|█         | 150/1355 [00:11<01:30, 13.32it/s, loss=1, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  11%|█         | 150/1355 [00:11<01:30, 13.32it/s, loss=1.35, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.804, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  13%|█▎        | 180/1355 [00:13<01:27, 13.38it/s, loss=1.35, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.804, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  13%|█▎        | 180/1355 [00:13<01:27, 13.38it/s, loss=0.543, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  15%|█▌        | 210/1355 [00:15<01:25, 13.43it/s, loss=0.543, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  15%|█▌        | 210/1355 [00:15<01:25, 13.43it/s, loss=0.956, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  18%|█▊        | 240/1355 [00:17<01:22, 13.53it/s, loss=0.956, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  18%|█▊        | 240/1355 [00:17<01:22, 13.53it/s, loss=0.91, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:  20%|█▉        | 270/1355 [00:19<01:20, 13.54it/s, loss=0.91, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  20%|█▉        | 270/1355 [00:19<01:20, 13.54it/s, loss=0.66, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  22%|██▏       | 300/1355 [00:22<01:17, 13.59it/s, loss=0.66, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.826, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  22%|██▏       | 300/1355 [00:22<01:17, 13.59it/s, loss=0.791, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.763, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  24%|██▍       | 330/1355 [00:24<01:15, 13.60it/s, loss=0.791, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.763, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  24%|██▍       | 330/1355 [00:24<01:15, 13.60it/s, loss=0.721, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.880, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  27%|██▋       | 360/1355 [00:26<01:13, 13.62it/s, loss=0.721, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.880, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  27%|██▋       | 360/1355 [00:26<01:13, 13.62it/s, loss=0.506, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  29%|██▉       | 390/1355 [00:28<01:10, 13.67it/s, loss=0.506, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  29%|██▉       | 390/1355 [00:28<01:10, 13.67it/s, loss=0.695, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  31%|███       | 420/1355 [00:30<01:08, 13.68it/s, loss=0.695, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  31%|███       | 420/1355 [00:30<01:08, 13.68it/s, loss=1.08, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.811, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:  33%|███▎      | 450/1355 [00:32<01:06, 13.71it/s, loss=1.08, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.811, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  33%|███▎      | 450/1355 [00:32<01:06, 13.71it/s, loss=0.632, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.819, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  35%|███▌      | 480/1355 [00:35<01:03, 13.71it/s, loss=0.632, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.819, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  35%|███▌      | 480/1355 [00:35<01:03, 13.71it/s, loss=1.1, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.912, val_f1_step=0.844, val_loss_step=0.290]  #015Epoch 3:  38%|███▊      | 510/1355 [00:37<01:01, 13.71it/s, loss=1.1, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.912, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  38%|███▊      | 510/1355 [00:37<01:01, 13.71it/s, loss=0.624, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.851, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  40%|███▉      | 540/1355 [00:39<00:59, 13.74it/s, loss=0.624, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.851, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  40%|███▉      | 540/1355 [00:39<00:59, 13.74it/s, loss=1.58, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.792, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:  42%|████▏     | 570/1355 [00:41<00:57, 13.73it/s, loss=1.58, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.792, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  42%|████▏     | 570/1355 [00:41<00:57, 13.73it/s, loss=1.08, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=1.08, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.821, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=1.02, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.701, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=1.02, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.701, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  46%|████▋     | 630/1355 [00:45<00:52, 13.73it/s, loss=1.06, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.762, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  49%|████▊     | 660/1355 [00:48<00:50, 13.73it/s, loss=1.06, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.762, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  49%|████▊     | 660/1355 [00:48<00:50, 13.73it/s, loss=0.584, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.797, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  51%|█████     | 690/1355 [00:50<00:48, 13.74it/s, loss=0.584, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.797, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  51%|█████     | 690/1355 [00:50<00:48, 13.74it/s, loss=0.322, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.873, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  53%|█████▎    | 720/1355 [00:52<00:46, 13.73it/s, loss=0.322, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.873, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  53%|█████▎    | 720/1355 [00:52<00:46, 13.73it/s, loss=1.14, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.824, val_f1_step=0.844, val_loss_step=0.290] #015Epoch 3:  55%|█████▌    | 750/1355 [00:54<00:44, 13.74it/s, loss=1.14, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.824, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  55%|█████▌    | 750/1355 [00:54<00:44, 13.74it/s, loss=1.12, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.751, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  58%|█████▊    | 780/1355 [00:56<00:41, 13.73it/s, loss=1.12, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.751, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  58%|█████▊    | 780/1355 [00:56<00:41, 13.73it/s, loss=0.54, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  60%|█████▉    | 810/1355 [00:59<00:39, 13.73it/s, loss=0.54, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  60%|█████▉    | 810/1355 [00:59<00:39, 13.73it/s, loss=0.714, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  62%|██████▏   | 840/1355 [01:01<00:37, 13.74it/s, loss=0.714, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.767, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  62%|██████▏   | 840/1355 [01:01<00:37, 13.74it/s, loss=0.484, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  64%|██████▍   | 870/1355 [01:03<00:35, 13.73it/s, loss=0.484, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  64%|██████▍   | 870/1355 [01:03<00:35, 13.73it/s, loss=0.547, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.902, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  66%|██████▋   | 900/1355 [01:05<00:33, 13.74it/s, loss=0.547, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.902, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  66%|██████▋   | 900/1355 [01:05<00:33, 13.74it/s, loss=0.619, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.730, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  69%|██████▊   | 930/1355 [01:07<00:30, 13.72it/s, loss=0.619, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.730, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  69%|██████▊   | 930/1355 [01:07<00:30, 13.72it/s, loss=1.4, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.290]  #015Epoch 3:  71%|███████   | 960/1355 [01:10<00:28, 13.69it/s, loss=1.4, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.755, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  71%|███████   | 960/1355 [01:10<00:28, 13.69it/s, loss=0.546, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.735, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  73%|███████▎  | 990/1355 [01:12<00:26, 13.71it/s, loss=0.546, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.735, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  73%|███████▎  | 990/1355 [01:12<00:26, 13.71it/s, loss=0.965, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.829, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.71it/s, loss=0.965, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.829, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  75%|███████▌  | 1020/1355 [01:14<00:24, 13.71it/s, loss=1.4, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.290]  #015Epoch 3:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.72it/s, loss=1.4, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.780, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.72it/s, loss=0.593, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  80%|███████▉  | 1080/1355 [01:18<00:20, 13.71it/s, loss=0.593, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.787, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  80%|███████▉  | 1080/1355 [01:18<00:20, 13.71it/s, loss=0.986, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.70it/s, loss=0.986, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.858, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.70it/s, loss=0.752, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.824, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  84%|████████▍ | 1140/1355 [01:23<00:15, 13.71it/s, loss=0.752, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.824, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  84%|████████▍ | 1140/1355 [01:23<00:15, 13.71it/s, loss=0.634, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.919, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  86%|████████▋ | 1170/1355 [01:25<00:13, 13.71it/s, loss=0.634, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.919, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  86%|████████▋ | 1170/1355 [01:25<00:13, 13.71it/s, loss=0.7, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.870, val_f1_step=0.844, val_loss_step=0.290]  #015Epoch 3:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.72it/s, loss=0.7, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.870, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.72it/s, loss=0.491, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  91%|█████████ | 1230/1355 [01:29<00:09, 13.71it/s, loss=0.491, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.840, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  91%|█████████ | 1230/1355 [01:29<00:09, 13.71it/s, loss=0.617, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]#015Epoch 3:  93%|█████████▎| 1260/1355 [01:29<00:06, 14.02it/s, loss=0.617, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/124 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  24%|██▍       | 30/124 [00:01<00:04, 23.44it/s]#033[A#015Epoch 3:  95%|█████████▌| 1290/1355 [01:31<00:04, 14.16it/s, loss=0.617, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]\u001b[0m\n",
      "\u001b[34m#015Validating:  48%|████▊     | 60/124 [00:02<00:02, 24.62it/s]#033[A#015Epoch 3:  97%|█████████▋| 1320/1355 [01:32<00:02, 14.32it/s, loss=0.617, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]\u001b[0m\n",
      "\u001b[34m#015Validating:  73%|███████▎  | 90/124 [00:03<00:01, 25.54it/s]#033[A#015Epoch 3: 100%|█████████▉| 1350/1355 [01:33<00:00, 14.47it/s, loss=0.617, v_num=0, val_f1_epoch=0.827, val_loss_epoch=0.246, train_f1=0.812, val_f1_step=0.844, val_loss_step=0.290]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m#015Validating:  97%|█████████▋| 120/124 [00:04<00:00, 26.27it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 124/124 [00:04<00:00, 27.76it/s]#033[A#015Epoch 3: 100%|██████████| 1355/1355 [01:34<00:00, 14.34it/s, loss=0.632, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.599, val_f1_step=0.844, val_loss_step=0.284]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 3:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.632, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.599, val_f1_step=0.844, val_loss_step=0.284]           #015Epoch 4:   0%|          | 0/1355 [00:00<?, ?it/s, loss=0.632, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.599, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   2%|▏         | 30/1355 [00:02<01:44, 12.64it/s, loss=0.632, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.599, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   2%|▏         | 30/1355 [00:02<01:44, 12.64it/s, loss=0.674, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   4%|▍         | 60/1355 [00:04<01:36, 13.46it/s, loss=0.674, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   4%|▍         | 60/1355 [00:04<01:36, 13.45it/s, loss=1.18, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.813, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:   7%|▋         | 90/1355 [00:06<01:33, 13.49it/s, loss=1.18, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.813, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   7%|▋         | 90/1355 [00:06<01:33, 13.49it/s, loss=0.416, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   9%|▉         | 120/1355 [00:08<01:30, 13.68it/s, loss=0.416, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.794, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:   9%|▉         | 120/1355 [00:08<01:30, 13.68it/s, loss=0.52, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:  11%|█         | 150/1355 [00:10<01:27, 13.70it/s, loss=0.52, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.779, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  11%|█         | 150/1355 [00:10<01:27, 13.70it/s, loss=0.465, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.845, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  13%|█▎        | 180/1355 [00:13<01:25, 13.70it/s, loss=0.465, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.845, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  13%|█▎        | 180/1355 [00:13<01:25, 13.70it/s, loss=0.799, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.863, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  15%|█▌        | 210/1355 [00:15<01:23, 13.74it/s, loss=0.799, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.863, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  15%|█▌        | 210/1355 [00:15<01:23, 13.74it/s, loss=0.398, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  18%|█▊        | 240/1355 [00:17<01:21, 13.72it/s, loss=0.398, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.816, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  18%|█▊        | 240/1355 [00:17<01:21, 13.72it/s, loss=0.69, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.873, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:  20%|█▉        | 270/1355 [00:19<01:18, 13.76it/s, loss=0.69, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.873, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  20%|█▉        | 270/1355 [00:19<01:18, 13.76it/s, loss=0.489, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.709, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  22%|██▏       | 300/1355 [00:21<01:16, 13.75it/s, loss=0.489, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.709, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  22%|██▏       | 300/1355 [00:21<01:16, 13.75it/s, loss=0.61, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.836, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:  24%|██▍       | 330/1355 [00:24<01:14, 13.73it/s, loss=0.61, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.836, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  24%|██▍       | 330/1355 [00:24<01:14, 13.73it/s, loss=0.342, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  27%|██▋       | 360/1355 [00:26<01:12, 13.77it/s, loss=0.342, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  27%|██▋       | 360/1355 [00:26<01:12, 13.77it/s, loss=0.324, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.887, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  29%|██▉       | 390/1355 [00:28<01:10, 13.76it/s, loss=0.324, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.887, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  29%|██▉       | 390/1355 [00:28<01:10, 13.76it/s, loss=0.914, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.879, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  31%|███       | 420/1355 [00:30<01:07, 13.79it/s, loss=0.914, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.879, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  31%|███       | 420/1355 [00:30<01:07, 13.79it/s, loss=0.683, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.889, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  33%|███▎      | 450/1355 [00:32<01:05, 13.76it/s, loss=0.683, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.889, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  33%|███▎      | 450/1355 [00:32<01:05, 13.76it/s, loss=0.557, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.728, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  35%|███▌      | 480/1355 [00:35<01:03, 13.71it/s, loss=0.557, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.728, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  35%|███▌      | 480/1355 [00:35<01:03, 13.71it/s, loss=0.487, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.855, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  38%|███▊      | 510/1355 [00:37<01:01, 13.74it/s, loss=0.487, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.855, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  38%|███▊      | 510/1355 [00:37<01:01, 13.74it/s, loss=0.573, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.868, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  40%|███▉      | 540/1355 [00:39<00:59, 13.74it/s, loss=0.573, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.868, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  40%|███▉      | 540/1355 [00:39<00:59, 13.74it/s, loss=0.596, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.802, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  42%|████▏     | 570/1355 [00:41<00:57, 13.75it/s, loss=0.596, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.802, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  42%|████▏     | 570/1355 [00:41<00:57, 13.75it/s, loss=0.494, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=0.494, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.841, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  44%|████▍     | 600/1355 [00:43<00:54, 13.74it/s, loss=0.573, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.860, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  46%|████▋     | 630/1355 [00:45<00:52, 13.74it/s, loss=0.573, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.860, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  46%|████▋     | 630/1355 [00:45<00:52, 13.74it/s, loss=0.823, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  49%|████▊     | 660/1355 [00:47<00:50, 13.76it/s, loss=0.823, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.772, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  49%|████▊     | 660/1355 [00:47<00:50, 13.76it/s, loss=0.677, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.850, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=0.677, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.850, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  51%|█████     | 690/1355 [00:50<00:48, 13.75it/s, loss=0.864, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  53%|█████▎    | 720/1355 [00:52<00:46, 13.76it/s, loss=0.864, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.777, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  53%|█████▎    | 720/1355 [00:52<00:46, 13.76it/s, loss=0.544, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.781, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  55%|█████▌    | 750/1355 [00:54<00:43, 13.76it/s, loss=0.544, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.781, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  55%|█████▌    | 750/1355 [00:54<00:43, 13.76it/s, loss=0.565, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.878, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  58%|█████▊    | 780/1355 [00:56<00:41, 13.75it/s, loss=0.565, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.878, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  58%|█████▊    | 780/1355 [00:56<00:41, 13.75it/s, loss=0.966, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.778, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  60%|█████▉    | 810/1355 [00:58<00:39, 13.77it/s, loss=0.966, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.778, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  60%|█████▉    | 810/1355 [00:58<00:39, 13.77it/s, loss=0.959, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.834, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  62%|██████▏   | 840/1355 [01:01<00:37, 13.76it/s, loss=0.959, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.834, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  62%|██████▏   | 840/1355 [01:01<00:37, 13.76it/s, loss=0.326, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.870, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  64%|██████▍   | 870/1355 [01:03<00:35, 13.78it/s, loss=0.326, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.870, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  64%|██████▍   | 870/1355 [01:03<00:35, 13.78it/s, loss=0.511, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.790, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  66%|██████▋   | 900/1355 [01:05<00:33, 13.78it/s, loss=0.511, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.790, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  66%|██████▋   | 900/1355 [01:05<00:33, 13.78it/s, loss=1.02, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.839, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:  69%|██████▊   | 930/1355 [01:07<00:30, 13.78it/s, loss=1.02, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.839, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  69%|██████▊   | 930/1355 [01:07<00:30, 13.78it/s, loss=0.383, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.865, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=0.383, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.865, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  71%|███████   | 960/1355 [01:09<00:28, 13.78it/s, loss=0.973, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.875, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=0.973, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.875, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  73%|███████▎  | 990/1355 [01:11<00:26, 13.78it/s, loss=0.597, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.835, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  75%|███████▌  | 1020/1355 [01:13<00:24, 13.79it/s, loss=0.597, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.835, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  75%|███████▌  | 1020/1355 [01:13<00:24, 13.79it/s, loss=0.565, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.890, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.79it/s, loss=0.565, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.890, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  77%|███████▋  | 1050/1355 [01:16<00:22, 13.79it/s, loss=0.591, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.78it/s, loss=0.591, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.782, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  80%|███████▉  | 1080/1355 [01:18<00:19, 13.78it/s, loss=0.547, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.785, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.79it/s, loss=0.547, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.785, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  82%|████████▏ | 1110/1355 [01:20<00:17, 13.79it/s, loss=1.07, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.868, val_f1_step=0.844, val_loss_step=0.284] #015Epoch 4:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.78it/s, loss=1.07, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.868, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  84%|████████▍ | 1140/1355 [01:22<00:15, 13.78it/s, loss=0.833, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.797, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  86%|████████▋ | 1170/1355 [01:24<00:13, 13.79it/s, loss=0.833, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.797, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  86%|████████▋ | 1170/1355 [01:24<00:13, 13.79it/s, loss=0.315, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.79it/s, loss=0.315, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.838, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  89%|████████▊ | 1200/1355 [01:27<00:11, 13.79it/s, loss=0.498, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.843, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  91%|█████████ | 1230/1355 [01:29<00:09, 13.79it/s, loss=0.498, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.843, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  91%|█████████ | 1230/1355 [01:29<00:09, 13.79it/s, loss=0.362, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.284]#015Epoch 4:  93%|█████████▎| 1260/1355 [01:29<00:06, 14.10it/s, loss=0.362, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.284]\u001b[0m\n",
      "\u001b[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:   0%|          | 0/124 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating:  24%|██▍       | 30/124 [00:01<00:04, 23.09it/s]#033[A#015Epoch 4:  95%|█████████▌| 1290/1355 [01:30<00:04, 14.23it/s, loss=0.362, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.284]\u001b[0m\n",
      "\u001b[34m#015Validating:  48%|████▊     | 60/124 [00:02<00:02, 24.26it/s]#033[A#015Epoch 4:  97%|█████████▋| 1320/1355 [01:31<00:02, 14.39it/s, loss=0.362, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.284]\u001b[0m\n",
      "\u001b[34m#015Validating:  73%|███████▎  | 90/124 [00:03<00:01, 25.08it/s]#033[A#015Epoch 4: 100%|█████████▉| 1350/1355 [01:32<00:00, 14.54it/s, loss=0.362, v_num=0, val_f1_epoch=0.844, val_loss_epoch=0.226, train_f1=0.846, val_f1_step=0.844, val_loss_step=0.284]\u001b[0m\n",
      "\u001b[34m#015Validating:  97%|█████████▋| 120/124 [00:04<00:00, 25.73it/s]#033[A\u001b[0m\n",
      "\u001b[34m#015Validating: 100%|██████████| 124/124 [00:04<00:00, 27.17it/s]#033[A#015Epoch 4: 100%|██████████| 1355/1355 [01:34<00:00, 14.40it/s, loss=0.367, v_num=0, val_f1_epoch=0.852, val_loss_epoch=0.218, train_f1=0.775, val_f1_step=0.844, val_loss_step=0.269]\u001b[0m\n",
      "\u001b[34m#015                                                             #033[A#015Epoch 4: 100%|██████████| 1355/1355 [01:35<00:00, 14.24it/s, loss=0.367, v_num=0, val_f1_epoch=0.852, val_loss_epoch=0.218, train_f1=0.775, val_f1_step=0.844, val_loss_step=0.269]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m(7806, 5)\u001b[0m\n",
      "\u001b[34m(7806, 5)\u001b[0m\n",
      "\u001b[34m2021-08-27 11:44:02.112957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34mINFO:root:reading, preprocessing data\u001b[0m\n",
      "\u001b[34m2021/08/27 11:44:31 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394686952 acquired on /root/.cache/huggingface/transformers/31d6577412393ebb07c02de876b2d1397fcae2d85cb053b588145f6869ab1a15.44cd178af39e607af310bc4cc48a944f5e5f746b372c161b32511f0fd585789b.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/526 [00:00<?, ?B/s]#015Downloading: 100%|██████████| 526/526 [00:00<00:00, 607kB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394686952 released on /root/.cache/huggingface/transformers/31d6577412393ebb07c02de876b2d1397fcae2d85cb053b588145f6869ab1a15.44cd178af39e607af310bc4cc48a944f5e5f746b372c161b32511f0fd585789b.lock\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394687344 acquired on /root/.cache/huggingface/transformers/a9c548057d82391e2bd98d883850cb32ebea77d731e8aef568b3a62626fcb8b3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 42.8MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394687344 released on /root/.cache/huggingface/transformers/a9c548057d82391e2bd98d883850cb32ebea77d731e8aef568b3a62626fcb8b3.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\u001b[0m\n",
      "\u001b[34mGPU available: True, used: True\u001b[0m\n",
      "\u001b[34mTPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394433728 acquired on /root/.cache/huggingface/transformers/b374e0476158ea0103ff70e6aba1af0f3eb008f2b864df9cefd392d127704aea.e8dbc1ac6bd489742b5b870482beb10cbda5561261f41884487a4f8424b346dd.lock\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]#015Downloading:   3%|▎         | 2.83M/90.9M [00:00<00:03, 28.3MB/s]#015Downloading:   6%|▌         | 5.68M/90.9M [00:00<00:03, 25.2MB/s]#015Downloading:  10%|█         | 9.23M/90.9M [00:00<00:03, 27.1MB/s]#015Downloading:  15%|█▍        | 13.2M/90.9M [00:00<00:02, 30.0MB/s]#015Downloading:  20%|██        | 18.5M/90.9M [00:00<00:02, 34.4MB/s]#015Downloading:  26%|██▌       | 23.7M/90.9M [00:00<00:01, 38.4MB/s]#015Downloading:  32%|███▏      | 28.9M/90.9M [00:00<00:01, 41.6MB/s]#015Downloading:  36%|███▋      | 33.2M/90.9M [00:00<00:01, 40.2MB/s]#015Downloading:  42%|████▏     | 38.4M/90.9M [00:00<00:01, 43.3MB/s]#015Downloading:  48%|████▊     | 43.8M/90.9M [00:01<00:01, 45.8MB/s]#015Downloading:  53%|█████▎    | 48.5M/90.9M [00:01<00:01, 39.2MB/s]#015Downloading:  59%|█████▉    | 53.6M/90.9M [00:01<00:00, 42.3MB/s]#015Downloading:  64%|██████▍   | 58.1M/90.9M [00:01<00:01, 27.3MB/s]#015Downloading:  70%|██████▉   | 63.5M/90.9M [00:01<00:00, 32.0MB/s]#015Downloading:  74%|███████▍  | 67.7M/90.9M [00:01<00:00, 33.2MB/s]#015Downloading:  80%|████████  | 73.1M/90.9M [00:01<00:00, 37.5MB/s]#015Downloading:  86%|████████▋ | 78.6M/90.9M [00:02<00:00, 41.6MB/s]#015Downloading:  92%|█████████▏| 83.4M/90.9M [00:02<00:00, 40.3MB/s]#015Downloading:  97%|█████████▋| 87.8M/90.9M [00:02<00:00, 31.6MB/s]#015Downloading: 100%|██████████| 90.9M/90.9M [00:02<00:00, 37.3MB/s]\u001b[0m\n",
      "\u001b[34mINFO:filelock:Lock 139788394433728 released on /root/.cache/huggingface/transformers/b374e0476158ea0103ff70e6aba1af0f3eb008f2b864df9cefd392d127704aea.e8dbc1ac6bd489742b5b870482beb10cbda5561261f41884487a4f8424b346dd.lock\u001b[0m\n",
      "\u001b[34mLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\u001b[0m\n",
      "\u001b[34mEpoch 0, global step 1230: val_f1 reached 0.77150 (best 0.77150), saving model to \"/opt/ml/model/model_severity.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 1, global step 2461: val_f1 reached 0.80190 (best 0.80190), saving model to \"/opt/ml/model/model_severity.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 2, global step 3692: val_f1 reached 0.82677 (best 0.82677), saving model to \"/opt/ml/model/model_severity.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 3, global step 4923: val_f1 reached 0.84414 (best 0.84414), saving model to \"/opt/ml/model/model_severity.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mEpoch 4, global step 6154: val_f1 reached 0.85179 (best 0.85179), saving model to \"/opt/ml/model/model_severity.ckpt\" as top 1\u001b[0m\n",
      "\u001b[34mFIT Profiler Report\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-27 11:54:19,844 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34mAction                             #011|  Mean duration (s)#011|Num calls      #011|  Total time (s) #011|  Percentage %   #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mTotal                              #011|  -              #011|_              #011|  573.5          #011|  100 %          #011|\u001b[0m\n",
      "\u001b[34m--------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34mrun_training_epoch                 #011|  99.202         #011|5              #011|  496.01         #011|  86.488         #011|\u001b[0m\n",
      "\u001b[34mrun_training_batch                 #011|  0.070649       #011|6155           #011|  434.84         #011|  75.823         #011|\u001b[0m\n",
      "\u001b[34moptimizer_step_and_closure_0       #011|  0.070254       #011|6155           #011|  432.41         #011|  75.399         #011|\u001b[0m\n",
      "\u001b[34mtraining_step_and_backward         #011|  0.060998       #011|6155           #011|  375.44         #011|  65.465         #011|\u001b[0m\n",
      "\u001b[34mbackward                           #011|  0.035032       #011|6155           #011|  215.62         #011|  37.598         #011|\u001b[0m\n",
      "\u001b[34mmodel_forward                      #011|  0.024271       #011|6155           #011|  149.39         #011|  26.049         #011|\u001b[0m\n",
      "\u001b[34mtraining_step                      #011|  0.023987       #011|6155           #011|  147.64         #011|  25.743         #011|\u001b[0m\n",
      "\u001b[34mevaluation_step_and_end            #011|  0.036252       #011|622            #011|  22.549         #011|  3.9318         #011|\u001b[0m\n",
      "\u001b[34mvalidation_step                    #011|  0.036031       #011|622            #011|  22.411         #011|  3.9078         #011|\u001b[0m\n",
      "\u001b[34mget_train_batch                    #011|  0.0028702      #011|6155           #011|  17.666         #011|  3.0804         #011|\u001b[0m\n",
      "\u001b[34mon_validation_end                  #011|  0.80113        #011|6              #011|  4.8068         #011|  0.83815        #011|\u001b[0m\n",
      "\u001b[34mon_train_start                     #011|  0.61403        #011|1              #011|  0.61403        #011|  0.10707        #011|\u001b[0m\n",
      "\u001b[34mcache_result                       #011|  2.1401e-05     #011|26553          #011|  0.56826        #011|  0.099086       #011|\u001b[0m\n",
      "\u001b[34mon_train_batch_end                 #011|  8.2189e-05     #011|6155           #011|  0.50587        #011|  0.088208       #011|\u001b[0m\n",
      "\u001b[34mon_after_backward                  #011|  2.6688e-05     #011|6155           #011|  0.16427        #011|  0.028643       #011|\u001b[0m\n",
      "\u001b[34mon_batch_start                     #011|  2.5591e-05     #011|6155           #011|  0.15751        #011|  0.027465       #011|\u001b[0m\n",
      "\u001b[34mon_before_zero_grad                #011|  2.2329e-05     #011|6155           #011|  0.13744        #011|  0.023965       #011|\u001b[0m\n",
      "\u001b[34mon_batch_end                       #011|  2.1852e-05     #011|6155           #011|  0.1345         #011|  0.023453       #011|\u001b[0m\n",
      "\u001b[34mon_train_batch_start               #011|  1.8516e-05     #011|6155           #011|  0.11396        #011|  0.019872       #011|\u001b[0m\n",
      "\u001b[34mtraining_step_end                  #011|  1.2984e-05     #011|6155           #011|  0.079915       #011|  0.013935       #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_end            #011|  5.5762e-05     #011|622            #011|  0.034684       #011|  0.0060477      #011|\u001b[0m\n",
      "\u001b[34mon_validation_batch_start          #011|  2.6185e-05     #011|622            #011|  0.016287       #011|  0.0028399      #011|\u001b[0m\n",
      "\u001b[34mvalidation_step_end                #011|  1.4745e-05     #011|622            #011|  0.0091717      #011|  0.0015992      #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_end            #011|  0.00070781     #011|6              #011|  0.0042469      #011|  0.00074052     #011|\u001b[0m\n",
      "\u001b[34mon_validation_start                #011|  0.00054628     #011|6              #011|  0.0032777      #011|  0.00057152     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_start               #011|  0.00056553     #011|5              #011|  0.0028277      #011|  0.00049305     #011|\u001b[0m\n",
      "\u001b[34mon_train_epoch_end                 #011|  0.00025092     #011|5              #011|  0.0012546      #011|  0.00021876     #011|\u001b[0m\n",
      "\u001b[34mon_train_end                       #011|  0.00065328     #011|1              #011|  0.00065328     #011|  0.00011391     #011|\u001b[0m\n",
      "\u001b[34mon_epoch_start                     #011|  2.7381e-05     #011|11             #011|  0.00030119     #011|  5.2518e-05     #011|\u001b[0m\n",
      "\u001b[34mon_epoch_end                       #011|  2.2311e-05     #011|11             #011|  0.00024542     #011|  4.2793e-05     #011|\u001b[0m\n",
      "\u001b[34mon_validation_epoch_start          #011|  1.8243e-05     #011|6              #011|  0.00010946     #011|  1.9086e-05     #011|\u001b[0m\n",
      "\u001b[34mon_fit_start                       #011|  3.3169e-05     #011|1              #011|  3.3169e-05     #011|  5.7836e-06     #011|\u001b[0m\n",
      "\u001b[34mon_before_accelerator_backend_setup#011|  2.0983e-05     #011|1              #011|  2.0983e-05     #011|  3.6588e-06     #011|\u001b[0m\n",
      "\u001b[34mon_val_dataloader                  #011|  1.5835e-05     #011|1              #011|  1.5835e-05     #011|  2.7611e-06     #011|\u001b[0m\n",
      "\u001b[34mon_train_dataloader                #011|  1.4741e-05     #011|1              #011|  1.4741e-05     #011|  2.5704e-06     #011|\n",
      "\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/123 [00:00<?, ?it/s]#015  1%|          | 1/123 [00:00<00:28,  4.25it/s]#015  3%|▎         | 4/123 [00:00<00:20,  5.68it/s]#015  7%|▋         | 8/123 [00:00<00:15,  7.53it/s]#015 10%|▉         | 12/123 [00:00<00:11,  9.73it/s]#015 13%|█▎        | 16/123 [00:00<00:08, 12.24it/s]#015 16%|█▋        | 20/123 [00:00<00:06, 14.95it/s]#015 20%|█▉        | 24/123 [00:00<00:05, 17.64it/s]#015 23%|██▎       | 28/123 [00:01<00:04, 20.20it/s]#015 26%|██▌       | 32/123 [00:01<00:04, 22.50it/s]#015 28%|██▊       | 35/123 [00:01<00:03, 24.30it/s]#015 32%|███▏      | 39/123 [00:01<00:03, 25.92it/s]#015 35%|███▍      | 43/123 [00:01<00:02, 27.18it/s]#015 38%|███▊      | 47/123 [00:01<00:02, 28.14it/s]#015 41%|████▏     | 51/123 [00:01<00:02, 28.88it/s]#015 45%|████▍     | 55/123 [00:02<00:02, 29.33it/s]#015 48%|████▊     | 59/123 [00:02<00:02, 29.71it/s]#015 51%|█████     | 63/123 [00:02<00:01, 30.03it/s]#015 54%|█████▍    | 67/123 [00:02<00:01, 30.09it/s]#015 58%|█████▊    | 71/123 [00:02<00:01, 30.34it/s]#015 61%|██████    | 75/123 [00:02<00:01, 30.45it/s]#015 64%|██████▍   | 79/123 [00:02<00:01, 30.61it/s]#015 67%|██████▋   | 83/123 [00:02<00:01, 30.72it/s]#015 71%|███████   | 87/123 [00:03<00:01, 30.68it/s]#015 74%|███████▍  | 91/123 [00:03<00:01, 30.49it/s]#015 77%|███████▋  | 95/123 [00:03<00:00, 30.33it/s]#015 80%|████████  | 99/123 [00:03<00:00, 30.27it/s]#015 84%|████████▎ | 103/123 [00:03<00:00, 30.21it/s]#015 87%|████████▋ | 107/123 [00:03<00:00, 30.34it/s]#015 90%|█████████ | 111/123 [00:03<00:00, 30.21it/s]#015 93%|█████████▎| 115/123 [00:03<00:00, 30.40it/s]#015 97%|█████████▋| 119/123 [00:04<00:00, 30.62it/s]#015100%|██████████| 123/123 [00:04<00:00, 30.64it/s]#015124it [00:04, 28.81it/s]                         \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-08-27 11:54:34 Uploading - Uploading generated training model\n",
      "2021-08-27 11:55:00 Completed - Training job completed\n",
      "Training seconds: 1013\n",
      "Billable seconds: 1013\n"
     ]
    }
   ],
   "source": [
    "# Fit the estimator\n",
    "\n",
    "estimator.fit(fit_arguments, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
