{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "import timeit\n",
    "from typing import List\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "from deep.constants import *\n",
    "from deep.utils import *\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=DEV_BUCKET.name)\n",
    "role = SAGEMAKER_ROLE\n",
    "role_arn = SAGEMAKER_ROLE_ARN\n",
    "tracking_uri = MLFLOW_SERVER\n",
    "\n",
    "from mlflow import sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.read_csv(os.path.join('final_data', 'test_gender_df.csv'))\n",
    "minorities_df = pd.read_csv(os.path.join('final_data', 'test_minorities_df.csv'))\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    os.path.join(\"..\", \"..\", \"..\", \"..\", \"data\", \"frameworks_data\", \"data_v0.7.1\", \"new_columns_test_v0.7.1.csv.gz\"),\n",
    "    compression='gzip'\n",
    ")[[\"excerpt\", \"entry_id\", \"lang\"]]\n",
    "test_df = test_df[test_df.lang=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/22 13:22:47 INFO mlflow.sagemaker: Using the python_function flavor for deployment!\n",
      "2022/09/22 13:22:48 INFO mlflow.sagemaker: No model data bucket specified, using the default bucket\n",
      "2022/09/22 13:22:54 INFO mlflow.sagemaker: Default bucket `mlflow-sagemaker-us-east-1-961104659532` already exists. Skipping creation.\n",
      "2022/09/22 13:28:19 INFO mlflow.sagemaker: tag response: {'ResponseMetadata': {'RequestId': 'XSR3QSE3ANJMQP9T', 'HostId': '31MvJpcTcDtuDdoYuUTvp7XhHdOGeBYrbhieAD/F30uUxG581NwI2gXCTmFKPBOQP7ezOgnhZD4=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': '31MvJpcTcDtuDdoYuUTvp7XhHdOGeBYrbhieAD/F30uUxG581NwI2gXCTmFKPBOQP7ezOgnhZD4=', 'x-amz-request-id': 'XSR3QSE3ANJMQP9T', 'date': 'Thu, 22 Sep 2022 11:28:20 GMT', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}}\n",
      "2022/09/22 13:28:19 INFO mlflow.sagemaker: Creating new endpoint with name: tmp-hum ...\n",
      "2022/09/22 13:28:20 INFO mlflow.sagemaker: Created model with arn: arn:aws:sagemaker:us-east-1:961104659532:model/tmp-hum-model-7zmm71q2t0i0d8w81nx4xw\n",
      "2022/09/22 13:28:20 INFO mlflow.sagemaker: Created endpoint configuration with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint-config/tmp-hum-config-ew5ljmfgrycdzbqelmrwhg\n",
      "2022/09/22 13:28:21 INFO mlflow.sagemaker: Created endpoint with arn: arn:aws:sagemaker:us-east-1:961104659532:endpoint/tmp-hum\n"
     ]
    }
   ],
   "source": [
    "sagemaker.deploy(\n",
    "    \"tmp-hum\",\n",
    "    \"s3://deep-mlflow-artifact/29/ad58f6c521e44c5f8cdd653f319344f3/artifacts/two_steps_models\",\n",
    "    execution_role_arn=SAGEMAKER_ROLE_ARN,\n",
    "    image_url=\"961104659532.dkr.ecr.us-east-1.amazonaws.com/mlflow-pyfunc:latest\",\n",
    "    region_name=\"us-east-1\",\n",
    "    instance_type= \"ml.c5.2xlarge\", # \"ml.g4dn.xlarge\", #\n",
    "    flavor=\"python_function\",\n",
    "    synchronous=False,\n",
    "    archive=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t: List[List]) -> List:\n",
    "    return [item for sublist in t for item in sublist]\n",
    "\n",
    "def get_probas(df):\n",
    "\n",
    "    client = boto3.session.Session().client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "\n",
    "    all_outputs = []\n",
    "    batch_size = 128\n",
    "    for i in tqdm(range(0, df.shape[0], batch_size)):\n",
    "        inputs = df.iloc[i : i + batch_size][['excerpt']]  \n",
    "        inputs['return_type'] = \"default_analyis\" \n",
    "        inputs['analyis_framework_id'] = 'all'\n",
    "        \n",
    "        #kw for interpretability\n",
    "        inputs['interpretability'] = False\n",
    "        #minimum ratio between proba and threshold to perform interpretability\n",
    "        inputs['ratio_interpreted_labels'] = 0.5\n",
    "        inputs['attribution_type'] = 'Layer DeepLift'\n",
    "\n",
    "        # predictions\n",
    "        inputs['return_prediction_labels'] = True\n",
    "\n",
    "        #kw for embeddings\n",
    "        inputs['output_backbone_embeddings'] = False\n",
    "        inputs['pooling_type'] = \"['cls', 'mean_pooling']\"\n",
    "        inputs['finetuned_task'] = \"['first_level_tags', 'secondary_tags', 'subpillars']\"\n",
    "        inputs['embeddings_return_type'] = 'array'\n",
    "        \n",
    "        backbone_inputs_json = inputs.to_json(orient=\"split\")\n",
    "\n",
    "        response = client.invoke_endpoint(\n",
    "            EndpointName='tmp-hum',\n",
    "            Body=backbone_inputs_json,\n",
    "            ContentType=\"application/json; format=pandas-split\",\n",
    "        )\n",
    "        output = response[\"Body\"].read().decode(\"ascii\")\n",
    "\n",
    "        #output = literal_eval(output)\n",
    "        \n",
    "        all_outputs.append(output)\n",
    "\n",
    "    clean_outputs = []\n",
    "    for batch in all_outputs:\n",
    "        eval_batch = literal_eval(batch)\n",
    "        clean_outputs.append(eval_batch['raw_predictions'])\n",
    "    clean_outputs = flatten(clean_outputs)\n",
    "\n",
    "    thresholds = eval_batch['thresholds']\n",
    "\n",
    "    output_predictions = []\n",
    "    for i in range (len(clean_outputs)):\n",
    "        tags_one_entry = clean_outputs[i]\n",
    "        output_predictions.append({\n",
    "            tag: round(100 * thresholds[tag] * ratio, 3) for tag, ratio in tags_one_entry.items()\n",
    "        })\n",
    "\n",
    "    return output_predictions\n",
    "\n",
    "\n",
    "def interpret_models(df):\n",
    "\n",
    "    client = boto3.session.Session().client(\"sagemaker-runtime\", region_name='us-east-1')\n",
    "\n",
    "    all_outputs = []\n",
    "    batch_size = 1\n",
    "    for i in tqdm(range(0, df.shape[0], batch_size)):\n",
    "        inputs = df.iloc[i : i + batch_size][['excerpt']]  \n",
    "        inputs['return_type'] = \"default_analyis\" \n",
    "        inputs['analyis_framework_id'] = 'all'\n",
    "        \n",
    "        #kw for interpretability\n",
    "        inputs['interpretability'] = True\n",
    "        #minimum ratio between proba and threshold to perform interpretability\n",
    "        inputs['ratio_interpreted_labels'] = 0.5\n",
    "        inputs['attribution_type'] = 'Layer DeepLift'\n",
    "\n",
    "        # predictions\n",
    "        inputs['return_prediction_labels'] = False\n",
    "\n",
    "        #kw for embeddings\n",
    "        inputs['output_backbone_embeddings'] = False\n",
    "        inputs['pooling_type'] = \"['cls', 'mean_pooling']\"\n",
    "        inputs['finetuned_task'] = \"['first_level_tags', 'secondary_tags', 'subpillars']\"\n",
    "        inputs['embeddings_return_type'] = 'array'\n",
    "        \n",
    "        backbone_inputs_json = inputs.to_json(orient=\"split\")\n",
    "\n",
    "        response = client.invoke_endpoint(\n",
    "            EndpointName='tmp-hum',\n",
    "            Body=backbone_inputs_json,\n",
    "            ContentType=\"application/json; format=pandas-split\",\n",
    "        )\n",
    "        output = response[\"Body\"].read().decode(\"ascii\")\n",
    "\n",
    "        #output = literal_eval(output)\n",
    "        \n",
    "        all_outputs.append(output)\n",
    "\n",
    "    return all_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df['probability'] = get_probas(gender_df)\n",
    "minorities_df['probability'] = get_probas(minorities_df)\n",
    "\n",
    "#gender_df.to_csv('final_data/gender_df_with_outputs.csv.gz', index=None, compression='gzip')\n",
    "#minorities_df.to_csv('final_data/minorities_df_with_outputs.csv.gz', index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>kw</th>\n",
       "      <th>type</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2276.0</td>\n",
       "      <td>Another attack in February 2017 hit a farm, wo...</td>\n",
       "      <td>['girl']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2276.0</td>\n",
       "      <td>Another attack in February 2017 hit a farm, wo...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2276.0</td>\n",
       "      <td>Another attack in February 2017 hit a farm, wo...</td>\n",
       "      <td>['boys']</td>\n",
       "      <td>original</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2576.0</td>\n",
       "      <td>In Benghazi and Sirte, 78,868 children (39,667...</td>\n",
       "      <td>['male']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2576.0</td>\n",
       "      <td>In Benghazi and Sirte, 78,868 children (39,667...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>498062.0</td>\n",
       "      <td>In Argentina it is almost a routine procedure ...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>498062.0</td>\n",
       "      <td>In Argentina it is almost a routine procedure ...</td>\n",
       "      <td>['women']</td>\n",
       "      <td>original</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>498072.0</td>\n",
       "      <td>\"The fucking father, I can not go to sleep,\" w...</td>\n",
       "      <td>['father']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>498072.0</td>\n",
       "      <td>\"The fucking person, I can not go to sleep,\" w...</td>\n",
       "      <td>['person']</td>\n",
       "      <td>augmented</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>498072.0</td>\n",
       "      <td>\"The fucking mother, I can not go to sleep,\" w...</td>\n",
       "      <td>['mother']</td>\n",
       "      <td>original</td>\n",
       "      <td>{'first_level_tags-&gt;pillars_1d-&gt;Casualties': 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3261 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entry_id                                            excerpt          kw  \\\n",
       "0       2276.0  Another attack in February 2017 hit a farm, wo...    ['girl']   \n",
       "1       2276.0  Another attack in February 2017 hit a farm, wo...  ['person']   \n",
       "2       2276.0  Another attack in February 2017 hit a farm, wo...    ['boys']   \n",
       "3       2576.0  In Benghazi and Sirte, 78,868 children (39,667...    ['male']   \n",
       "4       2576.0  In Benghazi and Sirte, 78,868 children (39,667...  ['person']   \n",
       "...        ...                                                ...         ...   \n",
       "3256  498062.0  In Argentina it is almost a routine procedure ...  ['person']   \n",
       "3257  498062.0  In Argentina it is almost a routine procedure ...   ['women']   \n",
       "3258  498072.0  \"The fucking father, I can not go to sleep,\" w...  ['father']   \n",
       "3259  498072.0  \"The fucking person, I can not go to sleep,\" w...  ['person']   \n",
       "3260  498072.0  \"The fucking mother, I can not go to sleep,\" w...  ['mother']   \n",
       "\n",
       "           type                                        probability  \n",
       "0     augmented  {'first_level_tags->pillars_1d->Casualties': 1...  \n",
       "1     augmented  {'first_level_tags->pillars_1d->Casualties': 1...  \n",
       "2      original  {'first_level_tags->pillars_1d->Casualties': 1...  \n",
       "3     augmented  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "4     augmented  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "...         ...                                                ...  \n",
       "3256  augmented  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "3257   original  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "3258  augmented  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "3259  augmented  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "3260   original  {'first_level_tags->pillars_1d->Casualties': 0...  \n",
       "\n",
       "[3261 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate interpretability results with DEEPLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17199/17199 [2:43:12<00:00,  1.76it/s]  \n"
     ]
    }
   ],
   "source": [
    "interpret_results = interpret_models(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['interpretability_col'] = interpret_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.to_csv('final_data/test_df_interpretability_DEEPLift.csv.gz', index=None, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('deepl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a5ddf8e25d962f331e8059973cfd97c5aef9d0ccfdd243943e9f1f512e91043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
